name: 'ğŸ—‚ï¸ Cleanup Caches'

# This workflow cleans up GitHub Actions caches to free up storage
# Trigger manually when you hit storage limits

on:
  workflow_dispatch:
    inputs:
      days:
        description: 'Delete caches older than this many days'
        required: false
        default: '7'
        type: string
      dry_run:
        description: 'Show what would be deleted without actually deleting'
        required: false
        default: 'false'
        type: boolean

jobs:
  cleanup:
    name: 'ğŸ—‚ï¸ Cleanup Caches'
    runs-on: ubuntu-latest
    
    steps:
      - name: 'ğŸ“¥ Checkout repository'
        uses: actions/checkout@v4
        
      - name: 'ğŸ Setup Python'
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: 'ğŸ“¦ Install requests'
        run: pip install requests
        
      - name: 'ğŸ—‚ï¸ Clean up old caches'
        run: |
          echo "ğŸ§¹ Cleaning up caches older than ${{ github.event.inputs.days }} days..."
          
          # Get caches
          CACHES=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/caches")
          
          # Parse and filter caches
          echo "$CACHES" | python3 -c "
          import json
          import sys
          from datetime import datetime, timedelta
          
          data = json.load(sys.stdin)
          cutoff_date = datetime.now() - timedelta(days=${{ github.event.inputs.days }})
          
          old_caches = []
          for cache in data.get('actions_caches', []):
              cache_date = datetime.fromisoformat(cache['created_at'].replace('Z', '+00:00'))
              if cache_date < cutoff_date.replace(tzinfo=cache_date.tzinfo):
                  old_caches.append(cache)
          
          print(f'Found {len(old_caches)} caches older than ${{ github.event.inputs.days }} days:')
          for cache in old_caches:
              size_mb = cache['size_in_bytes'] / (1024 * 1024)
              print(f'  - {cache[\"key\"]} ({size_mb:.1f} MB) from {cache[\"ref\"]}')
          
          if ${{ github.event.inputs.dry_run }} == 'true':
              print('\\nğŸ” Dry run mode - no caches will be deleted')
          else:
              print('\\nğŸ—‘ï¸  Deleting old caches...')
              for cache in old_caches:
                  response = requests.delete(
                      'https://api.github.com/repos/${{ github.repository }}/actions/caches',
                      headers={'Authorization': f'token ${{ secrets.GITHUB_TOKEN }}'},
                      json={'key': cache['key'], 'ref': cache.get('ref')}
                  )
                  if response.status_code == 200:
                      print(f'  âœ… Deleted {cache[\"key\"]}')
                  else:
                      print(f'  âŒ Failed to delete {cache[\"key\"]}: {response.status_code}')
          "
          
      - name: 'ğŸ“Š Show current cache usage'
        run: |
          echo "ğŸ“Š Current cache usage:"
          curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/caches" | \
            python3 -c "
          import json
          import sys
          
          data = json.load(sys.stdin)
          total_size = sum(cache['size_in_bytes'] for cache in data.get('actions_caches', []))
          total_size_mb = total_size / (1024 * 1024)
          
          print(f'Total caches: {len(data.get(\"actions_caches\", []))}')
          print(f'Total size: {total_size_mb:.1f} MB')
          " 