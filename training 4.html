<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="keywords" content="open-source, embedded systems, machine learning, tinyML">

<title>MACHINE LEARNING SYSTEMS - 8&nbsp; AI Training</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./efficient_ai.html" rel="next">
<link href="./frameworks.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://hypothes.is/embed.js" async=""></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">MACHINE LEARNING SYSTEMS</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto tools-wide">
    <a href="https://github.com/harvard-edge/cs249r_book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="./MACHINE-LEARNING-SYSTEMS.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="./MACHINE-LEARNING-SYSTEMS.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./training.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">AI Training</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./front.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FRONT MATTER</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dedication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedication</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contributors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./copyright.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">MAIN</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./embedded_sys.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Embedded Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./embedded_ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Embedded AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AI Workflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">AI Frameworks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">AI Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Efficient AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model Optimizations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Acceleration</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Benchmarking AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">On-Device Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Embedded AIOps</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Privacy and Security</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Responsible AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generative_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Generative AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Sustainable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Robust AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">EXERCISES</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./niclav_sys.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup Nicla Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CV on Nicla Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./object_detection_fomo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Audio Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kws_nicla.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP - Spectral Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./motion_classify_ad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Tools</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zoo_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zoo_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Model Zoo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learning_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./community.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Communities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./case_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Case Studies</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">8.1</span> Introduction</a></li>
  <li><a href="#mathematics-behind-neural-networks-and-deep-learning" id="toc-mathematics-behind-neural-networks-and-deep-learning" class="nav-link" data-scroll-target="#mathematics-behind-neural-networks-and-deep-learning"><span class="header-section-number">8.2</span> Mathematics behind Neural Networks and Deep Learning</a>
  <ul class="collapse">
  <li><a href="#neural-network-notation" id="toc-neural-network-notation" class="nav-link" data-scroll-target="#neural-network-notation"><span class="header-section-number">8.2.1</span> Neural Network Notation</a></li>
  <li><a href="#loss-function-as-a-measure-of-goodness-of-fit-against-training-data" id="toc-loss-function-as-a-measure-of-goodness-of-fit-against-training-data" class="nav-link" data-scroll-target="#loss-function-as-a-measure-of-goodness-of-fit-against-training-data"><span class="header-section-number">8.2.2</span> Loss Function as a Measure of Goodness of Fit against Training Data</a></li>
  <li><a href="#training-neural-networks-with-gradient-descent" id="toc-training-neural-networks-with-gradient-descent" class="nav-link" data-scroll-target="#training-neural-networks-with-gradient-descent"><span class="header-section-number">8.2.3</span> Training Neural Networks with Gradient Descent</a></li>
  <li><a href="#backpropagation" id="toc-backpropagation" class="nav-link" data-scroll-target="#backpropagation"><span class="header-section-number">8.2.4</span> Backpropagation</a></li>
  </ul></li>
  <li><a href="#optimization-algorithms" id="toc-optimization-algorithms" class="nav-link" data-scroll-target="#optimization-algorithms"><span class="header-section-number">8.3</span> Optimization Algorithms</a></li>
  <li><a href="#hyperparameter-tuning" id="toc-hyperparameter-tuning" class="nav-link" data-scroll-target="#hyperparameter-tuning"><span class="header-section-number">8.4</span> Hyperparameter Tuning</a></li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization"><span class="header-section-number">8.5</span> Regularization</a></li>
  <li><a href="#weight-initialization" id="toc-weight-initialization" class="nav-link" data-scroll-target="#weight-initialization"><span class="header-section-number">8.6</span> Weight Initialization</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions"><span class="header-section-number">8.7</span> Activation Functions</a></li>
  <li><a href="#training-data" id="toc-training-data" class="nav-link" data-scroll-target="#training-data"><span class="header-section-number">8.8</span> Training Data</a>
  <ul class="collapse">
  <li><a href="#splits" id="toc-splits" class="nav-link" data-scroll-target="#splits"><span class="header-section-number">8.8.1</span> Splits</a></li>
  <li><a href="#pitfalls-and-mistakes" id="toc-pitfalls-and-mistakes" class="nav-link" data-scroll-target="#pitfalls-and-mistakes"><span class="header-section-number">8.8.2</span> Pitfalls and Mistakes</a></li>
  </ul></li>
  <li><a href="#system-bottlenecks" id="toc-system-bottlenecks" class="nav-link" data-scroll-target="#system-bottlenecks"><span class="header-section-number">8.9</span> System Bottlenecks</a>
  <ul class="collapse">
  <li><a href="#runtime-complexity-of-matrix-multiplication-in-neural-networks" id="toc-runtime-complexity-of-matrix-multiplication-in-neural-networks" class="nav-link" data-scroll-target="#runtime-complexity-of-matrix-multiplication-in-neural-networks"><span class="header-section-number">8.9.1</span> Runtime Complexity of Matrix Multiplication in Neural Networks</a></li>
  <li><a href="#compute-vs-memory-bottleneck-in-neural-network-training-and-inference" id="toc-compute-vs-memory-bottleneck-in-neural-network-training-and-inference" class="nav-link" data-scroll-target="#compute-vs-memory-bottleneck-in-neural-network-training-and-inference"><span class="header-section-number">8.9.2</span> Compute vs Memory Bottleneck in Neural Network Training and Inference</a></li>
  <li><a href="#optimizing-matrix-multiplication" id="toc-optimizing-matrix-multiplication" class="nav-link" data-scroll-target="#optimizing-matrix-multiplication"><span class="header-section-number">8.9.3</span> Optimizing Matrix Multiplication</a></li>
  </ul></li>
  <li><a href="#parallelizing-ai-training" id="toc-parallelizing-ai-training" class="nav-link" data-scroll-target="#parallelizing-ai-training"><span class="header-section-number">8.10</span> Parallelizing AI training</a>
  <ul class="collapse">
  <li><a href="#data-parallel" id="toc-data-parallel" class="nav-link" data-scroll-target="#data-parallel"><span class="header-section-number">8.10.1</span> Data Parallel</a></li>
  <li><a href="#model-parallel" id="toc-model-parallel" class="nav-link" data-scroll-target="#model-parallel"><span class="header-section-number">8.10.2</span> Model Parallel</a></li>
  </ul></li>
  <li><a href="#efficient-and-distributed-training" id="toc-efficient-and-distributed-training" class="nav-link" data-scroll-target="#efficient-and-distributed-training"><span class="header-section-number">8.11</span> Efficient and Distributed Training</a></li>
  <li><a href="#debugging-and-profiling" id="toc-debugging-and-profiling" class="nav-link" data-scroll-target="#debugging-and-profiling"><span class="header-section-number">8.12</span> Debugging and Profiling</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/harvard-edge/cs249r_book/edit/main/training.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/harvard-edge/cs249r_book/blob/main/training.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">AI Training</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Understand the mathematics behind deep learning (i.e: backpropagation, gradient descent)</li>
<li>Identify the key operations and system bottlenecks in AI training</li>
<li>Learn how CPUs and GPUs accelerate AI inference and training by speeding up key operations</li>
</ul>
</div>
</div>
<section id="introduction" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">8.1</span> Introduction</h2>
<p>Deep learning has revolutionized the fields of machine learning and artificial intelligence, enabling computers to learn complex patterns and make intelligent decisions. At the heart of the deep learning revolution is the neural network, which, as discussed in section 3 “Deep Learning Primer”, is a cornerstone in some of these advancements.</p>
<p>Briefly, neural networks are computing systems loosely inspired by how the brain works. They learn to perform tasks like image recognition, language translation, and more by analyzing examples, rather than being explicitly programmed with rules.</p>
<p>At a high level, neural networks are made up of simple functions (“neurons”) layered on top of each other. Each layer takes in some data, performs a calculation on it, and passes it to the next layer. For example, in an image recognition network, the input layer may take in pixel values. The next layers detect simple shapes like edges, then larger shapes like noses or eyes, and so on. The final output layer classifies the image as a whole.</p>
<p>The “network” in a neural network refers to how these neurons are connected. Each neuron is connected to many others in the layers above and below it. The neurons have numeric weights associated with them, kind of like the synaptic strengths in a brain neuron. The network is trained by adjusting these weights. Initially the weights are set randomly. An input is fed in, and the output is compared to the desired result using a loss function. This loss function outputs a number indicating how far off the network’s prediction was. The weights are then tweaked slightly to reduce the loss. This process is repeated with many training examples until the network reliably minimizes the loss, indicating it has learned the patterns in the data. This training technique, called backpropagation, allows neural networks to learn without explicit programming. Once trained, the network can apply what it’s learned to new unseen data.</p>
<p>In this chapter, we will explore the mathematics behind neural networks, specifically how neural networks work and how to train them, then we dive into some of the key system challenges that underpin these models, and finally explore how to leverage CPUs and GPUs to accelerate them.</p>
</section>
<section id="mathematics-behind-neural-networks-and-deep-learning" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="mathematics-behind-neural-networks-and-deep-learning"><span class="header-section-number">8.2</span> Mathematics behind Neural Networks and Deep Learning</h2>
<p>At a high level, neural networks are mathematical models that consist of alternating linear and nonlinear operations, parameterized by a set of “weights” that are trained to minimize some loss function. This loss function is a measure of how good our model is with respect to fitting our training data, and it produces a numerical value (i.e: the “loss”) when evaluated on our model against the training data. Fundamentally, training neural networks involve evaluating the loss function to get a measure of how good our model is, then continuously tweaking the weights of our model so that the loss decreases, which ultimately optimizes the model to fit our training data.</p>
<section id="neural-network-notation" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="neural-network-notation"><span class="header-section-number">8.2.1</span> Neural Network Notation</h3>
<p>Diving into the details, the core of a neural network as introduced in section 3 can be viewed as a sequence of alternating linear and nonlinear operations: <span class="math display">\[
L_i = F_{i}(W_i \times L_{i-1})
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Convolutions are also linear operators, and can be cast as a matrix multiplication.</p>
</div>
</div>
</div>
<p>where <span class="math inline">\(L_{0}\)</span> is a vector input to the neural network (i.e: an image that we want the neural network to classify, or some other data that the neural network operates on), <span class="math inline">\(L_{n}\)</span> (where <span class="math inline">\(n\)</span> is the number of layers of the network) is the vector output of the neural network (i.e: a vector of size 10 in the case of classifying pictures of handwritten digits), <span class="math inline">\(W_i\)</span>s are the weights of the neural network that are tweaked at training time to fit our data, and <span class="math inline">\(F_{i}\)</span> is that layer’s nonlinear activation function (i.e: ReLU, softmax, etc). As defined, the intermediate output of the neural network is a vector of real-valued numbers with dimensions:</p>
<p><span class="math display">\[
L_i \in \mathbb{R}^{d_{i}}
\]</span></p>
<p>where <span class="math inline">\(d_{i}\)</span> is the number of neurons at layer <span class="math inline">\(i\)</span>; in the case of the first layer <span class="math inline">\(i=0\)</span>, <span class="math inline">\(d_{i}\)</span> is the dimension of the input data, and in the last layer <span class="math inline">\(i=n\)</span>, <span class="math inline">\(d_{n}\)</span> is the dimension of the output label, and anything in between can be set arbitrarily and may be viewed as the “architecture” of the neural network (i.e: dimensionality of the intermediate layers). The weights, which determine how each layer of the neural network interacts with each other, therefore are matrices of real numbers with shape</p>
<p><span class="math display">\[
W_i \in \mathbb{R}^{d_{i} \times d_{i-1}}
\]</span></p>
<p>Our neural network, as defined, performs a sequence of linear and nonlinear operations on the input data (<span class="math inline">\(L_{0}\)</span>), to optain predictions (<span class="math inline">\(L_{n}\)</span>) which hopefully is a good answer to what we want the neural network to do on the input (i.e: classify if the input image is a cat or not). Our neural network may then be represented succinctly as a function <span class="math inline">\(N\)</span> which takes in an input <span class="math inline">\(x \in \mathbb{R}^{d_0}\)</span> parameterized by <span class="math inline">\(W_1, ..., W_n\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
N(x; W_1, ... W_n) &amp;= \text{Let } L_0 = x, \text{ then output } L_n
\end{align*}
\]</span></p>
<p>Next we will see how to evaluate this neural network against training data by introducing a loss function.</p>
</section>
<section id="loss-function-as-a-measure-of-goodness-of-fit-against-training-data" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="loss-function-as-a-measure-of-goodness-of-fit-against-training-data"><span class="header-section-number">8.2.2</span> Loss Function as a Measure of Goodness of Fit against Training Data</h3>
<p>After defining our neural network, we are given some training data, which is a set of points <span class="math inline">\({(x_j, y_j)}\)</span> for <span class="math inline">\(j=1..M\)</span>, and we want to evaluate how good our neural network is on fitting this data. To do this, we introduce a “loss function”, which is a function that takes the output of the neural network on a particular datapoint (<span class="math inline">\(N(x_j; W_1, ..., W_n)\)</span>), and compares it against the “label” of that particular datapoint (the corresponding <span class="math inline">\(y_j\)</span>), and outputs a single numerical scalar (i.e: one real number) that represents how “good” the neural network fit that particular data point; the final measure of how good the neural network is on the entire dataset is therefore just the average of the losses across all datapoints.</p>
<p>There are many different types of loss functions, for example, in the case of image classification, we might use the cross-entropy loss function, which tells us how good two vectors that represent classification predictions compare (i.e: if our prediction predicts that an image is more likely a dog, but the label says it is a cat, it will return a high “loss” indicating a bad fit).</p>
<p>Mathematically, this loss function is a function which takes in two real-valued vectors of the shape of the label, and outputs a single numerical scalar <span class="math display">\[
L: \mathbb{R}^{d_{n}} \times \mathbb{R}^{d_{n}} \longrightarrow \mathbb{R}
\]</span></p>
<p>and the loss across the entire dataset can be written as the average loss across all datapoints in the training data</p>
<blockquote class="blockquote">
<p>Loss Function for Optimizing Neural Network Model on a Dataset <span class="math display">\[
L_{full} = \frac{1}{M} \sum_{j=1}^{M} L(N(x_j; W_1,...W_n), y_j)
\]</span></p>
</blockquote>
</section>
<section id="training-neural-networks-with-gradient-descent" class="level3" data-number="8.2.3">
<h3 data-number="8.2.3" class="anchored" data-anchor-id="training-neural-networks-with-gradient-descent"><span class="header-section-number">8.2.3</span> Training Neural Networks with Gradient Descent</h3>
<p>Now that we have a measure of how good our network fits the training data, we can optimize the weights of the neural network to minimize this loss. At a high level, we tweak the parameters of the real-valued matrices <span class="math inline">\(W_i\)</span>s so that the loss function <span class="math inline">\(L_{full}\)</span> is minimized. Overall, our mathematical objective is</p>
<blockquote class="blockquote">
<p>Neural Network Training Objective <span class="math display">\[
min_{W_1, ..., W_n} L_{full}
\]</span> <span class="math display">\[
= min_{W_1, ..., W_n} \frac{1}{M} \sum_{j=1}^{M} L(N(x_j; W_1,...W_n), y_j)
\]</span></p>
</blockquote>
<p>So how do we optimize this objective? Recall from calculus that minimizing a function can be done by taking the derivative of the function with respect to the input parameters and tweaking the parameters in the direction of the gradient. This technique is called “gradient descent” and concretely involves calculating the derivative of the loss function <span class="math inline">\(L_{full}\)</span> with respect to <span class="math inline">\(W_1, ..., W_n\)</span> to obtain a gradient for these parameters to take a step in, then updating these parameters in the direction of the gradient. Thus, we can train our neural network using gradient descent which repeatedly applies the update rule</p>
<blockquote class="blockquote">
<p>Gradient Descent Update Rule <span class="math display">\[
W_i := W_i - \lambda \frac{\partial L_{full}}{\partial W_i} \mbox{ for } i=1..n
\]</span></p>
</blockquote>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>In practice, the gradient is computed over a minibatch of datapoints, to improve computational efficiency. This is called stochastic gradient descent or batch gradient descent.</p>
</div>
</div>
</div>
<p>where <span class="math inline">\(\lambda\)</span> is the stepsize or learning rate of our tweaks. In training our neural network, we repeatedly perform the step above until convergence, or when the loss no longer decreases. This prior approach is known as “full gradient descent” since we are computing the derivative with respect to the entire training data, and only then taking a single gradient step; a more efficient approach is to calculate the gradient with respect to just a random “batch” of datapoints and then taking a step, a process known as “batch gradient descent” or “stochastic gradient descent”, which is more efficient since now we are taking many more steps per pass of the entire training data. Next we will cover the mathematics behind computing the gradient of the loss function with respect to the <span class="math inline">\(W_i\)</span>s, a process known as “backpropagation”.</p>
</section>
<section id="backpropagation" class="level3" data-number="8.2.4">
<h3 data-number="8.2.4" class="anchored" data-anchor-id="backpropagation"><span class="header-section-number">8.2.4</span> Backpropagation</h3>
<p>Training neural networks involve repeated applications of the gradient descent algorithm, which involves computing the derivative of the loss function with respect to the <span class="math inline">\(W_i\)</span>s. How do we compute the derivative of the loss with respect to the <span class="math inline">\(W_i\)</span>s given that the <span class="math inline">\(W_i\)</span>s are nested functions of each other in a deep neural network? The trick is to leverage the “chain rule”: we can compute the derivative of the loss with respect to the <span class="math inline">\(W_i\)</span>s by repeatedly applying the chain rule, in a complete process known as “backpropagation”. Specifically, we can calculate the gradients by computing the derivative of the loss with respect to the outputs of the last layer, then progressively use this to compute the derivative of the loss with respect to each prior layer, all the way to the input layer. This process starts from the end of the network (the layer closest to the output) and progresses backwards, and hence gets its name “backpropagation”.</p>
<p>Let’s break this down. We can compute the derivative of the loss with respect to the <em>the outputs of each layer of the neural network</em> by using repeated applications of the chain rule</p>
<p><span class="math display">\[
\frac{\partial L_{full}}{L_{n}} = \frac{\partial \frac{1}{M} \sum_{j=1}^{M} L(N(x_j; W_1, ..., W_n), y_j)}{\partial L_{n}}
\]</span></p>
<p><span class="math display">\[
\frac{\partial L_{full}}{\partial L_{n-1}} = \frac{\partial L_{full}}{\partial L_{n}} \frac{\partial L_{n}}{\partial L_{n-1}}
\]</span></p>
<p>or more generally</p>
<p><span class="math display">\[
\frac{\partial L_{full}}{L_{i}} = \frac{\partial L_{full}}{\partial L_{n}} \frac{\partial L_{n}}{\partial L_{n-1}} \frac{\partial L_{n-1}}{\partial L_{n-2}} ...  \frac{\partial L_{i+1}}{\partial L_{i}}
\]</span></p>
<p>After computing the derivative of the loss with respect to the <em>output of each layer</em>, we can easily obtain the derivative of the loss with respect to the <em>parameters</em>, again using the chain rule:</p>
<p><span class="math display">\[
\frac{\partial L_{full}}{W_{i}} = \frac{\partial L_{full}}{L_{i}} \frac{L_{i}}{W_{i}}
\]</span></p>
<p>And this is ultimately how the derivatives of the layers’ weights are computed using backpropagation! What does this concretely look like in a specific example? Below we walk through a specific example on a simple 2 layer neural network, on a regression task using a MSE loss function, with 100-dimensional inputs and a 30-dimensional hidden layer:</p>
<blockquote class="blockquote">
<p>Example of Backpropagation<br>
Suppose we have a two-layer neural network <span class="math display">\[
L_1 = ReLU(W_1 \times L_{0})
\]</span> <span class="math display">\[
L_2 = ReLU(W_2 \times L_{1})
\]</span> <span class="math display">\[
NN(x) = \mbox{Let } L_{0} = x \mbox{ then output } L_2
\]</span> where <span class="math inline">\(W_1 \in \mathbb{R}^{30 \times 100}\)</span> and <span class="math inline">\(W_2 \in \mathbb{R}^{1 \times 30}\)</span>. Furthermore suppose we use the MSE loss function: <span class="math display">\[
L(x, y) = (x-y)^2
\]</span> We wish to compute <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial W_i} \mbox{ for } i=1,2
\]</span> We start by computing the gradient with respect to the final output: <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial L_2} = \frac{\partial (L_2 - y)^2}{\partial L_2} = 2(L_2 - y)
\]</span> With respect to the output <span class="math inline">\(L_1\)</span> <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial L_1} = \frac{\partial L(NN(x), y)}{\partial L_2} \frac{\partial L_2}{\partial L_1}
\]</span> <span class="math display">\[
= [2(L_2 - y)] \times \frac{\partial ReLU(W_2 \times L_1)}{\partial L_1} = [2(L_2 - y)] \times W_2^T ReLU'(W_2 \times L_1)
\]</span> where <span class="math display">\[
ReLU'(x) = \begin{cases}
0 &amp; x\leq 0 \\
1 &amp; x &gt; 0
\end{cases}
\]</span> Then we can compute the gradients with respect to the weights <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial W_2} = \frac{\partial L(NN(x), y)}{\partial L_2} \frac{\partial L_2}{\partial W_2} = [2(L_2 - y)] \times ReLU'(W_2 \times L_1) L_1^T
\]</span> <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial W_1} = \frac{\partial L(NN(x), y)}{\partial L_1} \frac{\partial L_1}{\partial W_1} =  [(2(L_2 - y)) \times W_2^T ReLU'(W_2 \times L_1)] \times ReLU'(W_1 \times L_0)
\]</span> IMPORTANT: QUICKLY WRITTEN SO THIS IS NOT REALLY CORRECT THERE IS ACTUALLY A BUG HERE, REDO!</p>
</blockquote>
</section>
</section>
<section id="optimization-algorithms" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="optimization-algorithms"><span class="header-section-number">8.3</span> Optimization Algorithms</h2>
<p>Stochastic Gradient Descent involves updating the model’s parameters by considering the gradient of the loss function with respect to the parameters for each training example. While the basic concept of SGD is straightforward, finding the optimal set of parameters that minimizes the overall loss across the entire dataset may be difficult as the loss landscape is nonconvex.</p>
<p>To address the complexities of training neural networks, various optimization algorithms have been developed. These optimizers are designed to enhance the efficiency and convergence speed of the training process. They achieve this by adjusting the learning rates, incorporating momentum, and implementing adaptive strategies, among other techniques.</p>
<p>Some optimizers include:</p>
<ul>
<li>ADAM</li>
<li>AdaGrad</li>
<li>RMSProp</li>
<li>Momentum SGD</li>
</ul>
<p>Generally, from our experience Adam is the most popular optimizer and usually outperforms SGD in terms of training neural networks.</p>
</section>
<section id="hyperparameter-tuning" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="hyperparameter-tuning"><span class="header-section-number">8.4</span> Hyperparameter Tuning</h2>
<p>The performance of the neural network model depends on a set of crucial configurations known as hyperparameters. These hyperparameters, which are external to the model and cannot be learned during training, play a pivotal role in determining the model’s effectiveness, generalization capabilities, and overall performance on diverse datasets. These hyperparameters include learning rate, batch size, regularization strengths, and network architectures.</p>
<p>Several techniques are employed to conduct hyperparameter search, ranging from manual tuning by domain experts to automated methods such as grid search, random search, and more sophisticated optimization algorithms like Bayesian optimization.</p>
</section>
<section id="regularization" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="regularization"><span class="header-section-number">8.5</span> Regularization</h2>
<p>Neural networks are optimized to fit the training data, however, we would like the network to generalize and perform well to unseen data.</p>
<p>Regularization stands as a key technique in achieving this. It serves as a tool in preventing overfitting, a common pitfall where a model becomes overly complex and tailored to the training data, losing its ability to generalize.</p>
<p>Common regularization techniques include</p>
<ul>
<li><p>L1 and L2 Regularization</p>
<p>These methods add a penalty term based on the magnitudes of the model’s parameters to the loss function. L1 regularization encourages sparsity by introducing a penalty proportional to the absolute values of the parameters, while L2 regularization penalizes the square of the parameter values, promoting smaller weights.</p></li>
<li><p>Dropout</p>
<p>A technique commonly applied to neural networks, dropout involves randomly “dropping out” a fraction of neurons during each training iteration. This helps prevent co-adaptation of neurons, promoting more robust and generalized learning.</p></li>
<li><p>Early Stopping</p>
<p>By monitoring the model’s performance on a validation set during training, early stopping interrupts the training process when the model’s performance ceases to improve. This prevents the model from becoming overly specialized to the training data.</p></li>
</ul>
</section>
<section id="weight-initialization" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="weight-initialization"><span class="header-section-number">8.6</span> Weight Initialization</h2>
<p>Neural Networks are trained starting with weights initialized randomly, but how the weights are initialized may have a considerable impact on training convergence and feasibility. Proper weight initialization helps in overcoming issues like vanishing or exploding gradients, which can hinder the learning process. Here are some commonly used neural network weight initialization techniques:</p>
<p>as orthogonal matrices. This helps in preserving the gradients during backpropagation and can be particularly useful in recurrent neural networks (RNNs). Uniform and Normal Initialization:</p>
<p>Weights are initialized with random values drawn from a uniform or normal distribution. The choice between uniform and normal depends on the specific requirements of the model and the activation functions used. Choosing the right initialization method depends on the architecture of the neural network, the activation functions, and the specific problem being solved. Experimentation with different techniques is often necessary to find the most suitable initialization for a given scenario.</p>
<ul>
<li><p>Xavier/Glorot Initialization</p>
<p>Proposed by Xavier Glorot and Yoshua Bengio, this initialization is designed to work well with activation functions like tanh or logistic sigmoid. It initializes weights with random values drawn from a distribution with mean 0 and variance 2 / (number of input units + number of output units).</p></li>
<li><p>He Initialization</p>
<p>Proposed by Kaiming He et al., this initialization is tailored for ReLU (Rectified Linear Unit) activation functions. It initializes weights with random values drawn from a distribution with mean 0 and variance 2 / number of input units. This helps to mitigate the vanishing gradient problem often associated with deep networks.</p></li>
</ul>
</section>
<section id="activation-functions" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="activation-functions"><span class="header-section-number">8.7</span> Activation Functions</h2>
<p>Activation functions play a critical role in neural networks by introducing non-linearities into the model. These non-linearities enable neural networks to learn complex relationships and patterns in data, making them capable of solving a wide range of problems. Here are some commonly used activation functions:</p>
<ul>
<li><p>Rectified Linear Unit (ReLU):</p>
<p>ReLU is a popular activation function that returns zero for negative input values and passes positive input values unchanged. It is computationally efficient and has been widely used in deep learning models.</p></li>
<li><p>Sigmoid Function</p>
<p>The sigmoid function, also known as the logistic function, squashes input values between 0 and 1. It is often used in the output layer of binary classification models, where the goal is to produce probabilities.</p></li>
<li><p>Hyperbolic Tangent Function (tanh):</p>
<p>The hyperbolic tangent function is similar to the sigmoid but squashes input values between -1 and 1. It is often used in hidden layers of neural networks, especially when zero-centered outputs are desired.</p></li>
</ul>
</section>
<section id="training-data" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="training-data"><span class="header-section-number">8.8</span> Training Data</h2>
<section id="splits" class="level3" data-number="8.8.1">
<h3 data-number="8.8.1" class="anchored" data-anchor-id="splits"><span class="header-section-number">8.8.1</span> Splits</h3>
<p>When training machine learning models, it is important to properly split the available data into training, validation and test sets. This data splitting strategy is crucial for evaluating model performance and preventing issues like overfitting.</p>
<section id="training-set" class="level4">
<h4 class="anchored" data-anchor-id="training-set">Training Set</h4>
<p>The training set is used to actually train the model. It is the largest subset consisting of typically 60-80% of the total data. The model sees and learns from the training data in order to make predictions. A sufficiently large and representative training set is required for the model to effectively learn the underlying patterns.</p>
</section>
<section id="validation-set" class="level4">
<h4 class="anchored" data-anchor-id="validation-set">Validation Set</h4>
<p>The validation set is used to evaluate the model during training, usually after each epoch. Typically 20% of the data is allocated for the validation set. The model does not learn or update its parameters based on the validation data. It is used to tune hyperparameters and make other tweaks to improve training. Monitoring metrics like loss and accuracy on the validation set prevents overfitting on just the training data.</p>
</section>
<section id="test-set" class="level4">
<h4 class="anchored" data-anchor-id="test-set">Test Set</h4>
<p>The test set acts as a completely unseen dataset that the model did not see during training. It is used to provide an unbiased evaluation of the final trained model. Typically 20% of the data is reserved for testing. Maintaining a hold-out test set is vital for obtaining an accurate estimate of how the trained model would perform on real world unseen data. Data leakage from the test set must be avoided at all costs.</p>
<p>The relative proportions of the training, validation and test sets can vary based on data size and application. But following the general guideline of a 60/20/20 split is a good starting point. Careful splitting of data ensures models are properly trained, tuned and evaluated to achieve the best performance.</p>
</section>
</section>
<section id="pitfalls-and-mistakes" class="level3" data-number="8.8.2">
<h3 data-number="8.8.2" class="anchored" data-anchor-id="pitfalls-and-mistakes"><span class="header-section-number">8.8.2</span> Pitfalls and Mistakes</h3>
<section id="insufficient-training-data" class="level4">
<h4 class="anchored" data-anchor-id="insufficient-training-data">Insufficient Training Data</h4>
<p>Allocating too little data to the training set is a common mistake when splitting data that can severely impact model performance. If the training set is too small, the model will not have enough samples to effectively learn the true underlying patterns in the data. This leads to high variance and causes the model to fail to generalize well to new data.</p>
<p>For example, if you are training an image classification model to recognize handwritten digits, providing only 10 or 20 images per digit class would be completely inadequate. The model would struggle to capture the wide variances in writing styles, rotations, stroke widths and other variations with so few examples.</p>
<p>As a rule of thumb, the training set size should be at least in the hundreds or thousands of examples for most machine learning algorithms to work effectively. For deep neural networks, especially those using convolutional layers, the training set often needs to be in the tens or hundreds of thousands due to the large number of parameters.</p>
<p>Insufficient training data typically manifests in symptoms like high error rates on validation/test sets, low model accuracy, high variance, and overfitting on the small training set samples. Collecting more quality training data is the solution. Data augmentation techniques can also help virtually increase training data size for images, audio etc.</p>
<p>Carefully factoring in the model complexity and problem difficulty when allocating training samples is important to ensure sufficient data is available for the model to learn successfully. Following guidelines on minimum training set sizes for different algorithms is also recommended. Insufficient training data is a fundamental issue that will undermine the overall success of any machine learning application.</p>
</section>
<section id="data-leakage-between-sets" class="level4">
<h4 class="anchored" data-anchor-id="data-leakage-between-sets">Data Leakage Between Sets</h4>
<p>Data leakage refers to the unintentional transfer of information between the training, validation, and test sets. This violates the fundamental assumption that the splits are completely separated. Data leakage leads to seriously compromised evaluation results and inflated performance metrics.</p>
<p>A common way data leakage can occur is if some samples from the test set inadvertently get included in the training data. Now when evaluating on the test set, the model has already seen some of the data which gives overly optimistic scores. For example, if 2% of the test data leaks into the training set of a binary classifier, it can result in a accuracy boost of up to 20%!</p>
<p>More subtle forms of leakage can happen if the data splits are not done carefully. If the splits are not properly randomized and shuffled, samples close to each other in the dataset may end up across different splits. This creates information bleed through based on proximity in the dataset. Time series data is especially vulnerable unless special cross validation techniques are used.</p>
<p>Preventing data leakage requires creating solid separation between splits - no sample should exist in more than one split. Shuffling and randomized splitting help create robust divisions. Cross validation techniques can be used for more rigorous evaluation. Detecting leakage is difficult buttelltale signs include models doing way better on test vs.&nbsp;validation data.</p>
<p>Data leakage severely compromises the validity of evaluation because the model has already partially seen the test data. No amount of tuning or complex architectures can substitute for clean data splits. It is better to be conservative and create complete separation between splits to avoid this fundamental mistake in machine learning pipelines.</p>
</section>
<section id="small-or-unrepresentative-validation-set" class="level4">
<h4 class="anchored" data-anchor-id="small-or-unrepresentative-validation-set">Small or Unrepresentative Validation Set</h4>
<p>The validation set is used to evaluate models during training and for hyperparameter tuning. If the validation set is too small or not representative of the real data distribution, it will not provide reliable or stable evaluations during training. This makes model selection and tuning more difficult.</p>
<p>For example, if the validation set only contains 100 samples, metrics calculated on it will have high variance. The accuracy may fluctuate up to 5-10% between epochs just due to noise. This makes it difficult to know if a drop in validation accuracy is due to overfitting or natural variance. With a larger validation set of say 1000 samples, the metrics will be much more stable.</p>
<p>Additionally, if the validation set is not representative, perhaps missing certain subclasses, the estimated skill of the model may be inflated. This could lead to poor choices of hyperparameters or stopping training prematurely. Models selected based on such biased validation sets do not generalize well to real data.</p>
<p>A good rule of thumb is the validation set size should be at least several hundred samples, and up to 10-20% size of the training set. The splits should also be stratified, especially if working with imbalanced datasets. A larger validation set that well represents the original data characteristics is essential for proper model selection and tuning.</p>
<p>Care should be taken that the validation set is also not too large, leaving insufficient samples for training. Overall, the validation set is a critical piece of the data splitting process and care should be taken to avoid the pitfalls of small, inadequate samples that negatively impact model development.</p>
</section>
<section id="reusing-the-test-set-multiple-times" class="level4">
<h4 class="anchored" data-anchor-id="reusing-the-test-set-multiple-times">Reusing the Test Set Multiple Times</h4>
<p>The test set is designed to provide an unbiased evaluation of the fully-trained model only once at the end of the model development process. Reusing the test set multiple times during development for model evaluation, hyperparameter tuning, model selection etc. can result in overfitting on the test data.</p>
<p>If the test set is reused as part of the validation process, the model may start to see and learn from the test samples. This coupled with intentionally or unintentionally optimizing model performance on the test set can artificially inflate metrics like accuracy.</p>
<p>For example, if the test set is used repeatedly for model selection out of 5 architectures, the model may achieve 99% test accuracy just by memorizing the samples rather than learning generalizable patterns. However, deployed in the real world, the accuracy could drop to 60% on new data.</p>
<p>Best practice is to interact with the test set only once at the very end to report unbiased metrics on how the final tuned model would perform in the real world. The validation set should be used for all parameter tuning, model selection, early stopping etc. while developing the model.</p>
<p>Maintaining the complete separation of training/validation from the test set is essential to obtain accurate estimates of model performance. Even minor deviations from single use of the test set could positively bias results and metrics, providing an overly optimistic view of real world efficacy.</p>
</section>
<section id="same-data-splits-across-experiments" class="level4">
<h4 class="anchored" data-anchor-id="same-data-splits-across-experiments">Same Data Splits Across Experiments</h4>
<p>When comparing different machine learning models or experimenting with various architectures and hyperparameters, using the same data splits for training, validation and testing across the different experiments can introduce bias and invalidate the comparisons.</p>
<p>If the same splits are reused, the evaluation results may be overly correlated and not provide an accurate measure of which model performs better. For example, a certain random split of the data may happen to favor model A over model B irrespective of the algorithms. Reusing this split will then be biased towards model A.</p>
<p>Instead, the data splits should be randomized or shuffled for each experimental iteration. This ensures that randomness in the sampling of the splits does not confer an unfair advantage to any model.</p>
<p>With different splits per experiment, the evaluation becomes more robust. Each model is tested on a wide range of test sets drawn randomly from the overall population. This smoothens out variation and removes correlation between results.</p>
<p>Proper practice is to set a random seed before splitting the data for each experiment. Splitting should be carried out after any shuffling/resampling as part of the experimental pipeline. Carrying out comparisons on the same splits violates the i.i.d (independent and identically distributed) assumption required for statistical validity.</p>
<p>Unique splits are essential for fair model comparisons. Though more compute intensive, randomized allocation per experiment removes sampling bias and enables valid benchmarking. This highlights the true differences in model performance irrespective of a particular split’s characteristics.</p>
</section>
<section id="information-leakage-between-sets" class="level4">
<h4 class="anchored" data-anchor-id="information-leakage-between-sets">Information Leakage Between Sets</h4>
<p>Information leakage between the training, validation and test sets occurs when information from one set inadvertently bleeds into another set. This could happen due to flaws in the data splitting process and violates the assumption that the sets are mutually exclusive.</p>
<p>For example, consider a dataset sorted chronologically. If a simple random split is performed, samples close to each other in the dataset may end up in different splits. Models could then learn from ‘future’ data if test samples are leaked into the training set.</p>
<p>Similarly, if the splits are not properly shuffled, distribution biases may persist across sets. The training set may not contain certain outliers that end up in the test set only, compromising generalization. Issues like class imbalance may also get amplified if splitting is not stratified.</p>
<p>Another case is when datasets have linked samples that are inherently connected, such as graphs, networks or time series data. Naive splitting may isolate connected nodes or time steps into different sets. Models can make invalid assumptions based on partial information.</p>
<p>Preventing information leakage requires awareness of the structure of the dataset and relationships between samples. Shuffling, stratification and grouped splitting of related samples can help mitigate leakage. Proper cross validation procedures should be followed, being mindful of temporal or sample proximity.</p>
<p>Subtle leakage of information between sets undermines model evaluation and training. It creates misleading results on model effectiveness. Data splitting procedures should account for sample relationships and distribution differences to ensure mutual exclusivity between sets.</p>
</section>
<section id="failing-to-stratify-splits" class="level4">
<h4 class="anchored" data-anchor-id="failing-to-stratify-splits">Failing to Stratify Splits</h4>
<p>When splitting data into training, validation and test sets, failing to stratify the splits can result in uneven representation of the target classes across the splits and introduce sampling bias. This is especially problematic for imbalanced datasets.</p>
<p>Stratified splitting involves sampling data points such that the proportion of output classes is approximately preserved in each split. For example, if performing a 70/30 train-test split on a dataset with 60% negative and 40% positive samples, stratification ensures ~60% negative and ~40% positive examples in both training and test sets.</p>
<p>Without stratification, due to random chance, the training split could end up with 70% positive while test has 30% positive samples. The model trained on this skewed training distribution will not generalize well. Class imbalance also compromises model metrics like accuracy.</p>
<p>Stratification works best when done using the labels though proxies like clustering can be used for unsupervised learning. It becomes essential for highly skewed datasets with rare classes that could easily get omitted from splits.</p>
<p>Libraries like Scikit-Learn have stratified splitting methods inbuilt. Failing to use them could inadvertently introduce sampling bias and hurt model performance on minority groups. The overall class balance should be examined after performing the splits to ensure even representation across the splits.</p>
<p>Stratification provides a balanced dataset for both model training and evaluation. Though simple random splitting is easy, being mindful of stratification needs, especially for real-world imbalanced data, results in more robust model development and evaluation.</p>
</section>
<section id="ignoring-time-series-dependencies" class="level4">
<h4 class="anchored" data-anchor-id="ignoring-time-series-dependencies">Ignoring Time Series Dependencies</h4>
<p>Time series data has an inherent temporal structure with observations depending on past context. Naively splitting time series data into train and test sets without accounting for this dependency leads to data leakage and lookahead bias.</p>
<p>For example, simply splitting a time series into the first 70% training and last 30% as test data will contaminate the training data with future data points. The model can use this information to “peek” ahead during training.</p>
<p>This results in overly optimistic evaluation of the model’s performance. The model may appear to forecast the future accurately but has actually implicitly learned based on future data. This does not translate to real world performance.</p>
<p>Proper time series cross validation techniques should be used to preserve order and dependency, such as forward chaining. The test set should only contain data points from a future time window that the model did not get exposed to for training.</p>
<p>Failing to account for temporal relationships leads to invalid assumptions of causality. The model may also not learn how to extrapolate forecasts further into the future if the training data contains future points.</p>
<p>Maintaining the temporal flow of events and avoiding lookahead bias is key for properly training and testing time series models to ensure they can truly predict future patterns and not just memorize past training data.</p>
</section>
<section id="no-unseen-data-for-final-evaluation" class="level4">
<h4 class="anchored" data-anchor-id="no-unseen-data-for-final-evaluation">No Unseen Data for Final Evaluation</h4>
<p>A common mistake when splitting data is failing to keep aside some portion of the data just for final evaluation of the completed model. All of the data is used for training, validation and test sets during development.</p>
<p>This leaves no unseen data to get an unbiased estimate of how the final tuned model would perform in the real world. The metrics on the test set used during development may not fully reflect actual model skill.</p>
<p>For example, choices like early stopping and hyperparameter tuning are often optimized based on performance on the test set. This couples the model to the test data. An unseen dataset is needed to break this coupling and get true real-world metrics.</p>
<p>Best practice is to reserve a portion like 20-30% of the full dataset solely for final model evaluation. This data should not be used for any validation, tuning or model selection during development.</p>
<p>Saving some unseen data allows evaluating the completely trained model as a black box on real-world like data. This provides reliable metrics to decide if the model is truly ready for production deployment.</p>
<p>Failing to keep an unseen hold-out set for final validation risks optimistically biasing results and overlooking potential failures before model release. Having some fresh data provides a final sanity check on real-world efficacy.</p>
</section>
<section id="overoptimizing-on-the-validation-set" class="level4">
<h4 class="anchored" data-anchor-id="overoptimizing-on-the-validation-set">Overoptimizing on the Validation Set</h4>
<p>The validation set is meant to guide the model training process, not serve as additional training data. Overoptimizing on the validation set to maximize performance metrics treats it more like a secondary training set and leads to inflated metrics and poor generalization.</p>
<p>For example, techniques like extensively tuning hyperparameters or adding data augmentations targeted to boost validation accuracy can cause the model to fit too closely to the validation data. The model may achieve 99% validation accuracy but only 55% test accuracy.</p>
<p>Similarly, reusing the validation set for early stopping can also optimize the model specifically for that data. Stopping at the best validation performance overfits to noise and fluctuations caused by the small validation size.</p>
<p>The validation set serves as a proxy to tune and select models. But the end goal remains maximizing performance on real-world data, not the validation set. Minimizing the loss or error on validation data does not automatically translate to good generalization.</p>
<p>A good approach is to keep the validation set use minimal - hyperparameters can be tuned coarsely first on training data for example. The validation set guides the training, but should not influence or alter the model itself. It is a diagnostic, not an optimization tool.</p>
<p>Care should be taken to not overfit when assessing performance on the validation set. Tradeoffs are needed to build models that perform well on the overall population, not overly tuned to the validation samples.</p>
</section>
</section>
</section>
<section id="system-bottlenecks" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="system-bottlenecks"><span class="header-section-number">8.9</span> System Bottlenecks</h2>
<p>As introduced, neural networks consist of alternating linear and nonlinear operations. The main performance bottleneck is the linear layer, a matrix multiplication that maps the previous activations inputs to the next layer’s activation function.</p>
<section id="runtime-complexity-of-matrix-multiplication-in-neural-networks" class="level3" data-number="8.9.1">
<h3 data-number="8.9.1" class="anchored" data-anchor-id="runtime-complexity-of-matrix-multiplication-in-neural-networks"><span class="header-section-number">8.9.1</span> Runtime Complexity of Matrix Multiplication in Neural Networks</h3>
<p>Matrix multiplication is the main performance bottleneck in both neural network inference and training since its runtime complexity is the product of the dimensions of the input and output layers of the neural network, as well as the batch size. Generally, using a batch size of <span class="math inline">\(B\)</span> (i.e: training on batches of <span class="math inline">\(B\)</span> datapoints at a time), with an input layer dimension of <span class="math inline">\(M\)</span> nodes, and an output layer dimensions of <span class="math inline">\(N\)</span> nodes, the linear layer is a matrix-matrix multiplication size <span class="math inline">\(N \times M\)</span> by a <span class="math inline">\(M \times B\)</span>, leading to a complexity of <span class="math inline">\(O(NMB)\)</span>. This far dominates the computational complexity of the nonlinear activation functions which only need to be applied element-wise to the output vectors.</p>
</section>
<section id="compute-vs-memory-bottleneck-in-neural-network-training-and-inference" class="level3" data-number="8.9.2">
<h3 data-number="8.9.2" class="anchored" data-anchor-id="compute-vs-memory-bottleneck-in-neural-network-training-and-inference"><span class="header-section-number">8.9.2</span> Compute vs Memory Bottleneck in Neural Network Training and Inference</h3>
<p>As previously outlined, matrix multiplication is the key operational bottleneck in both neural network training and inference. However, this operation may pose a bottleneck to either the memory or computational capability of the underlying hardware system. Concretely, batched matrix multiplication (i.e: matrix-multiplicaton with a high batch-size <span class="math inline">\(B\)</span>) exhibits a much higher computation to memory ratio, and hence the underlying computational hardware must have more arithmetic computing capabilities than memory-transfer abilities to maximize performance in these scenarios (this is often the case in both CPUs and GPUs). This is because matrix multiplication performs <span class="math inline">\(O(NMB)\)</span> arithmetic operations, but only <span class="math inline">\(O(NM + MB)\)</span> memory operations; hence when <span class="math inline">\(B\)</span> is large, neural network inference/training requires more arithmetic operations, and when <span class="math inline">\(B\)</span> is small it requires relatively more memory operations. This detail is important since most of today’s hardware is better at performing computation rather than memory transfer, and hence from a computational perspective it is better to maximize batch size <span class="math inline">\(B\)</span> at training time to fully utilize the hardware. However, using a larger batch size <span class="math inline">\(B\)</span> at training time means doing fewer updates per pass of the dataset, which might decrease convergence time. Hence, selecting batch size <span class="math inline">\(B\)</span> has a considerable impact on both the convergence, computational efficiency, and runtime of neural networks, and must be tuned to attain high performance. Generally, a good rule of thumb for batch size is between 8-128.</p>
</section>
<section id="optimizing-matrix-multiplication" class="level3" data-number="8.9.3">
<h3 data-number="8.9.3" class="anchored" data-anchor-id="optimizing-matrix-multiplication"><span class="header-section-number">8.9.3</span> Optimizing Matrix Multiplication</h3>
<p>Matrix multiplication is essential to the performance of neural network inference and training, and hence efficiently evaluating matrix multiplication is crucial to performance. Broadly, various methods to accelerate matrix-multiplication include carefully writing the matrix-multiply routine to leverage the caches of the CPU, leveraging hardware-level parallel operations (i.e: SIMD), using hardware capabilities that perform multiply-adds simultaneously (i.e: fused add-multiply, and others. Even better at performing matrix multiplication than the CPU are GPUs, which have hardware that is suitable for performing a mass amount of parallel operations, a capability that is perfect for executing matrix-multiplication whose individual steps are highly parallelizable. Using the GPU, matrix multiplication can be accelerated by a significant factor over the GPU since the matrix-multiplication can be efficiently parallelized on a GPU, using standard techniques like blocking and tiling to maximize resource utilization. Other alternative ways to accelerate matrix-multiplication include using FPGAs, or dedicated hardware like TPUs (i.e: systolic arrays).</p>
</section>
</section>
<section id="parallelizing-ai-training" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="parallelizing-ai-training"><span class="header-section-number">8.10</span> Parallelizing AI training</h2>
<section id="data-parallel" class="level3" data-number="8.10.1">
<h3 data-number="8.10.1" class="anchored" data-anchor-id="data-parallel"><span class="header-section-number">8.10.1</span> Data Parallel</h3>
</section>
<section id="model-parallel" class="level3" data-number="8.10.2">
<h3 data-number="8.10.2" class="anchored" data-anchor-id="model-parallel"><span class="header-section-number">8.10.2</span> Model Parallel</h3>
</section>
</section>
<section id="efficient-and-distributed-training" class="level2" data-number="8.11">
<h2 data-number="8.11" class="anchored" data-anchor-id="efficient-and-distributed-training"><span class="header-section-number">8.11</span> Efficient and Distributed Training</h2>
</section>
<section id="debugging-and-profiling" class="level2" data-number="8.12">
<h2 data-number="8.12" class="anchored" data-anchor-id="debugging-and-profiling"><span class="header-section-number">8.12</span> Debugging and Profiling</h2>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./frameworks.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">AI Frameworks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./efficient_ai.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Efficient AI</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Edited by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This book was built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>