<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../">
<link href="../../../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" rel="next">
<link href="../../../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" rel="prev">
<link href="../../../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting-4a990d8dcb58f517c7c86712b8f2ac7c.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap-30b86197b7ded4c9dddbbc9b93dd1506.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<script src="../../../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script>
<style>
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
</style>
<style>
details.callout-quiz-question > summary::before {
  background-image: url("../../../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-quiz-answer > summary::before {
  background-image: url("../../../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
details.callout-resource-videos > summary::before {
  background-image: url("../../../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
</style>


</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-md " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../../assets/images/icons/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-download" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html">Grove Vision</a></li><li class="breadcrumb-item"><a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html">Image Classification</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden"><i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#image-classification" id="toc-image-classification" class="nav-link active" data-scroll-target="#image-classification">Image Classification</a>
  <ul>
  <li><a href="#sec-image-classification-introduction-d4a4" id="toc-sec-image-classification-introduction-d4a4" class="nav-link" data-scroll-target="#sec-image-classification-introduction-d4a4">Introduction</a>
  <ul class="collapse">
  <li><a href="#sec-image-classification-project-goal-d41d" id="toc-sec-image-classification-project-goal-d41d" class="nav-link" data-scroll-target="#sec-image-classification-project-goal-d41d">Project Goal</a></li>
  <li><a href="#sec-image-classification-data-collection-a172" id="toc-sec-image-classification-data-collection-a172" class="nav-link" data-scroll-target="#sec-image-classification-data-collection-a172">Data Collection</a></li>
  <li><a href="#sec-image-classification-collecting-data-sensecraft-ai-studio-ddc0" id="toc-sec-image-classification-collecting-data-sensecraft-ai-studio-ddc0" class="nav-link" data-scroll-target="#sec-image-classification-collecting-data-sensecraft-ai-studio-ddc0">Collecting Data with the SenseCraft AI Studio</a>
  <ul class="collapse">
  <li><a href="#sec-image-classification-image-collection-a27c" id="toc-sec-image-classification-image-collection-a27c" class="nav-link" data-scroll-target="#sec-image-classification-image-collection-a27c">Image Collection</a></li>
  </ul></li>
  <li><a href="#sec-image-classification-uploading-dataset-edge-impulse-studio-0a00" id="toc-sec-image-classification-uploading-dataset-edge-impulse-studio-0a00" class="nav-link" data-scroll-target="#sec-image-classification-uploading-dataset-edge-impulse-studio-0a00">Uploading the dataset to the Edge Impulse Studio</a></li>
  <li><a href="#sec-image-classification-impulse-design-preprocessing-1d91" id="toc-sec-image-classification-impulse-design-preprocessing-1d91" class="nav-link" data-scroll-target="#sec-image-classification-impulse-design-preprocessing-1d91">Impulse Design and Pre-Processing</a></li>
  <li><a href="#sec-image-classification-preprocessing-feature-generation-fbd0" id="toc-sec-image-classification-preprocessing-feature-generation-fbd0" class="nav-link" data-scroll-target="#sec-image-classification-preprocessing-feature-generation-fbd0">Pre-processing (Feature generation)</a></li>
  <li><a href="#sec-image-classification-model-design-training-test-5897" id="toc-sec-image-classification-model-design-training-test-5897" class="nav-link" data-scroll-target="#sec-image-classification-model-design-training-test-5897">Model Design, Training, and Test</a></li>
  <li><a href="#sec-image-classification-model-deployment-bb72" id="toc-sec-image-classification-model-deployment-bb72" class="nav-link" data-scroll-target="#sec-image-classification-model-deployment-bb72">Model Deployment</a></li>
  <li><a href="#sec-image-classification-deploy-model-sensecraft-ai-studio-5de7" id="toc-sec-image-classification-deploy-model-sensecraft-ai-studio-5de7" class="nav-link" data-scroll-target="#sec-image-classification-deploy-model-sensecraft-ai-studio-5de7">Deploy the model on the SenseCraft AI Studio</a></li>
  <li><a href="#sec-image-classification-image-classification-nonofficial-benchmark-d614" id="toc-sec-image-classification-image-classification-nonofficial-benchmark-d614" class="nav-link" data-scroll-target="#sec-image-classification-image-classification-nonofficial-benchmark-d614">Image Classification (non-official) Benchmark</a></li>
  <li><a href="#sec-image-classification-postprocessing-553f" id="toc-sec-image-classification-postprocessing-553f" class="nav-link" data-scroll-target="#sec-image-classification-postprocessing-553f">Postprocessing</a>
  <ul class="collapse">
  <li><a href="#sec-image-classification-getting-video-stream-a326" id="toc-sec-image-classification-getting-video-stream-a326" class="nav-link" data-scroll-target="#sec-image-classification-getting-video-stream-a326">Getting the Video Stream</a></li>
  <li><a href="#sec-image-classification-getting-inference-result-39d9" id="toc-sec-image-classification-getting-inference-result-39d9" class="nav-link" data-scroll-target="#sec-image-classification-getting-inference-result-39d9">Getting the Inference Result</a></li>
  <li><a href="#sec-image-classification-postprocessing-led-de30" id="toc-sec-image-classification-postprocessing-led-de30" class="nav-link" data-scroll-target="#sec-image-classification-postprocessing-led-de30">Postprocessing with LED</a></li>
  </ul></li>
  <li><a href="#sec-image-classification-optional-postprocessing-external-devices-e2ed" id="toc-sec-image-classification-optional-postprocessing-external-devices-e2ed" class="nav-link" data-scroll-target="#sec-image-classification-optional-postprocessing-external-devices-e2ed">Optional: Post-processing on external devices</a></li>
  </ul></li>
  <li><a href="#sec-image-classification-summary-53d0" id="toc-sec-image-classification-summary-53d0" class="nav-link" data-scroll-target="#sec-image-classification-summary-53d0">Summary</a></li>
  <li><a href="#sec-image-classification-resources-fbca" id="toc-sec-image-classification-resources-fbca" class="nav-link" data-scroll-target="#sec-image-classification-resources-fbca">Resources</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html">Grove Vision</a></li><li class="breadcrumb-item"><a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html">Image Classification</a></li></ol></nav></header>




<section id="image-classification" class="level1 unnumbered">
<h1 class="unnumbered">Image Classification</h1>
<p><strong>Using Seeed Studio Grove Vision AI Module V2 (Himax WiseEye2)</strong></p>
<p><a href="./images/jpeg/cover-VisionAI.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="./images/jpeg/cover-VisionAI.jpg" class="img-fluid"></a></p>
<p>In this Lab, we will explore Image Classification using the Seeed Studio <a href="https://wiki.seeedstudio.com/grove_vision_ai_v2/"><em>Grove Vision AI Module V2</em></a>, a powerful yet compact device specifically designed for embedded machine learning applications. Based on the <strong>Himax WiseEye2</strong> chip, this module is designed to enable AI capabilities on edge devices, making it an ideal tool for Edge Machine Learning (ML) applications.</p>
<section id="sec-image-classification-introduction-d4a4" class="level2">
<h2 class="anchored" data-anchor-id="sec-image-classification-introduction-d4a4">Introduction</h2>
<p>So far, we have explored several computer vision models previously uploaded by Seeed Studio or used the SenseCraft AI Studio for Image Classification, without choosing a specific model. Let’s now develop our Image Classification project from scratch, where we will select our data and model.</p>
<p>Below, we can see the project’s main steps and where we will work with them:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/block-diagram.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="./images/png/block-diagram.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<section id="sec-image-classification-project-goal-d41d" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-project-goal-d41d">Project Goal</h3>
<p>The first step in any machine learning (ML) project is defining the goal. In this case, the goal is to detect and classify two specific objects present in a single image. For this project, we will use two small toys: a robot and a small Brazilian parrot (named <em>Periquito</em>). Also, we will collect images of a background where those two objects are absent.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/img_class_goal_3rVvnUx29m.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="./images/png/img_class_goal_3rVvnUx29m.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
</section>
<section id="sec-image-classification-data-collection-a172" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-data-collection-a172">Data Collection</h3>
<p>With the Machine Learning project goal defined, dataset collection is the next and most crucial step. Suppose your project utilizes images that are publicly available on datasets, for example, to be used on a <strong>Person Detection</strong> project. In that case, you can download the <a href="https://edgeai.modelnova.ai/datasets/details/wake-vision">Wake Vision</a> dataset for use in the project.</p>
<p>But, in our case, we define a project where the images do not exist publicly, so we need to generate them. We can use a phone, computer camera, or other devices to capture the photos, offline or connected to the Edge Impulse Studio.</p>
<p>If you want to use the Grove Vision AI V2 to capture your dataset, you can use the SenseCraft AI Studio as we did in the previous Lab, or the <code>camera_web_server</code> sketch as we will describe later in the <strong>Postprocessing / Getting the Video Stream</strong> section of this Lab.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/Video-stream-cap.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="./images/png/Video-stream-cap.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>In this Lab, we will use the SenseCraft AI Studio to collect the dataset.</p>
</section>
<section id="sec-image-classification-collecting-data-sensecraft-ai-studio-ddc0" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-collecting-data-sensecraft-ai-studio-ddc0">Collecting Data with the SenseCraft AI Studio</h3>
<p>On SenseCraft AI Studio: Let’s open the tab <a href="https://sensecraft.seeed.cc/ai/training">Training</a>.</p>
<p>The default is to train a <code>Classification</code> model with a WebCam if it is available. Let’s select the <code>Grove Vision AI V2 instead</code>. Pressing the green button<code>[Connect]</code> <strong>(1),</strong> a Pop-Up window will appear. Select the corresponding Port <strong>(2)</strong> and press the blue button <code>[Connect]</code> <strong>(3)</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/data-collection.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="./images/png/data-collection.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>The image streamed from the Grove Vision AI V2 will be displayed.</p>
<section id="sec-image-classification-image-collection-a27c" class="level4">
<h4 class="anchored" data-anchor-id="sec-image-classification-image-collection-a27c">Image Collection</h4>
<p>Let’s create the classes, following, for example, an alphabetical order:</p>
<ul>
<li>Class1: background</li>
<li>Class 2: periquito</li>
<li>Class 3: robot</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/classes.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="./images/png/classes.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Select one of the classes (note that a green line will be around the window) and keep pressing the green button under the preview area. The collected images will appear on the Image Samples Screen.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/collect-class.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="./images/png/collect-class.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>After collecting the images, review them and, if necessary, delete any incorrect ones.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/erase-img.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="./images/png/erase-img.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Collect around 50 images from each class. After you collect the three classes, open the menu on each of them and select <code>Export Data</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/saving_data.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="./images/png/saving_data.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>In the Download area of the Computer, we will get three zip files, each one with its corresponding class name. Each Zip file contains a folder with the images.</p>
</section>
</section>
<section id="sec-image-classification-uploading-dataset-edge-impulse-studio-0a00" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-uploading-dataset-edge-impulse-studio-0a00">Uploading the dataset to the Edge Impulse Studio</h3>
<p>We will use the Edge Impulse Studio to train our model. <a href="https://www.edgeimpulse.com/">Edge Impulse</a>is a leading development platform for machine learning on edge devices.</p>
<ul>
<li>Enter your account credentials (or create a free account) at Edge Impulse.</li>
<li>Next, create a new project:</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/ei-proj.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="./images/png/ei-proj.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p>The dataset comprises approximately 50 images per label, with 40 for training and 10 for testing.</p>
</blockquote>
</section>
<section id="sec-image-classification-impulse-design-preprocessing-1d91" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-impulse-design-preprocessing-1d91">Impulse Design and Pre-Processing</h3>
<p><strong>Impulse Design</strong></p>
<p>An impulse takes raw data (in this case, images), extracts features (resizes pictures), and then uses a learning block to classify new data.</p>
<p>Classifying images is the most common application of deep learning, but a substantial amount of data is required to accomplish this task. We have around 50 images for each category. Is this number enough? Not at all! We will need thousands of images to “teach” or “model” each class, allowing us to differentiate them. However, we can resolve this issue by retraining a previously trained model using thousands of images. We refer to this technique as “Transfer Learning” (TL). With TL, we can fine-tune a pre-trained image classification model on our data, achieving good performance even with relatively small image datasets, as in our case.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/model_2.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="./images/png/model_2.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>So, starting from the raw images, we will resize them (96x96) pixels and feed them to our Transfer Learning block:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/impulse.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="./images/png/impulse.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p>For comparison, we will keep the image size as 96 x 96. However, keep in mind that with the Grove Vision AI Module V2 and its internal SRAM of 2.4 MB, larger images can be utilized (for example, 160 x 160).</p>
</blockquote>
<p>Also select the <code>Target</code> device (<code>Himax WiseEye2 (M55 400 MHz + U55)</code>) on the up-right corner.</p>
</section>
<section id="sec-image-classification-preprocessing-feature-generation-fbd0" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-preprocessing-feature-generation-fbd0">Pre-processing (Feature generation)</h3>
<p>Besides resizing the images, we can convert them to grayscale or retain their original RGB color depth. Let’s select <code>[RGB]</code> in the <code>Image</code> section. Doing that, each data sample will have a dimension of 27,648 features (96x96x3). Pressing <code>[Save Parameters]</code> will open a new tab, <code>Generate Features</code>. Press the button <code>[Generate Features]</code>to generate the features.</p>
</section>
<section id="sec-image-classification-model-design-training-test-5897" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-model-design-training-test-5897">Model Design, Training, and Test</h3>
<p>In 2007, Google introduced <a href="https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html">MobileNetV1</a>. In 2018, <a href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a>, was launched, and, in 2019, the V3. The Mobilinet is a family of general-purpose computer vision neural networks explicitly designed for mobile devices to support classification, detection, and other applications. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of various use cases.</p>
<p>Although the base MobileNet architecture is already compact and has low latency, a specific use case or application may often require the model to be even smaller and faster. MobileNets introduce a straightforward parameter, <strong>α</strong> (alpha), called the width multiplier to construct these smaller, less computationally expensive models. The role of the width multiplier α is to thin a network uniformly at each layer.</p>
<p>Edge Impulse Studio has available MobileNet V1 (96x96 images) and V2 (96x96 and 160x160 images), with several different <strong>α</strong> values (from 0.05 to 1.0). For example, you will get the highest accuracy with V2, 160x160 images, and α=1.0. Of course, there is a trade-off. The higher the accuracy, the more memory (around 1.3M RAM and 2.6M ROM) will be needed to run the model, implying more latency. The smaller footprint will be obtained at another extreme with MobileNet V1 and α=0.10 (around 53.2K RAM and 101K ROM).</p>
<blockquote class="blockquote">
<p>For comparison, we will use the <strong>MobileNet V2 0.1</strong> as our base model (but a model with a greater alpha can be used here). The final layer of our model, preceding the output layer, will have 8 neurons with a 10% dropout rate for preventing overfitting.</p>
</blockquote>
<p>Another necessary technique to use with deep learning is <strong>data augmentation</strong>. Data augmentation is a method that can help improve the accuracy of machine learning models by creating additional artificial data. A data augmentation system makes small, random changes to your training data during the training process (such as flipping, cropping, or rotating the images).</p>
<p>Set the Hyperparameters:</p>
<ul>
<li>Epochs: 20,</li>
<li>Bach Size: 32</li>
<li>Learning Rate: 0.0005</li>
<li>Validation size: 20%</li>
</ul>
<p>Training result:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/train-result.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="./images/png/train-result.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>The model profile predicts <strong>146 KB of RAM and 187 KB of Flash</strong>, indicating no problem with the Grove AI Vision (V2), which has almost 2.5 MB of internal SRAM. Additionally, the Studio indicates a <strong>latency of around 4 ms.</strong></p>
<blockquote class="blockquote">
<p>Despite this, with a 100% accuracy on the Validation set when using the spare data for testing, we confirmed an Accuracy of 81%, using the Quantized (Int8) trained model. However, it is sufficient for our purposes in this lab.</p>
</blockquote>
</section>
<section id="sec-image-classification-model-deployment-bb72" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-model-deployment-bb72">Model Deployment</h3>
<p>On the Deployment tab, we should select: <code>Seeed Grove Vision AI Module V2 (Himax WiseEye2)</code> and press <code>[Build]</code>. A ZIP file will be downloaded to our computer.</p>
<p>The Zip file contains the <code>model_vela.tflite</code>, which is a TensorFlow Lite (TFLite) model optimized for neural processing units (NPUs) using the Vela compiler, a tool developed by Arm to adapt TFLite models for Ethos-U NPUs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/zip.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="./images/png/zip.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>We can flash the model following the instructions in the <code>README.txt</code> or use the SenseCraft AI Studio. We will use the latter.</p>
</section>
<section id="sec-image-classification-deploy-model-sensecraft-ai-studio-5de7" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-deploy-model-sensecraft-ai-studio-5de7">Deploy the model on the SenseCraft AI Studio</h3>
<p>On SenseCraft AI Studio, go to the <code>Vision Workspace</code> tab, and connect the device:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/connect-deploy.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="./images/png/connect-deploy.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>You should see the last model that was uploaded to the device. Select the green button <code>[Upload Model]</code>. A pop-up window will ask for the <strong>model name</strong>, the <strong>model file,</strong> and to enter the class names (<strong>objects</strong>). We should use labels following alphabetical order: <code>0: background</code>, <code>1: periquito,</code> and <code>2: robot</code>, and then press <code>[Send]</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/enter-classes.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="./images/png/enter-classes.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>After a few seconds, the model will be uploaded (“flashed”) to our device, and the camera image will appear in real-time on the <strong>Preview</strong> Sector. The Classification result will be displayed under the image preview. It is also possible to select the <code>Confidence Threshold</code> of your inference using the cursor on <strong>Settings</strong>.</p>
<p>On the <strong>Device Logger</strong>, we can view the Serial Monitor, where we can observe the latency, which is approximately 1 to 2 ms for pre-processing and 4 to 5 ms for inference, aligning with the estimates made in Edge Impulse Studio.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/inference.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="./images/png/inference.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Here are other screenshots:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/infer-results.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img src="./images/png/infer-results.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>The power consumption of this model is approximately 70 mA, equivalent to 0.4 W.</p>
</section>
<section id="sec-image-classification-image-classification-nonofficial-benchmark-d614" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-image-classification-nonofficial-benchmark-d614">Image Classification (non-official) Benchmark</h3>
<p>Several development boards can be used for embedded machine learning (tinyML), and the most common ones (so far) for Computer Vision applications (with low energy) are the <strong>ESP32 CAM,</strong> the <strong>Seeed XIAO ESP32S3 Sense</strong>, and the Arduino <strong>Nicla Vision</strong>.</p>
<p>Taking advantage of this opportunity, a similarly trained model, MobilenetV2 96x96, with an alpha of 0.1, was also deployed on the ESP-CAM, the XIAO, and a Raspberry Pi Zero W2. Here is the result:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/benchmark.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img src="./images/png/benchmark.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p>The Grove Vision AI V2 with an <strong>ARM Ethus-U55</strong> was approximately 14 times faster than devices with an ARM-M7, and more than 100 times faster than an Xtensa LX6 (ESP-CAM). Even when compared to a Raspberry Pi, with a much more powerful CPU, the U55 reduces latency by almost half. Additionally, the power consumption is lower than that of other devices (see the <a href="https://www.hackster.io/limengdu0117/2024-mcu-ai-vision-boards-performance-comparison-998505">full</a> article here for power consumption comparison).</p>
</blockquote>
</section>
<section id="sec-image-classification-postprocessing-553f" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-postprocessing-553f">Postprocessing</h3>
<p>Now that we have the model uploaded to the board and working correctly, classifying our images, let’s connect a Master Device to export the inference result to it and see the result completely offline (disconnected from the PC and, for example, powered by a battery).</p>
<blockquote class="blockquote">
<p>Note that we can use any microcontroller as a Master Controller, such as the XIAO, Arduino, or Raspberry Pi.</p>
</blockquote>
<section id="sec-image-classification-getting-video-stream-a326" class="level4">
<h4 class="anchored" data-anchor-id="sec-image-classification-getting-video-stream-a326">Getting the Video Stream</h4>
<p>The image processing and model inference are processed locally in Grove Vision AI (V2), and we want the result to be output to the XIAO (Master Controller) via IIC. For that, we will use the <strong>Arduino SSMA library</strong>. This library’s primary purpose is to process Grove Vision AI’s data stream, which does not involve model inference.</p>
<blockquote class="blockquote">
<p>The Grove Vision AI (V2) communicates (Inference result) with the XIAO via the IIC; the device’s IIC address is 0x62. Image information transfer is via the USB serial port.</p>
</blockquote>
<p><strong>Step 1:</strong> Download the <a href="https://github.com/Seeed-Studio/Seeed_Arduino_SSCMA/">Arduino SSMA</a> library as a zip file from its GitHub:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/library.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img src="./images/png/library.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p><strong>Step 2</strong>: Install it in the Arduino IDE (<code>sketch &gt; Include Library &gt; Add .Zip Library</code>).</p>
<p><strong>Step 3</strong>: Install the <strong>ArduinoJSON</strong> library.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/jsonlib.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img src="./images/png/jsonlib.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p><strong>Step 4</strong>: Install the <strong>Eigen</strong> Library</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/eigen.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img src="./images/png/eigen.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p><strong>Step 3</strong>: Now, connect the XIAO and Grove Vision AI (V2) via the socket (a row of pins) located at the back of the device.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/jpeg/xiao-grove_mSUfqE5tWq.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img src="./images/jpeg/xiao-grove_mSUfqE5tWq.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p><strong>CAUTION</strong>: Please note the direction of the connection, Grove Vision AI’s Type-C connector should be in the same direction as XIAO’s Type-C connector.</p>
</blockquote>
<p><strong>Step 5</strong>: Connect the <strong>XIAO USB-C</strong> port to your computer</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/xiao-connection.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img src="./images/png/xiao-connection.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p><strong>Step 6</strong>: In the Arduino IDE, select the Xiao board and the corresponding USB port.</p>
<p>Once we want to stream the video to a webpage, we will use the <strong>XIAO ESP32S3</strong>, which has wifi and enough memory to handle images. Select <code>XIAO_ESP32S3</code> and the appropriate USB Port:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/xiao-setup.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img src="./images/png/xiao-setup.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>By default, the PSRAM is disabled. Open the <code>Tools</code> menu and on PSRAM: <code>"OPI PSRAM"</code>select <code>OPI PSRAM</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/mem.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img src="./images/png/mem.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p><strong>Step 7</strong>: Open the example in Arduino IDE:</p>
<p><code>File</code> -&gt; <code>Examples</code> -&gt; <code>Seeed_Arduino_SSCMA</code> -&gt; <code>camera_web_server</code>.</p>
<p>And edit the <code>ssid</code> and <code>password</code> in the <code>camera_web_server.ino</code> sketch to match the Wi-Fi network.</p>
<p><strong>Step 8</strong>: Upload the sketch to the board and open the Serial Monitor. When connected to the Wi-Fi network, the board’s IP address will be displayed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/webpage.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img src="./images/png/webpage.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Open the address using a web browser. A Video App will be available. To see <strong>only</strong> the video stream from the Grove Vision AI V2, press <code>[Sample Only]</code> and <code>[Start Stream]</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/video-app.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img src="./images/png/video-app.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>If you want to create an image dataset, you can use this app, saving frames of the video generated by the device. Pressing <code>[Save Frame]</code>, the image will be saved in the download area of our desktop.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/Video-stream-cap.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img src="./images/png/Video-stream-cap.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Opening the App <strong>without</strong> selecting <code>[Sample Only]</code>, the inference result should appear on the video screen, but this does not happen for Image Classification. For Object Detection or Pose Estimation, the result is embedded with the video stream.</p>
<p>For example, if the model is a Person Detection using YoloV8:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/person-detection-infer.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="./images/png/person-detection-infer.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
</section>
<section id="sec-image-classification-getting-inference-result-39d9" class="level4">
<h4 class="anchored" data-anchor-id="sec-image-classification-getting-inference-result-39d9">Getting the Inference Result</h4>
<ul>
<li><p>Go to <code>File</code> -&gt; <code>Examples</code> -&gt; <code>Seeed_Arduino_SSCMA</code> -&gt; <code>inference_class</code>.</p></li>
<li><p>Upload the sketch to the board, and open the Serial Monitor.</p></li>
<li><p>Pointing the camera at one of our objects, we can see the inference result on the Serial Terminal.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/inference-periquito.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="./images/png/inference-periquito.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p>The inference running on the Arduino IDE had an average consumption of 160 mA or 800 mW and a peak of 330 mA 1.65 W when transmitting the image to the App.</p>
</blockquote>
</section>
<section id="sec-image-classification-postprocessing-led-de30" class="level4">
<h4 class="anchored" data-anchor-id="sec-image-classification-postprocessing-led-de30">Postprocessing with LED</h4>
<p>The idea behind our postprocessing is that whenever a specific image is detected (for example, the Periquito - Label:1), the User LED is turned on. If the Robot or a background is detected, the LED will be off.</p>
<p>Copy the below code and past it to your IDE:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Seeed_Arduino_SSCMA.h&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>SSCMA AI<span class="op">;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> setup<span class="op">()</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    AI<span class="op">.</span>begin<span class="op">();</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    Serial<span class="op">.</span>begin<span class="op">(</span><span class="dv">115200</span><span class="op">);</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="op">(!</span>Serial<span class="op">);</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    Serial<span class="op">.</span>println<span class="op">(</span><span class="st">"Inferencing - Grove AI V2 / XIAO ESP32S3"</span><span class="op">);</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Pins for the built-in LED</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    pinMode<span class="op">(</span>LED_BUILTIN<span class="op">,</span> OUTPUT<span class="op">);</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Ensure the LED is OFF by default.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Note: The LED is ON when the pin is LOW, OFF when HIGH.</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LED_BUILTIN<span class="op">,</span> HIGH<span class="op">);</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> loop<span class="op">()</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(!</span>AI<span class="op">.</span>invoke<span class="op">()){</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>println<span class="op">(</span><span class="st">"</span><span class="sc">\n</span><span class="st">Invoke Success"</span><span class="op">);</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">"Latency [ms]: prepocess="</span><span class="op">);</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span>AI<span class="op">.</span>perf<span class="op">().</span>prepocess<span class="op">);</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">", inference="</span><span class="op">);</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span>AI<span class="op">.</span>perf<span class="op">().</span>inference<span class="op">);</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">", postpocess="</span><span class="op">);</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>println<span class="op">(</span>AI<span class="op">.</span>perf<span class="op">().</span>postprocess<span class="op">);</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="dt">int</span> pred_index <span class="op">=</span> AI<span class="op">.</span>classes<span class="op">()[</span><span class="dv">0</span><span class="op">].</span>target<span class="op">;</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">"Result= Label: "</span><span class="op">);</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span>pred_index<span class="op">);</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">", score="</span><span class="op">);</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>println<span class="op">(</span>AI<span class="op">.</span>classes<span class="op">()[</span><span class="dv">0</span><span class="op">].</span>score<span class="op">);</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        turn_on_led<span class="op">(</span>pred_index<span class="op">);</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co">/**</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co">* </span><span class="an">@brief</span><span class="co">      turn_off_led function - turn-off the User LED</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co">*/</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> turn_off_led<span class="op">(){</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LED_BUILTIN<span class="op">,</span> HIGH<span class="op">);</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co">/**</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co">* </span><span class="an">@brief</span><span class="co">      turn_on_led function used to turn on the User LED</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">* </span><span class="an">@param[in]</span><span class="co">  </span><span class="cv">pred_index</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 0: [0] ==&gt; ALL OFF</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 1: [1] ==&gt; LED ON</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 2: [2] ==&gt; ALL OFF</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 3: [3] ==&gt; ALL OFF</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">*/</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> turn_on_led<span class="op">(</span><span class="dt">int</span> pred_index<span class="op">)</span> <span class="op">{</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">switch</span> <span class="op">(</span>pred_index<span class="op">)</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">0</span><span class="op">:</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>            turn_off_led<span class="op">();</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">1</span><span class="op">:</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>            turn_off_led<span class="op">();</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>            digitalWrite<span class="op">(</span>LED_BUILTIN<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">2</span><span class="op">:</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>            turn_off_led<span class="op">();</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">3</span><span class="op">:</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>            turn_off_led<span class="op">();</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This sketch uses the Seeed_Arduino_SSCMA.h library to interface with the Grove Vision AI Module V2. The AI module and the LED are initialized in the <code>setup()</code> function, and serial communication is started.</p>
<p>The <code>loop()</code> function repeatedly calls the <code>invoke()</code> method to perform inference using the built-in algorithms of the Grove Vision AI Module V2. Upon a successful inference, the sketch prints out performance metrics to the serial monitor, including preprocessing, inference, and postprocessing times.</p>
<p>The sketch processes and prints out detailed information about the results of the inference:</p>
<ul>
<li>(<code>AI.classes()[0]</code>) that identifies the class of image (<code>.target</code>) and its confidence score (<code>.score</code>).</li>
<li>The inference result (class) is stored in the integer variable <code>pred_index</code>, which will be used as an input to the function <code>turn_on_led()</code>. As a result, the LED will turn ON, depending on the classification result.</li>
</ul>
<p>Here is the result:</p>
<p>If the Periquito is detected (Label:1), the LED is ON:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/led-on.png" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="./images/png/led-on.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>If the Robot is detected (Label:2) the LED is OFF (Same for Background (Label:0):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/led-off.png" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img src="./images/png/led-off.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Therefore, we can now power the Grove Viaon AI V2 + Xiao ESP32S3 with an external battery, and the inference result will be displayed by the LED completely offline. The consumption is approximately 165 mA or 825 mW.</p>
<blockquote class="blockquote">
<p>It is also possible to send the result using Wifi, BLE, or other communication protocols available on the used Master Device.</p>
</blockquote>
</section>
</section>
<section id="sec-image-classification-optional-postprocessing-external-devices-e2ed" class="level3">
<h3 class="anchored" data-anchor-id="sec-image-classification-optional-postprocessing-external-devices-e2ed">Optional: Post-processing on external devices</h3>
<p>Of course, one of the significant advantages of working with EdgeAI is that devices can run entirely disconnected from the cloud, allowing for seamless <strong>interactions with the real world</strong>. We did it in the last section, but using the internal Xiao LED. Now, we will connect external LEDs (which could be any actuator).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/block-iect-infer.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="./images/png/block-iect-infer.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p>The LEDS should be connected to the XIAO ground via a 220-ohm resistor.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/connection.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="./images/png/connection.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>The idea is to modify the previous sketch to handle the three external LEDs.</p>
<p><strong>GOAL</strong>: Whenever the image of a <strong>Periquito</strong> is detected, the LED <strong>Green</strong> will be ON; if it is a <strong>Robot</strong>, the LED <strong>Yellow</strong> will be ON; if it is a <strong>Background</strong>, the <strong>LED Red</strong> will be ON.</p>
<p>The image processing and model inference are processed locally in Grove Vision AI (V2), and we want the result to be output to the XIAO via IIC. For that, we will use the Arduino SSMA library again.</p>
<p>Here the sketch to be used:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Seeed_Arduino_SSCMA.h&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>SSCMA AI<span class="op">;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">// Define the LED pin according to the pin diagram</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">// The LEDS negative lead should be connected to the XIAO ground</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">// via a 220-ohm resistor.</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> LEDR <span class="op">=</span> D1<span class="op">;</span> <span class="er"># XIAO ESP32S3 Pin 1</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> LEDY <span class="op">=</span> D2<span class="op">;</span> <span class="er"># XIAO ESP32S3 Pin 2</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> LEDG <span class="op">=</span> D3<span class="op">;</span> <span class="er"># XIAO ESP32S3 Pin 3</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">void</span> setup<span class="op">()</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    AI<span class="op">.</span>begin<span class="op">();</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    Serial<span class="op">.</span>begin<span class="op">(</span><span class="dv">115200</span><span class="op">);</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="op">(!</span>Serial<span class="op">);</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    Serial<span class="op">.</span>println<span class="op">(</span><span class="st">"Inferencing - Grove AI V2 / XIAO ESP32S3"</span><span class="op">);</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">// Initialize the external LEDs</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    pinMode<span class="op">(</span>LEDR<span class="op">,</span> OUTPUT<span class="op">);</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    pinMode<span class="op">(</span>LEDY<span class="op">,</span> OUTPUT<span class="op">);</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    pinMode<span class="op">(</span>LEDG<span class="op">,</span> OUTPUT<span class="op">);</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Ensure the LEDs are OFF by default.</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Note: The LEDs are ON when the pin is HIGH, OFF when LOW.</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LEDR<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LEDY<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LEDG<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> loop<span class="op">()</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(!</span>AI<span class="op">.</span>invoke<span class="op">()){</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>println<span class="op">(</span><span class="st">"</span><span class="sc">\n</span><span class="st">Invoke Success"</span><span class="op">);</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">"Latency [ms]: prepocess="</span><span class="op">);</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span>AI<span class="op">.</span>perf<span class="op">().</span>prepocess<span class="op">);</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">", inference="</span><span class="op">);</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span>AI<span class="op">.</span>perf<span class="op">().</span>inference<span class="op">);</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">", postpocess="</span><span class="op">);</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>println<span class="op">(</span>AI<span class="op">.</span>perf<span class="op">().</span>postprocess<span class="op">);</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        <span class="dt">int</span> pred_index <span class="op">=</span> AI<span class="op">.</span>classes<span class="op">()[</span><span class="dv">0</span><span class="op">].</span>target<span class="op">;</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">"Result= Label: "</span><span class="op">);</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span>pred_index<span class="op">);</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>print<span class="op">(</span><span class="st">", score="</span><span class="op">);</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        Serial<span class="op">.</span>println<span class="op">(</span>AI<span class="op">.</span>classes<span class="op">()[</span><span class="dv">0</span><span class="op">].</span>score<span class="op">);</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        turn_on_leds<span class="op">(</span>pred_index<span class="op">);</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="co">/**</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="co">* </span><span class="an">@brief</span><span class="co"> turn_off_leds function - turn-off all LEDs</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co">*/</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> turn_off_leds<span class="op">(){</span></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LEDR<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LEDY<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    digitalWrite<span class="op">(</span>LEDG<span class="op">,</span> LOW<span class="op">);</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a><span class="co">/**</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a><span class="co">* </span><span class="an">@brief</span><span class="co"> turn_on_leds function used to turn on a specific LED</span></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a><span class="co">* </span><span class="an">@param[in]</span><span class="co">  </span><span class="cv">pred_index</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 0: [0] ==&gt; Red ON</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 1: [1] ==&gt; Green ON</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="co">*             label 2: [2] ==&gt; Yellow ON</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="co">*/</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> turn_on_leds<span class="op">(</span><span class="dt">int</span> pred_index<span class="op">)</span> <span class="op">{</span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">switch</span> <span class="op">(</span>pred_index<span class="op">)</span></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">0</span><span class="op">:</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>            turn_off_leds<span class="op">();</span></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>            digitalWrite<span class="op">(</span>LEDR<span class="op">,</span> HIGH<span class="op">);</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">1</span><span class="op">:</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>            turn_off_leds<span class="op">();</span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>            digitalWrite<span class="op">(</span>LEDG<span class="op">,</span> HIGH<span class="op">);</span></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">2</span><span class="op">:</span></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>            turn_off_leds<span class="op">();</span></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>            digitalWrite<span class="op">(</span>LEDY<span class="op">,</span> HIGH<span class="op">);</span></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">case</span> <span class="dv">3</span><span class="op">:</span></span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>            turn_off_leds<span class="op">();</span></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We should connect the Grove Vision AI V2 with the XIAO using its I2C Grove connector. For the XIAO, we will use an <a href="https://wiki.seeedstudio.com/Seeeduino-XIAO-Expansion-Board/">Expansion Board</a> for the facility (although it is possible to connect the I2C directly to the XIAO’s pins). We will power the boards using the USB-C connector, but a battery can also be used.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/montage.png" class="lightbox" data-gallery="quarto-lightbox-gallery-36"><img src="./images/png/montage.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<p>Here is the result:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./images/png/ext-les-inf.png" class="lightbox" data-gallery="quarto-lightbox-gallery-37"><img src="./images/png/ext-les-inf.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a></p>
</figure>
</div>
<blockquote class="blockquote">
<p>The power consumption reached a peak of 240 mA (Green LED), equivalent to 1.2 W. Driving the Yellow and Red LEDs consumes 14 mA, equivalent to 0.7 W. Sending information to the terminal via serial has no impact on power consumption.</p>
</blockquote>
</section>
</section>
<section id="sec-image-classification-summary-53d0" class="level2">
<h2 class="anchored" data-anchor-id="sec-image-classification-summary-53d0">Summary</h2>
<p>In this lab, we’ve explored the complete process of developing an image classification system using the Seeed Studio Grove Vision AI Module V2 powered by the Himax WiseEye2 chip. We’ve walked through every stage of the machine learning workflow, from defining our project goals to deploying a working model with real-world interactions.</p>
<p>The Grove Vision AI V2 has demonstrated impressive performance, with inference times of just 4-5ms, dramatically outperforming other common tinyML platforms. Our benchmark comparison showed it to be approximately 14 times faster than ARM-M7 devices and over 100 times faster than an Xtensa LX6 (ESP-CAM). Even when compared to a Raspberry Pi Zero W2, the Edge TPU architecture delivered nearly twice the speed while consuming less power.</p>
<p>Through this project, we’ve seen how transfer learning enables us to achieve good classification results with a relatively small dataset of custom images. The MobileNetV2 model with an alpha of 0.1 provided an excellent balance of accuracy and efficiency for our three-class problem, requiring only 146 KB of RAM and 187 KB of Flash memory, well within the capabilities of the Grove Vision AI Module V2’s 2.4 MB internal SRAM.</p>
<p>We also explored several deployment options, from viewing inference results through the SenseCraft AI Studio to creating a standalone system with visual feedback using LEDs. The ability to stream video to a web browser and process inference results locally demonstrates the versatility of edge AI systems for real-world applications.</p>
<p>The power consumption of our final system remained impressively low, ranging from approximately 70mA (0.4W) for basic inference to 240mA (1.2W) when driving external components. This efficiency makes the Grove Vision AI Module V2 an excellent choice for battery-powered applications where power consumption is critical.</p>
<p>This lab has demonstrated that sophisticated computer vision tasks can now be performed entirely at the edge, without reliance on cloud services or powerful computers. With tools like Edge Impulse Studio and SenseCraft AI Studio, the development process has become accessible even to those without extensive machine learning expertise.</p>
<p>As edge AI technology continues to evolve, we can expect even more powerful capabilities from compact, energy-efficient devices like the Grove Vision AI Module V2, opening up new possibilities for smart sensors, IoT applications, and embedded intelligence in everyday objects.</p>
</section>
<section id="sec-image-classification-resources-fbca" class="level2">
<h2 class="anchored" data-anchor-id="sec-image-classification-resources-fbca">Resources</h2>
<p><a href="https://sensecraft.seeed.cc/ai/training">Collecting Images with SenseCraft AI Studio</a>.</p>
<p><a href="https://studio.edgeimpulse.com/public/712491/live">Edge Impulse Studio Project</a></p>
<p><a href="https://sensecraft.seeed.cc/ai/device/local/36">SenseCraft AI Studio - Vision Workplace (Deploy Models)</a></p>
<p><a href="https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/Grove/Grove_Sensors/AI-powered/Grove-vision-ai-v2/Development/grove-vision-ai-v2-himax-sdk.md">Other Himax examples</a></p>
<p><a href="https://github.com/Mjrovai/Seeed-Grove-Vision-AI-V2/tree/main/Arduino_Sketches">Arduino Sketches</a></p>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/harvard-edge\.github\.io\/cs249r_book\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="pagination-link" aria-label="Setup and No-Code Applications">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Setup and No-Code Applications</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="pagination-link" aria-label="Object Detection">
        <span class="nav-page-text">Object Detection</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>