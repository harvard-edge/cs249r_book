<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Efficient AI – Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/optimizations/optimizations.html" rel="next">
<link href="../../../contents/core/training/training.html" rel="prev">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-fc6d358c97f25a8ea829b86655043430.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-5c6c0ad7bdfb89369003da8042cd4f02.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-a14f63a0e19d6d184e2c452ae6c32a55.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script src="../../../scripts/ai_menu/dist/bundle.js" defer=""></script>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/efficient_ai/efficient_ai.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Efficient AI</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/copyright.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/dedication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedication</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/contributors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributors &amp; Thanks</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">ML Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">DL Primer</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">AI Workflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">AI Frameworks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">AI Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Efficient AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Model Optimizations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI Acceleration</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">On-Device Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">ML Operations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Security &amp; Privacy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Responsible AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sustainable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Robust AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/generative_ai/generative_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Generative AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">LABS</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Shared Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">REFERENCES</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">8.1</span> Introduction</a></li>
  <li><a href="#the-need-for-efficient-ai" id="toc-the-need-for-efficient-ai" class="nav-link" data-scroll-target="#the-need-for-efficient-ai"><span class="header-section-number">8.2</span> The Need for Efficient AI</a></li>
  <li><a href="#efficient-model-architectures" id="toc-efficient-model-architectures" class="nav-link" data-scroll-target="#efficient-model-architectures"><span class="header-section-number">8.3</span> Efficient Model Architectures</a></li>
  <li><a href="#sec-efficient-model-compression" id="toc-sec-efficient-model-compression" class="nav-link" data-scroll-target="#sec-efficient-model-compression"><span class="header-section-number">8.4</span> Efficient Model Compression</a></li>
  <li><a href="#efficient-inference-hardware" id="toc-efficient-inference-hardware" class="nav-link" data-scroll-target="#efficient-inference-hardware"><span class="header-section-number">8.5</span> Efficient Inference Hardware</a></li>
  <li><a href="#sec-efficient-numerics" id="toc-sec-efficient-numerics" class="nav-link" data-scroll-target="#sec-efficient-numerics"><span class="header-section-number">8.6</span> Efficient Numerics</a>
  <ul>
  <li><a href="#sec-numerical-formats" id="toc-sec-numerical-formats" class="nav-link" data-scroll-target="#sec-numerical-formats"><span class="header-section-number">8.6.1</span> Numerical Formats</a></li>
  <li><a href="#sec-efficiency-benefits" id="toc-sec-efficiency-benefits" class="nav-link" data-scroll-target="#sec-efficiency-benefits"><span class="header-section-number">8.6.2</span> Efficiency Benefits</a></li>
  </ul></li>
  <li><a href="#evaluating-models" id="toc-evaluating-models" class="nav-link" data-scroll-target="#evaluating-models"><span class="header-section-number">8.7</span> Evaluating Models</a>
  <ul>
  <li><a href="#efficiency-metrics" id="toc-efficiency-metrics" class="nav-link" data-scroll-target="#efficiency-metrics"><span class="header-section-number">8.7.1</span> Efficiency Metrics</a></li>
  <li><a href="#efficiency-comparisons" id="toc-efficiency-comparisons" class="nav-link" data-scroll-target="#efficiency-comparisons"><span class="header-section-number">8.7.2</span> Efficiency Comparisons</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">8.8</span> Conclusion</a></li>
  <li><a href="#sec-efficient-ai-resource" id="toc-sec-efficient-ai-resource" class="nav-link" data-scroll-target="#sec-efficient-ai-resource"><span class="header-section-number">8.9</span> Resources</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/efficient_ai/efficient_ai.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/efficient_ai/efficient_ai.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-efficient_ai" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Efficient AI</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Resources: <a href="#sec-efficient-ai-resource">Slides</a>, <a href="#sec-efficient-ai-resource">Videos</a>, <a href="#sec-efficient-ai-resource">Exercises</a>, <a href="#sec-efficient-ai-resource">Labs</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/png/cover_efficient_ai.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL·E 3 Prompt: A conceptual illustration depicting efficiency in artificial intelligence using a shipyard analogy. The scene shows a bustling shipyard where containers represent bits or bytes of data. These containers are being moved around efficiently by cranes and vehicles, symbolizing the streamlined and rapid information processing in AI systems. The shipyard is meticulously organized, illustrating the concept of optimal performance within the constraints of limited resources. In the background, ships are docked, representing different platforms and scenarios where AI is applied. The atmosphere should convey advanced technology with an underlying theme of sustainability and wide applicability.</em></figcaption>
</figure>
</div>
<p>Efficiency in artificial intelligence is not simply a luxury but a necessity. In this chapter, we dive into the key concepts underpinning AI systems’ efficiency. The computational demands on neural networks can be daunting, even for minimal systems. For AI to be seamlessly integrated into everyday devices and essential systems, it must perform optimally within the constraints of limited resources while maintaining its efficacy. The pursuit of efficiency guarantees that AI models are streamlined, rapid, and sustainable, thereby widening their applicability across various platforms and scenarios.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Recognize the need for efficient AI in TinyML/edge devices.</p></li>
<li><p>Understand the need for efficient model architectures like MobileNets and SqueezeNet.</p></li>
<li><p>Understand why techniques for model compression are important.</p></li>
<li><p>Gain an appreciation for the value of efficient AI hardware.</p></li>
<li><p>Recognize the importance of numerical representations and their precision.</p></li>
<li><p>Understand the nuances of model comparison beyond just accuracy.</p></li>
<li><p>Recognize that model comparison involves memory, computation, power, and speed, not just accuracy.</p></li>
<li><p>Recognize efficiency encompasses technology, costs, and ethics.</p></li>
</ul>
</div>
</div>
<p>The focus is on gaining a conceptual understanding of the motivations and significance of the various strategies for achieving efficient AI, both in terms of techniques and a holistic perspective. Subsequent chapters provide a more in-depth exploration of these multiple concepts.</p>
<section id="introduction" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">8.1</span> Introduction</h2>
<p>Training models can consume significant energy, sometimes equivalent to the carbon footprint of sizable industrial processes. We will cover some of these sustainability details in the <a href="../../../contents/core/sustainable_ai/sustainable_ai.html">AI Sustainability</a> chapter. On the deployment side, if these models are not optimized for efficiency, they can quickly drain device batteries, demand excessive memory, or fall short of real-time processing needs. Through this chapter, we aim to elucidate the nuances of efficiency, setting the groundwork for a comprehensive exploration in the subsequent chapters.</p>
</section>
<section id="the-need-for-efficient-ai" class="level2 page-columns page-full" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="the-need-for-efficient-ai"><span class="header-section-number">8.2</span> The Need for Efficient AI</h2>
<p>Efficiency takes on different connotations depending on where AI computations occur. Let’s revisit Cloud, Edge, and TinyML (as discussed in <a href="../../../contents/core/ml_systems/ml_systems.html">ML Systems</a>) and differentiate between them in terms of efficiency. <a href="#fig-platforms" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-platforms</span></a> provides a big-picture comparison of the three different platforms.</p>
<div id="fig-platforms" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-platforms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.mdpi.com/futureinternet/futureinternet-14-00363/article_deploy/html/images/futureinternet-14-00363-g001-550.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-platforms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: Cloud, Mobile and TinyML. Source: <span class="citation" data-cites="schizas2022tinyml">Schizas et al. (<a href="#ref-schizas2022tinyml" role="doc-biblioref">2022</a>)</span>.
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-schizas2022tinyml" class="csl-entry" role="listitem">
Schizas, Nikolaos, Aristeidis Karras, Christos Karras, and Spyros Sioutas. 2022. <span>“<span>TinyML</span> for Ultra-Low Power <span>AI</span> and Large Scale <span>IoT</span> Deployments: <span>A</span> Systematic Review.”</span> <em>Future Internet</em> 14 (12): 363. <a href="https://doi.org/10.3390/fi14120363">https://doi.org/10.3390/fi14120363</a>.
</div></div></figure>
</div>
<p><strong>Cloud AI:</strong> Traditional AI models often run in large-scale data centers equipped with powerful GPUs and TPUs <span class="citation" data-cites="barroso2019datacenter">(<a href="#ref-barroso2019datacenter" role="doc-biblioref">Barroso, Hölzle, and Ranganathan 2019</a>)</span>. Here, efficiency pertains to optimizing computational resources, reducing costs, and ensuring timely data processing and return. However, relying on the cloud introduces latency, especially when dealing with large data streams that require uploading, processing, and downloading.</p>
<div class="no-row-height column-margin column-container"><div id="ref-barroso2019datacenter" class="csl-entry" role="listitem">
Barroso, Luiz André, Urs Hölzle, and Parthasarathy Ranganathan. 2019. <em>The Datacenter as a Computer: Designing Warehouse-Scale Machines</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-01761-2">https://doi.org/10.1007/978-3-031-01761-2</a>.
</div><div id="ref-li2019edge" class="csl-entry" role="listitem">
Li, En, Liekang Zeng, Zhi Zhou, and Xu Chen. 2020. <span>“Edge <span>AI:</span> <span class="nocase">On-demand</span> Accelerating Deep Neural Network Inference via Edge Computing.”</span> <em>IEEE Trans. Wireless Commun.</em> 19 (1): 447–57. <a href="https://doi.org/10.1109/twc.2019.2946140">https://doi.org/10.1109/twc.2019.2946140</a>.
</div></div><p><strong>Edge AI:</strong> Edge computing brings AI closer to the data source, processing information directly on local devices like smartphones, cameras, or industrial machines <span class="citation" data-cites="li2019edge">(<a href="#ref-li2019edge" role="doc-biblioref">Li et al. 2020</a>)</span>. Here, efficiency encompasses quick real-time responses and reduced data transmission needs. However, the constraints are tighter—these devices, while more powerful than microcontrollers, have limited computational power compared to cloud setups.</p>
<p><strong>TinyML:</strong> TinyML pushes the boundaries by enabling AI models to run on microcontrollers or extremely resource-constrained environments. The processor and memory performance difference between TinyML and cloud or mobile systems can be several orders of magnitude <span class="citation" data-cites="warden2019tinyml">(<a href="#ref-warden2019tinyml" role="doc-biblioref">Warden and Situnayake 2019</a>)</span>. Efficiency in TinyML is about ensuring models are lightweight enough to fit on these devices, consume minimal energy (critical for battery-powered devices), and still perform their tasks effectively.</p>
<div class="no-row-height column-margin column-container"><div id="ref-warden2019tinyml" class="csl-entry" role="listitem">
Warden, Pete, and Daniel Situnayake. 2019. <em>Tinyml: <span>Machine</span> Learning with Tensorflow Lite on Arduino and Ultra-Low-Power Microcontrollers</em>. O’Reilly Media.
</div></div><p>The spectrum from Cloud to TinyML represents a shift from vast, centralized computational resources to distributed, localized, and constrained environments. As we transition from one to the other, the challenges and strategies related to efficiency evolve, underlining the need for specialized approaches tailored to each scenario. Having established the need for efficient AI, especially within the context of TinyML, we will transition to exploring the methodologies devised to meet these challenges. The following sections outline the main concepts we will dive deeper into later. We will demonstrate the breadth and depth of innovation needed to achieve efficient AI as we explore these strategies.</p>
</section>
<section id="efficient-model-architectures" class="level2 page-columns page-full" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="efficient-model-architectures"><span class="header-section-number">8.3</span> Efficient Model Architectures</h2>
<p>Selecting an optimal model architecture is as crucial as optimizing it. In recent years, researchers have made significant strides in exploring innovative architectures that can inherently have fewer parameters while maintaining strong performance.</p>
<p><strong>MobileNets:</strong> MobileNets are efficient mobile and embedded vision application models <span class="citation" data-cites="howard2017mobilenets">(<a href="#ref-howard2017mobilenets" role="doc-biblioref">Howard et al. 2017</a>)</span>. The key idea that led to their success is depth-wise separable convolutions, significantly reducing the number of parameters and computations in the network. MobileNetV2 and V3 further enhance this design by introducing inverted residuals and linear bottlenecks.</p>
<div class="no-row-height column-margin column-container"><div id="ref-howard2017mobilenets" class="csl-entry" role="listitem">
Howard, Andrew G., Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. <span>“<span>MobileNets:</span> <span>Efficient</span> Convolutional Neural Networks for Mobile Vision Applications.”</span> <em>ArXiv Preprint</em>. <a href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a>.
</div><div id="ref-iandola2016squeezenet" class="csl-entry" role="listitem">
Iandola, Forrest N, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally, and Kurt Keutzer. 2016. <span>“<span>SqueezeNet:</span> <span class="nocase">Alexnet-level</span> Accuracy with 50x Fewer Parameters and 0.5 <span>MB</span> Model Size.”</span> <em>ArXiv Preprint</em> abs/1602.07360. <a href="https://arxiv.org/abs/1602.07360">https://arxiv.org/abs/1602.07360</a>.
</div></div><p><strong>SqueezeNet:</strong> SqueezeNet is a class of ML models known for its smaller size without sacrificing accuracy. It achieves this by using a “fire module” that reduces the number of input channels to 3x3 filters, thus reducing the parameters <span class="citation" data-cites="iandola2016squeezenet">(<a href="#ref-iandola2016squeezenet" role="doc-biblioref">Iandola et al. 2016</a>)</span>. Moreover, it employs delayed downsampling to increase the accuracy by maintaining a larger feature map.</p>
<p><strong>ResNet variants:</strong> The Residual Network (ResNet) architecture allows for the introduction of skip connections or shortcuts <span class="citation" data-cites="he2016deep">(<a href="#ref-he2016deep" role="doc-biblioref">He et al. 2016</a>)</span>. Some variants of ResNet are designed to be more efficient. For instance, ResNet-SE incorporates the “squeeze and excitation” mechanism to recalibrate feature maps <span class="citation" data-cites="hu2018squeeze">(<a href="#ref-hu2018squeeze" role="doc-biblioref">Hu, Shen, and Sun 2018</a>)</span>, while ResNeXt offers grouped convolutions for efficiency <span class="citation" data-cites="xie2017aggregated">(<a href="#ref-xie2017aggregated" role="doc-biblioref">Xie et al. 2017</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-he2016deep" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. <span>“Deep Residual Learning for Image Recognition.”</span> In <em>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 770–78. IEEE. <a href="https://doi.org/10.1109/cvpr.2016.90">https://doi.org/10.1109/cvpr.2016.90</a>.
</div><div id="ref-hu2018squeeze" class="csl-entry" role="listitem">
Hu, Jie, Li Shen, and Gang Sun. 2018. <span>“Squeeze-and-Excitation Networks.”</span> In <em>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 7132–41. IEEE. <a href="https://doi.org/10.1109/cvpr.2018.00745">https://doi.org/10.1109/cvpr.2018.00745</a>.
</div><div id="ref-xie2017aggregated" class="csl-entry" role="listitem">
Xie, Saining, Ross Girshick, Piotr Dollar, Zhuowen Tu, and Kaiming He. 2017. <span>“Aggregated Residual Transformations for Deep Neural Networks.”</span> In <em>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 1492–1500. IEEE. <a href="https://doi.org/10.1109/cvpr.2017.634">https://doi.org/10.1109/cvpr.2017.634</a>.
</div></div></section>
<section id="sec-efficient-model-compression" class="level2 page-columns page-full" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="sec-efficient-model-compression"><span class="header-section-number">8.4</span> Efficient Model Compression</h2>
<p>Model compression methods are essential for bringing deep learning models to devices with limited resources. These techniques reduce models’ size, energy consumption, and computational demands without significantly losing accuracy. At a high level, the methods can be categorized into the following fundamental methods:</p>
<p><strong>Pruning:</strong> We’ve mentioned pruning a few times in previous chapters but have not yet formally introduced it. Pruning is similar to trimming the branches of a tree. This was first thought of in the <a href="https://proceedings.neurips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf">Optimal Brain Damage</a> paper <span class="citation" data-cites="lecun1989optimal">(<a href="#ref-lecun1989optimal" role="doc-biblioref">LeCun, Denker, and Solla 1989</a>)</span> and was later popularized in the context of deep learning by <span class="citation" data-cites="han2016deep">Han, Mao, and Dally (<a href="#ref-han2016deep" role="doc-biblioref">2016</a>)</span>. Certain weights or entire neurons are removed from the network in pruning based on specific criteria. This can significantly reduce the model size. We will explore two of the main pruning strategies, structured and unstructured pruning, in <a href="#sec-pruning" class="quarto-xref"><span class="quarto-unresolved-ref">sec-pruning</span></a>. <a href="#fig-pruning" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-pruning</span></a> is an example of neural network pruning, where removing some of the nodes in the inner layers (based on specific criteria) reduces the number of edges between the nodes and, in turn, the model’s size.</p>
<div class="no-row-height column-margin column-container"><div id="ref-lecun1989optimal" class="csl-entry" role="listitem">
LeCun, Yann, John Denker, and Sara Solla. 1989. <span>“Optimal Brain Damage.”</span> <em>Adv Neural Inf Process Syst</em> 2.
</div><div id="ref-han2016deep" class="csl-entry" role="listitem">
Han, Song, Huizi Mao, and William J. Dally. 2016. <span>“Deep Compression: <span>Compressing</span> Deep Neural Networks with Pruning, Trained Quantization and <span>Huffman</span> Coding.”</span> <a href="https://arxiv.org/abs/1510.00149">https://arxiv.org/abs/1510.00149</a>.
</div></div><div id="fig-pruning" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pruning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/pruning.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pruning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: Neural Network Pruning.
</figcaption>
</figure>
</div>
<p><strong>Quantization:</strong> Quantization is the process of constraining an input from a large set to output in a smaller set, primarily in deep learning; this means reducing the number of bits that represent the weights and biases of the model. For example, using 16-bit or 8-bit representations instead of 32-bit can reduce the model size and speed up computations, with a minor trade-off in accuracy. We will explore these in more detail in <a href="#sec-quant" class="quarto-xref"><span class="quarto-unresolved-ref">sec-quant</span></a>. <a href="#fig-quantization" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-quantization</span></a> shows an example of quantization by rounding to the closest number. The conversion from 32-bit floating point to 16-bit reduces memory usage by 50%. Going from a 32-bit to an 8-bit integer reduces memory usage by 75%. While the loss in numeric precision, and consequently model performance, is minor, the memory usage efficiency is significant.</p>
<div id="fig-quantization" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-quantization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/quantization.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-quantization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.3: Different forms of quantization.
</figcaption>
</figure>
</div>
<p><strong>Knowledge Distillation:</strong> Knowledge distillation involves training a smaller model (student) to replicate the behavior of a larger model (teacher). The idea is to transfer the knowledge from the cumbersome model to the lightweight one. Hence, the smaller model attains performance close to its larger counterpart but with significantly fewer parameters. <a href="#fig-knowledge-dist" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-knowledge-dist</span></a> demonstrates the tutor-student framework for knowledge distillation. We will explore knowledge distillation in more detail in the <a href="#sec-kd" class="quarto-xref"><span class="quarto-unresolved-ref">sec-kd</span></a>.</p>
<div id="fig-knowledge-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knowledge-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/knowledgedistillation.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knowledge-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.4: The tutor-student framework for knowledge distillation. Source: <a href="URL:https://chukwubuikexo.medium.com/knowledge-distillation-approaches-in-machine-learning-5841a41a346a">Medium</a>
</figcaption>
</figure>
</div>
</section>
<section id="efficient-inference-hardware" class="level2 page-columns page-full" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="efficient-inference-hardware"><span class="header-section-number">8.5</span> Efficient Inference Hardware</h2>
<p>In the <a href="../../../contents/core/training/training.html">Training</a> chapter, we discussed the process of training AI models. Now, from an efficiency standpoint, it’s important to note that training is a resource and time-intensive task, often requiring powerful hardware and taking anywhere from hours to weeks to complete. Inference, on the other hand, needs to be as fast as possible, especially in real-time applications. This is where efficient inference hardware comes into play. By optimizing the hardware specifically for inference tasks, we can achieve rapid response times and power-efficient operation, which is especially crucial for edge devices and embedded systems.</p>
<p><strong>TPUs (Tensor Processing Units):</strong> <a href="https://cloud.google.com/tpu">TPUs</a> are custom-built ASICs (Application-Specific Integrated Circuits) by Google to accelerate machine learning workloads <span class="citation" data-cites="jouppi2017datacenter">(<a href="#ref-jouppi2017datacenter" role="doc-biblioref">Jouppi et al. 2017</a>)</span>. They are optimized for tensor operations, offering high throughput for low-precision arithmetic, and are designed specifically for neural network machine learning. TPUs significantly accelerate model training and inference compared to general-purpose GPU/CPUs. This boost means faster model training and real-time or near-real-time inference capabilities, crucial for applications like voice search and augmented reality.</p>
<div class="no-row-height column-margin column-container"><div id="ref-jouppi2017datacenter" class="csl-entry" role="listitem">
Jouppi, Norman P., Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, et al. 2017. <span>“In-Datacenter Performance Analysis of a Tensor Processing Unit.”</span> In <em>Proceedings of the 44th Annual International Symposium on Computer Architecture</em>, 1–12. ISCA ’17. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/3079856.3080246">https://doi.org/10.1145/3079856.3080246</a>.
</div></div><p><a href="https://cloud.google.com/edge-tpu">Edge TPUs</a> are a smaller, power-efficient version of Google’s TPUs tailored for edge devices. They provide fast on-device ML inferencing for TensorFlow Lite models. Edge TPUs allow for low-latency, high-efficiency inference on edge devices like smartphones, IoT devices, and embedded systems. AI capabilities can be deployed in real-time applications without communicating with a central server, thus saving bandwidth and reducing latency. Consider the table in <a href="#fig-edge-tpu-perf" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-edge-tpu-perf</span></a>. It shows the performance differences between running different models on CPUs versus a Coral USB accelerator. The Coral USB accelerator is an accessory by Google’s Coral AI platform that lets developers connect Edge TPUs to Linux computers. Running inference on the Edge TPUs was 70 to 100 times faster than on CPUs.</p>
<div id="fig-edge-tpu-perf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edge-tpu-perf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/tflite_edge_tpu_perf.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-edge-tpu-perf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.5: Accelerator vs CPU performance comparison across different hardware configurations. Desktop CPU: 64-bit Intel(R) Xeon(R) E5-1650 v4 @ 3.60GHz. Embedded CPU: Quad-core Cortex-A53 @ 1.5GHz, †Dev Board: Quad-core Cortex-A53 @ 1.5GHz + Edge TPU. Source: <a href="https://blog.tensorflow.org/2019/03/build-ai-that-works-offline-with-coral.html">TensorFlow Blog.</a>
</figcaption>
</figure>
</div>
<p><strong>NN (Neural Network) Accelerators:</strong> Fixed-function neural network accelerators are hardware accelerators designed explicitly for neural network computations. They can be standalone chips or part of a larger system-on-chip (SoC) solution. By optimizing the hardware for the specific operations that neural networks require, such as matrix multiplications and convolutions, NN accelerators can achieve faster inference times and lower power consumption than general-purpose CPUs and GPUs. They are especially beneficial in TinyML devices with power or thermal constraints, such as smartwatches, micro-drones, or robotics.</p>
<p>But these are all but the most common examples. Several other types of hardware are emerging that have the potential to offer significant advantages for inference. These include, but are not limited to, neuromorphic hardware, photonic computing, etc. In <a href="#sec-aihw" class="quarto-xref"><span class="quarto-unresolved-ref">sec-aihw</span></a>, we will explore these in greater detail.</p>
<p>Efficient hardware for inference speeds up the process, saves energy, extends battery life, and can operate in real-time conditions. As AI continues to be integrated into myriad applications, from smart cameras to voice assistants, the role of optimized hardware will only become more prominent. By leveraging these specialized hardware components, developers and engineers can bring the power of AI to devices and situations that were previously unthinkable.</p>
</section>
<section id="sec-efficient-numerics" class="level2 page-columns page-full" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="sec-efficient-numerics"><span class="header-section-number">8.6</span> Efficient Numerics</h2>
<p>Machine learning, and especially deep learning, involves enormous amounts of computation. Models can have millions to billions of parameters, often trained on vast datasets. Every operation, every multiplication or addition, demands computational resources. Therefore, the precision of the numbers used in these operations can significantly impact the computational speed, energy consumption, and memory requirements. This is where the concept of efficient numerics comes into play.</p>
<section id="sec-numerical-formats" class="level3 page-columns page-full" data-number="8.6.1">
<h3 data-number="8.6.1" class="anchored" data-anchor-id="sec-numerical-formats"><span class="header-section-number">8.6.1</span> Numerical Formats</h3>
<p>There are many different types of numerics. Numerics have a long history in computing systems.</p>
<p><strong>Floating point:</strong> Known as a single-precision floating point, FP32 utilizes 32 bits to represent a number, incorporating its sign, exponent, and mantissa. Understanding how floating point numbers are represented under the hood is crucial for grasping the various optimizations possible in numerical computations. The sign bit determines whether the number is positive or negative, the exponent controls the range of values that can be represented, and the mantissa determines the precision of the number. The combination of these components allows floating point numbers to represent a vast range of values with varying degrees of precision.</p>
<p><a href="#vid-floating-point-numbers" class="quarto-xref">Video&nbsp;<span class="quarto-unresolved-ref">vid-floating-point-numbers</span></a> provides a comprehensive overview of these three main components - sign, exponent, and mantissa - and how they work together to represent floating point numbers.</p>
<div id="vid-floating-point-numbers" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important&nbsp;8.1: Floating Point Numbers
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gc1Nl3mmCuY?si=nImcymfbE5H392vu" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<p>FP32 is widely adopted in many deep learning frameworks and balances accuracy and computational requirements. It is prevalent in the training phase for many neural networks due to its sufficient precision in capturing minute details during weight updates. Also known as half-precision floating point, FP16 uses 16 bits to represent a number, including its sign, exponent, and fraction. It offers a good balance between precision and memory savings. FP16 is particularly popular in deep learning training on GPUs that support mixed-precision arithmetic, combining the speed benefits of FP16 with the precision of FP32 where needed.</p>
<p><a href="#fig-float-point-formats" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-float-point-formats</span></a> shows three different floating-point formats: Float32, Float16, and BFloat16.</p>
<div id="fig-float-point-formats" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-float-point-formats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/three_float_types.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-float-point-formats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.6: Three floating-point formats.
</figcaption>
</figure>
</div>
<p>Several other numerical formats fall into an exotic class. An exotic example is BF16 or Brain Floating Point. It is a 16-bit numerical format designed explicitly for deep learning applications. It is a compromise between FP32 and FP16, retaining the 8-bit exponent from FP32 while reducing the mantissa to 7 bits (as compared to FP32’s 23-bit mantissa). This structure prioritizes range over precision. BF16 has achieved training results comparable in accuracy to FP32 while using significantly less memory and computational resources <span class="citation" data-cites="kalamkar2019study">(<a href="#ref-kalamkar2019study" role="doc-biblioref">Kalamkar et al. 2019</a>)</span>. This makes it suitable not just for inference but also for training deep neural networks.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kalamkar2019study" class="csl-entry" role="listitem">
Kalamkar, Dhiraj, Dheevatsa Mudigere, Naveen Mellempudi, Dipankar Das, Kunal Banerjee, Sasikanth Avancha, Dharma Teja Vooturi, et al. 2019. <span>“A Study of <span>BFLOAT16</span> for Deep Learning Training.”</span> <a href="https://arxiv.org/abs/1905.12322">https://arxiv.org/abs/1905.12322</a>.
</div></div><p>By retaining the 8-bit exponent of FP32, BF16 offers a similar range, which is crucial for deep learning tasks where certain operations can result in very large or very small numbers. At the same time, by truncating precision, BF16 allows for reduced memory and computational requirements compared to FP32. BF16 has emerged as a promising middle ground in the landscape of numerical formats for deep learning, providing an efficient and effective alternative to the more traditional FP32 and FP16 formats.</p>
<p><strong>Integer:</strong> These are integer representations using 8, 4, and 2 bits. They are often used during the inference phase of neural networks, where the weights and activations of the model are quantized to these lower precisions. Integer representations are deterministic and offer significant speed and memory advantages over floating-point representations. For many inference tasks, especially on edge devices, the slight loss in accuracy due to quantization is often acceptable, given the efficiency gains. An extreme form of integer numerics is for binary neural networks (BNNs), where weights and activations are constrained to one of two values: +1 or -1.</p>
<p><strong>Variable bit widths:</strong> Beyond the standard widths, research is ongoing into extremely low bit-width numerics, even down to binary or ternary representations. Extremely low bit-width operations can offer significant speedups and further reduce power consumption. While challenges remain in maintaining model accuracy with such drastic quantization, advances continue to be made in this area.</p>
<p>Efficient numerics is not just about reducing the bit-width of numbers but understanding the trade-offs between accuracy and efficiency. As machine learning models become more pervasive, especially in real-world, resource-constrained environments, the focus on efficient numerics will continue to grow. By thoughtfully selecting and leveraging the appropriate numeric precision, one can achieve robust model performance while optimizing for speed, memory, and energy. <a href="#tbl-precision" class="quarto-xref">Table&nbsp;<span class="quarto-unresolved-ref">tbl-precision</span></a> summarizes these trade-offs.</p>
<div id="tbl-precision" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-precision-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8.1: Comparing precision levels in deep learning.
</figcaption>
<div aria-describedby="tbl-precision-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 43%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Pros</th>
<th style="text-align: left;">Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FP32 (Floating Point 32-bit)</td>
<td style="text-align: left;"><ul>
<li>Standard precision used in most deep learning frameworks.</li>
<li>High accuracy due to ample representational capacity.</li>
<li>Well-suited for training</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>High memory usage.</li>
<li>Slower inference times compared to quantized models.</li>
<li>Higher energy consumption.</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">FP16 (Floating Point 16-bit)</td>
<td style="text-align: left;"><ul>
<li>Reduces memory usage compared to FP32.</li>
<li>Speeds up computations on hardware that supports FP16.</li>
<li>Often used in mixed-precision training to balance speed and accuracy.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Lower representational capacity compared to FP32.</li>
<li>Risk of numerical instability in some models or layers.</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">INT8 (8-bit Integer)</td>
<td style="text-align: left;"><ul>
<li>Significantly reduced memory footprint compared to floating-point representations.</li>
<li>Faster inference if hardware supports INT8 computations.</li>
<li>Suitable for many post-training quantization scenarios.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Quantization can lead to some accuracy loss.</li>
<li>Requires careful calibration during quantization to minimize accuracy degradation.</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">INT4 (4-bit Integer)</td>
<td style="text-align: left;"><ul>
<li>Even lower memory usage than INT8.</li>
<li>Further speedup potential for inference.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Higher risk of accuracy loss compared to INT8.</li>
<li>Calibration during quantization becomes more critical.</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Binary</td>
<td style="text-align: left;"><ul>
<li>Minimal memory footprint (only 1 bit per parameter).</li>
<li>Extremely fast inference due to bitwise operations.</li>
<li>Power efficient.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Significant accuracy drop for many tasks.</li>
<li>Complex training dynamics due to extreme quantization.</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Ternary</td>
<td style="text-align: left;"><ul>
<li>Low memory usage but slightly more than binary.</li>
<li>Offers a middle ground between representation and efficiency.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Accuracy might still be lower than that of higher precision models.</li>
<li>Training dynamics can be complex.</li>
</ul></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-efficiency-benefits" class="level3" data-number="8.6.2">
<h3 data-number="8.6.2" class="anchored" data-anchor-id="sec-efficiency-benefits"><span class="header-section-number">8.6.2</span> Efficiency Benefits</h3>
<p>Numerical efficiency matters for machine learning workloads for several reasons:</p>
<p><strong>Computational Efficiency :</strong> High-precision computations (like FP32 or FP64) can be slow and resource-intensive. Reducing numeric precision can achieve faster computation times, especially on specialized hardware that supports lower precision.</p>
<p><strong>Memory Efficiency:</strong> Storage requirements decrease with reduced numeric precision. For instance, FP16 requires half the memory of FP32. This is crucial when deploying models to edge devices with limited memory or working with large models.</p>
<p><strong>Power Efficiency:</strong> Lower precision computations often consume less power, which is especially important for battery-operated devices.</p>
<p><strong>Noise Introduction:</strong> Interestingly, the noise introduced using lower precision can sometimes act as a regularizer, helping to prevent overfitting in some models.</p>
<p><strong>Hardware Acceleration:</strong> Many modern AI accelerators and GPUs are optimized for lower precision operations, leveraging the efficiency benefits of such numerics.</p>
</section>
</section>
<section id="evaluating-models" class="level2 page-columns page-full" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="evaluating-models"><span class="header-section-number">8.7</span> Evaluating Models</h2>
<p>It’s worth noting that the actual benefits and trade-offs can vary based on the specific architecture of the neural network, the dataset, the task, and the hardware being used. Before deciding on a numeric precision, it’s advisable to perform experiments to evaluate the impact on the desired application.</p>
<section id="efficiency-metrics" class="level3" data-number="8.7.1">
<h3 data-number="8.7.1" class="anchored" data-anchor-id="efficiency-metrics"><span class="header-section-number">8.7.1</span> Efficiency Metrics</h3>
<p>A deep understanding of model evaluation methods is important to guide this process systematically. When assessing AI models’ effectiveness and suitability for various applications, efficiency metrics come to the forefront.</p>
<p><strong>FLOPs (Floating Point Operations)</strong>, as introduced in <a href="../training/training.html">Training</a>, gauge a model’s computational demands. For instance, a modern neural network like BERT has billions of FLOPs, which might be manageable on a powerful cloud server but would be taxing on a smartphone. Higher FLOPs can lead to more prolonged inference times and significant power drain, especially on devices without specialized hardware accelerators. Hence, for real-time applications such as video streaming or gaming, models with lower FLOPs might be more desirable.</p>
<p><strong>Memory Usage</strong> pertains to how much storage the model requires, affecting both the deploying device’s storage and RAM. Consider deploying a model onto a smartphone: a model that occupies several gigabytes of space not only consumes precious storage but might also be slower due to the need to load large weights into memory. This becomes especially crucial for edge devices like security cameras or drones, where minimal memory footprints are vital for storage and rapid data processing.</p>
<p><strong>Power Consumption</strong> becomes especially crucial for devices that rely on batteries. For instance, a wearable health monitor using a power-hungry model could drain its battery in hours, rendering it impractical for continuous health monitoring. Optimizing models for low power consumption becomes essential as we move toward an era dominated by IoT devices, where many devices operate on battery power.</p>
<p><strong>Inference Time</strong> is about how swiftly a model can produce results. In applications like autonomous driving, where split-second decisions are the difference between safety and calamity, models must operate rapidly. If a self-driving car’s model takes even a few seconds too long to recognize an obstacle, the consequences could be dire. Hence, ensuring a model’s inference time aligns with the real-time demands of its application is paramount.</p>
<p>In essence, these efficiency metrics are more than numbers dictating where and how a model can be effectively deployed. A model might boast high accuracy, but if its FLOPs, memory usage, power consumption, or inference time make it unsuitable for its intended platform or real-world scenarios, its practical utility becomes limited.</p>
</section>
<section id="efficiency-comparisons" class="level3 page-columns page-full" data-number="8.7.2">
<h3 data-number="8.7.2" class="anchored" data-anchor-id="efficiency-comparisons"><span class="header-section-number">8.7.2</span> Efficiency Comparisons</h3>
<p>The landscape of machine learning models is vast, with each model offering a unique set of strengths and implementation considerations. While raw accuracy figures or training and inference speeds might be tempting benchmarks, they provide an incomplete picture. A deeper comparative analysis reveals several critical factors influencing a model’s suitability for TinyML applications. Often, we encounter the delicate balance between accuracy and efficiency. For instance, while a dense, deep learning model and a lightweight MobileNet variant might excel in image classification, their computational demands could be at two extremes. This differentiation is especially pronounced when comparing deployments on resource-abundant cloud servers versus constrained TinyML devices. In many real-world scenarios, the marginal gains in accuracy could be overshadowed by the inefficiencies of a resource-intensive model.</p>
<p>Moreover, the optimal model choice is not always universal but often depends on the specifics of an application. For instance, a model that excels in general object detection scenarios might struggle in niche environments, such as detecting manufacturing defects on a factory floor. This adaptability- or the lack of it- can influence a model’s real-world utility.</p>
<p>Another important consideration is the relationship between model complexity and its practical benefits. Take voice-activated assistants, such as “Alexa” or “OK Google.” While a complex model might demonstrate a marginally superior understanding of user speech if it’s slower to respond than a simpler counterpart, the user experience could be compromised. Thus, adding layers or parameters only sometimes equates to better real-world outcomes.</p>
<p>Another important consideration is the relationship between model complexity and its practical benefits. Take voice-activated assistants like “Alexa” or “OK Google.” While a complex model might demonstrate a marginally superior understanding of user speech if it’s slower to respond than a simpler counterpart, the user experience could be compromised. Thus, adding layers or parameters only sometimes equates to better real-world outcomes.</p>
<p>Furthermore, while benchmark datasets, such as ImageNet <span class="citation" data-cites="russakovsky2015imagenet">(<a href="#ref-russakovsky2015imagenet" role="doc-biblioref">Russakovsky et al. 2015</a>)</span>, COCO <span class="citation" data-cites="lin2014microsoft">(<a href="#ref-lin2014microsoft" role="doc-biblioref">Lin et al. 2014</a>)</span>, Visual Wake Words <span class="citation" data-cites="chowdhery2019visual">(<a href="#ref-chowdhery2019visual" role="doc-biblioref">Wang and Zhan 2019</a>)</span>, Google Speech Commands <span class="citation" data-cites="warden2018speech">(<a href="#ref-warden2018speech" role="doc-biblioref">Warden 2018</a>)</span>, etc. provide a standardized performance metric, they might not capture the diversity and unpredictability of real-world data. Two facial recognition models with similar benchmark scores might exhibit varied competencies when faced with diverse ethnic backgrounds or challenging lighting conditions. Such disparities underscore the importance of robustness and consistency across varied data. For example, <a href="#fig-stoves" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-stoves</span></a> from the Dollar Street dataset shows stove images across extreme monthly incomes. Stoves have different shapes and technological levels across different regions and income levels. A model that is not trained on diverse datasets might perform well on a benchmark but fail in real-world applications. So, if a model was trained on pictures of stoves found in wealthy countries only, it would fail to recognize stoves from poorer regions.</p>
<div class="no-row-height column-margin column-container"><div id="ref-russakovsky2015imagenet" class="csl-entry" role="listitem">
Russakovsky, Olga, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, et al. 2015. <span>“<span>ImageNet</span> Large Scale Visual Recognition Challenge.”</span> <em>Int. J. Comput. Vision</em> 115 (3): 211–52. <a href="https://doi.org/10.1007/s11263-015-0816-y">https://doi.org/10.1007/s11263-015-0816-y</a>.
</div><div id="ref-lin2014microsoft" class="csl-entry" role="listitem">
Lin, Tsung-Yi, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. <span>“Microsoft Coco: <span>Common</span> Objects in Context.”</span> In <em>Computer Vision<span></span>ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part v 13</em>, 740–55. Springer.
</div><div id="ref-chowdhery2019visual" class="csl-entry" role="listitem">
Wang, LingFeng, and YaQing Zhan. 2019. <span>“A Conceptual Peer Review Model for <span class="nocase">arXiv</span> and Other Preprint Databases.”</span> <em>Learn. Publ.</em> 32 (3): 213–19. <a href="https://doi.org/10.1002/leap.1229">https://doi.org/10.1002/leap.1229</a>.
</div><div id="ref-warden2018speech" class="csl-entry" role="listitem">
Warden, Pete. 2018. <span>“Speech Commands: <span>A</span> Dataset for Limited-Vocabulary Speech Recognition.”</span> <em>arXiv Preprint arXiv:1804.03209</em>.
</div></div><div id="fig-stoves" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-stoves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/ds_stoves.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-stoves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.7: Different types of stoves. Source: Dollar Street stove images.
</figcaption>
</figure>
</div>
<p>In essence, a thorough comparative analysis transcends numerical metrics. It’s a holistic assessment intertwined with real-world applications, costs, and the intricate subtleties that each model brings to the table. This is why having standard benchmarks and metrics widely established and adopted by the community becomes important.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">8.8</span> Conclusion</h2>
<p>Efficient AI is crucial as we push towards broader and more diverse real-world deployment of machine learning. This chapter provided an overview, exploring the various methodologies and considerations behind achieving efficient AI, starting with the fundamental need, similarities, and differences across cloud, Edge, and TinyML systems.</p>
<p>We examined efficient model architectures and their usefulness for optimization. Model compression techniques such as pruning, quantization, and knowledge distillation exist to help reduce computational demands and memory footprint without significantly impacting accuracy. Specialized hardware like TPUs and NN accelerators offer optimized silicon for neural network operations and data flow. Efficient numerics balance precision and efficiency, enabling models to attain robust performance using minimal resources. We will explore these topics in depth and detail in the subsequent chapters.</p>
<p>Together, these form a holistic framework for efficient AI. But the journey doesn’t end here. Achieving optimally efficient intelligence requires continued research and innovation. As models become more sophisticated, datasets grow, and applications diversify into specialized domains, efficiency must evolve in lockstep. Measuring real-world impact requires nuanced benchmarks and standardized metrics beyond simplistic accuracy figures.</p>
<p>Moreover, efficient AI expands beyond technological optimization and encompasses costs, environmental impact, and ethical considerations for the broader societal good. As AI permeates industries and daily lives, a comprehensive outlook on efficiency underpins its sustainable and responsible progress. The subsequent chapters will build upon these foundational concepts, providing actionable insights and hands-on best practices for developing and deploying efficient AI solutions.</p>
</section>
<section id="sec-efficient-ai-resource" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="sec-efficient-ai-resource"><span class="header-section-number">8.9</span> Resources</h2>
<p>Here is a curated list of resources to support students and instructors in their learning and teaching journeys. We are continuously working on expanding this collection and will add new exercises soon.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>These slides are a valuable tool for instructors to deliver lectures and for students to review the material at their own pace. We encourage students and instructors to leverage these slides to improve their understanding and facilitate effective knowledge transfer.</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1tvSiOfQ1lYPXsvHcFVs8R1lYZPei_Nb7/edit?usp=drive_link&amp;ouid=102419556060649178683&amp;rtpof=true&amp;sd=true">Deploying on Edge Devices: challenges and techniques.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1jdBnIxgNovG3b8frTl3DwqiIOw_K4jvp3kyv2GoKfYQ/edit?usp=drive_link&amp;resourcekey=0-PN8sYpltO1nP_xePynJn9w">Model Evaluation.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1OuhwH5feIwPivEU6pTDyR3QMs7AFstHLiF_LB8T5qYQ/edit?usp=drive_link&amp;resourcekey=0-DZxIuVBUbJawuFh0AO-Pvw">Continuous Evaluation Challenges for TinyML.</a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Videos
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><em>Coming soon.</em></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercises
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>To reinforce the concepts covered in this chapter, we have curated a set of exercises that challenge students to apply their knowledge and deepen their understanding.</p>
<ul>
<li><em>Coming soon.</em></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Labs
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>In addition to exercises, we offer a series of hands-on labs allowing students to gain practical experience with embedded AI technologies. These labs provide step-by-step guidance, enabling students to develop their skills in a structured and supportive environment. We are excited to announce that new labs will be available soon, further enriching the learning experience.</p>
<ul>
<li><em>Coming soon.</em></li>
</ul>
</div>
</div>
</div>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/training/training.html" class="pagination-link" aria-label="AI Training">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">AI Training</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/optimizations/optimizations.html" class="pagination-link" aria-label="Model Optimizations">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Model Optimizations</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/efficient_ai/efficient_ai.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/efficient_ai/efficient_ai.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>