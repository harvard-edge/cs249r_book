@article{abadi2016tensorflow,
  title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
  author = {
    Abadi, Mart\'{\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng
    and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and
    Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael
    and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg,
    Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and
    Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal
    and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals,
    Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng,
    Xiaoqiang
  },
  journal = {arXiv preprint arXiv:1603.04467},
  url = {http://arxiv.org/abs/1603.04467v2},
  date = {2016-03-14},
  primaryclass = {cs.DC},
  archiveprefix = {arXiv},
}

@article{barroso2003web,
  title = {The Case for Energy-Proportional Computing},
  author = {Barroso, Luiz Andr\'{e} and H\"{o}lzle, Urs},
  journal = {Computer},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  volume = {40},
  number = {12},
  pages = {33--37},
  doi = {10.1109/mc.2007.443},
  issn = {0018-9162},
  url = {https://doi.org/10.1109/mc.2007.443},
  source = {Crossref},
  date = {2007-12},
}

@article{Brown2020,
  title = {Language Models are Few-Shot Learners},
  author = {
    Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and
    Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell,
    Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom
    and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens
    and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and
    Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec
    and Sutskever, Ilya and Amodei, Dario
  },
  journal = {arXiv preprint arXiv:2005.14165},
  url = {http://arxiv.org/abs/2005.14165v4},
  date = {2020-05-28},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
}

@article{brown2020language,
  title = {Language Models are Few-Shot Learners},
  author = {
    Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and
    al., et
  },
  year = {2020},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {33},
  pages = {1877--1901},
}

@article{chen2015mxnet,
  title = {
    MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems
  },
  author = {
    Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao,
    Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng
  },
  journal = {arXiv preprint arXiv:1512.01274},
  url = {http://arxiv.org/abs/1512.01274v1},
  date = {2015-12-03},
  primaryclass = {cs.DC},
  archiveprefix = {arXiv},
}

@article{chen2016training,
  title = {Training Deep Nets with Sublinear Memory Cost},
  author = {Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  journal = {CoRR},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  volume = {abs/1604.06174},
  url = {http://arxiv.org/abs/1604.06174v2},
  date = {2016-04-21},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  source = {DBLP},
}

@article{chetlur2014cudnn,
  title = {cuDNN: Efficient Primitives for Deep Learning},
  author = {
    Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran,
    John and Catanzaro, Bryan and Shelhamer, Evan
  },
  journal = {arXiv preprint arXiv:1410.0759},
  url = {http://arxiv.org/abs/1410.0759v3},
  date = {2014-10-03},
  primaryclass = {cs.NE},
  archiveprefix = {arXiv},
}

@article{dally2021evolution,
  title = {Evolution of the Graphics Processing Unit (GPU)},
  author = {Dally, William J. and Keckler, Stephen W. and Kirk, David B.},
  journal = {IEEE Micro},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  volume = {41},
  number = {6},
  pages = {42--51},
  doi = {10.1109/mm.2021.3113475},
  issn = {0272-1732,1937-4143},
  url = {https://doi.org/10.1109/mm.2021.3113475},
  source = {Crossref},
  date = {2021-11-01},
}

@article{dean2012large,
  title = {MapReduce},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  journal = {Communications of the ACM},
  booktitle = {Communications of the ACM},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {51},
  number = {1},
  pages = {107--113},
  doi = {10.1145/1327452.1327492},
  issn = {0001-0782,1557-7317},
  url = {https://doi.org/10.1145/1327452.1327492},
  source = {Crossref},
  subtitle = {simplified data processing on large clusters},
  date = {2008-01},
}

@manual{deepspeed_training_system_2021,
  title = {DeepSpeed: Extreme-scale Model Training for Everyone},
  author = {Research, Microsoft},
  year = {2021},
  note = {<https://www.microsoft.com/en-us/research/project/deepspeed/>},
}

@article{Devlin2019,
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle = {
    Proceedings of the 2019 Conference of the North American Chapter of the Association for
    Computational Linguistics: Human Language Technologies
  },
  pages = {4171--4186},
  url = {http://arxiv.org/abs/1810.04805v2},
  date = {2018-10-11},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
}

@article{dongarra1988extended,
  title = {An extended set of FORTRAN basic linear algebra subprograms},
  author = {Dongarra, Jack J. and Du Croz, Jeremy and Hammarling, Sven and Hanson, Richard J.},
  journal = {ACM Transactions on Mathematical Software},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {14},
  number = {1},
  pages = {1--17},
  doi = {10.1145/42288.42291},
  issn = {0098-3500,1557-7295},
  url = {https://doi.org/10.1145/42288.42291},
  source = {Crossref},
  date = {1988-03},
}

@article{Feldman2020,
  title = {
    The Cerebras Wafer-Scale Engine: Opportunities and Challenges of Building an Accelerator at
    Wafer Scale
  },
  author = {Feldman, Andrew and Lie, Sean and James, Michael and others},
  year = {2020},
  journal = {IEEE Micro},
  volume = {40},
  number = {2},
  pages = {20--29},
  doi = {10.1109/MM.2020.2975796},
}

@article{goodfellow2016deep,
  title = {Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning},
  author = {Goodfellow, Ian J. and Courville, Aaron and Bengio, Yoshua},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  volume = {35},
  number = {8},
  pages = {1902--1914},
  doi = {10.1109/tpami.2012.273},
  issn = {0162-8828,2160-9292},
  url = {https://doi.org/10.1109/tpami.2012.273},
  note = {Chapter 6: Deep Feedforward Networks, Activation Functions},
  source = {Crossref},
  date = {2013-08},
  essn = {1939-3539},
}

@inproceedings{he2016residual,
  title = {Deep Residual Learning for Image Recognition},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  pages = {770--778},
  doi = {10.1109/cvpr.2016.90},
  url = {https://doi.org/10.1109/cvpr.2016.90},
  source = {Crossref},
  date = {2016-06},
}

@article{hochreiter1998vanishing,
  title = {The Vanishing Gradient Problem During Learning Recurrent Neural Nets  and Problem Solutions},
  author = {Hochreiter, Sepp},
  journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  publisher = {World Scientific Pub Co Pte Lt},
  volume = {06},
  number = {02},
  pages = {107--116},
  doi = {10.1142/s0218488598000094},
  issn = {0218-4885,1793-6411},
  url = {https://doi.org/10.1142/s0218488598000094},
  source = {Crossref},
  date = {1998-04},
}

@inproceedings{Jouppi2017,
  title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
  author = {
    Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav
    and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and
    Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and
    Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and
    Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg,
    Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and
    Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy
    and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary,
    Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore,
    Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and
    Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and
    Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn,
    Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing,
    Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and
    Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun
  },
  journal = {Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA)},
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
  publisher = {ACM},
  pages = {1--12},
  doi = {10.1145/3079856.3080246},
  url = {https://doi.org/10.1145/3079856.3080246},
  source = {Crossref},
  date = {2017-06-24},
}

@inproceedings{jouppi2017tpu,
  title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
  author = {
    Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav
    and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and
    Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and
    Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and
    Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg,
    Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and
    Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy
    and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary,
    Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore,
    Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and
    Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and
    Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn,
    Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing,
    Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and
    Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun
  },
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
  publisher = {ACM},
  pages = {1--12},
  doi = {10.1145/3079856.3080246},
  url = {https://doi.org/10.1145/3079856.3080246},
  source = {Crossref},
  date = {2017-06-24},
}

@article{kingma2014adam,
  title = {Adam: A Method for Stochastic Optimization},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  journal = {ICLR},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  url = {http://arxiv.org/abs/1412.6980v9},
  date = {2014-12-22},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  source = {DBLP},
}

@article{krishnamoorthi2018quantizing,
  title = {Quantizing deep convolutional networks for efficient inference: A whitepaper},
  author = {Krishnamoorthi, Raghuraman},
  journal = {arXiv preprint arXiv:1806.08342},
  url = {http://arxiv.org/abs/1806.08342v1},
  date = {2018-06-21},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
}

@article{krizhevsky2012imagenet,
  title = {ImageNet classification with deep convolutional neural networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  journal = {Communications of the ACM},
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {60},
  number = {6},
  pages = {84--90},
  doi = {10.1145/3065386},
  issn = {0001-0782,1557-7317},
  url = {https://doi.org/10.1145/3065386},
  source = {Crossref},
  date = {2017-05-24},
}

@incollection{lecun1998efficient,
  title = {Efficient BackProp},
  author = {LeCun, Yann and Bottou, Leon and Orr, Genevieve B. and M\"{u}ller, Klaus -Robert},
  journal = {Lecture Notes in Computer Science (LNCS)},
  booktitle = {Neural Networks: Tricks of the Trade},
  publisher = {Springer Berlin Heidelberg},
  volume = {1524},
  pages = {9--50},
  doi = {10.1007/3-540-49430-8\_2},
  isbn = {9783540653110,9783540494300},
  issn = {0302-9743},
  url = {https://doi.org/10.1007/3-540-49430-8\_2},
  source = {Crossref},
  date = {1998},
}

@article{Micikevicius2018,
  title = {Mixed Precision Training},
  author = {
    Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich
    and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh,
    Ganesh and Wu, Hao
  },
  journal = {arXiv preprint arXiv:1710.03740},
  url = {http://arxiv.org/abs/1710.03740v3},
  date = {2017-10-10},
  primaryclass = {cs.AI},
  archiveprefix = {arXiv},
}

@inproceedings{micikevicius2018mixed,
  title = {
    OpenSeq2Seq: Extensible Toolkit for Distributed and Mixed Precision Training of
    Sequence-to-Sequence Models
  },
  author = {
    Kuchaiev, Oleksii and Ginsburg, Boris and Gitman, Igor and Lavrukhin, Vitaly and Case, Carl and
    Micikevicius, Paulius
  },
  booktitle = {Proceedings of Workshop for NLP Open Source Software (NLP-OSS)},
  publisher = {Association for Computational Linguistics},
  pages = {41--46},
  doi = {10.18653/v1/w18-2507},
  url = {https://doi.org/10.18653/v1/w18-2507},
  source = {Crossref},
  date = {2018},
}

@inproceedings{narayanan_pipeline_parallelism_2021,
  title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
  author = {
    Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary,
    Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer,
    Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei
  },
  journal = {
    Proceedings of the International Conference on High-Performance Computing, Networking, Storage
    and Analysis
  },
  booktitle = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
  publisher = {ACM},
  pages = {1--15},
  doi = {10.1145/3458817.3476209},
  url = {https://doi.org/10.1145/3458817.3476209},
  source = {Crossref},
  date = {2021-11-13},
}

@article{nvidia_mixed_precision_2018,
  title = {Mixed Precision Training},
  author = {
    Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich
    and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh,
    Ganesh and Wu, Hao
  },
  journal = {arXiv preprint arXiv:1710.03740},
  url = {http://arxiv.org/abs/1710.03740v3},
  note = {Available at <https://arxiv.org/abs/1710.03740>},
  date = {2017-10-10},
  primaryclass = {cs.AI},
  archiveprefix = {arXiv},
}

@article{nvidia_tensors_fp16_2017,
  title = {
    Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four
    Minutes
  },
  author = {
    Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu
    and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and Chen, Tiegang and Hu,
    Guangxiao and Shi, Shaohuai and Chu, Xiaowen
  },
  journal = {arXiv preprint arXiv:1807.11205},
  url = {http://arxiv.org/abs/1807.11205v1},
  note = {Available at <https://arxiv.org/abs/1807.11205>},
  date = {2018-07-30},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
}

@article{paszke2019pytorch,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and al., et},
  year = {2019},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {32},
  pages = {8026--8037},
}

@book{Patterson2021,
  title = {Computer Organization and Design RISC-V Edition: The Hardware Software Interface},
  author = {Patterson, David A. and Hennessy, John L.},
  year = {2021},
  publisher = {Morgan Kaufmann},
  address = {San Francisco, CA},
  edition = {2nd},
}

@book{patterson2021hardware,
  title = {Computer Architecture: A Quantitative Approach},
  author = {Patterson, David A. and Hennessy, John L.},
  year = {2021},
  publisher = {Morgan Kaufmann},
  isbn = {978-0128201091},
  edition = {6th},
}

@article{Putnam2014,
  title = {A reconfigurable fabric for accelerating large-scale datacenter services},
  author = {
    Putnam, Andrew and Caulfield, Adrian M. and Chung, Eric S. and Chiou, Derek and Constantinides,
    Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and
    Gray, Jan and Haselman, Michael and Hauck, Scott and Heil, Stephen and Hormati, Amir and Kim,
    Joo-Young and Lanka, Sitaram and Larus, James and Peterson, Eric and Pope, Simon and Smith,
    Aaron and Thong, Jason and Xiao, Phillip Yi and Burger, Doug
  },
  journal = {ACM SIGARCH Computer Architecture News},
  booktitle = {Proceedings of the 41st Annual International Symposium on Computer Architecture (ISCA)},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {42},
  number = {3},
  pages = {13--24},
  doi = {10.1145/2678373.2665678},
  issn = {0163-5964},
  url = {https://doi.org/10.1145/2678373.2665678},
  source = {Crossref},
  date = {2014-06-14},
}

@article{rumelhart1986learning,
  title = {Learning representations by back-propagating errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  volume = {323},
  number = {6088},
  pages = {533--536},
  doi = {10.1038/323533a0},
  issn = {0028-0836,1476-4687},
  url = {https://doi.org/10.1038/323533a0},
  source = {Crossref},
  date = {1986-10},
}

@article{shazeer_mixture_of_experts_2017,
  title = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author = {
    Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and
    Hinton, Geoffrey and Dean, Jeff
  },
  journal = {arXiv preprint arXiv:1701.06538},
  url = {http://arxiv.org/abs/1701.06538v1},
  date = {2017-01-23},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
}

@article{strassen1969gauss,
  title = {Gaussian elimination is not optimal},
  author = {Strassen, Volker},
  journal = {Numerische Mathematik},
  publisher = {Springer Science and Business Media LLC},
  volume = {13},
  number = {4},
  pages = {354--356},
  doi = {10.1007/bf02165411},
  issn = {0029-599X,0945-3245},
  url = {https://doi.org/10.1007/bf02165411},
  source = {Crossref},
  date = {1969-08},
}

@techreport{tensorflow_data_2015,
  title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems},
  author = {Abadi, Mart\'{\i}n and Agarwal, Ashish and Barham, Paul and others},
  year = {2015},
  note = {Available at <https://www.tensorflow.org/>},
  institution = {Google Brain},
}

@book{thinking_machines_cm5,
  title = {CM-5 Technical Summary},
  author = {Corporation, Thinking Machines},
  year = {1992},
  publisher = {Thinking Machines Corporation},
}

@article{thornton1965cdc,
  title = {Design of a Computer: The Control Data 6600},
  author = {Thornton, James E.},
  year = {1965},
  journal = {Communications of the ACM},
  publisher = {ACM},
  volume = {8},
  number = {6},
  pages = {330--335},
}

@article{towardsdatascienceSolvingBottlenecks,
  title = {
    Overcoming Data Preprocessing Bottlenecks with TensorFlow Data Service, NVIDIA DALI, and Other
    Methods
  },
  author = {Rand, C..},
  year = {2019},
  journal = {Towards Data Science},
  url = {
    https://medium.com/towards-data-science/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851
  },
}

@inproceedings{vaswani2017attention,
  title = {The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation},
  author = {
    Chen, Mia Xu and Firat, Orhan and Bapna, Ankur and Johnson, Melvin and Macherey, Wolfgang and
    Foster, George and Jones, Llion and Schuster, Mike and Shazeer, Noam and Parmar, Niki and
    Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Chen, Zhifeng and Wu, Yonghui and
    Hughes, Macduff
  },
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  booktitle = {
    Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)
  },
  publisher = {Association for Computational Linguistics},
  volume = {30},
  pages = {5998--6008},
  doi = {10.18653/v1/p18-1008},
  url = {https://doi.org/10.18653/v1/p18-1008},
  source = {Crossref},
  date = {2018},
}

@article{wang_bfloat16_2019,
  title = {BFloat16: The Secret to High Performance on Cloud TPUs},
  author = {Wang, Y. and Kanwar, P.},
  year = {2019},
  journal = {Google Cloud Blog},
  note = {
    Available at
    <https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus>
  },
}

@article{zhao2024galorememoryefficientllmtraining,
  title = {GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection},
  author = {
    Zhao, Jiawei and Zhang, Zhenyu and Chen, Beidi and Wang, Zhangyang and Anandkumar, Anima and
    Tian, Yuandong
  },
  url = {http://arxiv.org/abs/2403.03507v2},
  date = {2024-03-06},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  eprint = {2403.03507},
}
