@article{thornton1965cdc,
  author = {Thornton, James E.},
  title = {Design of a Computer: The Control Data 6600},
  year = {1965},
  journal = {Communications of the ACM},
  publisher = {ACM},
  volume = {8},
  number = {6},
  pages = {330--335},
}

@inproceedings{micikevicius2018mixed,
  doi = {10.18653/v1/w18-2507},
  pages = {41--46},
  source = {Crossref},
  author = {Kuchaiev, Oleksii and Ginsburg, Boris and Gitman, Igor and Lavrukhin, Vitaly and Case, Carl and Micikevicius, Paulius},
  date = {2018},
  url = {https://doi.org/10.18653/v1/w18-2507},
  booktitle = {Proceedings of Workshop for NLP Open Source Software (NLP-OSS)},
  publisher = {Association for Computational Linguistics},
  title = {OpenSeq2Seq: Extensible Toolkit for Distributed and Mixed Precision Training of Sequence-to-Sequence Models},
}

@book{thinking_machines_cm5,
  author = {Corporation, Thinking Machines},
  title = {CM-5 Technical Summary},
  year = {1992},
  publisher = {Thinking Machines Corporation},
}

@article{abadi2016tensorflow,
  url = {http://arxiv.org/abs/1603.04467v2},
  date = {2016-03-14},
  title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  primaryclass = {cs.DC},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1603.04467},
}

@article{barroso2003web,
  number = {12},
  doi = {10.1109/mc.2007.443},
  pages = {33--37},
  source = {Crossref},
  volume = {40},
  author = {Barroso, Luiz André and Hölzle, Urs},
  date = {2007-12},
  url = {https://doi.org/10.1109/mc.2007.443},
  issn = {0018-9162},
  journal = {Computer},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  title = {The Case for Energy-Proportional Computing},
}

@article{krizhevsky2012imagenet,
  number = {6},
  doi = {10.1145/3065386},
  pages = {84--90},
  source = {Crossref},
  volume = {60},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  url = {https://doi.org/10.1145/3065386},
  issn = {0001-0782,1557-7317},
  journal = {Communications of the ACM},
  publisher = {Association for Computing Machinery (ACM)},
  title = {ImageNet classification with deep convolutional neural networks},
  booktitle = {Advances in Neural Information Processing Systems},
}

@inproceedings{he2016residual,
  doi = {10.1109/cvpr.2016.90},
  source = {Crossref},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  url = {https://doi.org/10.1109/cvpr.2016.90},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  title = {Deep Residual Learning for Image Recognition},
  journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {770--778},
}

@article{strassen1969gauss,
  number = {4},
  doi = {10.1007/bf02165411},
  pages = {354--356},
  source = {Crossref},
  volume = {13},
  author = {Strassen, Volker},
  date = {1969-08},
  url = {https://doi.org/10.1007/bf02165411},
  issn = {0029-599X,0945-3245},
  journal = {Numerische Mathematik},
  publisher = {Springer Science and Business Media LLC},
  title = {Gaussian elimination is not optimal},
}

@article{goodfellow2016deep,
  number = {8},
  doi = {10.1109/tpami.2012.273},
  pages = {1902--1914},
  source = {Crossref},
  volume = {35},
  author = {Goodfellow, Ian J. and Courville, Aaron and Bengio, Yoshua},
  date = {2013-08},
  url = {https://doi.org/10.1109/tpami.2012.273},
  issn = {0162-8828,2160-9292},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  title = {Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning},
  essn = {1939-3539},
  note = {Chapter 6: Deep Feedforward Networks, Activation Functions},
}

@article{hochreiter1998vanishing,
  number = {02},
  doi = {10.1142/s0218488598000094},
  pages = {107--116},
  source = {Crossref},
  volume = {06},
  author = {Hochreiter, Sepp},
  date = {1998-04},
  url = {https://doi.org/10.1142/s0218488598000094},
  issn = {0218-4885,1793-6411},
  journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  publisher = {World Scientific Pub Co Pte Lt},
  title = {The Vanishing Gradient Problem During Learning Recurrent Neural Nets  and Problem Solutions},
}

@article{rumelhart1986learning,
  number = {6088},
  doi = {10.1038/323533a0},
  pages = {533--536},
  source = {Crossref},
  volume = {323},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  date = {1986-10},
  url = {https://doi.org/10.1038/323533a0},
  issn = {0028-0836,1476-4687},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  title = {Learning representations by back-propagating errors},
}

@incollection{lecun1998efficient,
  doi = {10.1007/3-540-49430-8\_2},
  pages = {9--50},
  source = {Crossref},
  author = {LeCun, Yann and Bottou, Leon and Orr, Genevieve B. and Müller, Klaus -Robert},
  date = {1998},
  isbn = {9783540653110,9783540494300},
  url = {https://doi.org/10.1007/3-540-49430-8\_2},
  issn = {0302-9743},
  booktitle = {Neural Networks: Tricks of the Trade},
  publisher = {Springer Berlin Heidelberg},
  title = {Efficient BackProp},
  journal = {Lecture Notes in Computer Science (LNCS)},
  volume = {1524},
}

@article{chetlur2014cudnn,
  url = {http://arxiv.org/abs/1410.0759v3},
  date = {2014-10-03},
  title = {cuDNN: Efficient Primitives for Deep Learning},
  author = {Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  primaryclass = {cs.NE},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1410.0759},
}

@inproceedings{jouppi2017tpu,
  doi = {10.1145/3079856.3080246},
  source = {Crossref},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
  date = {2017-06-24},
  url = {https://doi.org/10.1145/3079856.3080246},
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
  publisher = {ACM},
  title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
  pages = {1--12},
}

@article{dally2021evolution,
  number = {6},
  doi = {10.1109/mm.2021.3113475},
  pages = {42--51},
  source = {Crossref},
  volume = {41},
  author = {Dally, William J. and Keckler, Stephen W. and Kirk, David B.},
  date = {2021-11-01},
  url = {https://doi.org/10.1109/mm.2021.3113475},
  issn = {0272-1732,1937-4143},
  journal = {IEEE Micro},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  title = {Evolution of the Graphics Processing Unit (GPU)},
}

@article{krishnamoorthi2018quantizing,
  url = {http://arxiv.org/abs/1806.08342v1},
  date = {2018-06-21},
  title = {Quantizing deep convolutional networks for efficient inference: A whitepaper},
  author = {Krishnamoorthi, Raghuraman},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1806.08342},
}

@article{chen2015mxnet,
  url = {http://arxiv.org/abs/1512.01274v1},
  date = {2015-12-03},
  title = {MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems},
  author = {Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
  primaryclass = {cs.DC},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1512.01274},
}

@article{kingma2014adam,
  url = {http://arxiv.org/abs/1412.6980v9},
  date = {2014-12-22},
  title = {Adam: A Method for Stochastic Optimization},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  journal = {ICLR},
  source = {DBLP},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
}

@article{chen2016training,
  url = {http://arxiv.org/abs/1604.06174v2},
  date = {2016-04-21},
  title = {Training Deep Nets with Sublinear Memory Cost},
  author = {Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  journal = {CoRR},
  volume = {abs/1604.06174},
  source = {DBLP},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
}

@techreport{tensorflow_data_2015,
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and others},
  title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems},
  year = {2015},
  note = {Available at <https://www.tensorflow.org/>},
  institution = {Google Brain},
}

@article{nvidia_mixed_precision_2018,
  url = {http://arxiv.org/abs/1710.03740v3},
  date = {2017-10-10},
  title = {Mixed Precision Training},
  author = {Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
  primaryclass = {cs.AI},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1710.03740},
  note = {Available at <https://arxiv.org/abs/1710.03740>},
}

@article{shazeer_mixture_of_experts_2017,
  url = {http://arxiv.org/abs/1701.06538v1},
  date = {2017-01-23},
  title = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1701.06538},
}

@inproceedings{narayanan_pipeline_parallelism_2021,
  doi = {10.1145/3458817.3476209},
  pages = {1--15},
  source = {Crossref},
  author = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei},
  date = {2021-11-13},
  url = {https://doi.org/10.1145/3458817.3476209},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  publisher = {ACM},
  title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
  journal = {Proceedings of the International Conference on High-Performance Computing, Networking, Storage and Analysis},
}

@manual{deepspeed_training_system_2021,
  author = {Research, Microsoft},
  title = {DeepSpeed: Extreme-scale Model Training for Everyone},
  year = {2021},
  note = {<https://www.microsoft.com/en-us/research/project/deepspeed/>},
}

@article{wang_bfloat16_2019,
  author = {Wang, Y. and Kanwar, P.},
  title = {BFloat16: The Secret to High Performance on Cloud TPUs},
  year = {2019},
  journal = {Google Cloud Blog},
  note = {Available at <https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus>},
}

@book{patterson2021hardware,
  author = {Patterson, David A. and Hennessy, John L.},
  title = {Computer Architecture: A Quantitative Approach},
  publisher = {Morgan Kaufmann},
  year = {2021},
  edition = {6th},
  isbn = {978-0128201091},
}

@article{nvidia_tensors_fp16_2017,
  url = {http://arxiv.org/abs/1807.11205v1},
  date = {2018-07-30},
  title = {Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes},
  author = {Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and Chen, Tiegang and Hu, Guangxiao and Shi, Shaohuai and Chu, Xiaowen},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1807.11205},
  note = {Available at <https://arxiv.org/abs/1807.11205>},
}

@article{paszke2019pytorch,
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and al., et},
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  year = {2019},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {32},
  pages = {8026--8037},
}

@article{dean2012large,
  number = {1},
  doi = {10.1145/1327452.1327492},
  pages = {107--113},
  source = {Crossref},
  volume = {51},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  subtitle = {simplified data processing on large clusters},
  date = {2008-01},
  url = {https://doi.org/10.1145/1327452.1327492},
  issn = {0001-0782,1557-7317},
  journal = {Communications of the ACM},
  publisher = {Association for Computing Machinery (ACM)},
  title = {MapReduce},
  booktitle = {Communications of the ACM},
}

@inproceedings{vaswani2017attention,
  doi = {10.18653/v1/p18-1008},
  source = {Crossref},
  author = {Chen, Mia Xu and Firat, Orhan and Bapna, Ankur and Johnson, Melvin and Macherey, Wolfgang and Foster, George and Jones, Llion and Schuster, Mike and Shazeer, Noam and Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Chen, Zhifeng and Wu, Yonghui and Hughes, Macduff},
  date = {2018},
  url = {https://doi.org/10.18653/v1/p18-1008},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  publisher = {Association for Computational Linguistics},
  title = {The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {30},
  pages = {5998--6008},
}

@article{brown2020language,
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and al., et},
  title = {Language Models are Few-Shot Learners},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {33},
  pages = {1877--1901},
}

@article{dongarra1988extended,
  number = {1},
  doi = {10.1145/42288.42291},
  pages = {1--17},
  source = {Crossref},
  volume = {14},
  author = {Dongarra, Jack J. and Du Croz, Jeremy and Hammarling, Sven and Hanson, Richard J.},
  date = {1988-03},
  url = {https://doi.org/10.1145/42288.42291},
  issn = {0098-3500,1557-7295},
  journal = {ACM Transactions on Mathematical Software},
  publisher = {Association for Computing Machinery (ACM)},
  title = {An extended set of FORTRAN basic linear algebra subprograms},
}

@book{Patterson2021,
  author = {Patterson, David A. and Hennessy, John L.},
  title = {Computer Organization and Design RISC-V Edition: The Hardware Software Interface},
  year = {2021},
  edition = {2nd},
  publisher = {Morgan Kaufmann},
  address = {San Francisco, CA},
}

@article{Micikevicius2018,
  url = {http://arxiv.org/abs/1710.03740v3},
  date = {2017-10-10},
  title = {Mixed Precision Training},
  author = {Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
  primaryclass = {cs.AI},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1710.03740},
}

@article{Brown2020,
  url = {http://arxiv.org/abs/2005.14165v4},
  date = {2020-05-28},
  title = {Language Models are Few-Shot Learners},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2005.14165},
}

@inproceedings{Jouppi2017,
  doi = {10.1145/3079856.3080246},
  source = {Crossref},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
  date = {2017-06-24},
  url = {https://doi.org/10.1145/3079856.3080246},
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
  publisher = {ACM},
  title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
  journal = {Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA)},
  pages = {1--12},
}

@article{Devlin2019,
  url = {http://arxiv.org/abs/1810.04805v2},
  date = {2018-10-11},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages = {4171--4186},
}

@article{Feldman2020,
  author = {Feldman, Andrew and Lie, Sean and James, Michael and others},
  title = {The Cerebras Wafer-Scale Engine: Opportunities and Challenges of Building an Accelerator at Wafer Scale},
  journal = {IEEE Micro},
  year = {2020},
  volume = {40},
  number = {2},
  pages = {20--29},
  doi = {10.1109/MM.2020.2975796},
}

@article{Putnam2014,
  number = {3},
  doi = {10.1145/2678373.2665678},
  pages = {13--24},
  source = {Crossref},
  volume = {42},
  author = {Putnam, Andrew and Caulfield, Adrian M. and Chung, Eric S. and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and Haselman, Michael and Hauck, Scott and Heil, Stephen and Hormati, Amir and Kim, Joo-Young and Lanka, Sitaram and Larus, James and Peterson, Eric and Pope, Simon and Smith, Aaron and Thong, Jason and Xiao, Phillip Yi and Burger, Doug},
  date = {2014-06-14},
  url = {https://doi.org/10.1145/2678373.2665678},
  issn = {0163-5964},
  journal = {ACM SIGARCH Computer Architecture News},
  publisher = {Association for Computing Machinery (ACM)},
  title = {A reconfigurable fabric for accelerating large-scale datacenter services},
  booktitle = {Proceedings of the 41st Annual International Symposium on Computer Architecture (ISCA)},
}