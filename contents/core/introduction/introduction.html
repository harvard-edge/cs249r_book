<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/ml_systems/ml_systems.html" rel="next">
<link href="../../../contents/frontmatter/socratiq/socratiq.html" rel="prev">
<link href="../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-4a990d8dcb58f517c7c86712b8f2ac7c.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-30b86197b7ded4c9dddbbc9b93dd1506.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<script src="../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script>
<style>
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
</style>
<style>
details.callout-quiz-question > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-quiz-answer > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
details.callout-resource-videos > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
</style>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-md " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/images/icons/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-download" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Systems Foundations</a></li><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Introduction</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden"><i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul>
  <li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose</a></li>
  <li><a href="#sec-introduction-ai-pervasiveness-8869" id="toc-sec-introduction-ai-pervasiveness-8869" class="nav-link" data-scroll-target="#sec-introduction-ai-pervasiveness-8869">AI Pervasiveness</a></li>
  <li><a href="#sec-introduction-ai-ml-basics-041a" id="toc-sec-introduction-ai-ml-basics-041a" class="nav-link" data-scroll-target="#sec-introduction-ai-ml-basics-041a">AI and ML Basics</a></li>
  <li><a href="#sec-introduction-ai-evolution-0dd8" id="toc-sec-introduction-ai-evolution-0dd8" class="nav-link" data-scroll-target="#sec-introduction-ai-evolution-0dd8">AI Evolution</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-symbolic-ai-era-acc4" id="toc-sec-introduction-symbolic-ai-era-acc4" class="nav-link" data-scroll-target="#sec-introduction-symbolic-ai-era-acc4">Symbolic AI Era</a></li>
  <li><a href="#sec-introduction-expert-systems-era-c061" id="toc-sec-introduction-expert-systems-era-c061" class="nav-link" data-scroll-target="#sec-introduction-expert-systems-era-c061">Expert Systems Era</a></li>
  <li><a href="#sec-introduction-statistical-learning-era-6d5b" id="toc-sec-introduction-statistical-learning-era-6d5b" class="nav-link" data-scroll-target="#sec-introduction-statistical-learning-era-6d5b">Statistical Learning Era</a></li>
  <li><a href="#sec-introduction-shallow-learning-era-b2a9" id="toc-sec-introduction-shallow-learning-era-b2a9" class="nav-link" data-scroll-target="#sec-introduction-shallow-learning-era-b2a9">Shallow Learning Era</a></li>
  <li><a href="#sec-introduction-deep-learning-era-bd1a" id="toc-sec-introduction-deep-learning-era-bd1a" class="nav-link" data-scroll-target="#sec-introduction-deep-learning-era-bd1a">Deep Learning Era</a></li>
  </ul></li>
  <li><a href="#sec-introduction-ml-systems-engineering-c9fb" id="toc-sec-introduction-ml-systems-engineering-c9fb" class="nav-link" data-scroll-target="#sec-introduction-ml-systems-engineering-c9fb">ML Systems Engineering</a></li>
  <li><a href="#sec-introduction-defining-ml-systems-8f42" id="toc-sec-introduction-defining-ml-systems-8f42" class="nav-link" data-scroll-target="#sec-introduction-defining-ml-systems-8f42">Defining ML Systems</a></li>
  <li><a href="#sec-introduction-lifecycle-ml-systems-e40e" id="toc-sec-introduction-lifecycle-ml-systems-e40e" class="nav-link" data-scroll-target="#sec-introduction-lifecycle-ml-systems-e40e">Lifecycle of ML Systems</a></li>
  <li><a href="#sec-introduction-ml-systems-wild-e270" id="toc-sec-introduction-ml-systems-wild-e270" class="nav-link" data-scroll-target="#sec-introduction-ml-systems-wild-e270">ML Systems in the Wild</a></li>
  <li><a href="#sec-introduction-ml-systems-impact-lifecycle-f5f9" id="toc-sec-introduction-ml-systems-impact-lifecycle-f5f9" class="nav-link" data-scroll-target="#sec-introduction-ml-systems-impact-lifecycle-f5f9">ML Systems Impact on Lifecycle</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-emerging-trends-fb9c" id="toc-sec-introduction-emerging-trends-fb9c" class="nav-link" data-scroll-target="#sec-introduction-emerging-trends-fb9c">Emerging Trends</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-applicationlevel-innovation-5833" id="toc-sec-introduction-applicationlevel-innovation-5833" class="nav-link" data-scroll-target="#sec-introduction-applicationlevel-innovation-5833">Application-Level Innovation</a></li>
  <li><a href="#sec-introduction-system-architecture-evolution-0661" id="toc-sec-introduction-system-architecture-evolution-0661" class="nav-link" data-scroll-target="#sec-introduction-system-architecture-evolution-0661">System Architecture Evolution</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-introduction-practical-applications-cd2d" id="toc-sec-introduction-practical-applications-cd2d" class="nav-link" data-scroll-target="#sec-introduction-practical-applications-cd2d">Practical Applications</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-farmbeats-ml-agriculture-4a1e" id="toc-sec-introduction-farmbeats-ml-agriculture-4a1e" class="nav-link" data-scroll-target="#sec-introduction-farmbeats-ml-agriculture-4a1e">FarmBeats: ML in Agriculture</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-data-considerations-d32a" id="toc-sec-introduction-data-considerations-d32a" class="nav-link" data-scroll-target="#sec-introduction-data-considerations-d32a">Data Considerations</a></li>
  <li><a href="#sec-introduction-algorithmic-considerations-eed0" id="toc-sec-introduction-algorithmic-considerations-eed0" class="nav-link" data-scroll-target="#sec-introduction-algorithmic-considerations-eed0">Algorithmic Considerations</a></li>
  <li><a href="#sec-introduction-infrastructure-considerations-639d" id="toc-sec-introduction-infrastructure-considerations-639d" class="nav-link" data-scroll-target="#sec-introduction-infrastructure-considerations-639d">Infrastructure Considerations</a></li>
  <li><a href="#sec-introduction-future-implications-f705" id="toc-sec-introduction-future-implications-f705" class="nav-link" data-scroll-target="#sec-introduction-future-implications-f705">Future Implications</a></li>
  </ul></li>
  <li><a href="#sec-introduction-alphafold-scientific-ml-3aba" id="toc-sec-introduction-alphafold-scientific-ml-3aba" class="nav-link" data-scroll-target="#sec-introduction-alphafold-scientific-ml-3aba">AlphaFold: Scientific ML</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-data-considerations-8ae1" id="toc-sec-introduction-data-considerations-8ae1" class="nav-link" data-scroll-target="#sec-introduction-data-considerations-8ae1">Data Considerations</a></li>
  <li><a href="#sec-introduction-algorithmic-considerations-098e" id="toc-sec-introduction-algorithmic-considerations-098e" class="nav-link" data-scroll-target="#sec-introduction-algorithmic-considerations-098e">Algorithmic Considerations</a></li>
  <li><a href="#sec-introduction-infrastructure-considerations-89ec" id="toc-sec-introduction-infrastructure-considerations-89ec" class="nav-link" data-scroll-target="#sec-introduction-infrastructure-considerations-89ec">Infrastructure Considerations</a></li>
  <li><a href="#sec-introduction-future-implications-4168" id="toc-sec-introduction-future-implications-4168" class="nav-link" data-scroll-target="#sec-introduction-future-implications-4168">Future Implications</a></li>
  </ul></li>
  <li><a href="#sec-introduction-autonomous-vehicles-ml-2164" id="toc-sec-introduction-autonomous-vehicles-ml-2164" class="nav-link" data-scroll-target="#sec-introduction-autonomous-vehicles-ml-2164">Autonomous Vehicles</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-data-considerations-fdab" id="toc-sec-introduction-data-considerations-fdab" class="nav-link" data-scroll-target="#sec-introduction-data-considerations-fdab">Data Considerations</a></li>
  <li><a href="#sec-introduction-algorithmic-considerations-e223" id="toc-sec-introduction-algorithmic-considerations-e223" class="nav-link" data-scroll-target="#sec-introduction-algorithmic-considerations-e223">Algorithmic Considerations</a></li>
  <li><a href="#sec-introduction-infrastructure-considerations-503b" id="toc-sec-introduction-infrastructure-considerations-503b" class="nav-link" data-scroll-target="#sec-introduction-infrastructure-considerations-503b">Infrastructure Considerations</a></li>
  <li><a href="#sec-introduction-future-implications-7552" id="toc-sec-introduction-future-implications-7552" class="nav-link" data-scroll-target="#sec-introduction-future-implications-7552">Future Implications</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-introduction-challenges-ml-systems-f08f" id="toc-sec-introduction-challenges-ml-systems-f08f" class="nav-link" data-scroll-target="#sec-introduction-challenges-ml-systems-f08f">Challenges in ML Systems</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-datarelated-challenges-5b58" id="toc-sec-introduction-datarelated-challenges-5b58" class="nav-link" data-scroll-target="#sec-introduction-datarelated-challenges-5b58">Data-Related Challenges</a></li>
  <li><a href="#sec-introduction-modelrelated-challenges-ae5a" id="toc-sec-introduction-modelrelated-challenges-ae5a" class="nav-link" data-scroll-target="#sec-introduction-modelrelated-challenges-ae5a">Model-Related Challenges</a></li>
  <li><a href="#sec-introduction-systemrelated-challenges-3c6a" id="toc-sec-introduction-systemrelated-challenges-3c6a" class="nav-link" data-scroll-target="#sec-introduction-systemrelated-challenges-3c6a">System-Related Challenges</a></li>
  <li><a href="#sec-introduction-ethical-considerations-5c13" id="toc-sec-introduction-ethical-considerations-5c13" class="nav-link" data-scroll-target="#sec-introduction-ethical-considerations-5c13">Ethical Considerations</a></li>
  </ul></li>
  <li><a href="#sec-introduction-looking-ahead-532e" id="toc-sec-introduction-looking-ahead-532e" class="nav-link" data-scroll-target="#sec-introduction-looking-ahead-532e">Looking Ahead</a></li>
  <li><a href="#sec-introduction-book-structure-learning-path-411f" id="toc-sec-introduction-book-structure-learning-path-411f" class="nav-link" data-scroll-target="#sec-introduction-book-structure-learning-path-411f">Book Structure and Learning Path</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers">Self-Check Answers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Systems Foundations</a></li><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Introduction</a></li></ol></nav></header>




<section id="introduction" class="level1 page-columns page-full">
<h1>Introduction</h1>
<div class="{layout-narrow} page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="">
<p><em>DALL·E 3 Prompt: A detailed, rectangular, flat 2D illustration depicting a roadmap of a book’s chapters on machine learning systems, set on a crisp, clean white background. The image features a winding road traveling through various symbolic landmarks. Each landmark represents a chapter topic: Introduction, ML Systems, Deep Learning, AI Workflow, Data Engineering, AI Frameworks, AI Training, Efficient AI, Model Optimizations, AI Acceleration, Benchmarking AI, On-Device Learning, Embedded AIOps, Security &amp; Privacy, Responsible AI, Sustainable AI, AI for Good, Robust AI, Generative AI. The style is clean, modern, and flat, suitable for a technical book, with each landmark clearly labeled with its chapter title.</em></p>
</div></div><p> <img src="images/png/cover_introduction.png" class="img-fluid"></p>
</div>
<section id="purpose" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="purpose">Purpose</h2>
<p><em>What does it mean to engineer machine learning systems—not just design models?</em></p>
<p>As machine learning becomes deeply embedded in the fabric of modern technology, it is no longer sufficient to treat it purely as an algorithmic or theoretical pursuit. We start by framing the field of Machine Learning Systems Engineering as a discipline that unites the science of learning with the practical realities of deployment, scale, and infrastructure. It explores how this emerging discipline extends beyond model development to encompass the full lifecycle of intelligent systems—from data to deployment, from theory to engineering practice. Understanding this perspective is essential for anyone seeking to build AI systems that are not only powerful, but also reliable, efficient, and grounded in real-world constraints.</p>
</section>
<section id="sec-introduction-ai-pervasiveness-8869" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ai-pervasiveness-8869">AI Pervasiveness</h2>
<p>Artificial Intelligence (AI) has emerged as one of the most transformative forces in human history. From the moment we wake up to when we go to sleep, AI systems invisibly shape our world. They manage traffic flows in our cities, optimize power distribution across electrical grids, and enable billions of wireless devices to communicate seamlessly. In hospitals, AI analyzes medical images and helps doctors diagnose diseases. In research laboratories, it accelerates scientific discovery by simulating molecular interactions and processing vast datasets from particle accelerators. In space exploration, it helps rovers navigate distant planets and telescopes detect new celestial phenomena.</p>
<p>Throughout history, certain technologies have fundamentally transformed human civilization, defining their eras. The 18th and 19th centuries were shaped by the Industrial Revolution, where steam power and mechanization transformed how humans could harness physical energy. The 20th century was defined by the Digital Revolution, where the computer and internet transformed how we process and share information. Now, the 21st century appears to be the era of Artificial Intelligence, a shift noted by leading thinkers in technological evolution <span class="citation" data-cites="brynjolfsson2014second domingos2015master">(<a href="#ref-brynjolfsson2014second" role="doc-biblioref">Brynjolfsson and McAfee 2014</a>; <a href="#ref-domingos2015master" role="doc-biblioref">Domingos 2016</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-brynjolfsson2014second" class="csl-entry" role="listitem">
Brynjolfsson, Erik, and Andrew McAfee. 2014. <em>The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, 1st Edition.</em> W. W. Norton Company.
</div><div id="ref-domingos2015master" class="csl-entry" role="listitem">
Domingos, Pedro. 2016. <span>“The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World.”</span> <em>Choice Reviews Online</em> 53 (07): 53–3100. <a href="https://doi.org/10.5860/choice.194685">https://doi.org/10.5860/choice.194685</a>.
</div></div><p>The vision driving AI development extends far beyond the practical applications we see today. We aspire to create systems that can work alongside humanity, enhancing our problem-solving capabilities and accelerating scientific progress. Imagine AI systems that could help us understand consciousness, decode the complexities of biological systems, or unravel the mysteries of dark matter. Consider the potential of AI to help address global challenges like climate change, disease, or sustainable energy production. This is not just about automation or efficiency—it’s about expanding the boundaries of human knowledge and capability.</p>
<p>The impact of this revolution operates at multiple scales, each with profound implications. At the individual level, AI personalizes our experiences and augments our daily decision-making capabilities. At the organizational level, it transforms how businesses operate and how research institutions make discoveries. At the societal level, it reshapes everything from transportation systems to healthcare delivery. At the global level, it offers new approaches to addressing humanity’s greatest challenges, from climate change to drug discovery.</p>
<p>What makes this transformation unique is its unprecedented pace. While the Industrial Revolution unfolded over centuries and the Digital Revolution over decades, AI capabilities are advancing at an extraordinary rate. Technologies that seemed impossible just years ago, including systems that can understand human speech, generate novel ideas, or make complex decisions, are now commonplace. This acceleration suggests we are only beginning to understand how profoundly AI will reshape our world.</p>
<p>We stand at a historic inflection point. Just as the Industrial Revolution required us to master mechanical engineering to harness the power of steam and machinery, and the Digital Revolution demanded expertise in electrical and computer engineering to build the internet age, the AI Revolution presents us with a new engineering challenge. We must learn to build systems that can learn, reason, and potentially achieve superhuman capabilities in specific domains.</p>
</section>
<section id="sec-introduction-ai-ml-basics-041a" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ai-ml-basics-041a">AI and ML Basics</h2>
<p>The exploration of artificial intelligence’s transformative impact across society presents a fundamental question: How can we create these intelligent capabilities? Understanding the relationship between AI and ML provides the theoretical and practical framework necessary to address this question.</p>
<p>Artificial Intelligence represents the systematic pursuit of understanding and replicating intelligent behavior—specifically, the capacity to learn, reason, and adapt to new situations. It encompasses fundamental questions about the nature of intelligence, knowledge, and learning. How do we recognize patterns? How do we learn from experience? How do we adapt our behavior based on new information? AI as a field explores these questions, drawing insights from cognitive science, psychology, neuroscience, and computer science.</p>
<p>Machine Learning, in contrast, constitutes the methodological approach to creating systems that demonstrate intelligent behavior. Instead of implementing intelligence through predetermined rules, machine learning systems utilize gradient descent<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and other optimization techniques to identify patterns and relationships. This methodology reflects fundamental learning processes observed in biological systems. For instance, object recognition in machine learning systems parallels human visual learning processes, requiring exposure to numerous examples to develop robust recognition capabilities. Similarly, natural language processing systems acquire linguistic capabilities through extensive analysis of textual data.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<strong>Gradient Descent</strong>: An optimization algorithm that iteratively adjusts model parameters to minimize prediction errors by following the gradient (slope) of the error surface, similar to finding the bottom of a valley by always walking downhill.</p></div></div><p>The relationship between AI and ML exemplifies the connection between theoretical understanding and practical engineering implementation observed in other scientific fields. For instance, physics provides the theoretical foundation for mechanical engineering’s practical applications in structural design and machinery, while AI’s theoretical frameworks inform machine learning’s practical development of intelligent systems. Similarly, electrical engineering’s transformation of electromagnetic theory into functional power systems parallels machine learning’s implementation of intelligence theories into operational ML systems.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="AI and ML: Key Definitions">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
AI and ML: Key Definitions
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><strong>Artificial Intelligence (AI)</strong>: The goal of creating machines that can match or exceed human intelligence—representing humanity’s quest to build systems that can think, reason, and adapt.</p></li>
<li><p><strong>Machine Learning (ML)</strong>: The scientific discipline of understanding how systems can learn and improve from experience—providing the theoretical foundation for building intelligent systems.</p></li>
</ul>
</div>
</div>
<p>The emergence of machine learning as a viable scientific discipline approach to artificial intelligence resulted from extensive research and fundamental paradigm shifts in the field. The progression of artificial intelligence encompasses both theoretical advances in understanding intelligence and practical developments in implementation methodologies. This development mirrors the evolution of other scientific and engineering disciplines—from mechanical engineering’s advancement from basic force principles to contemporary robotics, to electrical engineering’s progression from fundamental electromagnetic theory to modern power and communication networks. Analysis of this historical trajectory reveals both the technological innovations leading to current machine learning approaches and the emergence of deep reinforcement learning<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> that inform contemporary AI system development.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;<strong>Deep Reinforcement Learning</strong>: A machine learning approach that combines deep neural networks with reinforcement learning principles, allowing agents to learn optimal actions through trial and error interaction with an environment while receiving rewards or penalties.</p></div></div><div id="quiz-question-sec-introduction-ai-ml-basics-041a" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.1</strong></summary><div>
<ol type="1">
<li><p>Explain how the relationship between AI and ML is similar to the relationship between physics and mechanical engineering.</p></li>
<li><p>True or False: Machine Learning systems implement intelligence through predetermined rules.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ai-ml-basics-041a" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ai-evolution-0dd8" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ai-evolution-0dd8">AI Evolution</h2>
<p>The evolution of AI, depicted in the timeline shown in <a href="#fig-ai-timeline" class="quarto-xref">Figure&nbsp;1</a>, highlights key milestones such as the development of the perceptron<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> in 1957 by Frank Rosenblatt, a foundational element for modern neural networks. Imagine walking into a computer lab in 1965. You’d find room-sized mainframes running programs that could prove basic mathematical theorems or play simple games like tic-tac-toe. These early artificial intelligence systems, while groundbreaking for their time, were a far cry from today’s machine learning systems that can detect cancer in medical images or understand human speech. The timeline shows the progression from early innovations like the ELIZA chatbot in 1966, to significant breakthroughs such as IBM’s Deep Blue defeating chess champion Garry Kasparov in 1997. More recent advancements include the introduction of OpenAI’s GPT-3 in 2020 and GPT-4 in 2023, demonstrating the dramatic evolution and increasing complexity of AI systems over the decades.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<strong>Perceptron</strong>: The first artificial neural network—a simple model that could learn to classify visual patterns, similar to a single neuron making a yes/no decision based on its inputs.</p></div></div><div id="fig-ai-timeline" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="t!" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="25cf57367aa5f23646232b9ae71c6b1104010d47.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: AI Development Timeline: Early AI research focused on symbolic reasoning and rule-based systems, while modern AI leverages data-driven approaches like neural networks to achieve increasingly complex tasks. This progression exposes a shift from hand-coded intelligence to learned intelligence, marked by milestones such as the perceptron, deep blue, and large language models like GPT-3."><img src="introduction_files/mediabag/25cf57367aa5f23646232b9ae71c6b1104010d47.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>AI Development Timeline</strong>: Early AI research focused on symbolic reasoning and rule-based systems, while modern AI leverages data-driven approaches like neural networks to achieve increasingly complex tasks. This progression exposes a shift from hand-coded intelligence to learned intelligence, marked by milestones such as the perceptron, deep blue, and large language models like GPT-3.
</figcaption>
</figure>
</div>
<p>Let’s explore how we got here.</p>
<section id="sec-introduction-symbolic-ai-era-acc4" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-symbolic-ai-era-acc4">Symbolic AI Era</h3>
<p>The story of machine learning begins at the historic Dartmouth Conference in 1956, where pioneers like John McCarthy, Marvin Minsky, and Claude Shannon first coined the term “artificial intelligence.” Their approach was based on a compelling idea: intelligence could be reduced to symbol manipulation. Consider Daniel Bobrow’s STUDENT system from 1964, one of the first AI programs that could solve algebra word problems. It was one of the first AI programs to demonstrate natural language understanding by converting English text into algebraic equations, marking an important milestone in symbolic AI.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Example: STUDENT (1964)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: STUDENT (1964)
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>Problem: "If the number of customers Tom gets is twice the
square of 20% of the number of advertisements he runs, and
the number of advertisements is 45, what is the number of
customers Tom gets?"

STUDENT would:

1. Parse the English text
2. Convert it to algebraic equations
3. Solve the equation: n = 2(0.2 × 45)²
4. Provide the answer: 162 customers</code></pre>
</div>
</div>
<p>Early AI like STUDENT suffered from a fundamental limitation: they could only handle inputs that exactly matched their pre-programmed patterns and rules. Imagine a language translator that only works when sentences follow perfect grammatical structure; even slight variations, such as changing word order, using synonyms, or natural speech patterns, would cause the STUDENT to fail. This “brittleness” meant that while these solutions could appear intelligent when handling very specific cases they were designed for, they would break down completely when faced with even minor variations or real-world complexity. This limitation wasn’t just a technical inconvenience—it revealed a deeper problem with rule-based approaches to AI: they couldn’t genuinely understand or generalize from their programming, they could only match and manipulate patterns exactly as specified.</p>
</section>
<section id="sec-introduction-expert-systems-era-c061" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-expert-systems-era-c061">Expert Systems Era</h3>
<p>By the mid-1970s, researchers realized that general AI was too ambitious. Instead, they focused on capturing human expert knowledge in specific domains. MYCIN, developed at Stanford, was one of the first large-scale expert systems designed to diagnose blood infections.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Example: MYCIN (1976)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: MYCIN (1976)
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>Rule Example from MYCIN:
IF
  The infection is primary-bacteremia
  The site of the culture is one of the sterile sites
  The suspected portal of entry is the gastrointestinal tract
THEN
  Found suggestive evidence (0.7) that infection is bacteroid</code></pre>
</div>
</div>
<p>While MYCIN represented a major advance in medical AI with its 600 expert rules for diagnosing blood infections, it revealed fundamental challenges that still plague ML today. Getting domain knowledge from human experts and converting it into precise rules proved incredibly time-consuming and difficult—doctors often couldn’t explain exactly how they made decisions. MYCIN struggled with uncertain or incomplete information, unlike human doctors who could make educated guesses. Perhaps most importantly, maintaining and updating the rule base became exponentially more complex as MYCIN grew, as adding new rules frequently conflicted with existing ones, while medical knowledge itself continued to evolve. These same challenges of knowledge capture, uncertainty handling, and maintenance remain central concerns in modern machine learning, even though we now use different technical approaches to address them.</p>
</section>
<section id="sec-introduction-statistical-learning-era-6d5b" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-statistical-learning-era-6d5b">Statistical Learning Era</h3>
<p>The 1990s marked a radical transformation in artificial intelligence as the field moved away from hand-coded rules toward statistical learning approaches. This wasn’t a simple choice—it was driven by three converging factors that made statistical methods both possible and powerful. The digital revolution meant massive amounts of data were suddenly available to train the algorithms. Moore’s Law<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> delivered the computational power needed to process this data effectively. And researchers developed new algorithms like Support Vector Machines and improved neural networks that could actually learn patterns from this data rather than following pre-programmed rules. This combination fundamentally changed how we built AI: instead of trying to encode human knowledge directly, we could now let machines discover patterns automatically from examples, leading to more robust and adaptable AI.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;<strong>Moore’s Law</strong>: The observation made by Intel co-founder Gordon Moore in 1965 that the number of transistors on a microchip doubles approximately every two years, while the cost halves. This exponential growth in computing power has been a key driver of advances in machine learning, though the pace has begun to slow in recent years.</p></div></div><p>Consider how email spam filtering evolved:</p>
<div class="callout callout-style-default callout-note callout-titled" title="Example: Early Spam Detection Systems">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Early Spam Detection Systems
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>Rule-based (1980s):
IF contains("viagra") OR contains("winner") THEN spam

Statistical (1990s):
P(spam|word) = (frequency in spam emails) / (total frequency)

Combined using Naive Bayes:
P(spam|email) ∝ P(spam) × ∏ P(word|spam)</code></pre>
</div>
</div>
<p>The move to statistical approaches fundamentally changed how we think about building AI by introducing three core concepts that remain important today. First, the quality and quantity of training data became as important as the algorithms themselves. AI could only learn patterns that were present in its training examples. Second, we needed rigorous ways to evaluate how well AI actually performed, leading to metrics that could measure success and compare different approaches. Third, we discovered an inherent tension between precision (being right when we make a prediction) and recall (catching all the cases we should find), forcing designers to make explicit trade-offs based on their application’s needs. For example, a spam filter might tolerate some spam to avoid blocking important emails, while medical diagnosis might need to catch every potential case even if it means more false alarms.</p>
<p><a href="#tbl-ai-evolution-strengths" class="quarto-xref">Table&nbsp;1</a> encapsulates the evolutionary journey of AI approaches we have discussed so far, highlighting the key strengths and capabilities that emerged with each new paradigm. As we move from left to right across the table, we can observe several important trends. We will talk about shallow and deep learning next, but it is useful to understand the trade-offs between the approaches we have covered so far.</p>
<div id="tbl-ai-evolution-strengths" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ai-evolution-strengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: <strong>AI Paradigm Evolution</strong>: Shifting from symbolic AI to statistical approaches fundamentally changed machine learning by prioritizing data quantity and quality, enabling rigorous performance evaluation, and necessitating explicit trade-offs between precision and recall to optimize system behavior for specific applications. The table outlines how each paradigm addressed these challenges, revealing a progression towards data-driven systems capable of handling complex, real-world problems.
</figcaption>
<div aria-describedby="tbl-ai-evolution-strengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspect</th>
<th style="text-align: left;">Symbolic AI</th>
<th style="text-align: left;">Expert Systems</th>
<th style="text-align: left;">Statistical Learning</th>
<th style="text-align: left;">Shallow / Deep Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Key Strength</td>
<td style="text-align: left;">Logical reasoning</td>
<td style="text-align: left;">Domain expertise</td>
<td style="text-align: left;">Versatility</td>
<td style="text-align: left;">Pattern recognition</td>
</tr>
<tr class="even">
<td style="text-align: left;">Best Use Case</td>
<td style="text-align: left;">Well-defined, rule-based problems</td>
<td style="text-align: left;">Specific domain problems</td>
<td style="text-align: left;">Various structured data problems</td>
<td style="text-align: left;">Complex, unstructured data problems</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Data Handling</td>
<td style="text-align: left;">Minimal data needed</td>
<td style="text-align: left;">Domain knowledge-based</td>
<td style="text-align: left;">Moderate data required</td>
<td style="text-align: left;">Large-scale data processing</td>
</tr>
<tr class="even">
<td style="text-align: left;">Adaptability</td>
<td style="text-align: left;">Fixed rules</td>
<td style="text-align: left;">Domain-specific adaptability</td>
<td style="text-align: left;">Adaptable to various domains</td>
<td style="text-align: left;">Highly adaptable to diverse tasks</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Problem Complexity</td>
<td style="text-align: left;">Simple, logic-based</td>
<td style="text-align: left;">Complicated, domain- specific</td>
<td style="text-align: left;">Complex, structured</td>
<td style="text-align: left;">Highly complex, unstructured</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The table serves as a bridge between the early approaches we’ve discussed and the more recent developments in shallow and deep learning that we’ll explore next. It sets the stage for understanding why certain approaches gained prominence in different eras and how each new paradigm built upon and addressed the limitations of its predecessors. Moreover, it illustrates how the strengths of earlier approaches continue to influence and enhance modern AI techniques, particularly in the era of foundation models.</p>
</section>
<section id="sec-introduction-shallow-learning-era-b2a9" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-shallow-learning-era-b2a9">Shallow Learning Era</h3>
<p>The 2000s marked a fascinating period in machine learning history that we now call the ``shallow learning’’ era. To understand why it’s “shallow,” imagine building a house: deep learning (which came later) is like having multiple construction crews working at different levels simultaneously, each crew learning from the work of crews below them. In contrast, shallow learning typically had just one or two levels of processing, similar to having just a foundation crew and a framing crew.</p>
<p>During this time, several powerful algorithms dominated the machine learning landscape. Each brought unique strengths to different problems: Decision trees provided interpretable results by making choices much like a flowchart. K-nearest neighbors made predictions by finding similar examples in past data, like asking your most experienced neighbors for advice. Linear and logistic regression offered straightforward, interpretable models that worked well for many real-world problems. Support Vector Machines (SVMs) excelled at finding complex boundaries between categories using the “kernel trick”—imagine being able to untangle a bowl of spaghetti into straight lines by lifting it into a higher dimension. These algorithms formed the foundation of practical machine learning.</p>
<p>Consider a typical computer vision solution from 2005:</p>
<div class="callout callout-style-default callout-note callout-titled" title="Example: Traditional Computer Vision Pipeline">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Traditional Computer Vision Pipeline
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>1. Manual Feature Extraction
  - SIFT (Scale-Invariant Feature Transform)
  - HOG (Histogram of Oriented Gradients)
  - Gabor filters
2. Feature Selection/Engineering
3. "Shallow" Learning Model (e.g., SVM)
4. Post-processing</code></pre>
</div>
</div>
<p>What made this era distinct was its hybrid approach: human-engineered features combined with statistical learning. They had strong mathematical foundations (researchers could prove why they worked). They performed well even with limited data. They were computationally efficient. They produced reliable, reproducible results.</p>
<p>Take the example of face detection, where the Viola-Jones algorithm (2001) achieved real-time performance using simple rectangular features and a cascade of classifiers. This algorithm powered digital camera face detection for nearly a decade.</p>
</section>
<section id="sec-introduction-deep-learning-era-bd1a" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-deep-learning-era-bd1a">Deep Learning Era</h3>
<p>While Support Vector Machines excelled at finding complex boundaries between categories using mathematical transformations, deep learning took a radically different approach inspired by the human brain’s architecture. Deep learning is built from layers of artificial neurons<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, where each layer learns to transform its input data into increasingly abstract representations. Imagine processing an image of a cat: the first layer might learn to detect simple edges and contrasts, the next layer combines these into basic shapes and textures, another layer might recognize whiskers and pointy ears, and the final layers assemble these features into the concept of “cat.”</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<strong>Artificial Neurons</strong>: Basic computational units in neural networks that mimic biological neurons, taking multiple inputs, applying weights and biases, and producing an output signal through an activation function.</p></div></div><p>Unlike shallow learning methods that required humans to carefully engineer features, deep learning networks can automatically discover useful features directly from raw data. This ability to learn hierarchical representations, ranging from simple to complex and concrete to abstract, is what makes deep learning “deep,” and it turned out to be a remarkably powerful approach for handling complex, real-world data like images, speech, and text.</p>
<p>In 2012, a deep neural network called AlexNet, shown in <a href="#fig-alexnet" class="quarto-xref">Figure&nbsp;2</a>, achieved a breakthrough in the ImageNet competition that would transform the field of machine learning. The challenge was formidable: correctly classify 1.2 million high-resolution images into 1,000 different categories. While previous approaches struggled with error rates above 25%, AlexNet<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> achieved a 15.3% error rate, dramatically outperforming all existing methods.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;A breakthrough deep neural network from 2012 that won the ImageNet competition by a large margin and helped spark the deep learning revolution.</p></div></div><p>The success of AlexNet wasn’t just a technical achievement; it was a watershed moment that demonstrated the practical viability of deep learning. It showed that with sufficient data, computational power, and architectural innovations, neural networks could outperform hand-engineered features and shallow learning methods that had dominated the field for decades. This single result triggered an explosion of research and applications in deep learning that continues to this day.</p>
<div id="fig-alexnet" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="719f646bcb413a020dff4682273395e92c893105.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Convolutional Neural Network Architecture: AlexNet pioneered the use of deep convolutional layers to automatically learn hierarchical feature representations from images, enabling significant improvements in image classification accuracy. By stacking convolutional layers with max-pooling, and culminating in fully connected layers, the network transforms raw pixel data into abstract features suitable for classification tasks."><img src="introduction_files/mediabag/719f646bcb413a020dff4682273395e92c893105.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <strong>Convolutional Neural Network Architecture</strong>: AlexNet pioneered the use of deep convolutional layers to automatically learn hierarchical feature representations from images, enabling significant improvements in image classification accuracy. By stacking convolutional layers with max-pooling, and culminating in fully connected layers, the network transforms raw pixel data into abstract features suitable for classification tasks.
</figcaption>
</figure>
</div>
<p>From this foundation, deep learning entered an era of unprecedented scale. By the late 2010s, companies like Google, Facebook, and OpenAI were training neural networks thousands of times larger than AlexNet. These massive models, often called “foundation models,” took deep learning to new heights. GPT-3, released in 2020, contained 175 billion parameters<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>—imagine a student that could read through all of Wikipedia multiple times and learn patterns from every article. These models showed remarkable abilities: writing human-like text, engaging in conversation, generating images from descriptions, and even writing computer code. The key insight was simple but powerful: as we made neural networks bigger and fed them more data, they became capable of solving increasingly complex tasks. However, this scale brought unprecedented systems challenges: how do you efficiently train models that require thousands of GPUs working in parallel? How do you store and serve models that are hundreds of gigabytes in size? How do you handle the massive datasets needed for training?</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;<strong>Parameters</strong>: The adjustable values within a neural network that are modified during training, similar to how the brain’s neural connections grow stronger as you learn a new skill. Having more parameters generally means that the model can learn more complex patterns.</p></div><div id="fn8"><p><sup>8</sup>&nbsp;<strong>Convolutional Neural Network (CNN)</strong>: A type of neural network specially designed for processing images, inspired by how the human visual system works. The “convolutional” part refers to how it scans images in small chunks, similar to how our eyes focus on different parts of a scene.</p></div></div><p>The deep learning revolution of 2012 didn’t emerge from nowhere, as it was founded on neural network research dating back to the 1950s. The story begins with Frank Rosenblatt’s Perceptron in 1957, which captured the imagination of researchers by showing how a simple artificial neuron could learn to classify patterns. While it could only handle linearly separable problems, a limitation that was dramatically highlighted by Minsky and Papert’s 1969 book, “Perceptrons,” it introduced the fundamental concept of trainable neural networks. The 1980s brought more important breakthroughs: Rumelhart, Hinton, and Williams introduced backpropagation in 1986, providing a systematic way to train multi-layer networks, while Yann LeCun demonstrated its practical application in recognizing handwritten digits using convolutional neural networks (CNNs)<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.</p>
<p>Yet these networks largely languished through the 1990s and 2000s, not because the ideas were wrong, but because they were ahead of their time. The field lacked three important ingredients: sufficient data to train complex networks, enough computational power to process this data, and the technical innovations needed to train very deep networks effectively.</p>


<div class="no-row-height column-margin column-container"><div class="">
  <div class="margin-video">
    <iframe src="https://www.youtube.com/embed/FwFduRA_L6Q?start=" style="width:100%; aspect-ratio: ; border:0;" allowfullscreen="">
    </iframe>
  </div>
  <p><em>Convolutional Network Demo from 1989 - Yann LeCun</em></p>
</div></div><p>The field had to wait for the convergence of big data, better computing hardware, and algorithmic breakthroughs before deep learning’s potential could be unlocked. This long gestation period helps explain why the 2012 ImageNet moment was less a sudden revolution and more the culmination of decades of accumulated research finally finding its moment. As we’ll explore in the following sections, this evolution has led to two significant developments in the field. First, it has given rise to define the field of machine learning systems engineering, a discipline that teaches how to bridge the gap between theoretical advancements and practical implementation. Second, it has necessitated a more comprehensive definition of machine learning systems, one that encompasses not just algorithms, but also data and computing infrastructure. Today’s challenges of scale echo many of the same fundamental questions about computation, data, and learning methods that researchers have grappled with since the field’s inception, but now within a more complex and interconnected framework.</p>
<p>As AI progressed from symbolic reasoning to statistical learning and deep learning, its applications became increasingly ambitious and complex. This growth introduced challenges that extended beyond algorithms, necessitating a new focus: engineering entire systems capable of deploying and sustaining AI at scale. This gave rise to the discipline of Machine Learning Systems Engineering.</p>
<div id="quiz-question-sec-introduction-ai-evolution-0dd8" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.2</strong></summary><div>
<ol type="1">
<li><p>Which AI era introduced the concept of using statistical methods to learn patterns from data rather than following pre-programmed rules?</p>
<ol type="a">
<li>Symbolic AI Era</li>
<li>Expert Systems Era</li>
<li>Statistical Learning Era</li>
<li>Deep Learning Era</li>
</ol></li>
<li><p>Explain why the transition from rule-based AI to statistical learning was significant for the development of modern machine learning systems.</p></li>
<li><p>True or False: The Deep Learning Era solved all the challenges faced by previous AI paradigms.</p></li>
<li><p>Order the following AI eras chronologically: Expert Systems Era, Symbolic AI Era, Statistical Learning Era, Deep Learning Era.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ai-evolution-0dd8" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-introduction-ml-systems-engineering-c9fb" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-ml-systems-engineering-c9fb">ML Systems Engineering</h2>
<p>The story we’ve traced, from the early days of the Perceptron through the deep learning revolution, has largely been one of algorithmic breakthroughs. Each era brought new mathematical insights and modeling approaches that pushed the boundaries of what AI could achieve. But something important changed over the past decade: the success of AI systems became increasingly dependent not just on algorithmic innovations, but on sophisticated engineering.</p>
<p>This shift mirrors the evolution of computer science and engineering in the late 1960s and early 1970s. During that period, as computing systems grew more complex, a new discipline emerged: Computer Engineering. This field bridged the gap between Electrical Engineering’s hardware expertise and Computer Science’s focus on algorithms and software. Computer Engineering arose because the challenges of designing and building complex computing systems required an integrated approach that neither discipline could fully address on its own.</p>
<p>Today, we’re witnessing a similar transition in the field of AI. While Computer Science continues to push the boundaries of ML algorithms and Electrical Engineering advances specialized AI hardware, neither discipline fully addresses the engineering principles needed to deploy, optimize, and sustain ML systems at scale. This gap highlights the need for a new discipline: Machine Learning Systems Engineering.</p>
<p>There is no explicit definition of what this field is as such today, but it can be broadly defined as such:</p>
<div class="callout callout-style-default callout-note callout-titled" title="Definition of Machine Learning Systems Engineering">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of Machine Learning Systems Engineering
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Machine Learning Systems Engineering (MLSysEng)</strong> is the engineering discipline focused on building <em>reliable</em>, <em>efficient</em>, and <em>scalable</em> AI systems across computational platforms, ranging from <em>embedded devices</em> to <em>data centers</em>. It spans the entire AI lifecycle, including <em>data acquisition</em>, <em>model development</em>, <em>system integration</em>, <em>deployment</em>, and <em>operations</em>, with an emphasis on <em>resource-awareness</em> and <em>system-level optimization</em>.</p>
</div>
</div>
<p>Let’s consider space exploration. While astronauts venture into new frontiers and explore the vast unknowns of the universe, their discoveries are only possible because of the complex engineering systems supporting them, such as the rockets that lift them into space, the life support systems that keep them alive, and the communication networks that keep them connected to Earth. Similarly, while AI researchers push the boundaries of what’s possible with learning algorithms, their breakthroughs only become practical reality through careful systems engineering. Modern AI systems need robust infrastructure to collect and manage data, powerful computing systems to train models, and reliable deployment platforms to serve millions of users.</p>
<p>This emergence of machine learning systems engineering as a important discipline reflects a broader reality: turning AI algorithms into real-world systems requires bridging the gap between theoretical possibilities and practical implementation. It’s not enough to have a brilliant algorithm if you can’t efficiently collect and process the data it needs, distribute its computation across hundreds of machines, serve it reliably to millions of users, or monitor its performance in production.</p>
<p>Understanding this interplay between algorithms and engineering has become fundamental for modern AI practitioners. While researchers continue to push the boundaries of what’s algorithmically possible, engineers are tackling the complex challenge of making these algorithms work reliably and efficiently in the real world. This brings us to a fundamental question: what exactly is a machine learning system, and what makes it different from traditional software systems?</p>
<div id="quiz-question-sec-introduction-ml-systems-engineering-c9fb" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.3</strong></summary><div>
<ol type="1">
<li><p>Machine Learning Systems Engineering focuses on building AI systems that are reliable, efficient, and ____ across computational platforms.</p></li>
<li><p>Which of the following best describes the role of Machine Learning Systems Engineering in AI development?</p>
<ol type="a">
<li>Developing new AI algorithms</li>
<li>Optimizing and deploying AI systems at scale</li>
<li>Creating specialized AI hardware</li>
<li>Focusing solely on data acquisition</li>
</ol></li>
<li><p>Explain why Machine Learning Systems Engineering is necessary for the practical implementation of AI systems.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ml-systems-engineering-c9fb" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-defining-ml-systems-8f42" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-defining-ml-systems-8f42">Defining ML Systems</h2>
<p>There’s no universally accepted, clear-cut textbook definition of a machine learning system. This ambiguity stems from the fact that different practitioners, researchers, and industries often refer to machine learning systems in varying contexts and with different scopes. Some might focus solely on the algorithmic aspects, while others might include the entire pipeline from data collection to model deployment. This loose usage of the term reflects the rapidly evolving and multidisciplinary nature of the field.</p>
<p>Given this diversity of perspectives, it is important to establish a clear and comprehensive definition that encompasses all these aspects. In this textbook, we take a holistic approach to machine learning systems, considering not just the algorithms but also the entire ecosystem in which they operate. Therefore, we define a machine learning system as follows:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Definition of a Machine Learning System">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of a Machine Learning System
</div>
</div>
<div class="callout-body-container callout-body">
<p>A machine learning system is an integrated computing system comprising three core components: (1) data that guides algorithmic behavior, (2) learning algorithms that extract patterns from this data, and (3) computing infrastructure that enables both the learning process (i.e., training) and the application of learned knowledge (i.e., inference/serving). Together, these components create a computing system capable of making predictions, generating content, or taking actions based on learned patterns.</p>
</div>
</div>
<p>The core of any machine learning system consists of three interrelated components, as illustrated in <a href="#fig-ai-triangle" class="quarto-xref">Figure&nbsp;3</a>: Models/Algorithms, Data, and Computing Infrastructure. These components form a triangular dependency where each element fundamentally shapes the possibilities of the others. The model architecture dictates both the computational demands for training and inference, as well as the volume and structure of data required for effective learning. The data’s scale and complexity influence what infrastructure is needed for storage and processing, while simultaneously determining which model architectures are feasible. The infrastructure capabilities establish practical limits on both model scale and data processing capacity, creating a framework within which the other components must operate.</p>
<div id="fig-ai-triangle" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-triangle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="a759079bcde839ae3fc7c80d0a6808ea0f79345c.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Component Interdependencies: Machine learning system performance relies on the coordinated interaction of models, data, and computing infrastructure; limitations in any one component constrain the capabilities of the others. Effective system design requires balancing these interdependencies to optimize overall performance and feasibility."><img src="introduction_files/mediabag/a759079bcde839ae3fc7c80d0a6808ea0f79345c.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-triangle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>Component Interdependencies</strong>: Machine learning system performance relies on the coordinated interaction of models, data, and computing infrastructure; limitations in any one component constrain the capabilities of the others. Effective system design requires balancing these interdependencies to optimize overall performance and feasibility.
</figcaption>
</figure>
</div>
<p>Each of these components serves a distinct but interconnected purpose:</p>
<ul>
<li><p><strong>Algorithms</strong>: Mathematical models and methods that learn patterns from data to make predictions or decisions</p></li>
<li><p><strong>Data</strong>: Processes and infrastructure for collecting, storing, processing, managing, and serving data for both training and inference.</p></li>
<li><p><strong>Computing</strong>: Hardware and software infrastructure that enables efficient training, serving, and operation of models at scale.</p></li>
</ul>
<p>The interdependency of these components means no single element can function in isolation. The most sophisticated algorithm cannot learn without data or computing resources to run on. The largest datasets are useless without algorithms to extract patterns or infrastructure to process them. And the most powerful computing infrastructure serves no purpose without algorithms to execute or data to process.</p>
<p>To illustrate these relationships, we can draw an analogy to space exploration. Algorithm developers are like astronauts, who explore new frontiers and make discoveries. Data science teams function like mission control specialists, who ensure the constant flow of critical information and resources necessary to maintain the mission’s operation. Computing infrastructure engineers are like rocket engineers—designing and building the systems that make the mission possible. Just as a space mission requires the seamless integration of astronauts, mission control, and rocket systems, a machine learning system demands the careful orchestration of algorithms, data, and computing infrastructure.</p>
<div id="quiz-question-sec-introduction-defining-ml-systems-8f42" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.4</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the core components of a machine learning system as defined in this textbook?</p>
<ol type="a">
<li>Algorithms, Data, and Computing Infrastructure</li>
<li>Models, Sensors, and Networking</li>
<li>Data, User Interfaces, and Algorithms</li>
<li>Hardware, Software, and User Experience</li>
</ol></li>
<li><p>Explain how the interdependency of algorithms, data, and computing infrastructure shapes the design and capabilities of a machine learning system.</p></li>
<li><p>In the analogy to space exploration, algorithm developers are likened to ____, who explore new frontiers and make discoveries.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-defining-ml-systems-8f42" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-lifecycle-ml-systems-e40e" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-lifecycle-ml-systems-e40e">Lifecycle of ML Systems</h2>
<p>Traditional software systems follow a predictable lifecycle where developers write explicit instructions for computers to execute. These systems are built on decades of established software engineering practices. Version control systems maintain precise histories of code changes. Continuous integration and deployment pipelines automate testing and release processes. Static analysis tools measure code quality and identify potential issues. This infrastructure enables reliable development, testing, and deployment of software systems, following well-defined principles of software engineering.</p>
<p>Machine learning systems represent a fundamental departure from this traditional paradigm. While traditional systems execute explicit programming logic, machine learning systems derive their behavior from patterns in data. This shift from code to data as the primary driver of system behavior introduces new complexities.</p>
<p>As illustrated in <a href="#fig-ml_lifecycle_overview" class="quarto-xref">Figure&nbsp;4</a>, the ML lifecycle consists of interconnected stages from data collection through model monitoring, with feedback loops for continuous improvement when performance degrades or models need enhancement.</p>
<div id="fig-ml_lifecycle_overview" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml_lifecycle_overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="7fe5c375ca4b6b91e493a3bcd4ce3a3debb9bfc1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: ML System Lifecycle: Continuous iteration defines successful machine learning systems, requiring feedback loops to refine models and address performance degradation across data collection, model training, evaluation, and deployment. This cyclical process contrasts with traditional software development and emphasizes the importance of ongoing monitoring and adaptation to maintain system reliability and accuracy in dynamic environments."><img src="introduction_files/mediabag/7fe5c375ca4b6b91e493a3bcd4ce3a3debb9bfc1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml_lifecycle_overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>ML System Lifecycle</strong>: Continuous iteration defines successful machine learning systems, requiring feedback loops to refine models and address performance degradation across data collection, model training, evaluation, and deployment. This cyclical process contrasts with traditional software development and emphasizes the importance of ongoing monitoring and adaptation to maintain system reliability and accuracy in dynamic environments.
</figcaption>
</figure>
</div>
<p>Unlike source code, which changes only when developers modify it, data reflects the dynamic nature of the real world. Changes in data distributions can silently alter system behavior. Traditional software engineering tools, designed for deterministic code-based systems, prove insufficient for managing these data-dependent systems. For example, version control systems that excel at tracking discrete code changes struggle to manage large, evolving datasets. Testing frameworks designed for deterministic outputs must be adapted for probabilistic predictions. This data-dependent nature creates a more dynamic lifecycle, requiring continuous monitoring and adaptation to maintain system relevance as real-world data patterns evolve.</p>
<p>Understanding the machine learning system lifecycle requires examining its distinct stages. Each stage presents unique requirements from both learning and infrastructure perspectives. This dual consideration, of learning needs and systems support, is wildly important for building effective machine learning systems.</p>
<p>However, the various stages of the ML lifecycle in production are not isolated; they are, in fact, deeply interconnected. This interconnectedness can create either virtuous or vicious cycles. In a virtuous cycle, high-quality data enables effective learning, robust infrastructure supports efficient processing, and well-engineered systems facilitate the collection of even better data. However, in a vicious cycle, poor data quality undermines learning, inadequate infrastructure hampers processing, and system limitations prevent the improvement of data collection—each problem compounds the others.</p>
<div id="quiz-question-sec-introduction-lifecycle-ml-systems-e40e" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.5</strong></summary><div>
<ol type="1">
<li><p>Order the following stages of the machine learning system lifecycle: Model Deployment, Data Collection, Model Training, Model Evaluation, Data Preparation, Model Monitoring.</p></li>
<li><p>Which of the following best describes a challenge unique to machine learning systems compared to traditional software systems?</p>
<ol type="a">
<li>Version control of source code</li>
<li>Testing deterministic outputs</li>
<li>Managing evolving datasets</li>
<li>Automating deployment processes</li>
</ol></li>
<li><p>Explain how the interconnected stages of the ML lifecycle can lead to either virtuous or vicious cycles.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-lifecycle-ml-systems-e40e" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ml-systems-wild-e270" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-ml-systems-wild-e270">ML Systems in the Wild</h2>
<p>The complexity of managing machine learning systems becomes even more apparent when we consider the broad spectrum across which ML is deployed today. ML systems exist at vastly different scales and in diverse environments, each presenting unique challenges and constraints.</p>
<p>At one end of the spectrum, we have cloud-based ML systems running in massive data centers. These systems, like large language models or recommendation engines, process petabytes of data and serve millions of users simultaneously. They can leverage virtually unlimited computing resources but must manage enormous operational complexity and costs.</p>
<p>At the other end, we find TinyML systems running on microcontrollers and embedded devices. These systems must perform ML tasks with severe constraints on memory, computing power, and energy consumption. Imagine a smart home device, such as Alexa or Google Assistant, that must recognize voice commands using less power than a LED bulb, or a sensor that must detect anomalies while running on a battery for months or even years.</p>
<p>Between these extremes, we find a rich variety of ML systems adapted for different contexts. Edge ML systems bring computation closer to data sources, reducing latency and bandwidth requirements while managing local computing resources. Mobile ML systems must balance sophisticated capabilities with battery life and processor limitations on smartphones and tablets. Enterprise ML systems often operate within specific business constraints, focusing on particular tasks while integrating with existing infrastructure. Some organizations employ hybrid approaches, distributing ML capabilities across multiple tiers to balance various requirements.</p>
<div id="quiz-question-sec-introduction-ml-systems-wild-e270" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.6</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes a tradeoff faced by cloud-based ML systems?</p>
<ol type="a">
<li>Limited computing resources</li>
<li>High operational complexity and costs</li>
<li>Severe constraints on memory and power</li>
<li>Inability to integrate with existing infrastructure</li>
</ol></li>
<li><p>True or False: TinyML systems are designed to operate with the same resource availability as cloud-based ML systems.</p></li>
<li><p>Explain how edge ML systems can reduce latency and bandwidth requirements.</p></li>
<li><p>Mobile ML systems must balance sophisticated capabilities with ____ life and processor limitations.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ml-systems-wild-e270" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ml-systems-impact-lifecycle-f5f9" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ml-systems-impact-lifecycle-f5f9">ML Systems Impact on Lifecycle</h2>
<p>The diversity of ML systems across the spectrum represents a complex interplay of requirements, constraints, and trade-offs. These decisions fundamentally impact every stage of the ML lifecycle we discussed earlier, from data collection to continuous operation.</p>
<p>Performance requirements often drive initial architectural decisions. Latency-sensitive applications, like autonomous vehicles or real-time fraud detection, might require edge or embedded architectures despite their resource constraints. Conversely, applications requiring massive computational power for training, such as large language models, naturally gravitate toward centralized cloud architectures. However, raw performance is just one consideration in a complex decision space.</p>
<p>Resource management varies dramatically across architectures. Cloud systems must optimize for cost efficiency at scale—balancing expensive GPU clusters, storage systems, and network bandwidth. Edge systems face fixed resource limits and must carefully manage local compute and storage. Mobile and embedded systems operate under the strictest constraints, where every byte of memory and milliwatt of power matters. These resource considerations directly influence both model design and system architecture.</p>
<p>Operational complexity increases with system distribution. While centralized cloud architectures benefit from mature deployment tools and managed services, edge and hybrid systems must handle the complexity of distributed system management. This complexity manifests throughout the ML lifecycle—from data collection and version control to model deployment and monitoring. This operational complexity can compound over time if not carefully managed.</p>
<p>Data considerations often introduce competing pressures. Privacy requirements or data sovereignty regulations might push toward edge or embedded architectures, while the need for large-scale training data might favor cloud approaches. The velocity and volume of data also influence architectural choices—real-time sensor data might require edge processing to manage bandwidth, while batch analytics might be better suited to cloud processing.</p>
<p>Evolution and maintenance requirements must be considered from the start. Cloud architectures offer flexibility for system evolution but can incur significant ongoing costs. Edge and embedded systems might be harder to update but could offer lower operational overhead. The continuous cycle of ML systems we discussed earlier becomes particularly challenging in distributed architectures, where updating models and maintaining system health requires careful orchestration across multiple tiers.</p>
<p>These trade-offs are rarely simple binary choices. Modern ML systems often adopt hybrid approaches, carefully balancing these considerations based on specific use cases and constraints. The key is understanding how these decisions will impact the system throughout its lifecycle, from initial development through continuous operation and evolution.</p>
<section id="sec-introduction-emerging-trends-fb9c" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-emerging-trends-fb9c">Emerging Trends</h3>
<p>The landscape of machine learning systems is evolving rapidly, with innovations happening from user-facing applications down to core infrastructure. These changes are reshaping how we design and deploy ML systems.</p>
<section id="sec-introduction-applicationlevel-innovation-5833" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-applicationlevel-innovation-5833">Application-Level Innovation</h4>
<p>The rise of agentic systems marks a profound shift from traditional reactive ML systems that simply made predictions based on input data. Modern applications can now take actions, learn from outcomes, and adapt their behavior accordingly through multi-agent systems<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> and advanced planning algorithms. These autonomous agents can plan, reason, and execute complex tasks, introducing new requirements for decision-making frameworks and safety constraints.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;<strong>Multi-Agent System</strong>: A computational system where multiple intelligent agents interact within an environment, each pursuing their own objectives while potentially cooperating or competing with other agents.</p></div></div><p>This increased sophistication extends to operational intelligence. Applications will likely incorporate sophisticated self-monitoring, automated resource management, and adaptive deployment strategies. They can automatically handle data distribution shifts, model updates, and system optimization, marking a significant advance in autonomous operation.</p>
</section>
<section id="sec-introduction-system-architecture-evolution-0661" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-system-architecture-evolution-0661">System Architecture Evolution</h4>
<p>Supporting these advanced applications requires fundamental changes in the underlying system architecture. Integration frameworks are evolving to handle increasingly complex interactions between ML systems and broader technology ecosystems. Modern ML systems must seamlessly connect with existing software, process diverse data sources, and operate across organizational boundaries, driving new approaches to system design.</p>
<p>Resource efficiency has become a central architectural concern as ML systems scale. Innovation in model compression and efficient training techniques is being driven by both environmental and economic factors. Future architectures must carefully balance the pursuit of more powerful models against growing sustainability concerns.</p>
<p>At the infrastructure level, new hardware is reshaping deployment possibilities. Specialized AI accelerators are emerging across the spectrum—from powerful data center chips to efficient edge processors<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> to tiny neural processing units in mobile devices. This heterogeneous computing landscape enables dynamic model distribution across tiers based on computing capabilities and conditions, blurring traditional boundaries between cloud, edge, and embedded systems.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;<strong>Edge Processor</strong>: A specialized computing device designed to perform AI computations close to where data is generated, optimized for low latency and energy efficiency rather than raw computing power.</p></div></div><p>These trends are creating ML systems that are more capable and efficient while managing increasing complexity. Success in this evolving landscape requires understanding how application requirements flow down to infrastructure decisions, ensuring systems can grow sustainably while delivering increasingly sophisticated capabilities.</p>
<div id="quiz-question-sec-introduction-ml-systems-impact-lifecycle-f5f9" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.7</strong></summary><div>
<ol type="1">
<li><p>Which architectural choice is most likely to be driven by latency-sensitive applications such as autonomous vehicles?</p>
<ol type="a">
<li>Centralized cloud architecture</li>
<li>Edge or embedded architecture</li>
<li>Hybrid architecture</li>
<li>Mobile architecture</li>
</ol></li>
<li><p>Explain how resource management differs between cloud and edge ML systems and the implications for system design.</p></li>
<li><p>In a distributed ML system, ____ complexity increases with the number of system components and their interactions.</p></li>
<li><p>True or False: The evolution and maintenance of ML systems are easier in edge architectures compared to cloud architectures.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ml-systems-impact-lifecycle-f5f9" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-introduction-practical-applications-cd2d" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-practical-applications-cd2d">Practical Applications</h2>
<p>The diverse architectures and scales of ML systems demonstrate their potential to revolutionize industries. By examining real-world applications, we can see how these systems address practical challenges and drive innovation. Their ability to operate effectively across varying scales and environments has already led to significant changes in numerous sectors. This section highlights examples where theoretical concepts and practical considerations converge to produce tangible, impactful results.</p>
<section id="sec-introduction-farmbeats-ml-agriculture-4a1e" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-farmbeats-ml-agriculture-4a1e">FarmBeats: ML in Agriculture</h3>
<p><a href="https://www.microsoft.com/en-us/research/project/farmbeats-iot-agriculture/">FarmBeats</a>, a project developed by Microsoft Research, shown in <a href="#fig-farmbeats-overview" class="quarto-xref">Figure&nbsp;5</a> is a significant advancement in the application of machine learning to agriculture. This system aims to increase farm productivity and reduce costs by leveraging AI and IoT technologies. FarmBeats exemplifies how edge and embedded ML systems can be deployed in challenging, real-world environments to solve practical problems. By bringing ML capabilities directly to the farm, FarmBeats demonstrates the potential of distributed AI systems in transforming traditional industries.</p>
<div id="fig-farmbeats-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-farmbeats-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./images/png/farmbeats.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Edge-Based Agricultural System: FarmBeats leverages IoT devices and edge computing to collect and process real-time data on soil conditions, microclimate, and plant health, enabling data-driven decision-making for optimized resource allocation and increased crop yields. This distributed architecture minimizes reliance on cloud connectivity, reducing latency and improving responsiveness in remote or bandwidth-constrained agricultural environments."><img src="./images/png/farmbeats.png" class="img-fluid figure-img" style="width:95.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-farmbeats-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>Edge-Based Agricultural System</strong>: FarmBeats leverages IoT devices and edge computing to collect and process real-time data on soil conditions, microclimate, and plant health, enabling data-driven decision-making for optimized resource allocation and increased crop yields. This distributed architecture minimizes reliance on cloud connectivity, reducing latency and improving responsiveness in remote or bandwidth-constrained agricultural environments.
</figcaption>
</figure>
</div>
<section id="sec-introduction-data-considerations-d32a" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-data-considerations-d32a">Data Considerations</h4>
<p>The data ecosystem in FarmBeats is diverse and distributed. Sensors deployed across fields collect real-time data on soil moisture, temperature, and nutrient levels. Drones equipped with multispectral cameras capture high-resolution imagery of crops, providing insights into plant health and growth patterns. Weather stations contribute local climate data, while historical farming records offer context for long-term trends. The challenge lies not just in collecting this heterogeneous data, but in managing its flow from dispersed, often remote locations with limited connectivity. FarmBeats employs innovative data transmission techniques, such as using TV white spaces (unused broadcasting frequencies) to extend internet connectivity to far-flung sensors. This approach to data collection and transmission embodies the principles of edge computing we discussed earlier, where data processing begins at the source to reduce bandwidth requirements and enable real-time decision making.</p>
</section>
<section id="sec-introduction-algorithmic-considerations-eed0" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-algorithmic-considerations-eed0">Algorithmic Considerations</h4>
<p>FarmBeats uses a variety of ML algorithms tailored to agricultural applications. For soil moisture prediction, it uses temporal neural networks that can capture the complex dynamics of water movement in soil. Computer vision algorithms process drone imagery to detect crop stress, pest infestations, and yield estimates. These models must be robust to noisy data and capable of operating with limited computational resources. Machine learning methods such as “transfer learning” allow models to learn on data-rich farms to be adapted for use in areas with limited historical data. The system also incorporates a mixture of methods that combine outputs from multiple algorithms to improve prediction accuracy and reliability. A key challenge FarmBeats addresses is model personalization, adapting general models to the specific conditions of individual farms. These conditions may include unique soil compositions, microclimates, and farming practices.</p>
</section>
<section id="sec-introduction-infrastructure-considerations-639d" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-infrastructure-considerations-639d">Infrastructure Considerations</h4>
<p>FarmBeats exemplifies the edge computing paradigm we explored in our discussion of the ML system spectrum. At the lowest level, embedded ML models run directly on IoT devices and sensors, performing basic data filtering and anomaly detection. Edge devices, such as ruggedized field gateways, aggregate data from multiple sensors and run more complex models for local decision-making. These edge devices operate in challenging conditions, requiring robust hardware designs and efficient power management to function reliably in remote agricultural settings. The system employs a hierarchical architecture, with more computationally intensive tasks offloaded to on-premises servers or the cloud. This tiered approach allows FarmBeats to balance the need for real-time processing with the benefits of centralized data analysis and model training. The infrastructure also includes mechanisms for over-the-air model updates, ensuring that edge devices can receive improved models as more data becomes available and algorithms are refined.</p>
</section>
<section id="sec-introduction-future-implications-f705" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-future-implications-f705">Future Implications</h4>
<p>FarmBeats shows how ML systems can be deployed in resource-constrained, real-world environments to drive significant improvements in traditional industries. By providing farmers with AI-driven insights, the system has shown potential to increase crop yields, reduce water usage, and optimize resource allocation. Looking forward, the FarmBeats approach could be extended to address global challenges in food security and sustainable agriculture. The success of this system also highlights the growing importance of edge and embedded ML in IoT applications, where bringing intelligence closer to the data source can lead to more responsive, efficient, and scalable solutions. As edge computing capabilities continue to advance, we can expect to see similar distributed ML architectures applied to other domains, from smart cities to environmental monitoring.</p>
</section>
</section>
<section id="sec-introduction-alphafold-scientific-ml-3aba" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-alphafold-scientific-ml-3aba">AlphaFold: Scientific ML</h3>
<p><a href="https://deepmind.google/technologies/alphafold/">AlphaFold</a>, developed by DeepMind, is a landmark achievement in the application of machine learning to complex scientific problems. This AI system is designed to predict the three-dimensional structure of proteins, as shown in <a href="#fig-alphafold-overview" class="quarto-xref">Figure&nbsp;6</a>, from their amino acid sequences, a challenge known as the “protein folding problem” that has puzzled scientists for decades. AlphaFold’s success demonstrates how large-scale ML systems can accelerate scientific discovery and potentially revolutionize fields like structural biology and drug design. This case study exemplifies the use of advanced ML techniques and massive computational resources to tackle problems at the frontiers of science.</p>
<div id="fig-alphafold-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alphafold-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/gif/alphafold.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: AlphaFold: Protein targets that AlphaFold can predict solely from amino acid sequences, showcasing its prowess in tackling the protein folding problem."><img src="images/gif/alphafold.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alphafold-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>AlphaFold</strong>: Protein targets that AlphaFold can predict solely from amino acid sequences, showcasing its prowess in tackling the protein folding problem.
</figcaption>
</figure>
</div>
<section id="sec-introduction-data-considerations-8ae1" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-data-considerations-8ae1">Data Considerations</h4>
<p>The data underpinning AlphaFold’s success is vast and multifaceted. The primary dataset is the Protein Data Bank (PDB), which contains the experimentally determined structures of over 180,000 proteins. This is complemented by databases of protein sequences, which number in the hundreds of millions. AlphaFold also utilizes evolutionary data in the form of multiple sequence alignments (MSAs), which provide insights into the conservation patterns of amino acids across related proteins. The challenge lies not just in the volume of data, but in its quality and representation. Experimental protein structures can contain errors or be incomplete, requiring sophisticated data cleaning and validation processes. Moreover, the representation of protein structures and sequences in a form amenable to machine learning is a significant challenge in itself. AlphaFold’s data pipeline involves complex preprocessing steps to convert raw sequence and structural data into meaningful features that capture the physical and chemical properties relevant to protein folding.</p>
</section>
<section id="sec-introduction-algorithmic-considerations-098e" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-algorithmic-considerations-098e">Algorithmic Considerations</h4>
<p>AlphaFold’s algorithmic approach represents a tour de force in the application of deep learning to scientific problems. At its core, AlphaFold uses a novel neural network architecture that combines with techniques from computational biology. The model learns to predict inter-residue distances and torsion angles, which are then used to construct a full 3D protein structure. A key innovation is the use of “equivariant attention” layers that respect the symmetries inherent in protein structures. The learning process involves multiple stages, including initial “pretraining” on a large corpus of protein sequences, followed by fine-tuning on known structures. AlphaFold also incorporates domain knowledge in the form of physics-based constraints and scoring functions, creating a hybrid system that leverages both data-driven learning and scientific prior knowledge. The model’s ability to generate accurate confidence estimates for its predictions is crucial, allowing researchers to assess the reliability of the predicted structures.</p>
</section>
<section id="sec-introduction-infrastructure-considerations-89ec" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-infrastructure-considerations-89ec">Infrastructure Considerations</h4>
<p>The computational demands of AlphaFold epitomize the challenges of large-scale scientific ML systems. Training the model requires massive parallel computing resources, leveraging clusters of GPUs or TPUs (Tensor Processing Units) in a distributed computing environment. DeepMind utilized Google’s cloud infrastructure, with the final version of AlphaFold trained on 128 TPUv3 cores for several weeks. The inference process, while less computationally intensive than training, still requires significant resources, especially when predicting structures for large proteins or processing many proteins in parallel. To make AlphaFold more accessible to the scientific community, DeepMind has collaborated with the European Bioinformatics Institute to create a <a href="https://alphafold.ebi.ac.uk/">public database</a> of predicted protein structures, which itself represents a substantial computing and data management challenge. This infrastructure allows researchers worldwide to access AlphaFold’s predictions without needing to run the model themselves, demonstrating how centralized, high-performance computing resources can be leveraged to democratize access to advanced ML capabilities.</p>
</section>
<section id="sec-introduction-future-implications-4168" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-future-implications-4168">Future Implications</h4>
<p>AlphaFold’s impact on structural biology has been profound, with the potential to accelerate research in areas ranging from fundamental biology to drug discovery. By providing accurate structural predictions for proteins that have resisted experimental methods, AlphaFold opens new avenues for understanding disease mechanisms and designing targeted therapies. The success of AlphaFold also serves as a powerful demonstration of how ML can be applied to other complex scientific problems, potentially leading to breakthroughs in fields like materials science or climate modeling. However, it also raises important questions about the role of AI in scientific discovery and the changing nature of scientific inquiry in the age of large-scale ML systems. As we look to the future, the AlphaFold approach suggests a new paradigm for scientific ML, where massive computational resources are combined with domain-specific knowledge to push the boundaries of human understanding.</p>
</section>
</section>
<section id="sec-introduction-autonomous-vehicles-ml-2164" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-autonomous-vehicles-ml-2164">Autonomous Vehicles</h3>
<p><a href="https://waymo.com/">Waymo</a>, a subsidiary of Alphabet Inc., stands at the forefront of autonomous vehicle technology, representing one of the most ambitious applications of machine learning systems to date. Evolving from the Google Self-Driving Car Project initiated in 2009, Waymo’s approach to autonomous driving exemplifies how ML systems can span the entire spectrum from embedded systems to cloud infrastructure. This case study demonstrates the practical implementation of complex ML systems in a safety-critical, real-world environment, integrating real-time decision-making with long-term learning and adaptation.</p>
<section id="sec-introduction-data-considerations-fdab" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-data-considerations-fdab">Data Considerations</h4>
<p>The data ecosystem underpinning Waymo’s technology is vast and dynamic. Each vehicle serves as a roving data center, its sensor suite, which comprises LiDAR, radar, and high-resolution cameras, generating approximately one terabyte of data per hour of driving. This real-world data is complemented by an even more extensive simulated dataset, with Waymo’s vehicles having traversed over 20 billion miles in simulation and more than 20 million miles on public roads. The challenge lies not just in the volume of data, but in its heterogeneity and the need for real-time processing. Waymo must handle both structured (e.g., GPS coordinates) and unstructured data (e.g., camera images) simultaneously. The data pipeline spans from edge processing on the vehicle itself to massive cloud-based storage and processing systems. Sophisticated data cleaning and validation processes are necessary, given the safety-critical nature of the application. Moreover, the representation of the vehicle’s environment in a form amenable to machine learning presents significant challenges, requiring complex preprocessing to convert raw sensor data into meaningful features that capture the dynamics of traffic scenarios.</p>
</section>
<section id="sec-introduction-algorithmic-considerations-e223" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-algorithmic-considerations-e223">Algorithmic Considerations</h4>
<p>Waymo’s ML stack represents a sophisticated ensemble of algorithms tailored to the multifaceted challenge of autonomous driving. The perception system employs deep learning techniques, including convolutional neural networks, to process visual data for object detection and tracking. Prediction models, needed for anticipating the behavior of other road users, leverage recurrent neural networks (RNNs)<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> to understand temporal sequences. Waymo has developed custom ML models like VectorNet for predicting vehicle trajectories. The planning and decision-making systems may incorporate reinforcement learning or imitation learning techniques to navigate complex traffic scenarios. A key innovation in Waymo’s approach is the integration of these diverse models into a coherent system capable of real-time operation. The ML models must also be interpretable to some degree, as understanding the reasoning behind a vehicle’s decisions is vital for safety and regulatory compliance. Waymo’s learning process involves continuous refinement based on real-world driving experiences and extensive simulation, creating a feedback loop that constantly improves the system’s performance.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;<strong>Recurrent Neural Network (RNN)</strong>: A type of neural network specifically designed to handle sequential data by maintaining an internal memory state that allows it to learn patterns across time, making it particularly useful for tasks like language processing and time series prediction.</p></div></div></section>
<section id="sec-introduction-infrastructure-considerations-503b" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-infrastructure-considerations-503b">Infrastructure Considerations</h4>
<p>The computing infrastructure supporting Waymo’s autonomous vehicles epitomizes the challenges of deploying ML systems across the full spectrum from edge to cloud. Each vehicle is equipped with a custom-designed compute platform capable of processing sensor data and making decisions in real-time, often leveraging specialized hardware like GPUs or tensor processing units (TPUs)<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. This edge computing is complemented by extensive use of cloud infrastructure, leveraging the power of Google’s data centers for training models, running large-scale simulations, and performing fleet-wide learning. The connectivity between these tiers is critical, with vehicles requiring reliable, high-bandwidth communication for real-time updates and data uploading. Waymo’s infrastructure must be designed for robustness and fault tolerance, ensuring safe operation even in the face of hardware failures or network disruptions. The scale of Waymo’s operation presents significant challenges in data management, model deployment, and system monitoring across a geographically distributed fleet of vehicles.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;<strong>Tensor Processing Unit (TPU)</strong>: A specialized AI accelerator chip designed by Google specifically for neural network machine learning, particularly efficient at matrix operations common in deep learning workloads.</p></div></div></section>
<section id="sec-introduction-future-implications-7552" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-future-implications-7552">Future Implications</h4>
<p>Waymo’s impact extends beyond technological advancement, potentially revolutionizing transportation, urban planning, and numerous aspects of daily life. The launch of Waymo One, a commercial ride-hailing service using autonomous vehicles in Phoenix, Arizona, represents a significant milestone in the practical deployment of AI systems in safety-critical applications. Waymo’s progress has broader implications for the development of robust, real-world AI systems, driving innovations in sensor technology, edge computing, and AI safety that have applications far beyond the automotive industry. However, it also raises important questions about liability, ethics, and the interaction between AI systems and human society. As Waymo continues to expand its operations and explore applications in trucking and last-mile delivery, it serves as an important test bed for advanced ML systems, driving progress in areas such as continual learning, robust perception, and human-AI interaction. The Waymo case study underscores both the tremendous potential of ML systems to transform industries and the complex challenges involved in deploying AI in the real world.</p>
<div id="quiz-question-sec-introduction-practical-applications-cd2d" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.8</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes a key challenge faced by FarmBeats in deploying ML systems in agricultural environments?</p>
<ol type="a">
<li>High computational power requirements</li>
<li>Limited internet connectivity and data transmission</li>
<li>Lack of available data</li>
<li>Excessive power consumption by IoT devices</li>
</ol></li>
<li><p>True or False: The infrastructure for Waymo’s autonomous vehicles relies solely on edge computing for real-time decision-making.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-practical-applications-cd2d" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-introduction-challenges-ml-systems-f08f" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-challenges-ml-systems-f08f">Challenges in ML Systems</h2>
<p>Building and deploying machine learning systems presents unique challenges that go beyond traditional software development. These challenges help explain why creating effective ML systems is about more than just choosing the right algorithm or collecting enough data. Let’s explore the key areas where ML practitioners face significant hurdles.</p>
<section id="sec-introduction-datarelated-challenges-5b58" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-datarelated-challenges-5b58">Data-Related Challenges</h3>
<p>The foundation of any ML system is its data, and managing this data introduces several fundamental challenges. First, there’s the basic question of data quality, as real-world data is often messy and inconsistent. Imagine a healthcare application that needs to process patient records from different hospitals. Each hospital might record information differently, use different units of measurement, or have different standards for what data to collect. Some records might have missing information, while others might contain errors or inconsistencies that need to be cleaned up before the data can be useful.</p>
<p>As ML systems grow, they often need to handle increasingly large amounts of data. A video streaming service like Netflix, for example, needs to process billions of viewer interactions to power its recommendation system. This scale introduces new challenges in how to store, process, and manage such large datasets efficiently.</p>
<p>Another critical challenge is how data changes over time. This phenomenon, known as “data drift”<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>, occurs when the patterns in new data begin to differ from the patterns the system originally learned from. For example, many predictive models struggled during the COVID-19 pandemic because consumer behavior changed so dramatically that historical patterns became less relevant. ML systems need ways to detect when this happens and adapt accordingly.</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;<strong>Data Drift</strong>: The gradual change in the statistical properties of the target variable (what the model is trying to predict) over time, which can degrade model performance if not properly monitored and addressed.</p></div></div></section>
<section id="sec-introduction-modelrelated-challenges-ae5a" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-modelrelated-challenges-ae5a">Model-Related Challenges</h3>
<p>Creating and maintaining the ML models themselves presents another set of challenges. Modern ML models, particularly in deep learning, can be extremely complex. Consider a language model like GPT-3, which has hundreds of billions of parameters that need to be optimized through backpropagation<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. This complexity creates practical challenges: these models require enormous computing power to train and run, making it difficult to deploy them in situations with limited resources, like on mobile phones or IoT devices.</p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;<strong>Backpropagation</strong>: The primary algorithm used to train neural networks, which calculates how each parameter in the network should be adjusted to minimize prediction errors by propagating error gradients backward through the network layers.</p></div><div id="fn15"><p><sup>15</sup>&nbsp;<strong>Transfer Learning</strong>: A machine learning method where a model developed for one task is reused as the starting point for a model on a second task, significantly reducing the amount of training data and computation required.</p></div></div><p>Training these models effectively is itself a significant challenge. Unlike traditional programming where we write explicit instructions, ML models learn from examples through techniques like transfer learning<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. This learning process involves many choices: How should we structure the model? How long should we train it? How can we tell if it’s learning the right things? Making these decisions often requires both technical expertise and considerable trial and error.</p>
<p>A particularly important challenge is ensuring that models work well in real-world conditions. A model might perform excellently on its training data but fail when faced with slightly different situations in the real world. This gap between training performance and real-world performance is a central challenge in machine learning, especially for critical applications like autonomous vehicles or medical diagnosis systems.</p>
</section>
<section id="sec-introduction-systemrelated-challenges-3c6a" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-systemrelated-challenges-3c6a">System-Related Challenges</h3>
<p>Getting ML systems to work reliably in the real world introduces its own set of challenges. Unlike traditional software that follows fixed rules, ML systems need to handle uncertainty and variability in their inputs and outputs. They also typically need both training systems (for learning from data) and serving systems (for making predictions), each with different requirements and constraints.</p>
<p>Consider a company building a speech recognition system. They need infrastructure to collect and store audio data, systems to train models on this data, and then separate systems to actually process users’ speech in real-time. Each part of this pipeline needs to work reliably and efficiently, and all the parts need to work together seamlessly.</p>
<p>These systems also need constant monitoring and updating. How do we know if the system is working correctly? How do we update models without interrupting service? How do we handle errors or unexpected inputs? These operational challenges become particularly complex when ML systems are serving millions of users.</p>
</section>
<section id="sec-introduction-ethical-considerations-5c13" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-ethical-considerations-5c13">Ethical Considerations</h3>
<p>As ML systems become more prevalent in our daily lives, their broader impacts on society become increasingly important to consider. One major concern is fairness, as ML systems can sometimes learn to make decisions that discriminate against certain groups of people. This often happens unintentionally, as the systems pick up biases present in their training data. For example, a job application screening system might inadvertently learn to favor certain demographics if those groups were historically more likely to be hired.</p>
<p>Another important consideration is transparency. Many modern ML models, particularly deep learning models, work as “black boxes”—while they can make predictions, it’s often difficult to understand how they arrived at their decisions. This becomes particularly problematic when ML systems are making important decisions about people’s lives, such as in healthcare or financial services.</p>
<p>Privacy is also a major concern. ML systems often need large amounts of data to work effectively, but this data might contain sensitive personal information. How do we balance the need for data with the need to protect individual privacy? How do we ensure that models don’t inadvertently memorize and reveal private information through inference attacks<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>? These challenges aren’t merely technical problems to be solved, but ongoing considerations that shape how we approach ML system design and deployment.</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;<strong>Inference Attack</strong>: A technique where an adversary attempts to extract sensitive information about the training data by making careful queries to a trained model, exploiting patterns the model may have inadvertently memorized during training.</p></div></div><p>These challenges aren’t merely technical problems to be solved, but ongoing considerations that shape how we approach ML system design and deployment. Throughout this book, we’ll explore these challenges in detail and examine strategies for addressing them effectively.</p>
<div id="quiz-question-sec-introduction-challenges-ml-systems-f08f" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.9</strong></summary><div>
<ol type="1">
<li><p>Explain why ensuring that ML models work well in real-world conditions is a significant challenge.</p></li>
<li><p>True or False: Ethical considerations in ML systems only concern the technical performance of the models.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-challenges-ml-systems-f08f" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-introduction-looking-ahead-532e" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-looking-ahead-532e">Looking Ahead</h2>
<p>As we look to the future of machine learning systems, several exciting trends are shaping the field. These developments promise to both solve existing challenges and open new possibilities for what ML systems can achieve.</p>
<p>One of the most significant trends is the democratization of AI technology. Just as personal computers transformed computing from specialized mainframes to everyday tools, ML systems are becoming more accessible to developers and organizations of all sizes. Cloud providers now offer pre-trained models and automated ML platforms that reduce the expertise needed to deploy AI solutions. This democratization is enabling new applications across industries, from small businesses using AI for customer service to researchers applying ML to previously intractable problems.</p>
<p>As concerns about computational costs and environmental impact grow, there’s an increasing focus on making ML systems more efficient. Researchers are developing new techniques for training models with less data and computing power. Innovation in specialized hardware, from improved GPUs to custom AI chips, is making ML systems faster and more energy-efficient. These advances could make sophisticated AI capabilities available on more devices, from smartphones to IoT sensors.</p>
<p>Perhaps the most transformative trend is the development of more autonomous ML systems that can adapt and improve themselves. These systems are beginning to handle their own maintenance tasks, such as detecting when they need retraining, automatically finding and correcting errors, and optimizing their own performance. This automation could dramatically reduce the operational overhead of running ML systems while improving their reliability.</p>
<p>While these trends are promising, it’s important to recognize the field’s limitations. Creating truly artificial general intelligence remains a distant goal. Current ML systems excel at specific tasks but lack the flexibility and understanding that humans take for granted. Challenges around bias, transparency, and privacy continue to require careful consideration. As ML systems become more prevalent, addressing these limitations while leveraging new capabilities will be crucial.</p>
<div id="quiz-question-sec-introduction-looking-ahead-532e" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.10</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the impact of AI democratization on small businesses?</p>
<ol type="a">
<li>Increased computational costs</li>
<li>Limited access to ML technologies</li>
<li>Enhanced ability to deploy AI solutions</li>
<li>Decreased need for customer service</li>
</ol></li>
<li><p>True or False: The development of more efficient ML systems is primarily driven by the need to reduce computational costs and environmental impact.</p></li>
<li><p>Explain how autonomous ML systems could reduce the operational overhead of running machine learning systems.</p></li>
<li><p>The trend towards more autonomous ML systems involves developing models that can ____ and improve themselves.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-looking-ahead-532e" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-book-structure-learning-path-411f" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-book-structure-learning-path-411f">Book Structure and Learning Path</h2>
<p>This book is designed to guide you from understanding the fundamentals of ML systems to effectively designing and implementing them. To address the complexities and challenges of Machine Learning Systems engineering, we’ve organized the content around five fundamental pillars that encompass the lifecycle of ML systems. These pillars provide a framework for understanding, developing, and maintaining robust ML systems.</p>
<div id="fig-pillars" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pillars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/book_pillars.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: ML System Lifecycle: Robust machine learning systems require careful consideration of five interconnected pillars—data management, model development, experiment tracking, deployment, and monitoring—that define a complete lifecycle for building and maintaining effective AI solutions. Understanding these pillars provides a foundational framework for designing, implementing, and iteratively improving ML systems in real-world applications."><img src="images/png/book_pillars.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pillars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: <strong>ML System Lifecycle</strong>: Robust machine learning systems require careful consideration of five interconnected pillars—data management, model development, experiment tracking, deployment, and monitoring—that define a complete lifecycle for building and maintaining effective AI solutions. Understanding these pillars provides a foundational framework for designing, implementing, and iteratively improving ML systems in real-world applications.
</figcaption>
</figure>
</div>
<p>As illustrated in <a href="#fig-pillars" class="quarto-xref">Figure&nbsp;7</a>, the five pillars central to the framework are:</p>
<ul>
<li><p><strong>Data</strong>: Emphasizing data engineering and foundational principles critical to how AI operates in relation to data.</p></li>
<li><p><strong>Training</strong>: Exploring the methodologies for AI training, focusing on efficiency, optimization, and acceleration techniques to enhance model performance.</p></li>
<li><p><strong>Deployment</strong>: Encompassing benchmarks, on-device learning strategies, and machine learning operations to ensure effective model application.</p></li>
<li><p><strong>Operations</strong>: Highlighting the maintenance challenges unique to machine learning systems, which require specialized approaches distinct from traditional engineering systems.</p></li>
<li><p><strong>Ethics &amp; Governance</strong>: Addressing concerns such as security, privacy, responsible AI practices, and the broader societal implications of AI technologies.</p></li>
</ul>
<p>Each pillar represents a critical phase in the lifecycle of ML systems and is composed of foundational elements that build upon each other. This structure ensures a comprehensive understanding of MLSE, from basic principles to advanced applications and ethical considerations.</p>
<p>For more detailed information about the book’s overview, contents, learning outcomes, target audience, prerequisites, and navigation guide, please refer to the <a href="../../../contents/frontmatter/about/about.html">About the Book</a> section. There, you’ll also find valuable details about our learning community and how to maximize your experience with this resource.</p>


<div id="quiz-question-sec-introduction-book-structure-learning-path-411f" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.11</strong></summary><div>
<ol type="1">
<li><p>Which of the following is NOT one of the five fundamental pillars of Machine Learning Systems Engineering?</p>
<ol type="a">
<li>Data</li>
<li>Training</li>
<li>Deployment</li>
<li>Hardware Design</li>
</ol></li>
<li><p>Order the following ML system lifecycle phases according to the book’s framework: Operations, Training, Data, Deployment, Ethics &amp; Governance.</p></li>
<li><p>Explain why the book’s structure emphasizes the interconnected nature of ML system components.</p></li>
<li><p>The ____ pillar addresses concerns such as security, privacy, responsible AI practices, and broader societal implications of AI technologies.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-book-structure-learning-path-411f" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="self-check-answers" class="level2">
<h2 class="anchored" data-anchor-id="self-check-answers">Self-Check Answers</h2>
<div id="quiz-answer-sec-introduction-ai-ml-basics-041a" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.1</strong></summary><div>
<ol type="1">
<li><p><strong>Explain how the relationship between AI and ML is similar to the relationship between physics and mechanical engineering.</strong></p>
<p><em>Answer</em>: AI provides the theoretical frameworks that inform ML’s practical development of intelligent systems, similar to how physics provides the theoretical foundation for mechanical engineering’s practical applications in structural design and machinery.</p>
<p><em>Learning Objective</em>: Analyze the relationship between AI and ML in the context of theoretical and practical applications.</p></li>
<li><p><strong>True or False: Machine Learning systems implement intelligence through predetermined rules.</strong></p>
<p><em>Answer</em>: False. Machine Learning systems do not implement intelligence through predetermined rules; instead, they use optimization techniques like gradient descent to learn from data.</p>
<p><em>Learning Objective</em>: Correct misconceptions about how ML systems implement intelligence.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ai-ml-basics-041a" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ai-evolution-0dd8" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.2</strong></summary><div>
<ol type="1">
<li><p><strong>Which AI era introduced the concept of using statistical methods to learn patterns from data rather than following pre-programmed rules?</strong></p>
<ol type="a">
<li>Symbolic AI Era</li>
<li>Expert Systems Era</li>
<li>Statistical Learning Era</li>
<li>Deep Learning Era</li>
</ol>
<p><em>Answer</em>: The correct answer is C. The Statistical Learning Era introduced the use of statistical methods to learn patterns from data, marking a shift from rule-based AI to data-driven approaches.</p>
<p><em>Learning Objective</em>: Understand the transition to statistical learning and its significance in AI evolution.</p></li>
<li><p><strong>Explain why the transition from rule-based AI to statistical learning was significant for the development of modern machine learning systems.</strong></p>
<p><em>Answer</em>: The transition was significant because it allowed AI systems to learn from data rather than relying on hand-coded rules. This shift enabled more adaptable and robust AI, capable of handling real-world complexity and variability, laying the groundwork for modern machine learning systems.</p>
<p><em>Learning Objective</em>: Analyze the impact of transitioning from rule-based to statistical learning on modern ML systems.</p></li>
<li><p><strong>True or False: The Deep Learning Era solved all the challenges faced by previous AI paradigms.</strong></p>
<p><em>Answer</em>: False. While deep learning addressed many challenges, such as feature extraction, it introduced new systems challenges like scaling, data requirements, and computational demands.</p>
<p><em>Learning Objective</em>: Understand the ongoing challenges in AI despite advancements in deep learning.</p></li>
<li><p><strong>Order the following AI eras chronologically: Expert Systems Era, Symbolic AI Era, Statistical Learning Era, Deep Learning Era.</strong></p>
<p><em>Answer</em>: Symbolic AI Era, Expert Systems Era, Statistical Learning Era, Deep Learning Era. This sequence reflects the chronological development of AI paradigms.</p>
<p><em>Learning Objective</em>: Recall the chronological order of AI eras to understand the historical progression of AI development.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ai-evolution-0dd8" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ml-systems-engineering-c9fb" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.3</strong></summary><div>
<ol type="1">
<li><p><strong>Machine Learning Systems Engineering focuses on building AI systems that are reliable, efficient, and ____ across computational platforms.</strong></p>
<p><em>Answer</em>: scalable. Machine Learning Systems Engineering aims to ensure AI systems can handle increasing workloads and user demands efficiently.</p>
<p><em>Learning Objective</em>: Understand the core focus areas of Machine Learning Systems Engineering.</p></li>
<li><p><strong>Which of the following best describes the role of Machine Learning Systems Engineering in AI development?</strong></p>
<ol type="a">
<li>Developing new AI algorithms</li>
<li>Optimizing and deploying AI systems at scale</li>
<li>Creating specialized AI hardware</li>
<li>Focusing solely on data acquisition</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Machine Learning Systems Engineering focuses on optimizing and deploying AI systems at scale, bridging the gap between theoretical algorithms and practical implementation.</p>
<p><em>Learning Objective</em>: Identify the primary role of Machine Learning Systems Engineering in the AI lifecycle.</p></li>
<li><p><strong>Explain why Machine Learning Systems Engineering is necessary for the practical implementation of AI systems.</strong></p>
<p><em>Answer</em>: Machine Learning Systems Engineering is necessary because it addresses the challenges of deploying AI systems efficiently and reliably. It ensures that AI algorithms can be integrated into real-world applications, handling data acquisition, system optimization, and scalability across various platforms.</p>
<p><em>Learning Objective</em>: Analyze the necessity of Machine Learning Systems Engineering for deploying AI systems in real-world scenarios.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ml-systems-engineering-c9fb" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-defining-ml-systems-8f42" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.4</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the core components of a machine learning system as defined in this textbook?</strong></p>
<ol type="a">
<li>Algorithms, Data, and Computing Infrastructure</li>
<li>Models, Sensors, and Networking</li>
<li>Data, User Interfaces, and Algorithms</li>
<li>Hardware, Software, and User Experience</li>
</ol>
<p><em>Answer</em>: The correct answer is A. The textbook defines a machine learning system as comprising Algorithms, Data, and Computing Infrastructure, emphasizing the interdependency of these components.</p>
<p><em>Learning Objective</em>: Understand the core components of a machine learning system as defined in the textbook.</p></li>
<li><p><strong>Explain how the interdependency of algorithms, data, and computing infrastructure shapes the design and capabilities of a machine learning system.</strong></p>
<p><em>Answer</em>: The interdependency means that each component influences and limits the others. Algorithms dictate computational and data requirements, data scale affects infrastructure needs and model feasibility, and infrastructure sets practical limits on model and data processing. This creates a framework where all components must align for effective system operation.</p>
<p><em>Learning Objective</em>: Analyze the interdependent relationships among the components of a machine learning system.</p></li>
<li><p><strong>In the analogy to space exploration, algorithm developers are likened to ____, who explore new frontiers and make discoveries.</strong></p>
<p><em>Answer</em>: astronauts. This analogy highlights the role of algorithm developers in exploring new possibilities and making discoveries within the ML system.</p>
<p><em>Learning Objective</em>: Apply the space exploration analogy to understand the roles within a machine learning system.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-defining-ml-systems-8f42" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-lifecycle-ml-systems-e40e" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.5</strong></summary><div>
<ol type="1">
<li><p><strong>Order the following stages of the machine learning system lifecycle: Model Deployment, Data Collection, Model Training, Model Evaluation, Data Preparation, Model Monitoring.</strong></p>
<p><em>Answer</em>: Data Collection, Data Preparation, Model Training, Model Evaluation, Model Deployment, Model Monitoring. This sequence reflects the typical progression of tasks required to develop, evaluate, and deploy a machine learning model, followed by monitoring its performance.</p>
<p><em>Learning Objective</em>: Understand the sequence and purpose of lifecycle stages in ML systems.</p></li>
<li><p><strong>Which of the following best describes a challenge unique to machine learning systems compared to traditional software systems?</strong></p>
<ol type="a">
<li>Version control of source code</li>
<li>Testing deterministic outputs</li>
<li>Managing evolving datasets</li>
<li>Automating deployment processes</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Managing evolving datasets. Unlike traditional software, ML systems rely on data that can change over time, affecting system behavior and requiring continuous adaptation.</p>
<p><em>Learning Objective</em>: Identify challenges faced by ML systems due to their data-dependent nature.</p></li>
<li><p><strong>Explain how the interconnected stages of the ML lifecycle can lead to either virtuous or vicious cycles.</strong></p>
<p><em>Answer</em>: In a virtuous cycle, high-quality data leads to effective learning, robust infrastructure supports processing, and well-engineered systems improve data collection, enhancing the entire lifecycle. Conversely, in a vicious cycle, poor data quality undermines learning, inadequate infrastructure hampers processing, and system limitations degrade data collection, compounding issues.</p>
<p><em>Learning Objective</em>: Analyze the impact of interconnected lifecycle stages on ML system performance.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-lifecycle-ml-systems-e40e" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ml-systems-wild-e270" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.6</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes a tradeoff faced by cloud-based ML systems?</strong></p>
<ol type="a">
<li>Limited computing resources</li>
<li>High operational complexity and costs</li>
<li>Severe constraints on memory and power</li>
<li>Inability to integrate with existing infrastructure</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Cloud-based ML systems, while having virtually unlimited computing resources, must manage enormous operational complexity and costs due to their scale and the volume of data processed.</p>
<p><em>Learning Objective</em>: Understand the tradeoffs and challenges faced by cloud-based ML systems.</p></li>
<li><p><strong>True or False: TinyML systems are designed to operate with the same resource availability as cloud-based ML systems.</strong></p>
<p><em>Answer</em>: False. TinyML systems operate with severe constraints on memory, computing power, and energy consumption, unlike cloud-based systems that have access to vast resources.</p>
<p><em>Learning Objective</em>: Recognize the resource constraints specific to TinyML systems compared to cloud-based systems.</p></li>
<li><p><strong>Explain how edge ML systems can reduce latency and bandwidth requirements.</strong></p>
<p><em>Answer</em>: Edge ML systems bring computation closer to the data sources, which reduces the need to send data to centralized cloud servers. This proximity minimizes latency and decreases bandwidth usage, as data processing occurs locally, improving response times and reducing network load.</p>
<p><em>Learning Objective</em>: Analyze how edge ML systems optimize latency and bandwidth by processing data closer to its source.</p></li>
<li><p><strong>Mobile ML systems must balance sophisticated capabilities with ____ life and processor limitations.</strong></p>
<p><em>Answer</em>: battery. Mobile ML systems need to provide advanced functionalities while managing the limited battery life and processing power available on mobile devices.</p>
<p><em>Learning Objective</em>: Identify the specific constraints that mobile ML systems must manage.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ml-systems-wild-e270" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ml-systems-impact-lifecycle-f5f9" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.7</strong></summary><div>
<ol type="1">
<li><p><strong>Which architectural choice is most likely to be driven by latency-sensitive applications such as autonomous vehicles?</strong></p>
<ol type="a">
<li>Centralized cloud architecture</li>
<li>Edge or embedded architecture</li>
<li>Hybrid architecture</li>
<li>Mobile architecture</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Edge or embedded architecture is often chosen for latency-sensitive applications like autonomous vehicles because it allows for real-time processing close to the data source, reducing latency.</p>
<p><em>Learning Objective</em>: Understand the impact of latency requirements on architectural decisions in ML systems.</p></li>
<li><p><strong>Explain how resource management differs between cloud and edge ML systems and the implications for system design.</strong></p>
<p><em>Answer</em>: Cloud systems focus on cost efficiency and scalability, managing large-scale resources like GPU clusters and storage. Edge systems operate under fixed resource limits, requiring careful management of local compute and storage. This influences model design, as cloud systems can afford larger models, while edge systems prioritize efficiency and compactness.</p>
<p><em>Learning Objective</em>: Analyze how different resource management strategies affect ML system design and operation.</p></li>
<li><p><strong>In a distributed ML system, ____ complexity increases with the number of system components and their interactions.</strong></p>
<p><em>Answer</em>: operational. Operational complexity increases as more components and interactions are introduced, requiring careful management throughout the ML lifecycle.</p>
<p><em>Learning Objective</em>: Identify the factors contributing to operational complexity in distributed ML systems.</p></li>
<li><p><strong>True or False: The evolution and maintenance of ML systems are easier in edge architectures compared to cloud architectures.</strong></p>
<p><em>Answer</em>: False. Cloud architectures offer more flexibility for system evolution and maintenance due to their centralized nature and access to mature deployment tools, whereas edge architectures may face challenges in updating and maintaining distributed components.</p>
<p><em>Learning Objective</em>: Evaluate the challenges of maintaining and evolving ML systems across different architectures.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ml-systems-impact-lifecycle-f5f9" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-practical-applications-cd2d" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.8</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes a key challenge faced by FarmBeats in deploying ML systems in agricultural environments?</strong></p>
<ol type="a">
<li>High computational power requirements</li>
<li>Limited internet connectivity and data transmission</li>
<li>Lack of available data</li>
<li>Excessive power consumption by IoT devices</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Limited internet connectivity and data transmission. FarmBeats addresses the challenge of limited connectivity by using innovative data transmission techniques like TV white spaces to extend internet connectivity to remote sensors.</p>
<p><em>Learning Objective</em>: Understand the data transmission challenges and solutions in deploying ML systems in remote environments.</p></li>
<li><p><strong>True or False: The infrastructure for Waymo’s autonomous vehicles relies solely on edge computing for real-time decision-making.</strong></p>
<p><em>Answer</em>: False. While Waymo’s vehicles use edge computing for real-time decision-making, they also rely on cloud infrastructure for model training, large-scale simulations, and fleet-wide learning. This hybrid approach ensures robust and scalable operations.</p>
<p><em>Learning Objective</em>: Understand the hybrid infrastructure model combining edge and cloud computing in autonomous vehicle systems.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-practical-applications-cd2d" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-challenges-ml-systems-f08f" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.9</strong></summary><div>
<ol type="1">
<li><p><strong>Explain why ensuring that ML models work well in real-world conditions is a significant challenge.</strong></p>
<p><em>Answer</em>: Ensuring ML models work well in real-world conditions is challenging because models may perform well on training data but fail in different real-world scenarios. This performance gap is critical in applications like autonomous vehicles or medical diagnosis, where model errors can have serious consequences. Adapting models to handle real-world variability and uncertainty is essential for reliable deployment.</p>
<p><em>Learning Objective</em>: Analyze the challenges of deploying ML models in real-world scenarios and their implications.</p></li>
<li><p><strong>True or False: Ethical considerations in ML systems only concern the technical performance of the models.</strong></p>
<p><em>Answer</em>: False. Ethical considerations in ML systems extend beyond technical performance to include issues like fairness, transparency, and privacy. These considerations shape how ML systems are designed and deployed, ensuring they do not inadvertently discriminate or violate privacy.</p>
<p><em>Learning Objective</em>: Recognize the scope of ethical considerations in ML systems beyond technical performance.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-challenges-ml-systems-f08f" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-looking-ahead-532e" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.10</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the impact of AI democratization on small businesses?</strong></p>
<ol type="a">
<li>Increased computational costs</li>
<li>Limited access to ML technologies</li>
<li>Enhanced ability to deploy AI solutions</li>
<li>Decreased need for customer service</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Enhanced ability to deploy AI solutions. AI democratization enables small businesses to access pre-trained models and automated ML platforms, allowing them to implement AI solutions without requiring extensive expertise.</p>
<p><em>Learning Objective</em>: Understand the impact of AI democratization on various industries, particularly small businesses.</p></li>
<li><p><strong>True or False: The development of more efficient ML systems is primarily driven by the need to reduce computational costs and environmental impact.</strong></p>
<p><em>Answer</em>: True. The push for more efficient ML systems is largely motivated by the desire to minimize computational expenses and environmental consequences, making AI technologies more sustainable and accessible.</p>
<p><em>Learning Objective</em>: Recognize the motivations behind efforts to improve the efficiency of ML systems.</p></li>
<li><p><strong>Explain how autonomous ML systems could reduce the operational overhead of running machine learning systems.</strong></p>
<p><em>Answer</em>: Autonomous ML systems can self-manage tasks such as retraining, error correction, and performance optimization, reducing the need for human intervention. This automation decreases the operational burden and enhances system reliability, allowing organizations to focus resources on other strategic areas.</p>
<p><em>Learning Objective</em>: Analyze the potential operational benefits of autonomous ML systems.</p></li>
<li><p><strong>The trend towards more autonomous ML systems involves developing models that can ____ and improve themselves.</strong></p>
<p><em>Answer</em>: adapt. Autonomous ML systems are designed to adapt and improve themselves by handling maintenance tasks and optimizing performance, which reduces the need for manual intervention.</p>
<p><em>Learning Objective</em>: Understand the concept of autonomous ML systems and their self-improvement capabilities.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-looking-ahead-532e" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-book-structure-learning-path-411f" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.11</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following is NOT one of the five fundamental pillars of Machine Learning Systems Engineering?</strong></p>
<ol type="a">
<li>Data</li>
<li>Training</li>
<li>Deployment</li>
<li>Hardware Design</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Hardware Design. The five pillars are Data, Training, Deployment, Operations, and Ethics &amp; Governance. Hardware Design is not a separate pillar but is covered within other pillars.</p>
<p><em>Learning Objective</em>: Recall the five fundamental pillars of ML Systems Engineering as outlined in the book.</p></li>
<li><p><strong>Order the following ML system lifecycle phases according to the book’s framework: Operations, Training, Data, Deployment, Ethics &amp; Governance.</strong></p>
<p><em>Answer</em>: Data, Training, Deployment, Operations, Ethics &amp; Governance. This sequence reflects the typical progression of ML system development and the ongoing considerations throughout the lifecycle.</p>
<p><em>Learning Objective</em>: Understand the logical progression of the five pillars in the ML system lifecycle.</p></li>
<li><p><strong>Explain why the book’s structure emphasizes the interconnected nature of ML system components.</strong></p>
<p><em>Answer</em>: The book emphasizes interconnectedness because ML systems require all components (data, algorithms, infrastructure) to work together effectively. Changes in one component affect others, and successful ML systems require understanding these interdependencies to make informed design decisions.</p>
<p><em>Learning Objective</em>: Analyze the importance of understanding component interdependencies in ML systems.</p></li>
<li><p><strong>The ____ pillar addresses concerns such as security, privacy, responsible AI practices, and broader societal implications of AI technologies.</strong></p>
<p><em>Answer</em>: Ethics &amp; Governance. This pillar ensures that ML systems are developed and deployed responsibly, considering their impact on society and individuals.</p>
<p><em>Learning Objective</em>: Identify the pillar responsible for ethical considerations in ML systems.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-book-structure-learning-path-411f" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>

</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="pagination-link" aria-label="SocratiQ AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">SocratiQ AI</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/ml_systems/ml_systems.html" class="pagination-link" aria-label="ML Systems">
        <span class="nav-page-text">ML Systems</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>