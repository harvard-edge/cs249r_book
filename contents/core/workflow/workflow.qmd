---
bibliography: workflow.bib
---

# AI Workflow {#sec-ai_workflow}

::: {.content-visible when-format="html"}
Resources: [Slides](#sec-ai-workflow-resource), [Videos](#sec-ai-workflow-resource), [Exercises](#sec-ai-workflow-resource)
:::

![_DALL·E 3 Prompt: Create a rectangular illustration of a stylized flowchart representing the AI workflow/pipeline. From left to right, depict the stages as follows: 'Data Collection' with a database icon, 'Data Preprocessing' with a filter icon, 'Model Design' with a brain icon, 'Training' with a weight icon, 'Evaluation' with a checkmark, and 'Deployment' with a rocket. Connect each stage with arrows to guide the viewer horizontally through the AI processes, emphasizing these steps' sequential and interconnected nature._](images/png/cover_ai_workflow.png)

## Purpose {.unnumbered}

_What are the diverse elements of AI systems and how do we combine to create effective machine learning system solutions?_

The creation of practical AI solutions requires the orchestration of multiple system components into coherent workflows. Architectural patterns serve as building blocks, while workflow design highlights the connections and interactions that animate these components. This systematic perspective reveals how data flow, model training, and deployment considerations are intertwined to form robust AI systems. Analyzing these interconnections offers crucial insights into system-level design choices, establishing a framework for understanding how theoretical concepts can be translated into deployable solutions that meet real-world needs.

::: {.callout-tip}

## Learning Objectives

* Understand the ML workflow and gain insights into the structured approach and stages of developing, deploying, and maintaining machine learning models.

* Learn about the unique challenges and distinctions between workflows for Traditional machine learning and embedded AI.

* Appreciate the roles in ML projects and understand their responsibilities and significance.

* Understanding the importance, applications, and considerations for implementing ML models in resource-constrained environments.

* Gain awareness about the ethical and legal aspects that must be considered and adhered to in ML and embedded AI projects.

* Establish a basic understanding of ML workflows and roles to be well-prepared for deeper exploration in the following chapters.

:::

## Overview

The ML workflow is a structured approach encompassing the entire machine learning system lifecycle, from initial development through deployment and maintenance. While individual algorithmic components are important, the success of ML systems heavily depends on the surrounding infrastructure, tooling, and practices---aspects that are often overlooked but create significant technical debt when neglected.

Building effective ML systems requires orchestrating both the model development pipeline and the broader system architecture that supports it. From a model development perspective, teams face challenges in selecting appropriate algorithms, tuning hyperparameters, managing training data quality, and ensuring model convergence. These fundamental ML challenges are amplified when moving from experimental environments to production systems, where models must maintain performance while meeting strict operational requirements.

The system-level challenges of ML workflows present equally complex demands on infrastructure and architecture. Teams must design scalable data pipelines, efficient model serving infrastructure, comprehensive monitoring systems, and robust resource management frameworks. Each component must work in concert while adhering to constraints around computational efficiency, memory usage, power consumption, and latency requirements. Success requires careful attention to both the technical aspects of model deployment and the operational considerations of running ML systems at scale.

In this chapter, we explore the machine learning workflow from a systems perspective, examining how different components interact and the infrastructure needed to support them at a high level. We begin by introducing the ML lifecycle and its key stages. As @fig-lifecycle-overview illustrates, it typically involves the following key steps:

![ML lifecycle overview.](images/png/ML_life_cycle_overview.png){#fig-lifecycle-overview}

1. **Problem Definition:** Start by clearly articulating the specific problem you want to solve. This focuses on your efforts during data collection and model building.
2. **Data Collection and Preparation:** Gather relevant, high-quality training data that captures all aspects of the problem. Clean and preprocess the data to prepare it for modeling.
3. **Model Development and Training:** Choose a machine learning algorithm suited to your problem type and data. Consider the pros and cons of different approaches. Feed the prepared data into the model to train it. Training time varies based on data size and model complexity.
4. **Model Evaluation and Validation:** Test the trained model on new unseen data to measure its predictive accuracy. Identify any limitations.
5. **Model Deployment and Integration:** Integrate the validated model into applications or systems to start operationalization.
6. **Monitoring and Maintenance:** Track model performance in production. Retrain periodically on new data to keep it current.

We will continue this discussion with an examination of how these stages are manifested in various deployment scenarios. We will also discuss the roles and responsibilities in ML systems development, and conclude with practical considerations for implementation. While we are providing a high-level overview here, subsequent chapters will delve into core concepts such as data engineering, ML frameworks, training infrastructure, and deployment optimizations.

This foundation is essential for understanding the complexities of building production ML systems. Whether deploying models in cloud environments, edge devices, or embedded systems, the principles and practices covered here will help guide the development of robust, maintainable, and effective ML solutions. By considering both the algorithmic and systems aspects of ML workflows from the start, teams can better navigate the challenges of bringing machine learning from concept to production.

## ML Lifecycle

### Defining the ML Lifecycle

Machine learning has evolved rapidly over the past decade, transforming from an academic discipline into a foundational component of modern software systems. Despite its growing significance, the field lacks a universally accepted definition of the ML lifecycle. While various organizations and researchers have proposed frameworks to guide ML development, no single standard has emerged. Here, we propose a definition that synthesizes insights from industry practices and academic research.

:::{.callout-note}
## Definition of the ML Lifecycle

The Machine Learning (ML) lifecycle is a **structured, iterative process** that outlines the **key stages** required to develop, evaluate, and refine ML systems.
:::

Unlike focusing on implementation details, the lifecycle emphasizes what needs to be achieved at each stage. This process forms a virtuous cycle of continuous improvement, where insights from evaluation, and real-world feedback inform iterative refinements. The stages typically include problem formulation, data acquisition, preprocessing, model training, evaluation, and optimization, each building on the outcomes of the previous one. 

Understanding and defining the ML lifecycle is more than an academic exercise—it provides a foundation for systematically approaching the complexities of machine learning system development. By framing the lifecycle as a structured, iterative process, practitioners can navigate the inherent challenges of working with data-driven systems, ensuring consistency, efficiency, and reliability in their workflows.

From a pedagogical perspective, the ML lifecycle also serves as a conceptual framework that allows us to break down the complexities of machine learning into manageable, interconnected components. Each stage of the lifecycle—from problem formulation to iterative improvement—can be studied in depth, providing students with a clear roadmap to understand and master the distinct subcomponents of a machine learning system.

This decomposition not only mirrors how ML systems are developed in practice but also enables a step-by-step exploration of the core concepts and techniques that underpin the field. In the following chapters, we will study each stage of the lifecycle, building a comprehensive understanding of machine learning systems from the ground up.

### Comparison with Traditional Lifecycles

Software development lifecycles have evolved through decades of engineering practice, establishing well-defined patterns for system development. Whether following waterfall or agile methodologies, these lifecycles consist of sequential phases: requirements gathering, system design, implementation, testing, and deployment. Each phase produces specific artifacts that serve as inputs to subsequent phases. In financial software development, for instance, the requirements phase produces detailed specifications for transaction processing, security protocols, and regulatory compliance - specifications that directly translate into system behavior through explicit programming.

Machine learning systems require a fundamentally different approach to this traditional lifecycle model. The deterministic nature of conventional software, where behavior is explicitly programmed, contrasts sharply with the probabilistic nature of ML systems. Consider financial transaction processing: traditional systems follow predetermined rules (if account balance > transaction amount, then allow transaction), while ML-based fraud detection systems learn to recognize suspicious patterns from historical transaction data. This shift from explicit programming to learned behavior fundamentally reshapes the development lifecycle.

@tbl-lifecycle emphasizes fundamental differences in how these systems are conceived, developed, and evolved, rather than focusing on operational aspects. Each row captures a key philosophical or architectural distinction between traditional and ML-based approaches. The learning-based paradigm of ML systems introduces several fundamental characteristics that differentiate their lifecycle. 

+---------------------+-----------------------------------------+------------------------------------------+
| Development Stage   | Traditional Software Lifecycle          | Machine Learning Lifecycle               |
+:====================+:========================================+:=========================================+
| System Design       | Fixed functional specifications         | Performance-driven objectives            |
+---------------------+-----------------------------------------+------------------------------------------+
| Core Behavior       | Explicit programming logic              | Learning from data patterns              |
+---------------------+-----------------------------------------+------------------------------------------+
| Development Process | Sequential progression of features      | Iterative experimentation and refinement |
+---------------------+-----------------------------------------+------------------------------------------+
| Success Criteria    | Binary correctness (works/doesn't work) | Statistical performance metrics          |
+---------------------+-----------------------------------------+------------------------------------------+
| System Evolution    | Discrete version updates                | Continuous adaptation to new data        |
+---------------------+-----------------------------------------+------------------------------------------+
| Quality Assurance   | Deterministic testing                   | Probabilistic validation                 |
+---------------------+-----------------------------------------+------------------------------------------+
| Failure Modes       | Logic errors and edge cases             | Data quality and distribution shifts     |
+---------------------+-----------------------------------------+------------------------------------------+
| Performance Changes | Only with code modifications            | Can occur without code changes           |
+---------------------+-----------------------------------------+------------------------------------------+

: Distinctions between traditional software and machine learning lifecycles. {#tbl-lifecycle .striped .hover}

Data dependencies form the foundation of ML system behavior. Unlike traditional software where behavior emerges from programmed logic, which we first discussed in [Chapter 1](../introduction/introduction.qmd), ML systems derive their capabilities from training data. This dependency means that system performance is intrinsically linked to data quality, completeness, and representativeness.

Performance characteristics also differ significantly. Traditional software operates on binary correctness criteria---a function either works correctly or it doesn't. ML systems, however, operate on a continuous spectrum of performance, where effectiveness must be measured across multiple metrics and contexts. 

System evolution follows a distinct pattern in ML systems. While traditional software remains static after deployment until explicitly updated, ML systems require continuous monitoring and adaptation to maintain performance as real-world data distributions shift. 

Finally, development patterns in ML systems follow iterative refinement cycles. The system's current behavior influences future data collection and model development decisions, creating feedback loops that don't exist in traditional software development.

### Importance of a Structured Approach

The complexity and dynamic nature of machine learning systems necessitate a structured development approach. While traditional software development methodologies provide some guidance, the unique characteristics of ML systems demand specialized frameworks to manage their development lifecycle. Understanding why this structure matters helps teams build more reliable and effective ML systems.

ML systems present three fundamental challenges that a structured approach addresses. First, these systems exhibit inherent complexity arising from the interaction between data, models, and deployment environments. Data quality affects model performance, model architecture influences computational requirements, and deployment constraints impact both data collection and model design. Without a systematic framework, teams risk creating brittle systems that fail to account for these complex interdependencies.

Second, ML development involves multiple specialized roles—data scientists, ML engineers, domain experts, and operations teams—each with distinct responsibilities and expertise. A structured lifecycle delineates clear interfaces between these roles while maintaining their interdependence. For example, data scientists' decisions about feature engineering must align with both domain experts' knowledge and ML engineers' deployment constraints. The lifecycle framework provides a shared language and process for managing these interactions.

Third, ML systems must maintain reproducibility despite their probabilistic nature. A structured approach enforces rigorous tracking of experiments, data versions, and model artifacts. This systematic recording enables teams to debug performance issues, validate improvements, and understand how system behavior evolves over time. As ML systems scale and team sizes grow, this reproducibility becomes crucial for maintaining system reliability.

It is worth noting the distinction between the ML lifecycle and MLOps (Machine Learning Operations), as these terms are often confused in practice. The ML lifecycle, as discussed in this chapter, describes the fundamental stages and evolution of ML systems—the what and why of ML system development. MLOps, which we will explore in detail in the [MLOps Chapter](../ops/ops.qmd), focuses on the how: the specific practices, tools, and automation that enable efficient implementation of the lifecycle stages. This distinction helps clarify why we begin with the lifecycle; it provides the conceptual foundation necessary for later discussions of operational considerations.


## Conclusion

This chapter has laid the foundation for understanding the machine learning workflow, a structured approach crucial for the development, deployment, and maintenance of ML models. We explored the unique challenges faced in ML workflows, where resource optimization, real-time processing, data management, and hardware-software integration are paramount. These distinctions underscore the importance of tailoring workflows to meet the specific demands of the application environment.

Moreover, we emphasized the significance of multidisciplinary collaboration in ML projects. By examining the diverse roles involved, from data scientists to software engineers, we gained an overview of the teamwork necessary to navigate the experimental and resource-intensive nature of ML development. This understanding is crucial for fostering effective communication and collaboration across different domains of expertise.

As we move forward to more detailed discussions in subsequent chapters, this high-level overview equips us with a holistic perspective on the ML workflow and the various roles involved. This foundation will prove important as we dive into specific aspects of machine learning, which will allow us to contextualize advanced concepts within the broader framework of ML development and deployment.

## Resources {#sec-ai-workflow-resource}

Here is a curated list of resources to support students and instructors in their learning and teaching journeys. We are continuously working on expanding this collection and will add new exercises soon.

:::{.callout-note collapse="false"}

#### Slides

These slides are a valuable tool for instructors to deliver lectures and for students to review the material at their own pace. We encourage students and instructors to leverage these slides to improve their understanding and facilitate effective knowledge transfer.

* [ML Workflow.](https://docs.google.com/presentation/d/1rWXLegepZjpJHonYLKcOJYfOIunmOBnrg0SGhy1pZ_I/edit)

* [ML Lifecycle.](https://docs.google.com/presentation/d/1zOxDX-tKlY8t9KmCYek0E-mZA9ENPjW9ymVyFV17DmE/edit)

:::

:::{.callout-important collapse="false"}

#### Videos

* _Coming soon._
:::

:::{.callout-caution collapse="false"}

#### Exercises

To reinforce the concepts covered in this chapter, we have curated a set of exercises that challenge students to apply their knowledge and deepen their understanding.

* _Coming soon._
:::
