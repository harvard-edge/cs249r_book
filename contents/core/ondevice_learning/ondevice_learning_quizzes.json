{
  "metadata": {
    "source_file": "/Users/VJ/GitHub/MLSysBook/contents/core/ondevice_learning/ondevice_learning.qmd",
    "total_sections": 10,
    "sections_with_quizzes": 7,
    "sections_without_quizzes": 3
  },
  "sections": [
    {
      "section_id": "#sec-ondevice-learning-overview-5b5c",
      "section_title": "Overview",
      "quiz_data": {
        "quiz_needed": false,
        "rationale": "This section serves as an overview, providing context and setting the stage for the detailed exploration of on-device learning in subsequent sections. It outlines the concept, benefits, and challenges of on-device learning but does not delve into specific technical tradeoffs, system components, or operational implications that would require active understanding or application. The section primarily introduces the topic and defines key terms, which are not suitable for a self-check quiz focused on system-level reasoning or practical application. Therefore, a quiz is not needed for this overview."
      }
    },
    {
      "section_id": "#sec-ondevice-learning-deployment-drivers-1919",
      "section_title": "Deployment Drivers",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "System-level reasoning for on-device learning",
            "Operational implications of decentralized learning"
          ],
          "question_strategy": "The questions are designed to test understanding of the operational and system-level implications of on-device learning, focusing on personalization, privacy, and infrastructure efficiency.",
          "difficulty_progression": "The questions progress from understanding basic motivations and benefits of on-device learning to analyzing its operational implications and challenges.",
          "integration": "The questions build on the section's explanation of on-device learning benefits and challenges, ensuring students understand how these concepts apply in real-world scenarios.",
          "ranking_explanation": "This section introduces complex system-level concepts that are critical for understanding the shift from centralized to decentralized learning, making it essential for students to actively engage with the material."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following is NOT a primary motivation for on-device learning?",
            "choices": [
              "Personalization",
              "Latency and availability",
              "Centralized data aggregation",
              "Privacy"
            ],
            "answer": "The correct answer is C. Centralized data aggregation is not a motivation for on-device learning; instead, it is a characteristic of traditional centralized learning systems.",
            "learning_objective": "Understand the key motivations driving the shift to on-device learning."
          },
          {
            "question_type": "SHORT",
            "question": "Explain how on-device learning can improve privacy compared to centralized learning.",
            "answer": "On-device learning improves privacy by keeping raw data on the device, reducing the need to transmit sensitive information to the cloud. This approach aligns with privacy regulations such as GDPR and HIPAA, as it minimizes data exposure and potential compliance issues.",
            "learning_objective": "Analyze the privacy benefits of on-device learning in comparison to centralized learning."
          },
          {
            "question_type": "FILL",
            "question": "On-device learning allows models to adapt using ____ data, which is often unavailable to centralized infrastructure.",
            "answer": "local. On-device learning leverages local data for model adaptation, enabling personalization and reducing reliance on cloud-based data aggregation.",
            "learning_objective": "Recall the type of data used in on-device learning and its significance."
          },
          {
            "question_type": "TF",
            "question": "True or False: On-device learning can operate effectively without any connectivity to centralized infrastructure.",
            "answer": "True. On-device learning is designed to function autonomously, allowing models to adapt locally even in fully offline or delay-sensitive environments, which is crucial for scenarios with unreliable connectivity.",
            "learning_objective": "Understand the operational independence of on-device learning from centralized infrastructure."
          },
          {
            "question_type": "ORDER",
            "question": "Order the following steps in the transition from centralized to on-device learning: A) Model deployment to client devices, B) Local data collection and model adaptation, C) Centralized training on aggregated data.",
            "answer": "C, A, B. Centralized training on aggregated data occurs first, followed by model deployment to client devices, and finally, local data collection and model adaptation occur on-device.",
            "learning_objective": "Understand the sequence of processes in transitioning from centralized to on-device learning."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-design-constraints-51d3",
      "section_title": "Design Constraints",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Design tradeoffs for on-device learning",
            "Constraints in model, data, and compute resources"
          ],
          "question_strategy": "Focus on system-level implications and design tradeoffs involved in on-device learning, emphasizing the constraints and adaptations required for different hardware platforms.",
          "difficulty_progression": "Start with understanding the constraints individually, then move to analyze their combined impact on system design.",
          "integration": "Questions build on the understanding of constraints to explore how these affect the design and operation of on-device learning systems.",
          "ranking_explanation": "This section introduces critical constraints and tradeoffs necessary for designing effective on-device learning systems, making it essential to reinforce these concepts through self-check questions."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following is a primary challenge of on-device learning compared to cloud-based learning?",
            "choices": [
              "Access to large, curated datasets",
              "Availability of extensive compute resources",
              "Limited memory and energy resources",
              "High-speed internet connectivity"
            ],
            "answer": "The correct answer is C. On-device learning is challenged by limited memory and energy resources, which are not typically constraints in cloud-based environments.",
            "learning_objective": "Understand the primary resource constraints that differentiate on-device learning from cloud-based learning."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why non-IID data is a concern for on-device learning systems.",
            "answer": "Non-IID data is a concern because it can lead to models that do not generalize well across different devices or users. The data collected on-device is often specific to individual users or environments, which may not represent the overall distribution used during initial training, complicating model adaptation and convergence.",
            "learning_objective": "Analyze the impact of non-IID data on the performance and generalizability of on-device learning systems."
          },
          {
            "question_type": "FILL",
            "question": "On-device learning systems often use techniques such as ____ to reduce memory and compute requirements while maintaining performance.",
            "answer": "quantization. Quantization reduces the precision of model parameters, allowing models to fit within the limited memory and compute resources available on-device, while still maintaining acceptable performance.",
            "learning_objective": "Recall techniques used to optimize models for on-device learning environments."
          },
          {
            "question_type": "TF",
            "question": "True or False: On-device learning systems can rely on traditional deep learning libraries without modification.",
            "answer": "False. On-device learning systems often require modifications to traditional deep learning libraries to accommodate resource constraints, such as limited memory and the absence of floating-point operations.",
            "learning_objective": "Understand the necessity of adapting deep learning libraries for resource-constrained environments."
          },
          {
            "question_type": "ORDER",
            "question": "Order the following steps in adapting a model for on-device learning: A) Quantization, B) Meta-training with generic data, C) Ranking and selecting layers for adaptation.",
            "answer": "B, A, C. First, the model undergoes meta-training with generic data. Then, quantization is applied to reduce the model's resource requirements. Finally, layers are ranked and selected for adaptation based on device-specific constraints.",
            "learning_objective": "Understand the process of adapting a model for on-device learning, considering resource constraints."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-model-adaptation-661a",
      "section_title": "Model Adaptation",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Tradeoffs in adaptation strategies",
            "Operational implications of model adaptation on-device"
          ],
          "question_strategy": "Use a mix of question types to cover different aspects of model adaptation strategies, focusing on system-level tradeoffs and operational considerations.",
          "difficulty_progression": "Begin with understanding basic concepts of adaptation strategies, then progress to analyzing their tradeoffs and implications in real-world scenarios.",
          "integration": "Questions build on the understanding of model adaptation strategies, complementing earlier sections by focusing on the practical application and system-level reasoning.",
          "ranking_explanation": "The questions are designed to test both foundational knowledge and the ability to apply concepts in real-world scenarios, ensuring a comprehensive understanding of the section."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following adaptation strategies is most suitable for devices with extreme memory and compute limitations?",
            "choices": [
              "Bias-only updates",
              "Residual adapters",
              "Sparse layer updates",
              "Full model fine-tuning"
            ],
            "answer": "The correct answer is A. Bias-only updates are most suitable for devices with extreme memory and compute limitations because they only update scalar offsets, significantly reducing memory and computational requirements.",
            "learning_objective": "Understand which adaptation strategies are suitable for specific hardware constraints."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why residual adapters might be preferred over bias-only updates in a mobile device scenario.",
            "answer": "Residual adapters might be preferred because they offer greater flexibility and expressivity while maintaining control over adaptation cost. They allow for user-specific tuning, which is beneficial in mobile scenarios where moderate adaptation capacity is needed.",
            "learning_objective": "Analyze the benefits of using residual adapters over bias-only updates in specific scenarios."
          },
          {
            "question_type": "FILL",
            "question": "Task-adaptive sparse updates require a mechanism for ____ to determine which layers or parameters to update.",
            "answer": "layer selection. Task-adaptive sparse updates require a mechanism for layer selection to determine which layers or parameters to update based on their contribution to performance.",
            "learning_objective": "Understand the requirements for implementing task-adaptive sparse updates."
          },
          {
            "question_type": "TF",
            "question": "True or False: Low-rank updates increase the number of trainable parameters compared to full model fine-tuning.",
            "answer": "False. Low-rank updates reduce the number of trainable parameters by approximating updates with low-rank matrices, thereby decreasing the computational load compared to full model fine-tuning.",
            "learning_objective": "Understand the impact of low-rank updates on trainable parameters and computational load."
          },
          {
            "question_type": "SHORT",
            "question": "Discuss the tradeoffs involved in using task-adaptive sparse updates for on-device learning.",
            "answer": "Task-adaptive sparse updates offer high expressivity and allow for task-specific fine-tuning, but they require a complex mechanism for layer selection and profiling. They can adapt to large domain shifts but introduce overhead in contribution analysis and require careful validation to ensure sufficient adaptation capacity.",
            "learning_objective": "Evaluate the tradeoffs of using task-adaptive sparse updates in on-device learning scenarios."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-data-efficiency-7b59",
      "section_title": "Data Efficiency",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Data-efficient adaptation techniques",
            "Operational constraints and tradeoffs"
          ],
          "question_strategy": "Utilize a mix of question types to explore different aspects of data efficiency in on-device learning, focusing on practical implications and system-level tradeoffs.",
          "difficulty_progression": "Start with basic understanding of data-efficient techniques, then progress to analyzing tradeoffs and applying concepts to real-world scenarios.",
          "integration": "Questions will integrate concepts from the section to reinforce understanding of how data efficiency is achieved in on-device learning, emphasizing practical applications and tradeoffs.",
          "ranking_explanation": "This section introduces critical techniques for data-efficient on-device learning, requiring students to understand and apply these concepts in practical scenarios."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which technique is most suitable for adapting models on devices with extremely limited memory and compute resources?",
            "choices": [
              "Full model finetuning",
              "Few-shot adaptation",
              "Experience replay",
              "Batch training with large datasets"
            ],
            "answer": "The correct answer is B. Few-shot adaptation is designed to work with a small number of labeled examples and minimal compute resources, making it suitable for devices with limited capacity.",
            "learning_objective": "Understand which data-efficient techniques are suitable for resource-constrained environments."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why experience replay is beneficial for on-device learning in non-stationary environments.",
            "answer": "Experience replay helps mitigate catastrophic forgetting by allowing models to retrain on past examples, thus improving stability in non-stationary environments where data distribution may change over time.",
            "learning_objective": "Analyze the benefits of experience replay in maintaining model performance over time."
          },
          {
            "question_type": "TF",
            "question": "True or False: Compressed data representations can help reduce the memory footprint of on-device learning systems.",
            "answer": "True. Compressed data representations transform raw inputs into lower-dimensional embeddings, reducing memory usage and enabling efficient adaptation.",
            "learning_objective": "Understand the role of compressed data representations in managing memory constraints."
          },
          {
            "question_type": "FILL",
            "question": "In on-device learning, ____ adaptation allows models to update continuously as new data arrives, without requiring access to prior data.",
            "answer": "streaming. Streaming adaptation enables models to learn incrementally from new data, adapting in real-time without needing to store large datasets.",
            "learning_objective": "Recall the concept of streaming adaptation and its application in real-time learning scenarios."
          },
          {
            "question_type": "CALC",
            "question": "A device uses a replay buffer with a capacity of 100 samples. If it stores compressed feature vectors of 256 bytes each, what is the total memory usage of the buffer in kilobytes?",
            "answer": "The total memory usage is 25.6 KB. This is calculated by multiplying the number of samples (100) by the size of each compressed feature vector (256 bytes), then converting bytes to kilobytes (100 * 256 / 1024 = 25.6 KB). This calculation helps in understanding memory constraints in on-device learning systems.",
            "learning_objective": "Calculate memory requirements for replay buffers in on-device learning systems."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-federated-learning-c3c6",
      "section_title": "Federated Learning",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "System-level tradeoffs in federated learning",
            "Operational challenges and client scheduling"
          ],
          "question_strategy": "The questions focus on understanding the tradeoffs and operational challenges in federated learning, particularly in the context of mobile and embedded systems. They aim to test the student's ability to apply concepts to real-world scenarios and evaluate system-level implications.",
          "difficulty_progression": "The quiz begins with foundational understanding and progresses to more complex application and analysis of federated learning strategies.",
          "integration": "These questions build on the understanding of on-device learning by extending it to federated learning scenarios, emphasizing the integration of privacy, communication, and personalization strategies.",
          "ranking_explanation": "Federated learning introduces significant system-level considerations, making it essential to evaluate understanding of its tradeoffs, operational challenges, and real-world applications."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following is a primary advantage of federated learning over traditional centralized learning?",
            "choices": [
              "Reduced model complexity",
              "Improved data privacy",
              "Increased training speed",
              "Simplified deployment"
            ],
            "answer": "The correct answer is B. Federated learning improves data privacy by keeping raw data on the device and only sharing model updates, unlike centralized learning which requires data aggregation at a central location.",
            "learning_objective": "Understand the privacy benefits of federated learning compared to centralized learning."
          },
          {
            "question_type": "SHORT",
            "question": "Explain how client scheduling impacts the performance and fairness of federated learning systems.",
            "answer": "Client scheduling affects which devices participate in training, impacting model convergence and fairness. Poor scheduling can lead to participation bias, where only devices with favorable conditions contribute, skewing the model towards certain user groups. Effective scheduling ensures diverse and representative client participation, balancing system performance and fairness.",
            "learning_objective": "Analyze the impact of client scheduling on federated learning system performance and fairness."
          },
          {
            "question_type": "FILL",
            "question": "In federated learning, the process of aggregating model updates from multiple clients is known as ____. This process is crucial for creating a global model that benefits from diverse data without compromising individual privacy.",
            "answer": "Federated Averaging. This process is crucial for creating a global model that benefits from diverse data without compromising individual privacy.",
            "learning_objective": "Recall the key process used in federated learning for aggregating model updates."
          },
          {
            "question_type": "TF",
            "question": "True or False: Federated learning completely eliminates the risk of data leakage.",
            "answer": "False. While federated learning reduces data leakage by keeping raw data on devices, model updates can still leak information about local data. Techniques like secure aggregation and differential privacy are needed to mitigate these risks.",
            "learning_objective": "Recognize the limitations of federated learning in terms of data privacy and security."
          },
          {
            "question_type": "CALC",
            "question": "A federated learning system involves 100 devices, each with a local dataset of 500 samples. If each device performs 10 local training steps per round and the average model update size is 1MB, calculate the total data transmitted to the server in one round in GB.",
            "answer": "The total data transmitted is 100 devices * 1MB = 100MB. In GB, this is 0.1GB. This calculation highlights the communication cost in federated learning and the importance of efficient update mechanisms.",
            "learning_objective": "Calculate and understand the communication overhead in federated learning systems."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-practical-system-design-2a97",
      "section_title": "Practical System Design",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "System design tradeoffs and operational considerations",
            "Security and privacy in on-device learning systems"
          ],
          "question_strategy": "The questions are designed to test understanding of system design tradeoffs, operational considerations, and security measures in on-device learning systems. They focus on applying concepts to real-world scenarios and understanding the implications of different design choices.",
          "difficulty_progression": "The questions progress from understanding basic design principles to analyzing operational and security considerations in on-device learning systems.",
          "integration": "The questions integrate concepts from the section by focusing on practical system design, security, and operational concerns, ensuring a comprehensive understanding of on-device learning systems.",
          "ranking_explanation": "This section is critical for understanding how to design robust and efficient on-device learning systems, making it essential for students to actively engage with and apply the concepts presented."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following strategies is most suitable for minimizing the adaptation footprint in on-device learning systems?",
            "choices": [
              "Full-model fine-tuning",
              "Bias-only optimization",
              "Centralized training",
              "Heavy adaptation with large heads"
            ],
            "answer": "The correct answer is B. Bias-only optimization is suitable for minimizing the adaptation footprint as it involves updating only a small part of the model, reducing resource usage while still allowing for personalization.",
            "learning_objective": "Understand the importance of minimizing adaptation footprint in on-device learning systems."
          },
          {
            "question_type": "TF",
            "question": "True or False: Opportunistic scheduling in on-device learning systems helps in reducing the impact on device performance and user experience.",
            "answer": "True. Opportunistic scheduling defers local updates to periods when the device is idle or connected to power, minimizing the impact on latency, battery consumption, and thermal performance.",
            "learning_objective": "Recognize the role of opportunistic scheduling in maintaining device performance and user experience."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why lightweight encryption is important for on-device learning systems.",
            "answer": "Lightweight encryption is important for on-device learning systems to protect sensitive data such as replay buffers and adaptation logs from unauthorized access while imposing minimal resource overhead. This ensures data security without significantly impacting device performance.",
            "learning_objective": "Understand the importance of security measures in protecting data in on-device learning systems."
          },
          {
            "question_type": "FILL",
            "question": "In on-device learning, retaining trusted model checkpoints is crucial for enabling ____ in case of adaptation failures.",
            "answer": "rollback mechanisms. Retaining trusted model checkpoints allows systems to revert to a known-good state if local adaptations lead to unacceptable behavior, ensuring robustness and reliability.",
            "learning_objective": "Understand the role of model checkpoints in ensuring system robustness and reliability."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-challenges-cf40",
      "section_title": "Challenges",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "System heterogeneity and its implications",
            "Challenges of data fragmentation in on-device learning",
            "Resource management and deployment risks"
          ],
          "question_strategy": "The questions are designed to test understanding of the systemic challenges and trade-offs involved in on-device learning, focusing on heterogeneity, data fragmentation, and resource management. They aim to encourage students to think critically about how these challenges impact system design and deployment.",
          "difficulty_progression": "The questions progress from understanding the implications of heterogeneity to analyzing the challenges of data fragmentation, and finally to evaluating resource management and deployment risks.",
          "integration": "These questions integrate knowledge of system-level challenges with practical implications for deploying and managing on-device learning systems, complementing previous sections by focusing on operational concerns.",
          "ranking_explanation": "The section presents complex challenges that are critical for understanding the operational and deployment aspects of on-device learning systems, warranting a comprehensive self-check to reinforce these concepts."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following best describes a challenge posed by hardware heterogeneity in on-device learning systems?",
            "choices": [
              "Uniform training environments across all devices",
              "Standardized software stacks and runtime libraries",
              "Diverse hardware capabilities affecting model deployment",
              "Consistent network connectivity and power availability"
            ],
            "answer": "The correct answer is C. Diverse hardware capabilities affecting model deployment. Hardware heterogeneity introduces complexity in deploying models across devices with varying memory, processing power, and AI accelerators, impacting the feasibility and efficiency of on-device learning.",
            "learning_objective": "Understand the implications of hardware heterogeneity on the deployment of on-device learning systems."
          },
          {
            "question_type": "SHORT",
            "question": "Explain how data fragmentation challenges the generalization of on-device learning models.",
            "answer": "Data fragmentation results in non-IID data distributions, where each device collects unique user-specific data. This can lead to models overfitting to local idiosyncrasies, reducing their ability to generalize across different devices and contexts.",
            "learning_objective": "Analyze the impact of data fragmentation on model generalization in on-device learning systems."
          },
          {
            "question_type": "FILL",
            "question": "In on-device learning, the absence of centralized validation data complicates the process of ____ and monitoring model updates.",
            "answer": "validation. Without centralized validation data, it is challenging to ensure that model updates are beneficial, as models adapt based on local inputs without systematic evaluation.",
            "learning_objective": "Recognize the challenges in validating and monitoring model updates in decentralized learning environments."
          },
          {
            "question_type": "TF",
            "question": "True or False: Resource contention in on-device learning systems is primarily due to the need for additional storage space.",
            "answer": "False. Resource contention arises from competing demands for compute cycles, memory bandwidth, and energy, as training workloads require more resources than inference-only deployments.",
            "learning_objective": "Understand the nature of resource contention in on-device learning systems and its impact on system performance."
          },
          {
            "question_type": "SHORT",
            "question": "Discuss how deployment risks in on-device learning systems can affect regulatory compliance.",
            "answer": "Deployment risks include the loss of centralized oversight, which complicates validation and rollback. This can lead to models drifting outside of compliance boundaries, making it difficult to demonstrate consistent behavior required for regulatory approval.",
            "learning_objective": "Evaluate the impact of deployment risks on regulatory compliance in on-device learning systems."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-conclusion-5294",
      "section_title": "Conclusion",
      "quiz_data": {
        "quiz_needed": false,
        "rationale": "The section titled 'Conclusion' primarily summarizes the key points discussed in the chapter without introducing new technical concepts, system components, or operational implications. It does not present system design tradeoffs or require the active application of concepts. Instead, it provides a high-level overview of the motivations, challenges, and strategies related to on-device learning that have already been covered in detail in previous sections. As such, it does not warrant a self-check quiz, as it does not introduce actionable concepts or require reinforcement of specific technical understanding."
      }
    },
    {
      "section_id": "#sec-ondevice-learning-resources-e3f5",
      "section_title": "Resources",
      "quiz_data": {
        "quiz_needed": false,
        "rationale": "The section titled 'Resources' does not seem to introduce new technical concepts, system components, or operational implications that require active understanding or application. It likely serves as a placeholder for additional materials such as slides, videos, and exercises, which are not yet available. Without specific content to analyze, there are no actionable concepts, design tradeoffs, or system-level reasoning to test. Therefore, a self-check quiz is not warranted for this section."
      }
    }
  ]
}