<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Machine Learning Systems - 17&nbsp; Sustainable AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../contents/ai_for_good/ai_for_good.html" rel="next">
<link href="../../contents/responsible_ai/responsible_ai.html" rel="prev">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="../../Machine-Learning-Systems.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="../../Machine-Learning-Systems.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/introduction.html">MAIN</a></li><li class="breadcrumb-item"><a href="../../contents/sustainable_ai/sustainable_ai.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sustainable AI</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">FRONT MATTER</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dedication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedication</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/contributors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/copyright.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MAIN</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/embedded_sys/embedded_sys.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Embedded Systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/embedded_ml/embedded_ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Embedded AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AI Workflow</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">AI Frameworks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">AI Training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Efficient AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model Optimizations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Acceleration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Benchmarking AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">On-Device Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Embedded AIOps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Security &amp; Privacy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Responsible AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sustainable AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Robust AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/generative_ai/generative_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Generative AI</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">REFERENCES</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LABS</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/niclav_sys/niclav_sys.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup Nicla Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CV on Nicla Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/object_detection_fomo/object_detection_fomo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Audio Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/kws_nicla/kws_nicla.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP - Spectral Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/motion_classify_ad/motion_classify_ad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Tools</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/zoo_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/zoo_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Model Zoo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/learning_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/community.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Communities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/case_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Case Studies</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">17.1</span> Introduction</a></li>
  <li><a href="#social-and-ethical-responsibility" id="toc-social-and-ethical-responsibility" class="nav-link" data-scroll-target="#social-and-ethical-responsibility"><span class="header-section-number">17.2</span> Social and Ethical Responsibility</a>
  <ul>
  <li><a href="#ethical-considerations" id="toc-ethical-considerations" class="nav-link" data-scroll-target="#ethical-considerations"><span class="header-section-number">17.2.1</span> Ethical Considerations</a></li>
  <li><a href="#long-term-sustainability" id="toc-long-term-sustainability" class="nav-link" data-scroll-target="#long-term-sustainability"><span class="header-section-number">17.2.2</span> Long-term Sustainability</a></li>
  <li><a href="#ai-for-environmental-good" id="toc-ai-for-environmental-good" class="nav-link" data-scroll-target="#ai-for-environmental-good"><span class="header-section-number">17.2.3</span> AI for Environmental Good</a></li>
  <li><a href="#case-study" id="toc-case-study" class="nav-link" data-scroll-target="#case-study"><span class="header-section-number">17.2.4</span> Case Study</a></li>
  </ul></li>
  <li><a href="#energy-consumption" id="toc-energy-consumption" class="nav-link" data-scroll-target="#energy-consumption"><span class="header-section-number">17.3</span> Energy Consumption</a>
  <ul>
  <li><a href="#understanding-energy-needs" id="toc-understanding-energy-needs" class="nav-link" data-scroll-target="#understanding-energy-needs"><span class="header-section-number">17.3.1</span> Understanding Energy Needs</a>
  <ul class="collapse">
  <li><a href="#energy-requirements-for-ai-training" id="toc-energy-requirements-for-ai-training" class="nav-link" data-scroll-target="#energy-requirements-for-ai-training">Energy Requirements for AI Training</a></li>
  <li><a href="#operational-energy-use" id="toc-operational-energy-use" class="nav-link" data-scroll-target="#operational-energy-use">Operational Energy Use</a></li>
  </ul></li>
  <li><a href="#data-centers-and-their-impact" id="toc-data-centers-and-their-impact" class="nav-link" data-scroll-target="#data-centers-and-their-impact"><span class="header-section-number">17.3.2</span> Data Centers and Their Impact</a>
  <ul class="collapse">
  <li><a href="#scale" id="toc-scale" class="nav-link" data-scroll-target="#scale">Scale</a></li>
  <li><a href="#energy-demand" id="toc-energy-demand" class="nav-link" data-scroll-target="#energy-demand">Energy Demand</a></li>
  <li><a href="#the-environmental-impact" id="toc-the-environmental-impact" class="nav-link" data-scroll-target="#the-environmental-impact">The Environmental Impact</a></li>
  </ul></li>
  <li><a href="#energy-optimization" id="toc-energy-optimization" class="nav-link" data-scroll-target="#energy-optimization"><span class="header-section-number">17.3.3</span> Energy Optimization</a></li>
  </ul></li>
  <li><a href="#carbon-footprint" id="toc-carbon-footprint" class="nav-link" data-scroll-target="#carbon-footprint"><span class="header-section-number">17.4</span> Carbon Footprint</a>
  <ul>
  <li><a href="#definition-and-significance" id="toc-definition-and-significance" class="nav-link" data-scroll-target="#definition-and-significance"><span class="header-section-number">17.4.1</span> Definition and Significance</a></li>
  <li><a href="#the-need-for-awareness-and-action" id="toc-the-need-for-awareness-and-action" class="nav-link" data-scroll-target="#the-need-for-awareness-and-action"><span class="header-section-number">17.4.2</span> The Need for Awareness and Action</a></li>
  <li><a href="#estimating-the-ai-carbon-footprint" id="toc-estimating-the-ai-carbon-footprint" class="nav-link" data-scroll-target="#estimating-the-ai-carbon-footprint"><span class="header-section-number">17.4.3</span> Estimating the AI Carbon Footprint</a></li>
  </ul></li>
  <li><a href="#beyond-carbon-footprint" id="toc-beyond-carbon-footprint" class="nav-link" data-scroll-target="#beyond-carbon-footprint"><span class="header-section-number">17.5</span> Beyond Carbon Footprint</a>
  <ul>
  <li><a href="#water-usage-and-stress" id="toc-water-usage-and-stress" class="nav-link" data-scroll-target="#water-usage-and-stress"><span class="header-section-number">17.5.1</span> Water Usage and Stress</a></li>
  <li><a href="#hazardous-chemicals-usage" id="toc-hazardous-chemicals-usage" class="nav-link" data-scroll-target="#hazardous-chemicals-usage"><span class="header-section-number">17.5.2</span> Hazardous Chemicals Usage</a></li>
  <li><a href="#resource-depletion" id="toc-resource-depletion" class="nav-link" data-scroll-target="#resource-depletion"><span class="header-section-number">17.5.3</span> Resource Depletion</a></li>
  <li><a href="#hazardous-waste-generation" id="toc-hazardous-waste-generation" class="nav-link" data-scroll-target="#hazardous-waste-generation"><span class="header-section-number">17.5.4</span> Hazardous Waste Generation</a></li>
  <li><a href="#biodiversity-impacts" id="toc-biodiversity-impacts" class="nav-link" data-scroll-target="#biodiversity-impacts"><span class="header-section-number">17.5.5</span> Biodiversity Impacts</a>
  <ul class="collapse">
  <li><a href="#habitat-disruption-and-fragmentation" id="toc-habitat-disruption-and-fragmentation" class="nav-link" data-scroll-target="#habitat-disruption-and-fragmentation">Habitat Disruption and Fragmentation</a></li>
  <li><a href="#aquatic-life-disturbances" id="toc-aquatic-life-disturbances" class="nav-link" data-scroll-target="#aquatic-life-disturbances">Aquatic Life Disturbances</a></li>
  <li><a href="#air-and-chemical-emissions" id="toc-air-and-chemical-emissions" class="nav-link" data-scroll-target="#air-and-chemical-emissions">Air and Chemical Emissions</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#life-cycle-analysis" id="toc-life-cycle-analysis" class="nav-link" data-scroll-target="#life-cycle-analysis"><span class="header-section-number">17.6</span> Life Cycle Analysis</a>
  <ul>
  <li><a href="#stages-of-an-ai-systems-life-cycle" id="toc-stages-of-an-ai-systems-life-cycle" class="nav-link" data-scroll-target="#stages-of-an-ai-systems-life-cycle"><span class="header-section-number">17.6.1</span> Stages of an AI System’s Life Cycle</a></li>
  <li><a href="#environmental-impact-at-each-stage" id="toc-environmental-impact-at-each-stage" class="nav-link" data-scroll-target="#environmental-impact-at-each-stage"><span class="header-section-number">17.6.2</span> Environmental Impact at Each Stage</a></li>
  </ul></li>
  <li><a href="#challenges-in-lca" id="toc-challenges-in-lca" class="nav-link" data-scroll-target="#challenges-in-lca"><span class="header-section-number">17.7</span> Challenges in LCA</a>
  <ul>
  <li><a href="#lack-of-consistency-and-standards" id="toc-lack-of-consistency-and-standards" class="nav-link" data-scroll-target="#lack-of-consistency-and-standards"><span class="header-section-number">17.7.1</span> Lack of Consistency and Standards</a></li>
  <li><a href="#data-gaps" id="toc-data-gaps" class="nav-link" data-scroll-target="#data-gaps"><span class="header-section-number">17.7.2</span> Data Gaps</a></li>
  <li><a href="#rapid-pace-of-evolution" id="toc-rapid-pace-of-evolution" class="nav-link" data-scroll-target="#rapid-pace-of-evolution"><span class="header-section-number">17.7.3</span> Rapid Pace of Evolution</a></li>
  <li><a href="#supply-chain-complexity" id="toc-supply-chain-complexity" class="nav-link" data-scroll-target="#supply-chain-complexity"><span class="header-section-number">17.7.4</span> Supply Chain Complexity</a></li>
  </ul></li>
  <li><a href="#sustainable-design-and-development" id="toc-sustainable-design-and-development" class="nav-link" data-scroll-target="#sustainable-design-and-development"><span class="header-section-number">17.8</span> Sustainable Design and Development</a>
  <ul>
  <li><a href="#sustainability-principles" id="toc-sustainability-principles" class="nav-link" data-scroll-target="#sustainability-principles"><span class="header-section-number">17.8.1</span> Sustainability Principles</a></li>
  </ul></li>
  <li><a href="#green-ai-infrastructure" id="toc-green-ai-infrastructure" class="nav-link" data-scroll-target="#green-ai-infrastructure"><span class="header-section-number">17.9</span> Green AI Infrastructure</a>
  <ul>
  <li><a href="#energy-efficient-ai-systems" id="toc-energy-efficient-ai-systems" class="nav-link" data-scroll-target="#energy-efficient-ai-systems"><span class="header-section-number">17.9.1</span> Energy Efficient AI Systems</a></li>
  <li><a href="#sustainable-ai-infrastructure" id="toc-sustainable-ai-infrastructure" class="nav-link" data-scroll-target="#sustainable-ai-infrastructure"><span class="header-section-number">17.9.2</span> Sustainable AI Infrastructure</a></li>
  <li><a href="#frameworks-and-tools" id="toc-frameworks-and-tools" class="nav-link" data-scroll-target="#frameworks-and-tools"><span class="header-section-number">17.9.3</span> Frameworks and Tools</a></li>
  <li><a href="#benchmarks-and-leaderboards" id="toc-benchmarks-and-leaderboards" class="nav-link" data-scroll-target="#benchmarks-and-leaderboards"><span class="header-section-number">17.9.4</span> Benchmarks and Leaderboards</a></li>
  </ul></li>
  <li><a href="#case-study-google-4ms" id="toc-case-study-google-4ms" class="nav-link" data-scroll-target="#case-study-google-4ms"><span class="header-section-number">17.10</span> Case Study: Google’s 4Ms</a>
  <ul>
  <li><a href="#google-4m-best-practices" id="toc-google-4m-best-practices" class="nav-link" data-scroll-target="#google-4m-best-practices"><span class="header-section-number">17.10.1</span> Google’s 4M Best Practices</a></li>
  <li><a href="#significant-results" id="toc-significant-results" class="nav-link" data-scroll-target="#significant-results"><span class="header-section-number">17.10.2</span> Significant Results</a></li>
  <li><a href="#further-improvements" id="toc-further-improvements" class="nav-link" data-scroll-target="#further-improvements"><span class="header-section-number">17.10.3</span> Further Improvements</a></li>
  </ul></li>
  <li><a href="#embedded-ai-internet-of-trash" id="toc-embedded-ai-internet-of-trash" class="nav-link" data-scroll-target="#embedded-ai-internet-of-trash"><span class="header-section-number">17.11</span> Embedded AI - Internet of Trash</a>
  <ul>
  <li><a href="#e-waste" id="toc-e-waste" class="nav-link" data-scroll-target="#e-waste">E-waste</a></li>
  <li><a href="#disposable-electronics" id="toc-disposable-electronics" class="nav-link" data-scroll-target="#disposable-electronics">Disposable Electronics</a></li>
  <li><a href="#planned-obsolescence" id="toc-planned-obsolescence" class="nav-link" data-scroll-target="#planned-obsolescence">Planned Obsolescence</a></li>
  </ul></li>
  <li><a href="#policy-and-regulatory-considerations" id="toc-policy-and-regulatory-considerations" class="nav-link" data-scroll-target="#policy-and-regulatory-considerations"><span class="header-section-number">17.12</span> Policy and Regulatory Considerations</a>
  <ul>
  <li><a href="#measurement-and-reporting-mandates" id="toc-measurement-and-reporting-mandates" class="nav-link" data-scroll-target="#measurement-and-reporting-mandates"><span class="header-section-number">17.12.1</span> Measurement and Reporting Mandates</a></li>
  <li><a href="#restriction-mechanisms" id="toc-restriction-mechanisms" class="nav-link" data-scroll-target="#restriction-mechanisms"><span class="header-section-number">17.12.2</span> Restriction Mechanisms</a></li>
  <li><a href="#government-incentives" id="toc-government-incentives" class="nav-link" data-scroll-target="#government-incentives"><span class="header-section-number">17.12.3</span> Government Incentives</a></li>
  <li><a href="#self-regulation" id="toc-self-regulation" class="nav-link" data-scroll-target="#self-regulation"><span class="header-section-number">17.12.4</span> Self-Regulation</a></li>
  <li><a href="#global-considerations" id="toc-global-considerations" class="nav-link" data-scroll-target="#global-considerations"><span class="header-section-number">17.12.5</span> Global Considerations</a></li>
  </ul></li>
  <li><a href="#public-perception-and-engagement" id="toc-public-perception-and-engagement" class="nav-link" data-scroll-target="#public-perception-and-engagement"><span class="header-section-number">17.13</span> Public Perception and Engagement</a>
  <ul>
  <li><a href="#ai-awareness" id="toc-ai-awareness" class="nav-link" data-scroll-target="#ai-awareness"><span class="header-section-number">17.13.1</span> AI Awareness</a></li>
  <li><a href="#messaging" id="toc-messaging" class="nav-link" data-scroll-target="#messaging"><span class="header-section-number">17.13.2</span> Messaging</a></li>
  <li><a href="#equitable-participation" id="toc-equitable-participation" class="nav-link" data-scroll-target="#equitable-participation"><span class="header-section-number">17.13.3</span> Equitable Participation</a></li>
  <li><a href="#transparency" id="toc-transparency" class="nav-link" data-scroll-target="#transparency"><span class="header-section-number">17.13.4</span> Transparency</a></li>
  </ul></li>
  <li><a href="#future-directions-and-challenges" id="toc-future-directions-and-challenges" class="nav-link" data-scroll-target="#future-directions-and-challenges"><span class="header-section-number">17.14</span> Future Directions and Challenges</a>
  <ul>
  <li><a href="#future-directions" id="toc-future-directions" class="nav-link" data-scroll-target="#future-directions"><span class="header-section-number">17.14.1</span> Future Directions</a></li>
  <li><a href="#challenges" id="toc-challenges" class="nav-link" data-scroll-target="#challenges"><span class="header-section-number">17.14.2</span> Challenges</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">17.15</span> Conclusion</a></li>
  <li><a href="#sec-sustainable-ai-resource" id="toc-sec-sustainable-ai-resource" class="nav-link" data-scroll-target="#sec-sustainable-ai-resource">Resources</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/main/contents/sustainable_ai/sustainable_ai.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/main/contents/sustainable_ai/sustainable_ai.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/introduction.html">MAIN</a></li><li class="breadcrumb-item"><a href="../../contents/sustainable_ai/sustainable_ai.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sustainable AI</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sustainable-ai" class="quarto-section-identifier"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sustainable AI</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Resources: <a href="#sec-sustainable-ai-resource">Slides</a>, <a href="#sec-sustainable-ai-resource">Labs</a>, <a href="#sec-sustainable-ai-resource">Exercises</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/png/cover_sustainable_ai.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL·E 3 Prompt: 3D illustration on a light background of a sustainable AI network interconnected with a myriad of eco-friendly energy sources. The AI actively manages and optimizes its energy from sources like solar arrays, wind turbines, and hydro dams, emphasizing power efficiency and performance. Deep neural networks spread throughout, receiving energy from these sustainable resources.</em></figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Understand the various aspects of AI’s environmental impact, including energy consumption, carbon emissions, electronic waste, and biodiversity effects.</li>
<li>Learn about methods and best practices for developing sustainable AI systems</li>
<li>Appreciate the importance of taking a lifecycle perspective when evaluating and addressing the sustainability of AI systems.</li>
<li>Recognize the roles various stakeholders like researchers, corporations, policymakers and end users play in furthering responsible and sustainable AI progress.</li>
<li>Learn about specific frameworks, metrics and tools aimed at enabling greener AI development.</li>
<li>Appreciate real-world case studies like Google’s 4M efficiency practices that showcase how organizations are taking tangible steps to improve AI’s environmental record</li>
</ul>
</div>
</div>
<section id="introduction" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">17.1</span> Introduction</h2>
<p>The rapid advancements in artificial intelligence (AI) and machine learning (ML) have led to many beneficial applications and optimizations for performance efficiency. However, the remarkable growth of AI comes with a significant, yet often overlooked cost: its environmental impact. The most recent report released by the IPCC, the international body leading scientific assessments of climate change and its impacts, emphasized the pressing importance of tackling climate change. Without immediate efforts to decrease global <span class="math inline">\(\textrm{CO}_2\)</span> emissions by at least 43 percent before 2030, we exceed global warming of 1.5 degrees celsius <span class="citation" data-cites="lecocq2022mitigation">(<a href="../../references.html#ref-lecocq2022mitigation" role="doc-biblioref">Winkler et al. 2022</a>)</span>. This could initiate positive feedback loops pushing temperatures even higher. Next to environmental issues, the United Nations recognized <a href="https://sdgs.un.org/goals">17 Sustainable Development Goals (SDGs)</a>, in which AI can play an important role, and vice versa, play an important role in the development of AI systems. As the field continues expanding, considering sustainability is crucial.</p>
<p>AI systems, particularly large language models like <a href="https://openai.com/blog/gpt-3-apps/">GPT-3</a> and computer vision models like <a href="https://openai.com/dall-e-2/">DALL-E 2</a>, require massive amounts of computational resources for training. For example, GPT-3 was estimated to consume 1,300 megawatt-hours of electricity, which is equal to 1,450 average U.S. households in an entire month <span class="citation" data-cites="maslej2023artificial">(<a href="../../references.html#ref-maslej2023artificial" role="doc-biblioref">Maslej et al. 2023</a>)</span>, or put another way it consumed enough energy to supply an average U.S. household for 120 years! This immense energy demand stems primarily from power-hungry data centers with servers running intense computations to train these complex neural networks for days or weeks.</p>
<p>Current estimates indicate that the carbon emissions produced from developing a single sophisticated AI model can equal the emissions over the lifetime of five standard gasoline-powered vehicles <span class="citation" data-cites="strubell2019energy">(<a href="../../references.html#ref-strubell2019energy" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019</a>)</span>. A significant portion of the electricity presently consumed by data centers is generated from nonrenewable sources such as coal and natural gas, resulting in data centers contributing around <a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks">1% of total worldwide carbon emissions</a>. This is comparable to the emissions from the entire airline sector. This immense carbon footprint demonstrates the pressing need to transition to renewable power sources such as solar and wind to operate AI development.</p>
<p>Additionally, even small-scale AI systems deployed to edge devices as part of TinyML have environmental impacts that should not be ignored <span class="citation" data-cites="prakash2023tinyml">(<a href="../../references.html#ref-prakash2023tinyml" role="doc-biblioref">Prakash et al. 2023</a>)</span>. The specialized hardware required for AI has an environmental toll from natural resource extraction and manufacturing. GPUs, CPUs, and chips like TPUs depend on rare earth metals whose mining and processing generate substantial pollution. The production of these components also has its energy demands. Furthermore, the process of collecting, storing, and preprocessing data used to train both small- and large-scale models comes with environmental costs, which further exacerbates the sustainability implications of ML systems.</p>
<p>Thus, while AI promises innovative breakthroughs in many fields, sustaining progress requires addressing its sustainability challenges. AI can continue advancing responsibly by optimizing the efficiency of models, exploring alternative specialized hardware and renewable energy sources for data centers, and tracking the overall environmental impact.</p>
</section>
<section id="social-and-ethical-responsibility" class="level2" data-number="17.2">
<h2 data-number="17.2" class="anchored" data-anchor-id="social-and-ethical-responsibility"><span class="header-section-number">17.2</span> Social and Ethical Responsibility</h2>
<p>The environmental impact of AI is not just a technical issue but an ethical and social one as well. As AI becomes more integrated into our lives and industries, its sustainability becomes increasingly critical.</p>
<section id="ethical-considerations" class="level3" data-number="17.2.1">
<h3 data-number="17.2.1" class="anchored" data-anchor-id="ethical-considerations"><span class="header-section-number">17.2.1</span> Ethical Considerations</h3>
<p>The scale of AI’s environmental footprint raises profound ethical questions about the responsibilities of AI developers and companies to minimize their carbon emissions and energy usage. As the creators of AI systems and technologies that can have sweeping global impacts, developers have an ethical obligation to consciously integrate environmental stewardship into their design process, even if sustainability comes at the cost of some efficiency gains.</p>
<p>There is a clear and present need for us to have open and honest conversations about AI’s environmental tradeoffs earlier in the development lifecycle. Researchers should feel empowered to voice concerns if organizational priorities do not align with ethical goals, as in the case of the <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter to pause giant AI experiments</a>.</p>
<p>Additionally, there is increasing need for AI companies to scrutinize their contributions to climate change and environmental harm. Large tech firms are responsible for the cloud infrastructure, data center energy demands, and resource extraction required to power today’s AI. Leadership should assess if organizational values and policies promote sustainability, from hardware manufacturing through model training pipelines.</p>
<p>Furthermore, voluntary self-regulation may not be enough—governments may need to introduce new regulations aimed at sustainable AI standards and practices if we hope to curb the projected energy explosion of ever-larger models. Reported metrics like compute usage, carbon footprint, and efficiency benchmarks could help hold organizations accountable.</p>
<p>Through ethical principles, company policies, and public rules, AI technologists and corporations have a profound duty to our planet to ensure the responsible and sustainable advancement of technology positioned to transform modern society radically. We owe it to future generations to get this right.</p>
</section>
<section id="long-term-sustainability" class="level3" data-number="17.2.2">
<h3 data-number="17.2.2" class="anchored" data-anchor-id="long-term-sustainability"><span class="header-section-number">17.2.2</span> Long-term Sustainability</h3>
<p>The massive projected expansion of AI raises urgent concerns about its long-term sustainability. As AI software and applications rapidly increase in complexity and usage across industries, demand for computing power and infrastructure will skyrocket exponentially in the coming years.</p>
<p>To put the scale of projected growth in perspective, the total computing capacity required for training AI models saw an astonishing 350,000x increase from 2012 to 2019 <span class="citation" data-cites="schwartz2020green">(<a href="../../references.html#ref-schwartz2020green" role="doc-biblioref">R. Schwartz et al. 2020</a>)</span>. Researchers forecast over an order of magnitude growth each year moving forward as personalized AI assistants, autonomous technology, precision medicine tools, and more are developed. Similar trends are estimated for embedded ML systems, with an estimated 2.5 billion AI-enabled edge devices being deployed by 2030.</p>
<p>Managing this expansion level requires software and hardware-focused breakthroughs in efficiency and renewable integration from AI engineers and scientists. On the software side, novel techniques in model optimization, distillation, pruning, low-precision numerics, knowledge sharing between systems, and other areas must become widespread best practices to curb energy needs. For example, realizing even a 50% reduced computational demand per capability doubling would have massive compounding on total energy.</p>
<p>On the hardware infrastructure side, due to increasing costs of data transfer, storage, cooling, and space, continuing today’s centralized server farm model at data centers is likely infeasible long-term <span class="citation" data-cites="lannelongue2021green">(<a href="../../references.html#ref-lannelongue2021green" role="doc-biblioref">Lannelongue, Grealey, and Inouye 2021</a>)</span>. Exploring alternative decentralized computing options around “edge AI” on local devices or within telco networks can alleviate scaling pressures on power-hungry hyperscale data centers. Likewise, the shift towards carbon-neutral, hybrid renewable energy sources powering leading cloud provider data centers worldwide will be essential.</p>
</section>
<section id="ai-for-environmental-good" class="level3" data-number="17.2.3">
<h3 data-number="17.2.3" class="anchored" data-anchor-id="ai-for-environmental-good"><span class="header-section-number">17.2.3</span> AI for Environmental Good</h3>
<p>While much focus goes on AI’s sustainability challenges, these powerful technologies provide unique solutions to combat climate change and drive environmental progress. For example, ML can continuously optimize smart power grids to improve renewable integration and electricity distribution efficiency across networks <span class="citation" data-cites="zhang2018review">(<a href="../../references.html#ref-zhang2018review" role="doc-biblioref">Zhang, Han, and Deng 2018</a>)</span>. Models can ingest the real-time status of a power grid and weather forecasts to allocate and shift sources responding to supply and demand.</p>
<p>Fine-tuned neural networks have also proven remarkably effective at next-generation <a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/">weather forecasting</a> <span class="citation" data-cites="lam2023learning">(<a href="../../references.html#ref-lam2023learning" role="doc-biblioref">Lam et al. 2023</a>)</span> and climate modeling <span class="citation" data-cites="kurth2023fourcastnet">(<a href="../../references.html#ref-kurth2023fourcastnet" role="doc-biblioref">Kurth et al. 2023</a>)</span>. They can rapidly analyze massive volumes of climate data to boost extreme event preparation and resource planning for hurricanes, floods, droughts and more. Climate researchers have achieved state-of-the-art storm path accuracy by combining AI simulations with traditional numerical models.</p>
<p>AI also enables better tracking of biodiversity <span class="citation" data-cites="silvestro2022improving">(<a href="../../references.html#ref-silvestro2022improving" role="doc-biblioref">Silvestro et al. 2022</a>)</span>, wildlife <span class="citation" data-cites="schwartz2021deployment">(<a href="../../references.html#ref-schwartz2021deployment" role="doc-biblioref">D. Schwartz et al. 2021</a>)</span>, <a href="https://blogs.nvidia.com/blog/conservation-ai-detects-threats-to-endangered-species/#:~:text=The%20Conservation%20AI%20platform%20%E2%80%94%20built,of%20potential%20threats%20via%20email">ecosystems</a>, and illegal deforestation using drones and satellite feeds. Computer vision algorithms can automate species population estimates and habitat health assessments over huge untracked regions. These capabilities provide conservationists with powerful tools for combating poaching <span class="citation" data-cites="bondi2018spot">(<a href="../../references.html#ref-bondi2018spot" role="doc-biblioref">Bondi et al. 2018</a>)</span>, reducing species extinction risks, and understanding ecological shifts.</p>
<p>Targeted investment into AI applications for environmental sustainability, cross-sector data sharing, and model accessibility can profoundly accelerate solutions to pressing ecological issues. Emphasizing AI for social good steers innovation in cleaner directions, guiding these world-shaping technologies towards ethical and responsible development.</p>
</section>
<section id="case-study" class="level3" data-number="17.2.4">
<h3 data-number="17.2.4" class="anchored" data-anchor-id="case-study"><span class="header-section-number">17.2.4</span> Case Study</h3>
<p>Google’s data centers are foundational to powering products like Search, Gmail, and YouTube used by billions daily. However, keeping the vast server farms up and running requires substantial energy, particularly for vital cooling systems. Google continuously strives to enhance efficiency across operations. Yet progress was proving difficult through traditional methods alone considering the complex, custom dynamics involved. This challenge prompted an ML breakthrough yielding potential savings.</p>
<p>After over a decade of optimizing data center design, inventing energy-efficient computing hardware, and securing renewable energy sources, <a href="https://blog.google/outreach-initiatives/environment/deepmind-ai-reduces-energy-used-for/">Google brought DeepMind scientists to unlock further advances</a>. The AI experts faced intricate factors surrounding the functioning of industrial cooling apparatuses. Equipment like pumps and chillers interact nonlinearly, while external weather and internal architectural variables also change. Capturing this complexity confounded rigid engineering formulas and human intuition.</p>
<p>The DeepMind team leveraged Google’s extensive historical sensor data detailing temperatures, power draw, and other attributes as training inputs. They built a flexible system based on neural networks to model the relationships and predict optimal configurations, minimizing power usage effectiveness (PUE) <span class="citation" data-cites="barroso2019datacenter">(<a href="../../references.html#ref-barroso2019datacenter" role="doc-biblioref">Barroso, Hölzle, and Ranganathan 2019</a>)</span>; PUE is the standard measurement for gauging how efficiently a data center uses energy-it gives the proportion of total facility power consumed divided by the power directly used for computing operations. When tested live, the AI system delivered remarkable gains beyond prior innovations, lowering cooling energy by 40% for a 15% drop in total PUE, a new site record. The generalizable framework learned cooling dynamics rapidly across shifting conditions that static rules could not match. The breakthrough highlights AI’s rising role in transforming modern tech and enabling a sustainable future.</p>
</section>
</section>
<section id="energy-consumption" class="level2" data-number="17.3">
<h2 data-number="17.3" class="anchored" data-anchor-id="energy-consumption"><span class="header-section-number">17.3</span> Energy Consumption</h2>
<section id="understanding-energy-needs" class="level3" data-number="17.3.1">
<h3 data-number="17.3.1" class="anchored" data-anchor-id="understanding-energy-needs"><span class="header-section-number">17.3.1</span> Understanding Energy Needs</h3>
<p>In the rapidly evolving field of AI, understanding the energy needs for training and operating AI models is crucial. With AI entering widespread use in many new fields <span class="citation" data-cites="bohr2020rise sudhakar2023data">(<a href="../../references.html#ref-bohr2020rise" role="doc-biblioref">Bohr and Memarzadeh 2020</a>; <a href="../../references.html#ref-sudhakar2023data" role="doc-biblioref">Sudhakar, Sze, and Karaman 2023</a>)</span>, the demand for AI enabled devices and data centers is expected to explode. This understanding helps us grasp why AI, particularly deep learning, is often labeled as energy-intensive.</p>
<section id="energy-requirements-for-ai-training" class="level4">
<h4 class="anchored" data-anchor-id="energy-requirements-for-ai-training">Energy Requirements for AI Training</h4>
<p>The training of complex AI systems like large deep learning models can demand startlingly high levels of computing power–with profound energy implications. Consider OpenAI’s state-of-the-art language model GPT-3 as a prime example. This system pushes the frontiers of text generation through algorithms trained on massive datasets, yet the energy GPT-3 consumed for a single training cycle could rival an <a href="https://www.washington.edu/news/2023/07/27/how-much-energy-does-chatgpt-use/">entire small town’s monthly usage</a>. In recent years, these generative AI models have gained increasing popularity, leading to an increased number of models being trained. Next to the increased number of models, the number of parameters in these models is likely to increase as well. Research shows that increasing the model size (number of parameters), dataset size, and compute used for training improves performance smoothly with no signs of saturation <span class="citation" data-cites="kaplan2020scaling">(<a href="../../references.html#ref-kaplan2020scaling" role="doc-biblioref">Kaplan et al. 2020</a>)</span>. See how in <a href="#fig-scaling-laws" class="quarto-xref">Figure&nbsp;<span>17.1</span></a> the test loss decreases as each of the 3 aforementioned increases.</p>
<div id="fig-scaling-laws" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scaling-laws-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/model_scaling.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scaling-laws-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.1: Performance improves with compute, dataset set, and model size. Credit: <span class="citation" data-cites="kaplan2020scaling">Kaplan et al. (<a href="../../references.html#ref-kaplan2020scaling" role="doc-biblioref">2020</a>)</span>.
</figcaption>
</figure>
</div>
<p>What drives such immense requirements? During training, models like GPT-3 essentially learn their capabilities by continuously processing huge volumes of data to adjust internal parameters. The processing capacity that enables AI’s rapid advances also contributes to surging energy usage, especially as datasets and models balloon in size. In fact, GPT-3 highlights a steady trajectory in the field where each leap in AI’s sophistication traces back to ever more substantial computational power and resources. Its predecessor GPT-2 required 10x less training compute being only 1.5 billion parameters; a difference now dwarfed by magnitudes as GPT-3 comprises 175 billion parameters. Sustaining this trajectory toward increasingly capable AI therefore raises energy and infrastructure provision challenges ahead.</p>
</section>
<section id="operational-energy-use" class="level4">
<h4 class="anchored" data-anchor-id="operational-energy-use">Operational Energy Use</h4>
<p>The development and training of AI models requires immense amounts of data, computing power, and energy. However, the deployment and operation of those models also incurs significant recurrent resource costs over time. AI systems are now integrated across various industries and applications, and entering daily lives of an increasing demographic. Their cumulative operational energy and infrastructure impacts could eclipse that of the upfront model training.</p>
<p>This concept is reflected in the demand of training and inference hardware, in datacenters and on the edge. Inference refers to the actual usage of a trained model to make predictions or decisions on real-world data. According to a <a href="https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Artificial%20intelligence%20hardware%20New%20opportunities%20for%20semiconductor%20companies/Artificial-intelligence-hardware.ashx">recent McKinsey analysis</a>, the need for advanced systems to train ever-larger models is rapidly growing. However, inference computations already make up a dominant and increasing portion of total AI workloads, as shown in <a href="#fig-mckinsey" class="quarto-xref">Figure&nbsp;<span>17.2</span></a>. Running real-time inference with trained models–whether for image classification, speech recognition, or predictive analytics–invariably demands computing hardware like servers and chips. But even a model handling thousands of facial recognition requests or natural language queries daily is dwarfed by massive platforms like Meta. Where inference on millions of photos and videos shared on social media, the infrastructure energy requirements continue to scale!</p>
<div id="fig-mckinsey" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mckinsey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/mckinsey_analysis.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mckinsey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.2: Market size for inference and training hardware. Credit: <a href="https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Artificial%20intelligence%20hardware%20New%20opportunities%20for%20semiconductor%20companies/Artificial-intelligence-hardware.ashx">McKinsey.</a>
</figcaption>
</figure>
</div>
<p>Algorithms powering AI-enabled smart assistants, automated warehouses, self-driving vehicles, tailored healthcare, and more have marginal individual energy footprints. However, the projected proliferation of these technologies could add hundreds of millions of endpoints running AI algorithms continually, causing the scale of their collective energy requirements to surge. Current efficiency gains struggle to counterbalance this sheer growth.</p>
<p>AI is expected to see an <a href="https://www.forbes.com/advisor/business/ai-statistics/">annual growth rate of 37.3% between 2023 and 2030</a>. Yet applying the same growth rate to operational compute could multiply annual AI energy needs up to 1000 times by 2030. So while model optimization tackles one facet, responsible innovation must also consider total lifecycle costs at global deployment scales that were unfathomable just years ago but now pose infrastructure and sustainability challenges ahead.</p>
</section>
</section>
<section id="data-centers-and-their-impact" class="level3" data-number="17.3.2">
<h3 data-number="17.3.2" class="anchored" data-anchor-id="data-centers-and-their-impact"><span class="header-section-number">17.3.2</span> Data Centers and Their Impact</h3>
<p>The impact of data centers on the energy consumption of AI systems is a topic of increasing importance, as the demand for AI services grows. These facilities, while crucial for the advancement and deployment of AI, contribute significantly to its energy footprint.</p>
<section id="scale" class="level4">
<h4 class="anchored" data-anchor-id="scale">Scale</h4>
<p>Data centers are the essential workhorses enabling the recent computational demands of advanced AI systems. For example, leading providers like Meta operate massive data centers spanning up to the <a href="https://tech.facebook.com/engineering/2021/8/eagle-mountain-data-center/">size of multiple football fields</a>, housing hundreds of thousands of high-capacity servers optimized for parallel processing and data throughput.</p>
<p>These massive facilities provide the infrastructure for training complex neural networks on vast datasets–for instance, based on <a href="https://www.semianalysis.com/p/gpt-4-architecture-infrastructure">leaked information</a>, OpenAI’s language model GPT-4 was trained on Azure data centers packing over 25,000 Nvidia A100 GPUs, used continuously for over 90 to 100 days.</p>
<p>Additionally, real-time inference for consumer AI applications at scale is only made possible by leveraging the server farms inside data centers. Services like Alexa, Siri and Google Assistant process billions of voice requests per month from users globally by relying on data center computing for low-latency response. Going forward, expanding cutting-edge use cases like self-driving vehicles, precision medicine diagnostics, and accurate climate forecasting models require significant computational resources, obtained by tapping into vast on-demand cloud computing resources from data centers. For some emerging applications like autonomous cars, there are harsh latency and bandwidth constraints. Locating data center-level compute power on the edge rather than the cloud will be necessary.</p>
<p>MIT research prototypes have shown trucks and cars with on-board hardware performing real-time AI processing of sensor data equivalent to small data centers <span class="citation" data-cites="sudhakar2023data">(<a href="../../references.html#ref-sudhakar2023data" role="doc-biblioref">Sudhakar, Sze, and Karaman 2023</a>)</span>. These innovative “data centers on wheels” demonstrate how vehicles like self-driving trucks may need embedded data center-scale compute on board to achieve millisecond system latency for navigation, though still likely supplemented by wireless 5G connectivity to more powerful cloud data centers.</p>
<p>The bandwidth, storage, and processing capacities required for enabling this future technology at scale will depend heavily on continuing data center infrastructure advancement alongside AI algorithmic innovations.</p>
</section>
<section id="energy-demand" class="level4">
<h4 class="anchored" data-anchor-id="energy-demand">Energy Demand</h4>
<p>The energy demand of data centers can roughly be divided into 4 components. Infrastructure, network, storage and servers. In <a href="#fig-energydemand" class="quarto-xref">Figure&nbsp;<span>17.3</span></a>, we see that the data infrastructure (which includes aspects such as cooling, lighting and controls) and the servers use the majority of the total energy budget of datacenters in the US <span class="citation" data-cites="shehabi2016united">(<a href="../../references.html#ref-shehabi2016united" role="doc-biblioref">Shehabi et al. 2016</a>)</span>. In this section, we break down the energy demand for the servers and the infrastructure. For the latter, the focus is laid on the cooling systems, as cooling is the dominant factor in energy consumption in the infrastructure.</p>
<div id="fig-energydemand" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-energydemand-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/energy_datacenter.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-energydemand-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.3: Data centers energy consumption in the US. Credit: International Energy Agency (IEA).
</figcaption>
</figure>
</div>
<section id="servers" class="level5">
<h5 class="anchored" data-anchor-id="servers">Servers</h5>
<p>The increase in energy consumption of data centers stems mainly from exponentially growing AI computing requirements. NVIDIA DGX H100 machines that are optimized for deep learning can draw up to <a href="https://docs.nvidia.com/dgx/dgxh100-user-guide/introduction-to-dgxh100.html">10.2 kW at peak</a>. Leading providers operate data centers with hundreds to thousands of these power-hungry DGX nodes networked to train the latest AI models. For example, the supercomputer developed for OpenAI is a single system with more than 285,000 CPU cores, 10,000 GPUs and 400 gigabits per second of network connectivity for each GPU server.</p>
<p>The intensive computations needed across an entire facility’s densely packed fleet and supporting hardware result in data centers drawing tens of megawatts around the clock. Overall, advancing AI algorithms continue to expand data center energy consumption as more DGX nodes get deployed to keep pace with projected growth in demand for AI compute resources over the coming years.</p>
</section>
<section id="cooling-systems" class="level5">
<h5 class="anchored" data-anchor-id="cooling-systems">Cooling Systems</h5>
<p>To keep the beefy servers fed at peak capacity and cool, data centers require tremendous cooling capacity to counteract the heat produced by densely packed servers, networking equipment, and other hardware running computationally-intensive workloads without pause. With large data centers packing thousands of server racks operating at full tilt, massive industrial-scale cooling towers and chillers are required, using energy amounting to 30-40% of the total data center electricity footprint <span class="citation" data-cites="dayarathna2015data">(<a href="../../references.html#ref-dayarathna2015data" role="doc-biblioref">Dayarathna, Wen, and Fan 2016</a>)</span>. Consequently, companies are looking for alternative methods of cooling. For example, Microsoft’s data center in Ireland leverages a nearby fjord to exchange heat <a href="https://local.microsoft.com/communities/emea/dublin/">using over half a million gallons of seawater daily</a>.</p>
<p>Recognizing the importance of energy-efficient cooling, there have been innovations aimed at reducing this energy demand. Techniques like free cooling, which uses outside air or water sources when conditions are favorable, and the use of AI to optimize cooling systems, are examples of how the industry is adapting. These innovations not only reduce energy consumption but also lower operational costs and lessen the environmental footprint. However, exponential increases in AI model complexity continue to demand more servers and acceleration hardware operating at higher utilization, translating to rising heat generation and ever greater energy used solely for cooling purposes.</p>
</section>
</section>
<section id="the-environmental-impact" class="level4">
<h4 class="anchored" data-anchor-id="the-environmental-impact">The Environmental Impact</h4>
<p>The environmental impact of data centers is not only caused by direct energy consumption of the datacenter itself <span class="citation" data-cites="siddik2021environmental">(<a href="../../references.html#ref-siddik2021environmental" role="doc-biblioref">Siddik, Shehabi, and Marston 2021</a>)</span>. The operation of data centers involves the supply of treated water to the datacenter and the discharge of wastewater from the datacenter. Water and wastewater facilities are major electricity consumers.</p>
<p>Next to electricity usage, there are many more aspects to the environmental impacts of these data centers. The water usage of the data centers can lead to water scarcity issues, increased water treatment needs and proper wastewater discharge infrastructure. Also raw materials required for construction and network transmission pose considerable impacts on the environment. Finally, components in data centers need to be upgraded and maintained. Where almost 50 percent of servers were refreshed within 3 years of usage, refresh cycles have shown to slow down <span class="citation" data-cites="davis2022uptime">(<a href="../../references.html#ref-davis2022uptime" role="doc-biblioref">Davis et al. 2022</a>)</span>. Still, this generates a significant amount of e-waste which can be hard to recycle.</p>
</section>
</section>
<section id="energy-optimization" class="level3" data-number="17.3.3">
<h3 data-number="17.3.3" class="anchored" data-anchor-id="energy-optimization"><span class="header-section-number">17.3.3</span> Energy Optimization</h3>
<p>Ultimately, measuring and understanding the energy consumption of AI facilitate the optimization of energy consumption.</p>
<p>One way to reduce the energy consumption of a given amount of computational work is to run it on more energy-efficient hardware. For instance, TPU chips can be more energy-efficient compared to CPUs when it comes to running large tensor computations for AI, as TPUs can run such computations much faster without drawing significantly more power than CPUs. Another way is to build software systems that are aware of energy consumption and application characteristics. Good examples are systems works such as Zeus <span class="citation" data-cites="jie2023zeus">(<a href="../../references.html#ref-jie2023zeus" role="doc-biblioref">You, Chung, and Chowdhury 2023</a>)</span> and Perseus <span class="citation" data-cites="jaewon2023perseus">(<a href="../../references.html#ref-jaewon2023perseus" role="doc-biblioref">Chung et al. 2023</a>)</span>, both of which characterize the trade-off between computation time and energy consumption at various levels of an ML training system to achieve energy reduction without end-to-end slowdown. In reality, building both energy-efficient hardware and software and combining their benefits should be promising, along with open-source frameworks (e.g., <a href="https://ml.energy/zeus">Zeus</a>) that facilitate community efforts.</p>
</section>
</section>
<section id="carbon-footprint" class="level2" data-number="17.4">
<h2 data-number="17.4" class="anchored" data-anchor-id="carbon-footprint"><span class="header-section-number">17.4</span> Carbon Footprint</h2>
<p>The massive electricity demands of data centers can lead to significant environmental externalities absent an adequate renewable power supply. Many facilities rely heavily on non-renewable energy sources like coal and natural gas. For example, data centers are estimated to produce up to <a href="https://www.independent.co.uk/climate-change/news/global-warming-data-centres-to-consume-three-times-as-much-energy-in-next-decade-experts-warn-a6830086.html">2% of total global <span class="math inline">\(\textrm{CO}_2\)</span> emissions</a> which is <a href="https://www.computerworld.com/article/3431148/why-data-centres-are-the-new-frontier-in-the-fight-against-climate-change.html">closing the gap with the airline industry</a>. As mentioned in previous sections, the computational demands of AI are set to increase. The emissions of this surge are threefold. First, data centers are projected to increase in size <span class="citation" data-cites="liu2020energy">(<a href="../../references.html#ref-liu2020energy" role="doc-biblioref">Liu et al. 2020</a>)</span>. Secondly, emissions during training are set to increase significantly <span class="citation" data-cites="patterson2022carbon">(<a href="../../references.html#ref-patterson2022carbon" role="doc-biblioref">Patterson et al. 2022</a>)</span>. Thirdly, inference calls to these models are set to increase dramatically as well.</p>
<p>Without action, this exponential demand growth risks ratcheting up the carbon footprint of data centers further to unsustainable levels. Major providers have pledged carbon neutrality and committed funds to secure clean energy, but progress remains incremental compared to overall industry expansion plans. More radical grid decarbonization policies and renewable energy investments may prove essential to counteracting the climate impact of the coming tide of new data centers aimed at supporting the next generation of AI.</p>
<section id="definition-and-significance" class="level3" data-number="17.4.1">
<h3 data-number="17.4.1" class="anchored" data-anchor-id="definition-and-significance"><span class="header-section-number">17.4.1</span> Definition and Significance</h3>
<p>The concept of a ‘carbon footprint’ has emerged as a key metric. This term refers to the total amount of greenhouse gasses, particularly carbon dioxide, that are emitted directly or indirectly by an individual, organization, event, or product. These emissions significantly contribute to the greenhouse effect, which in turn accelerates global warming and climate change. The carbon footprint is measured in terms of carbon dioxide equivalents (<span class="math inline">\(\textrm{CO}_2\)</span>e), allowing for a comprehensive account that includes various greenhouse gasses and their relative impact on the environment. Examples of this as applied to large-scale ML tasks is shown in <a href="#fig-carbonfootprint" class="quarto-xref">Figure&nbsp;<span>17.4</span></a>.</p>
<div id="fig-carbonfootprint" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-carbonfootprint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/model_carbonfootprint.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-carbonfootprint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.4: Carbon footprint of large-scale ML tasks. Credit: <span class="citation" data-cites="wu2022sustainable">Wu et al. (<a href="../../references.html#ref-wu2022sustainable" role="doc-biblioref">2022</a>)</span>.
</figcaption>
</figure>
</div>
<p>The consideration of the carbon footprint is especially important in the field of AI. AI’s rapid advancement and integration into various sectors have brought its environmental impact into sharp focus. AI systems, particularly those involving intensive computations like deep learning and large-scale data processing, are known for their substantial energy demands. This energy, often drawn from power grids, may still predominantly rely on fossil fuels, leading to significant greenhouse gas emissions.</p>
<p>Take, for example, the training of large AI models such as GPT-3 or complex neural networks. These processes require immense computational power, typically provided by data centers. The energy consumption associated with operating these centers, particularly for such high-intensity tasks, results in notable greenhouse gas emissions. Studies have highlighted that training a single AI model can generate carbon emissions comparable to that of the lifetime emissions of multiple cars, shedding light on the environmental cost of developing advanced AI technologies <span class="citation" data-cites="dayarathna2015data">(<a href="../../references.html#ref-dayarathna2015data" role="doc-biblioref">Dayarathna, Wen, and Fan 2016</a>)</span>. <a href="#fig-carboncars" class="quarto-xref">Figure&nbsp;<span>17.5</span></a> shows a comparison from lowest to highest carbon footprints, starting with a roundtrip flight between NY and SF, human life average per year, American life average per year, US car including fuel over a lifetime, and a Transformer model with neural architecture search, which has the highest footprint.</p>
<div id="fig-carboncars" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-carboncars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/carbon_benchmarks.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-carboncars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.5: Carbon footprint of NLP model in lbs of <span class="math inline">\(\textrm{CO}_2\)</span> equivalent. Credit: <span class="citation" data-cites="dayarathna2015data">Dayarathna, Wen, and Fan (<a href="../../references.html#ref-dayarathna2015data" role="doc-biblioref">2016</a>)</span>.
</figcaption>
</figure>
</div>
<p>Moreover, the carbon footprint of AI extends beyond the operational phase. The entire lifecycle of AI systems, including the manufacturing of computing hardware, the energy used in data centers for cooling and maintenance, and the disposal of electronic waste, contributes to their overall carbon footprint. Some of which we have discussed earlier and we will discuss the waste aspects later on in this chapter.</p>
</section>
<section id="the-need-for-awareness-and-action" class="level3" data-number="17.4.2">
<h3 data-number="17.4.2" class="anchored" data-anchor-id="the-need-for-awareness-and-action"><span class="header-section-number">17.4.2</span> The Need for Awareness and Action</h3>
<p>Understanding the carbon footprint of AI systems is crucial for several reasons. Primarily, it is a step towards mitigating the impacts of climate change. As AI continues to grow and permeate different aspects of our lives, its contribution to global carbon emissions becomes a significant concern. Awareness of these emissions can inform decisions made by developers, businesses, policymakers, and even ML engineers and scientists like us to ensure a balance between technological innovation and environmental responsibility.</p>
<p>Furthermore, this understanding stimulates the drive towards ‘Green AI’ <span class="citation" data-cites="schwartz2020green">(<a href="../../references.html#ref-schwartz2020green" role="doc-biblioref">R. Schwartz et al. 2020</a>)</span>. This approach focuses on developing AI technologies that are efficient, powerful, and environmentally sustainable. It encourages the exploration of energy-efficient algorithms, the use of renewable energy sources in data centers, and the adoption of practices that reduce the overall environmental impact of AI.</p>
<p>In essence, the carbon footprint is an essential consideration in developing and applying AI technologies. As AI evolves and its applications become more widespread, managing its carbon footprint is key to ensuring that this technological progress aligns with the broader environmental sustainability goals.</p>
</section>
<section id="estimating-the-ai-carbon-footprint" class="level3" data-number="17.4.3">
<h3 data-number="17.4.3" class="anchored" data-anchor-id="estimating-the-ai-carbon-footprint"><span class="header-section-number">17.4.3</span> Estimating the AI Carbon Footprint</h3>
<p>In understanding AI’s environmental impact, estimating AI systems’ carbon footprint is a critical step. This involves analyzing the various elements contributing to emissions throughout the lifecycle of AI technologies and employing specific methodologies to quantify these emissions accurately. Many different methods for quantifying these carbon emissions of ML have been proposed.</p>
<p>The carbon footprint of AI encompasses several key elements, each contributing to the overall environmental impact. First, energy is consumed during AI model training and operational phases. The source of this energy heavily influences the carbon emissions. Once trained, these models, depending on their application and scale, continue to consume electricity during operation. Next to energy considerations, the hardware used stresses the environment as well.</p>
<p>The carbon footprint varies significantly based on the energy sources used. The composition of the sources providing the energy used in the grid varies widely with geographical regions, and even with time in a single day! For example, in the USA, <a href="https://www.eia.gov/tools/faqs/faq.php?id=427&amp;t=3">roughly 60 percent of the total energy supply is still covered by fossil fuels</a>. The remaining 40 percent is roughly equally covered by nuclear and renewable energy sources. These fractions are not constant throughout the day. As the production of renewable energy usually relies on environmental factors, such as solar radiation and pressure fields, they do not provide a constant source of energy.</p>
<p>The variability of renewable energy production has been an ongoing challenge in the widespread use of these sources. Looking at <a href="#fig-energyprod" class="quarto-xref">Figure&nbsp;<span>17.6</span></a>, which shows data for the European grid, we see that it is not yet possible to produce the required amount of energy throughout the entire day. While solar energy peaks in the middle of the day, wind energy shows two distinct peaks in the mornings and evenings. Currently, to supply the lack of energy during times where renewable energy does not meet requirements, we rely on fossil and coal based energy generation methods.</p>
<p>To enable constant use of renewable energy sources, innovation in energy storage solutions is required. Base energy load is currently met with nuclear energy. This constant energy source does not directly emit carbon emissions, but is too slow to accommodate for the variability of renewable energy sources. Tech companies such as Microsoft have shown interest in nuclear energy sources <a href="https://www.bloomberg.com/news/newsletters/2023-09-29/microsoft-msft-sees-artificial-intelligence-and-nuclear-energy-as-dynamic-duo">to power their data centers</a>. As the demand of data centers is more constant than the demand of regular households, nuclear energy could be used as a dominant source of energy.</p>
<div id="fig-energyprod" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-energyprod-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/europe_energy_grid.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-energyprod-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.6: Energy sources and generation capabilities. Credit: <a href="https://www.energy-charts.info/?l=en&amp;c=DE">Energy Charts.</a>.
</figcaption>
</figure>
</div>
<p>Additionally, the manufacturing and disposal of AI hardware add to the carbon footprint. The production of specialized computing devices, such as GPUs and CPUs, is an energy- and resource-intensive process. This phase often relies on energy sources that contribute to greenhouse gas emissions. The manufacturing process of the electronics industry has been identified as one of the big eight supply chains, responsible for more than 50 percent of total global emissions <span class="citation" data-cites="challenge2021supply">(<a href="../../references.html#ref-challenge2021supply" role="doc-biblioref">Challenge 2021</a>)</span>. Furthermore, the end-of-life disposal of this hardware, which can lead to electronic waste, also has environmental implications. As mentioned before, servers currently have a refresh cycle of roughly 3 to 5 years. Of this e-waste, currently <a href="https://www.genevaenvironmentnetwork.org/resources/updates/the-growing-environmental-risks-of-e-waste/">only 17.4 percent is properly collected and recycled.</a> The carbon emissions of this e-waste has shown an increase of more than 50 percent between 2014 and 2020 <span class="citation" data-cites="singh2022disentangling">(<a href="../../references.html#ref-singh2022disentangling" role="doc-biblioref">Singh and Ogunseitan 2022</a>)</span>.</p>
<p>As is clear from the above, a proper Life Cycle Analysis is necessary to portray all relevant aspects of the emissions caused by AI. Another method is carbon accounting, which quantifies the amount of carbon dioxide emissions directly and indirectly associated with AI operations. This measurement is typically in terms of <span class="math inline">\(\textrm{CO}_2\)</span> equivalents, allowing for a standardized way of reporting and assessing emissions.</p>
</section>
</section>
<section id="beyond-carbon-footprint" class="level2" data-number="17.5">
<h2 data-number="17.5" class="anchored" data-anchor-id="beyond-carbon-footprint"><span class="header-section-number">17.5</span> Beyond Carbon Footprint</h2>
<p>The current focus on reducing the carbon emissions and energy consumption of AI systems addresses one crucial aspect of sustainability. However, the manufacturing of the semiconductors and hardware that enable AI also carries severe environmental impacts that receive comparatively less public attention. Building and operating a leading-edge semiconductor fabrication plant, or “fab”, has substantial resource requirements and polluting byproducts beyond just a large carbon footprint.</p>
<p>For example, a state-of-the-art fab producing state of the art chips like in 5nm can require up to <a href="https://wccftech.com/tsmc-using-water-tankers-for-chip-production-as-5nm-plant-faces-rationing/">four million gallons of pure water each day</a>. This water usage approaches what a city of half a million people would require for all needs. Sourcing this consistently places immense strain on local water tables and reservoirs, especially in already water-stressed regions which host many high-tech manufacturing hubs.</p>
<p>Additionally, over 250 unique hazardous chemicals are utilized at various stages of semiconductor production within fabs <span class="citation" data-cites="mills1997overview">(<a href="../../references.html#ref-mills1997overview" role="doc-biblioref">Mills and Le Hunte 1997</a>)</span>. These include volatile solvents like sulfuric acid, nitric acid, hydrogen fluoride, along with arsine, phosphine and other highly toxic substances. Preventing discharge of these chemicals requires extensive safety controls and wastewater treatment infrastructure to avoid soil contamination and risks to surrounding communities. Any improper chemical handling or unanticipated spill carries dire consequences.</p>
<p>Beyond water consumption and chemical risks, fab operation also depends on rare metals sourcing, generates tons of dangerous waste products, and can hamper local biodiversity. This section will analyze these critical but less discussed impacts. With vigilance and investment in safety, the harms from semiconductor manufacturing can be contained while still enabling technological progress. However, ignoring these externalized issues will exacerbate ecological damage and health risks over the long run.</p>
<section id="water-usage-and-stress" class="level3" data-number="17.5.1">
<h3 data-number="17.5.1" class="anchored" data-anchor-id="water-usage-and-stress"><span class="header-section-number">17.5.1</span> Water Usage and Stress</h3>
<p>Semiconductor fabrication is an incredibly water-intensive process. Based on an article from 2009, a typical 300mm silicon wafer requires 8,328 litres of water in total, of which 5,678 litres is ultrapure water <span class="citation" data-cites="cope2009pure">(<a href="../../references.html#ref-cope2009pure" role="doc-biblioref">Cope 2009</a>)</span>. Today, a typical fab can use up to <a href="https://wccftech.com/tsmc-arizona-foundry-205-million-approved/">four million gallons of pure water</a>. TSMC’s latest fab in Arizona is projected to use 8.9 million gallons per day, or nearly 3 percent of the city’s current water production, just to operate one facility. To put things in perspective, an by Intel and <a href="https://quantis.com/">Quantis</a> found that over 97% of their direct water consumption is attributed to semiconductor manufacturing operations within their own fabrication facilities <span class="citation" data-cites="cooper2011semiconductor">(<a href="../../references.html#ref-cooper2011semiconductor" role="doc-biblioref">Cooper et al. 2011</a>)</span>.</p>
<p>This water is used to flush away contaminants in cleaning steps repeatedly and also acts as a coolant and carrier fluid in thermal oxidation, chemical deposition, and chemical mechanical planarization processes. This approximates the daily water consumption of a city with a population of half a million people during peak summer months.</p>
<p>Despite being located in regions with sufficient water, the intensive usage can severely depress local water tables and drainage basins. For example, the city of Hsinchu in Taiwan suffered <a href="https://wccftech.com/tsmc-using-water-tankers-for-chip-production-as-5nm-plant-faces-rationing/">sinking water tables and seawater intrusion</a> into aquifers due to excessive pumping to satisfy water supply demands from the Taiwan Semiconductor Manufacturing Company (TSMC) fab. In water-scarce inland areas like Arizona, <a href="https://www.americanbar.org/groups/environment_energy_resources/publications/wr/a-tale-of-two-shortages/">massive water inputs are needed</a> to support fabs despite already strained reservoirs.</p>
<p>Besides depletion, water discharge from fabs also risks environmental contamination if not properly treated. While much discharge is recycled within the fab, the purification systems still filter out metals, acids, and other contaminants that can pollute rivers and lakes if not cautiously handled <span class="citation" data-cites="prakash2022cfu">(<a href="../../references.html#ref-prakash2022cfu" role="doc-biblioref">Prakash et al. 2022</a>)</span>. These factors make managing water usage an essential consideration when mitigating wider sustainability impacts.</p>
</section>
<section id="hazardous-chemicals-usage" class="level3" data-number="17.5.2">
<h3 data-number="17.5.2" class="anchored" data-anchor-id="hazardous-chemicals-usage"><span class="header-section-number">17.5.2</span> Hazardous Chemicals Usage</h3>
<p>Modern semiconductor fabrication involves working with many highly hazardous chemicals under extreme conditions of heat and pressure <span class="citation" data-cites="kim2018chemical">(<a href="../../references.html#ref-kim2018chemical" role="doc-biblioref">Kim et al. 2018</a>)</span>. Key chemicals utilized include:</p>
<ul>
<li><strong>Strong acids:</strong> Hydrofluoric, sulfuric, nitric, and hydrochloric acids rapidly eat through oxides and other surface contaminants but also pose toxicity dangers. Fabs can use thousands of metric tons of these acids annually. Accidental exposure can be fatal for workers.</li>
<li><strong>Solvents:</strong> Key solvents like xylene, methanol, methyl isobutyl ketone (MIBK) handle dissolving photoresists but have adverse health impacts like skin/eye irritation, narcotic effects if mishandled. They also create explosive and air pollution risks.</li>
<li><strong>Toxic gases:</strong> Gas mixtures containing arsine (AsH3), phosphine (PH3), diborane (B2H6), germane (GeH4), etc. are some of the deadliest chemicals used in doping and vapor deposition steps. Minimal exposures can lead to poisoning, tissue damage, and even death without quick treatment.</li>
<li><strong>Chlorinated compounds:</strong> Older chemical mechanical planarization formulations incorporated perchloroethylene, trichloroethylene and other chlorinated solvents since banned due to carcinogenic effects and ozone layer impacts. However, their prior release still threatens surrounding groundwater sources.</li>
</ul>
<p>Strict handling protocols, protective equipment for workers, ventilation, filtrating/scrubbing systems, secondary containment tanks, and specialized disposal mechanisms are vital where these chemicals are used to minimize health, explosion, air, and environmental spill dangers <span class="citation" data-cites="wald1987semiconductor">(<a href="../../references.html#ref-wald1987semiconductor" role="doc-biblioref">Wald and Jones 1987</a>)</span>. But human errors and equipment failures still occasionally occur–highlighting why reducing fab chemical intensities is an ongoing sustainability effort.</p>
</section>
<section id="resource-depletion" class="level3" data-number="17.5.3">
<h3 data-number="17.5.3" class="anchored" data-anchor-id="resource-depletion"><span class="header-section-number">17.5.3</span> Resource Depletion</h3>
<p>While silicon forms the base, there is an almost endless supply of silicon available on Earth. In fact, <a href="https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust">silicon is the second most plentiful element found in the Earth’s crust</a>, accounting for 27.7% of the crust’s total mass. Only oxygen exceeds silicon in abundance within the crust. Therefore, silicon is not necessary to consider for resource depletion. However, the various specialty metals and materials that enable the integrated circuit fabrication process and provide specific properties are scarce. Maintaining supplies of these resources is crucial yet threatened by finite availability and geopolitical influences <span class="citation" data-cites="nakano2021geopolitics">(<a href="../../references.html#ref-nakano2021geopolitics" role="doc-biblioref">Nakano 2021</a>)</span>.</p>
<p>Gallium, indium, and arsenic are vital ingredients in forming ultra-efficient compound semiconductors used in highest speed chips suited for 5G and AI applications <span class="citation" data-cites="chen2006gallium">(<a href="../../references.html#ref-chen2006gallium" role="doc-biblioref">Chen 2006</a>)</span>. However, these rare elements have relatively scarce natural deposits that are being depleted. The United States Geological Survey has indium on its list of most critical at-risk commodities–estimated to have less than a 15 year viable global supply at current demand growth <span class="citation" data-cites="davies2011endangered">(<a href="../../references.html#ref-davies2011endangered" role="doc-biblioref">Davies 2011</a>)</span>.</p>
<p>Helium is required in huge volumes for next-gen fabs to enable precise wafer cooling during operation. But helium’s relative rarity and the fact that once it vents into the atmosphere it quickly escapes Earth makes maintaining helium supplies extremely challenging long-term <span class="citation" data-cites="davies2011endangered">(<a href="../../references.html#ref-davies2011endangered" role="doc-biblioref">Davies 2011</a>)</span>. Substantial price increases and supply shocks are already occurring in this thinly-traded market according to the US National Academies.</p>
<p>Other risks include how China controls over 90% of the rare earth elements critical to semiconductor materials production <span class="citation" data-cites="jha2014rare">(<a href="../../references.html#ref-jha2014rare" role="doc-biblioref">Jha 2014</a>)</span>. Any supply chain issues or trade disputes can lead to catastrophic raw material shortages given lack of current alternatives. In conjunction with helium shortages, resolving the limited availability and geographic imbalance in accessing essential ingredients remains a sector priority for sustainability.</p>
</section>
<section id="hazardous-waste-generation" class="level3" data-number="17.5.4">
<h3 data-number="17.5.4" class="anchored" data-anchor-id="hazardous-waste-generation"><span class="header-section-number">17.5.4</span> Hazardous Waste Generation</h3>
<p>Semiconductor fabs generate tons of hazardous waste annually as byproducts from the various chemical processes involved <span class="citation" data-cites="grossman2007high">(<a href="../../references.html#ref-grossman2007high" role="doc-biblioref">Grossman 2007</a>)</span>. The key waste streams include:</p>
<ul>
<li><strong>Gaseous waste:</strong> Fab ventilation systems capture harmful gases like arsine, phosphine, germane and filter them out to avoid worker exposure. But this produces significant quantities of dangerous condensed gas in need of specialized treatment.</li>
<li><strong>VOCs:</strong> Volatile organic compounds like xylene, acetone, methanol are used extensively as photoresist solvents and get evaporated as emissions during baking, etching, and stripping stages. VOCs pose toxicity issues and require scrubbing systems to prevent release.</li>
<li><strong>Spent acids:</strong> Strong acids such as sulfuric acid, hydrofluoric acid, nitric acid get depleted in cleaning and etching steps transforming into a corrosive toxic soup that can dangerously react releasing heat and fumes if mixed.</li>
<li><strong>Sludge:</strong> Water treatment of discharged effluent contains concentrated heavy metals, acid residues, and chemical contaminants. Filter press systems separate this hazardous sludge.</li>
<li><strong>Filter cake:</strong> Gaseous filtration systems generate multi-ton sticky cakes of dangerous absorbed compounds requiring containment.</li>
</ul>
<p>Without proper handling procedures, storage tanks, packaging materials, and secondary containment–improper disposal of any of these waste streams can lead to dangerous spills, explosions, and environmental release. And the massive volumes mean even well-run fabs produce tons of hazardous waste year after year requiring extensive treatment.</p>
</section>
<section id="biodiversity-impacts" class="level3" data-number="17.5.5">
<h3 data-number="17.5.5" class="anchored" data-anchor-id="biodiversity-impacts"><span class="header-section-number">17.5.5</span> Biodiversity Impacts</h3>
<section id="habitat-disruption-and-fragmentation" class="level4">
<h4 class="anchored" data-anchor-id="habitat-disruption-and-fragmentation">Habitat Disruption and Fragmentation</h4>
<p>Semiconductor fabs require large, contiguous land areas to accommodate cleanrooms, support facilities, chemical storage, waste treatment, and ancillary infrastructure. Developing these vast built-up spaces inevitably dismantles existing habitats, damaging sensitive biomes that may have taken decades to develop. For example, constructing a new fabrication module may level local forest ecosystems relied upon by species like spotted owls and elk for survival. The outright removal of such habitats severely threatens any wildlife populations dependant on those lands.</p>
<p>Furthermore, the pipelines, water channels, air and waste exhaust systems, access roads, transmission towers and other support infrastructure fragments the remaining undisturbed habitats. Animals ranging in their daily movements for food, water and spawning can find migration patterns blocked by these physical human barriers bisecting previously natural corridors.</p>
</section>
<section id="aquatic-life-disturbances" class="level4">
<h4 class="anchored" data-anchor-id="aquatic-life-disturbances">Aquatic Life Disturbances</h4>
<p>With semi-conductor fabs consuming millions of gallons of ultra-pure water daily, accessing and discharging such volumes risks altering the suitability of nearby aquatic environments housing fish, water plants, amphibians and other species. If the fab is tapping groundwater tables as its primary supply source, overdrawing at unsustainable rates can deplete lakes or lead to drying of streams as water levels drop <span class="citation" data-cites="davies2011endangered">(<a href="../../references.html#ref-davies2011endangered" role="doc-biblioref">Davies 2011</a>)</span>.</p>
<p>Additionally, discharging higher temperature wastewater used for cooling fabrication equipment can shift downstream river conditions through thermal pollution. Temperature changes beyond thresholds which native species evolved for can disrupt reproductive cycles. Warmer water also holds less dissolved oxygen critical to support aquatic plant and animal life <span class="citation" data-cites="poff2002aquatic">(<a href="../../references.html#ref-poff2002aquatic" role="doc-biblioref">LeRoy Poff, Brinson, and Day 2002</a>)</span>. Combined with traces of residual contaminants that escape filtration systems, the discharged water can cumulatively transform environments to be far less habitable for sensitive organisms <span class="citation" data-cites="till2019fish">(<a href="../../references.html#ref-till2019fish" role="doc-biblioref">Till et al. 2019</a>)</span>.</p>
</section>
<section id="air-and-chemical-emissions" class="level4">
<h4 class="anchored" data-anchor-id="air-and-chemical-emissions">Air and Chemical Emissions</h4>
<p>While modern semiconductor fabs aim to contain air and chemical discharges through extensive filtration systems, some level of emissions often persist raising risks for nearby flora and fauna. Air pollutants including volatile organic compounds (VOCs), nitrogen oxide compounds (NOxs), and particulate matter from fab operational exhausts as well as power plant fuel emissions can carry downwind.</p>
<p>As contaminants permeate local soils and water sources, wildlife ingesting affected food and water ingest toxic substances which research shows can hamper cell function, reproduction rates and longevity–slowly poisoning ecosystems <span class="citation" data-cites="hsu2016accumulation">(<a href="../../references.html#ref-hsu2016accumulation" role="doc-biblioref">Hsu et al. 2016</a>)</span>.</p>
<p>Likewise, accidental chemical spills and improper waste handling which releases acids, BODs, and heavy metals into soils can dramatically affect retention and leeching capabilities. Flora such as vulnerable native orchids adapted to nutrient-poor substrates can experience die-offs when contacted by foreign runoff chemicals that alter soil pH and permeability. One analysis found that a single 500 gallon nitric acid spill led to the regional extinction of a rare moss species in the year following when the acidic effluent reached nearby forest habitats. Such contamination events set off chain reactions across the interconnected web of life. Thus strict protocols are essential to avoid hazardous discharge and runoff.</p>
</section>
</section>
</section>
<section id="life-cycle-analysis" class="level2" data-number="17.6">
<h2 data-number="17.6" class="anchored" data-anchor-id="life-cycle-analysis"><span class="header-section-number">17.6</span> Life Cycle Analysis</h2>
<p>Understanding the holistic environmental impact of AI systems requires a comprehensive approach that considers the entire life cycle of these technologies. Life Cycle Analysis (LCA) refers to a methodological framework used to quantify the environmental impacts across all stages in the lifespan of a product or system, from raw material extraction to end-of-life disposal. Applying LCA to AI systems can help identify priority areas to target for reducing overall environmental footprints.</p>
<section id="stages-of-an-ai-systems-life-cycle" class="level3" data-number="17.6.1">
<h3 data-number="17.6.1" class="anchored" data-anchor-id="stages-of-an-ai-systems-life-cycle"><span class="header-section-number">17.6.1</span> Stages of an AI System’s Life Cycle</h3>
<p>The life cycle of an AI system can be divided into four key phases:</p>
<ul>
<li><p><strong>Design Phase:</strong> This includes the energy and resources used in the research and development of AI technologies. It encompasses the computational resources used for algorithm development and testing contributing to carbon emissions.</p></li>
<li><p><strong>Manufacture Phase:</strong> This stage involves producing hardware components such as graphics cards, processors, and other computing devices necessary for running AI algorithms. Manufacturing these components often involves significant energy use for material extraction, processing, and greenhouse gas emissions.</p></li>
<li><p><strong>Use Phase:</strong> The next most energy-intensive phase involves the operational use of AI systems. It includes the electricity consumed in data centers for training and running neural networks and powering end-user applications. This is arguably one of the most carbon-intensive stages.</p></li>
<li><p><strong>Disposal Phase:</strong> This final stage covers the end-of-life aspects of AI systems, including the recycling and disposal of electronic waste generated from outdated or non-functional hardware past their usable lifespan.</p></li>
</ul>
</section>
<section id="environmental-impact-at-each-stage" class="level3" data-number="17.6.2">
<h3 data-number="17.6.2" class="anchored" data-anchor-id="environmental-impact-at-each-stage"><span class="header-section-number">17.6.2</span> Environmental Impact at Each Stage</h3>
<p><strong>Design and Manufacturing</strong></p>
<p>The environmental impact during these beginning-of-life phases includes emissions from energy use and resource depletion from extracting materials for hardware production. At the heart of AI hardware are semiconductors, primarily silicon, used to make the integrated circuits in processors and memory chips. This hardware manufacturing relies on metals like copper for wiring, aluminum for casings, and various plastics and composites for other components. It also uses rare earth metals and specialized alloys–elements like neodymium, terbium, and yttrium, are used in small but vital quantities. For example, the creation of GPUs relies on copper and aluminum. At the same time, chips use rare earth metals–the mining process for which can generate substantial carbon emissions and ecosystem damage.</p>
<p><strong>Use Phase</strong></p>
<p>AI computes the majority of emissions in the lifecycle due to continuous high-power consumption, especially for training and running models. This includes direct emissions from electricity usage and indirect emissions from non-renewable grid energy generation. Studies estimate training complex models can have a carbon footprint comparable to the lifetime emissions of up to five cars.</p>
<p><strong>Disposal Phase</strong></p>
<p>The impact of the disposal stage includes air and water pollution from toxic materials in devices, challenges associated with complex electronics recycling, and contamination when improperly handled. Harmful compounds from burned e-waste are released into the atmosphere. At the same time, landfill leakage of lead, mercury and other materials poses risks of soil and groundwater contamination if not properly controlled. Implementing effective electronics recycling is crucial.</p>
</section>
</section>
<section id="challenges-in-lca" class="level2" data-number="17.7">
<h2 data-number="17.7" class="anchored" data-anchor-id="challenges-in-lca"><span class="header-section-number">17.7</span> Challenges in LCA</h2>
<section id="lack-of-consistency-and-standards" class="level3" data-number="17.7.1">
<h3 data-number="17.7.1" class="anchored" data-anchor-id="lack-of-consistency-and-standards"><span class="header-section-number">17.7.1</span> Lack of Consistency and Standards</h3>
<p>One major challenge facing life cycle analysis (LCA) for AI systems is the current lack of consistent methodological standards and frameworks. Unlike product categories like building materials that have developed international standards for LCA through ISO 14040, there are no firmly established guidelines tailored to analyzing the environmental footprint of complex information technology like AI.</p>
<p>This absence of uniformity means researchers make differing assumptions and varying methodological choices. For example, a 2021 study from the University of Massachusetts Amherst <span class="citation" data-cites="strubell2019energy">(<a href="../../references.html#ref-strubell2019energy" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019</a>)</span> analyzed the life cycle emissions of several natural language processing models but only considered computational resource usage for training and omitted hardware manufacturing impacts. A more comprehensive 2020 study from Stanford University researchers included emissions estimates from the production of relevant servers, processors, and other components, following an ISO-aligned LCA standard for computer hardware. However, these diverging choices in system boundaries and accounting approaches reduce robustness and prevent apples-to-apples comparisons of results.</p>
<p>Having standardized frameworks and protocols tailored to the unique aspects and rapid update cycles of AI systems would provide more coherence. This could better equip researchers and developers to understand environmental hotspots, compare technology options, and accurately track progress on sustainability initiatives across the AI field. Industry groups and international standards bodies like the IEEE or ACM should prioritize addressing this methodological gap.</p>
</section>
<section id="data-gaps" class="level3" data-number="17.7.2">
<h3 data-number="17.7.2" class="anchored" data-anchor-id="data-gaps"><span class="header-section-number">17.7.2</span> Data Gaps</h3>
<p>Another key challenge for comprehensive life cycle assessment of AI systems is substantial data gaps, especially regarding upstream supply chain impacts and downstream electronic waste flows. Most existing studies focus narrowly on the learner or usage phase emissions from computational power demands, which misses a significant portion of lifetime emissions <span class="citation" data-cites="gupta2022">(<a href="../../references.html#ref-gupta2022" role="doc-biblioref">Gupta et al. 2022</a>)</span>.</p>
<p>For example, little public data from companies exists quantifying energy use and emissions from manufacturing the specialized hardware components that enable AI–including high-end GPUs, ASIC chips, solid-state drives and more. Researchers often rely on secondary sources or generic industry averages to approximate production impacts. Similarly, there is limited transparency into downstream fate once AI systems are discarded after 4-5 years of usable lifespans on average.</p>
<p>While electronic waste generation levels can be estimated, specifics on hazardous material leakage, recycling rates, and disposal methods for the complex components are hugely uncertain without better corporate documentation or regulatory reporting requirements.</p>
<p>Even for the usage phase, the lack of fine-grained data on computational resource consumption for training different model types makes reliable per-parameter or per-query emissions calculations difficult. Attempts to create lifecycle inventories estimating average energy needs for key AI tasks exist <span class="citation" data-cites="henderson2020towards anthony2020carbontracker">(<a href="../../references.html#ref-henderson2020towards" role="doc-biblioref">Henderson et al. 2020</a>; <a href="../../references.html#ref-anthony2020carbontracker" role="doc-biblioref">Anthony, Kanding, and Selvan 2020</a>)</span> but variability across hardware setups, algorithms, and input data uncertainty remains extremely high. Furthermore, real time carbon intensity data, which is critical in accurately tracking operational carbon footprint, is lacking in many geographic locations, thereby rendering existing tools for operational carbon emission mere approximations based on annual average carbon intensity values.</p>
<p>The challenge is that tools like <a href="https://codecarbon.io/">CodeCarbon</a> and <a href="https://mlco2.github.io/impact/#compute">ML <span class="math inline">\(\textrm{CO}_2\)</span></a> but these are ad hoc approaches at best. Bridging the real data gaps with more rigorous corporate sustainability disclosures and mandated environmental impact reporting will be key for AI’s overall climatic impacts to be understood and managed.</p>
</section>
<section id="rapid-pace-of-evolution" class="level3" data-number="17.7.3">
<h3 data-number="17.7.3" class="anchored" data-anchor-id="rapid-pace-of-evolution"><span class="header-section-number">17.7.3</span> Rapid Pace of Evolution</h3>
<p>The extremely quick evolution of AI systems poses additional challenges when it comes to keeping life cycle assessments up-to-date and accounting for the latest hardware and software advancements. The core algorithms, specialized chips, frameworks, and technical infrastructure underpinning AI have all been advancing at exceptionally fast rates, with new developments rapidly rendering prior systems obsolete.</p>
<p>For example, in the deep learning space, novel neural network architectures that achieve significantly better performance on key benchmarks or new optimized hardware like Google’s TPU chips can completely change what an “average” model looks like in less than a year. These swift shifts make one-off LCA studies outdated quickly for accurately tracking emissions from designing, running, or disposing of the latest AI.</p>
<p>However, the resources and access required to continuously update LCAs also poses barriers. Frequently re-doing labor and data intensive life cycle inventories and impact modeling to stay current with AI’s state of the art is likely infeasible for many researchers and organizations. But without updated analyses, the environmental hotspots as algorithms and silicon chips continue rapidly evolving could be missed.</p>
<p>This presents a difficulty in balancing dynamic precision through continuous assessment with pragmatic constraints. Some researchers have proposed simplified proxy metrics like tracking hardware generations over time or using representative benchmarks as an oscillating set of goalposts for relative comparisons, though granularity may be sacrificed. Overall, the challenge of rapid change will require innovative methodological solutions to prevent underestimating AI’s evolving environmental burdens.</p>
</section>
<section id="supply-chain-complexity" class="level3" data-number="17.7.4">
<h3 data-number="17.7.4" class="anchored" data-anchor-id="supply-chain-complexity"><span class="header-section-number">17.7.4</span> Supply Chain Complexity</h3>
<p>Finally, the complex and often opaque supply chains associated with producing the wide array of specialized hardware components that enable AI pose challenges for comprehensive life cycle modeling. State-of-the-art AI relies on leveraging cutting-edge advancements in processing chips, graphics cards, data storage, networking equipment and more. However, tracking emissions and resource use across the tiered networks of globalized suppliers for all these components is extremely difficult.</p>
<p>For example, NVIDIA graphics processing units dominate much AI computing hardware, but the company relies on over several discrete suppliers across Asia and beyond to produce the GPUs. Many firms at each supplier tier choose not to disclose facility-level environmental data that could enable robust LCAs fully. Gaining end-to-end transparency down multiple levels of suppliers across disparate geographies with varying disclosure protocols and regulations poses barriers, despite being crucial for complete boundary setting. This becomes even more complex when attempting to model emerging hardware accelerators like tensor processing units (TPUs), whose production networks still need to be made public.</p>
<p>Without willingness from tech giants to require and consolidate environmental impact data disclosure from across their global electronics supply chains, considerable uncertainty will remain around quantifying the full lifecycle footprint of AI hardware enablement. More supply chain visibility coupled with standardized sustainability reporting frameworks specifically addressing AI’s complex inputs hold promise for enriching LCAs and prioritizing environmental impact reductions.</p>
</section>
</section>
<section id="sustainable-design-and-development" class="level2" data-number="17.8">
<h2 data-number="17.8" class="anchored" data-anchor-id="sustainable-design-and-development"><span class="header-section-number">17.8</span> Sustainable Design and Development</h2>
<section id="sustainability-principles" class="level3" data-number="17.8.1">
<h3 data-number="17.8.1" class="anchored" data-anchor-id="sustainability-principles"><span class="header-section-number">17.8.1</span> Sustainability Principles</h3>
<p>As the impact of AI on the environment becomes increasingly evident, the focus on sustainable design and development in AI is gaining prominence. This involves incorporating sustainability principles into AI design, developing energy-efficient models, and integrating these considerations throughout the AI development pipeline. There is a growing need to consider its sustainability implications and develop principles to guide responsible innovation. Below is a core set of principles. The principles flows from the conceptual foundation, to practical execution, to supporting implementation factors, the principles provide a full cycle perspective on embedding sustainability in AI design and development.</p>
<p><strong>Lifecycle Thinking:</strong> Encouraging designers to consider the entire lifecycle of AI systems, from data collection and preprocessing to model development, training, deployment, and monitoring. The goal is to ensure sustainability is considered at each stage. This includes using energy-efficient hardware, prioritizing renewable energy sources, and planning to reuse or recycle retired models.</p>
<p><strong>Future Proofing:</strong> Designing AI systems anticipating future needs and changes can enhance sustainability. This may involve making models adaptable via transfer learning and modular architectures. It also includes planning capacity for projected increases in operational scale and data volumes.</p>
<p><strong>Efficiency and Minimalism:</strong> This principle focuses on creating AI models that achieve desired results with the least possible resource use. It involves simplifying models and algorithms to reduce computational requirements. Specific techniques include pruning redundant parameters, quantizing and compressing models, and designing efficient model architectures, such as those discussed in the <a href="../../contents/optimizations/optimizations.html">Optimizations</a> chapter.</p>
<p><strong>Lifecycle Assessment (LCA) Integration:</strong> Analyzing environmental impacts throughout the development and deployment lifecycles highlights unsustainable practices early on. Teams can then make needed adjustments, instead of discovering issues late when they are more difficult to address. Integrating this analysis into the standard design flow avoids creating legacy sustainability problems.</p>
<p><strong>Incentive Alignment:</strong> Economic and policy incentives should promote and reward sustainable AI development. This may include government grants, corporate initiatives, industry standards, and academic mandates for sustainability. Aligned incentives enable sustainability to become embedded in AI culture.</p>
<p><strong>Sustainability Metrics and Goals:</strong> Metrics that measure sustainability factors like carbon usage and energy efficiency are important to establish clearly. Establishing clear targets for these metrics provides concrete guidelines for teams to develop responsible AI systems. Tracking performance on metrics over time shows progress towards set sustainability goals.</p>
<p><strong>Fairness, Transparency, and Accountability:</strong> Sustainable AI systems should be fair, transparent, and accountable. Models should be unbiased, with transparent development processes and mechanisms for auditing and redressing issues. This builds public trust and enables the identification of unsustainable practices.</p>
<p><strong>Cross-disciplinary Collaboration:</strong> AI researchers teaming up with environmental scientists and engineers can lead to innovative systems that are high-performing yet environmentally friendly. Combining expertise from different fields from the start of projects enables sustainable thinking to be incorporated into the AI design process.</p>
<p><strong>Education and Awareness:</strong> Workshops, training programs, and course curricula that cover AI sustainability raise awareness among the next generation of practitioners. This equips students with the knowledge to develop AI that consciously minimizes negative societal and environmental impacts. Instilling these values from the start shapes tomorrow’s professionals and company cultures.</p>
</section>
</section>
<section id="green-ai-infrastructure" class="level2" data-number="17.9">
<h2 data-number="17.9" class="anchored" data-anchor-id="green-ai-infrastructure"><span class="header-section-number">17.9</span> Green AI Infrastructure</h2>
<p>Green AI represents a transformative approach to AI that incorporates environmental sustainability as a fundamental principle across the AI system design and lifecycle <span class="citation" data-cites="schwartz2020green">(<a href="../../references.html#ref-schwartz2020green" role="doc-biblioref">R. Schwartz et al. 2020</a>)</span>. This shift is driven by growing awareness of AI technologies’ significant carbon footprint and ecological impact, especially the compute-intensive process of training complex ML models.</p>
<p>The essence of Green AI lies in its commitment to align AI advancement with sustainability goals around energy efficiency, renewable energy usage, and waste reduction. The introduction of Green AI ideals reflects maturing responsibility across the tech industry towards environmental stewardship and ethical technology practices. It moves beyond technical optimizations towards holistic life cycle assessment on how AI systems affect sustainability metrics. Setting new bars for ecologically conscious AI paves the way for the harmonious coexistence of technological progress and planetary health.</p>
<section id="energy-efficient-ai-systems" class="level3" data-number="17.9.1">
<h3 data-number="17.9.1" class="anchored" data-anchor-id="energy-efficient-ai-systems"><span class="header-section-number">17.9.1</span> Energy Efficient AI Systems</h3>
<p>Energy efficiency in AI systems is a cornerstone of Green AI, aiming to reduce the significant energy demands traditionally associated with AI development and operations. This shift towards energy-conscious AI practices is vital in addressing the environmental concerns raised by the rapidly expanding field of AI. By focusing on energy efficiency, AI systems can become more sustainable, lessening their environmental impact and paving the way for more responsible AI use.</p>
<p>As we have discussed earlier, the training and operation of AI models, especially large-scale ones, are known for their high energy consumption stemming from compute-intensive model architecture and reliance on vast amounts of training data. For example, it is estimated that training a large state-of-the-art neural network model can have a carbon footprint of 284 tonnes–equivalent to the lifetime emissions of 5 cars <span class="citation" data-cites="strubell2019energy">(<a href="../../references.html#ref-strubell2019energy" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019</a>)</span>.</p>
<p>To tackle the massive energy demands, researchers and developers are actively exploring methods to optimize AI systems for better energy efficiency without losing model accuracy or performance. This includes techniques like the ones we have discussed in the model optimizations, efficient AI and hardware acceleration chapters:</p>
<ul>
<li>Knowledge distillation to transfer knowledge from large AI models to miniature versions</li>
<li>Quantization and pruning approaches that reduce computational and space complexities</li>
<li>Low-precision numerics–lowering mathematical precision without impacting model quality</li>
<li>Specialized hardware like TPUs, neuromorphic chips tuned explicitly for efficient AI processing</li>
</ul>
<p>One example is Intel’s work on Q8BERT—quantizing BERT language model with 8-bit integers, leading to 4x reduction in model size with minimal accuracy loss <span class="citation" data-cites="zafrir2019q8bert">(<a href="../../references.html#ref-zafrir2019q8bert" role="doc-biblioref">Zafrir et al. 2019</a>)</span>. The push for energy-efficient AI is not just a technical endeavor–it has tangible real-world implications. More performant systems lower AI’s operational costs and carbon footprint, making it accessible for widespread deployment on mobile and edge devices. It also paves the path toward the democratization of AI and mitigates unfair biases that can emerge from uneven access to computing resources across regions and communities. Pursuing energy-efficient AI is thus crucial for creating an equitable and sustainable future with AI.</p>
</section>
<section id="sustainable-ai-infrastructure" class="level3" data-number="17.9.2">
<h3 data-number="17.9.2" class="anchored" data-anchor-id="sustainable-ai-infrastructure"><span class="header-section-number">17.9.2</span> Sustainable AI Infrastructure</h3>
<p>Sustainable AI infrastructure includes the physical and technological frameworks that support AI systems, focusing on environmental sustainability. This involves designing and operating AI infrastructure in a way that minimizes ecological impact, conserves resources, and reduces carbon emissions. The goal is to create a sustainable ecosystem for AI that aligns with broader environmental objectives.</p>
<p>Central to sustainable AI infrastructure are green data centers, which are optimized for energy efficiency and often powered by renewable energy sources. These data centers employ advanced cooling technologies <span class="citation" data-cites="ebrahimi2014review">(<a href="../../references.html#ref-ebrahimi2014review" role="doc-biblioref">Ebrahimi, Jones, and Fleischer 2014</a>)</span>, energy-efficient server designs <span class="citation" data-cites="uddin2012energy">(<a href="../../references.html#ref-uddin2012energy" role="doc-biblioref">Uddin and Rahman 2012</a>)</span>, and smart management systems <span class="citation" data-cites="buyya2010energyefficient">(<a href="../../references.html#ref-buyya2010energyefficient" role="doc-biblioref">Buyya, Beloglazov, and Abawajy 2010</a>)</span> to reduce power consumption. The shift towards green computing infrastructure also involves adopting energy-efficient hardware, like AI-optimized processors that deliver high performance with lower energy requirements, which we discussed in the <a href="../../contents/hw_acceleration/hw_acceleration.html">AI Acceleration</a> chapter. These efforts collectively reduce the carbon footprint of running large-scale AI operations.</p>
<p>Integrating renewable energy sources, such as solar, wind, and hydroelectric power, into AI infrastructure is important for environmental sustainability <span class="citation" data-cites="chua1971memristor">(<a href="../../references.html#ref-chua1971memristor" role="doc-biblioref">Chua 1971</a>)</span>. Many tech companies and research institutions are <a href="https://www.forbes.com/sites/siemens-smart-infrastructure/2023/03/13/how-data-centers-are-driving-the-renewable-energy-transition/?sh=3208c5b54214">investing in renewable energy projects to power their data centers</a>. This not only helps in making AI operations carbon-neutral but also promotes the wider adoption of clean energy. Using renewable energy sources is a clear statement of commitment to environmental responsibility in the AI industry.</p>
<p>Sustainability in AI also extends to the materials and hardware used in creating AI systems. This involves choosing environmentally friendly materials, adopting recycling practices, and ensuring responsible electronic waste disposal. Efforts are underway to develop more sustainable hardware components, including energy-efficient chips designed for domain-specific tasks (such as AI accelerators) and environmentally friendly materials in device manufacturing <span class="citation" data-cites="cenci2021ecofriendly irimiavladu2014textquotedblleftgreentextquotedblright">(<a href="../../references.html#ref-cenci2021ecofriendly" role="doc-biblioref">Cenci et al. 2021</a>; <a href="../../references.html#ref-irimiavladu2014textquotedblleftgreentextquotedblright" role="doc-biblioref">Irimia-Vladu 2014</a>)</span>. The lifecycle of these components is also a focus, with initiatives aimed at extending the lifespan of hardware and promoting recycling and reuse.</p>
<p>While strides are being made in sustainable AI infrastructure, challenges remain, such as the high costs of green technology and the need for global standards in sustainable practices. Future directions may include more widespread adoption of green energy, further innovations in energy-efficient hardware, and international collaboration on sustainable AI policies. The pursuit of sustainable AI infrastructure is not just a technical endeavor but a holistic approach that encompasses environmental, economic, and social aspects, ensuring that AI advances in harmony with our planet’s health.</p>
</section>
<section id="frameworks-and-tools" class="level3" data-number="17.9.3">
<h3 data-number="17.9.3" class="anchored" data-anchor-id="frameworks-and-tools"><span class="header-section-number">17.9.3</span> Frameworks and Tools</h3>
<p>To effectively implement Green AI practices, it is essential to have access to the right frameworks and tools. These resources are designed to assist developers and researchers in creating more energy-efficient and environmentally friendly AI systems. They range from software libraries optimized for low-power consumption to platforms that facilitate the development of sustainable AI applications.</p>
<p>There are several software libraries and development environments specifically tailored for Green AI. These tools often include features for optimizing AI models to reduce their computational load and, consequently, their energy consumption. For example, libraries in PyTorch and TensorFlow that support model pruning, quantization, and efficient neural network architectures enable developers to build AI systems that require less processing power and energy. Additionally, there are open source communities like the <a href="https://github.com/Green-Software-Foundation">Green Carbon Foundation</a> creating a centralized carbon intensity metric and building software for carbon-aware computing.</p>
<p>Energy monitoring tools are crucial for Green AI, as they allow developers to measure and analyze the energy consumption of their AI systems. By providing detailed insights into where and how energy is being used, these tools enable developers to make informed decisions about optimizing their models for better energy efficiency. This can involve adjustments in algorithm design, hardware selection, cloud computing software selection, or operational parameters. <a href="#fig-azuredashboard" class="quarto-xref">Figure&nbsp;<span>17.7</span></a> is a screenshot of an energy consumption dashboard provided by Microsoft’s cloud services platform.</p>
<div id="fig-azuredashboard" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-azuredashboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/azure_dashboard.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-azuredashboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.7: Microsoft Azure energy consumption dashboard. Credit: <a href="https://techcommunity.microsoft.com/t5/green-tech-blog/charting-the-path-towards-sustainable-ai-with-azure-machine/ba-p/2866923">Will Buchanan.</a>
</figcaption>
</figure>
</div>
<p>With the increasing integration of renewable energy sources in AI operations, frameworks that facilitate this process are becoming more important. These frameworks help manage the energy supply from renewable sources like solar or wind power, ensuring that AI systems can operate efficiently with fluctuating energy inputs.</p>
<p>Beyond energy efficiency, sustainability assessment tools help evaluate the broader environmental impact of AI systems. These tools can analyze factors like the carbon footprint of AI operations, the lifecycle impact of hardware components <span class="citation" data-cites="gupta2022">(<a href="../../references.html#ref-gupta2022" role="doc-biblioref">Gupta et al. 2022</a>)</span>, and the overall sustainability of AI projects <span class="citation" data-cites="prakash2022cfu">(<a href="../../references.html#ref-prakash2022cfu" role="doc-biblioref">Prakash et al. 2022</a>)</span>.</p>
<p>The availability and ongoing development of Green AI frameworks and tools are critical for advancing sustainable AI practices. By providing the necessary resources for developers and researchers, these tools facilitate the creation of more environmentally friendly AI systems and encourage a broader shift towards sustainability in the tech community. As Green AI continues to evolve, these frameworks and tools will play a vital role in shaping a more sustainable future for AI.</p>
</section>
<section id="benchmarks-and-leaderboards" class="level3" data-number="17.9.4">
<h3 data-number="17.9.4" class="anchored" data-anchor-id="benchmarks-and-leaderboards"><span class="header-section-number">17.9.4</span> Benchmarks and Leaderboards</h3>
<p>Benchmarks and leaderboards are important for driving progress in Green AI by providing standardized ways to measure and compare different methods. Well-designed benchmarks that capture relevant metrics around energy efficiency, carbon emissions, and other sustainability factors enable the community to track advancements in a fair and meaningful way.</p>
<p>There exist extensive benchmarks for tracking AI model performance, such as those extensively discussed in the <a href="../../contents/benchmarking/benchmarking.html">Benchmarking</a> chapter, but there is a clear and pressing need for additional standardized benchmarks focused on sustainability metrics like energy efficiency, carbon emissions, and overall ecological impact. Understanding the environmental costs of AI is currently hampered by a lack of transparency and standardized measurement around these factors.</p>
<p>Emerging efforts such as the <a href="https://ml.energy/leaderboard">ML.ENERGY Leaderboard</a>, which provides performance and energy consumption benchmarking results for large language models (LLMs) text generation, assists in enhancing the understanding of the energy cost of GenAI deployment.</p>
<p>As with any benchmark, it is important that Green AI benchmarks represent realistic usage scenarios and workloads. Benchmarks that focus narrowly on easily gamed metrics may lead to short-term gains but fail to reflect actual production environments where more holistic measures of efficiency and sustainability are needed. The community should continue expanding benchmarks to cover diverse use cases.</p>
<p>Wider adoption of common benchmark suites by industry players will accelerate innovation in Green AI by allowing easier comparison of techniques across organizations. Shared benchmarks lower the barrier for demonstrating the sustainability benefits of new tools and best practices. However, care must be taken around issues like intellectual property, privacy, and commercial sensitivity when designing industry-wide benchmarks. Initiatives to develop open reference datasets for Green AI evaluation may help drive broader participation.</p>
<p>As methods and infrastructure for Green AI continue maturing, the community also needs to revisit benchmark design to ensure existing suites capture new techniques and scenarios well. Tracking the evolving landscape through regular benchmark updates and reviews will be important to maintain representative comparisons over time. Community efforts for benchmark curation can enable sustainable benchmark suites that stand the test of time. Comprehensive benchmark suites owned by research communities or neutral third parties like <a href="https://mlcommons.org">MLCommons</a> may encourage wider participation and standardization.</p>
</section>
</section>
<section id="case-study-google-4ms" class="level2" data-number="17.10">
<h2 data-number="17.10" class="anchored" data-anchor-id="case-study-google-4ms"><span class="header-section-number">17.10</span> Case Study: Google’s 4Ms</h2>
<p>Over the past decade, AI has rapidly moved from the realm of academic research to large-scale production systems powering numerous Google products and services. As AI models and workloads have grown exponentially in size and computational demands, concerns have emerged about their energy consumption and carbon footprint. Some researchers predicted runaway growth in ML’s energy appetite that could outweigh efficiencies gained from improved algorithms and hardware <span class="citation" data-cites="thompson2021deep">(<a href="../../references.html#ref-thompson2021deep" role="doc-biblioref">Thompson et al. 2021</a>)</span>.</p>
<p>However, Google’s own production data reveals a different story–with AI representing a steady 10-15% of total company energy usage from 2019 to 2021. This case study analyzes how Google applied a systematic approach leveraging four best practices–what they term the “4 Ms” of model efficiency, machine optimization, mechanization through cloud computing, and mapping to green locations to bend the curve on emissions from AI workloads.</p>
<p>The scale of Google’s AI usage makes it an ideal case study. In 2021 alone, the company was training models like the 1.2 trillion parameter GLam model. Analyzing how the application of AI has been paired with rapid efficiency gains in this environment helps us by providing a logical blueprint for the broader AI field to follow.</p>
<p>By transparently publishing detailed energy usage statistics, adoption rates of carbon-free clouds and renewables purchases, and more alongside its technical innovations, Google has enabled outside researchers to accurately measure progress. Their study in the ACM CACM <span class="citation" data-cites="patterson2022carbon">(<a href="../../references.html#ref-patterson2022carbon" role="doc-biblioref">Patterson et al. 2022</a>)</span> highlights how the company’s multi-pronged approach shows that predictions of runaway AI energy consumption can be overcome through focusing engineering efforts on sustainable development patterns. The pace of improvements also suggests ML’s efficiency gains are just getting started.</p>
<section id="google-4m-best-practices" class="level3" data-number="17.10.1">
<h3 data-number="17.10.1" class="anchored" data-anchor-id="google-4m-best-practices"><span class="header-section-number">17.10.1</span> Google’s 4M Best Practices</h3>
<p>To curb emissions from their rapidly expanding AI workloads, Google engineers systematically identified four best practice areas–termed the “4 Ms”–where optimizations could compound to reduce the carbon footprint of ML:</p>
<ul>
<li>Model - Selecting efficient AI model architectures can reduce computation by 5-10X with no loss in model quality. Google has focused extensive research on developing sparse models and neural architecture search to create more efficient models like the Evolved Transformer and Primer.</li>
<li>Machine - Using hardware optimized for AI over general purpose systems improves performance per watt by 2-5X. Google’s Tensor Processing Units (TPUs) led to 5-13X better carbon efficiency versus GPUs not optimized for ML.</li>
<li>Mechanization - By leveraging cloud computing systems tailored for high utilization over conventional on-premise data centers, energy costs reduce by 1.4-2X. Google cites its data centers’ Power Usage Effectiveness outpacing industry averages.</li>
<li>Map - Choosing data center locations with low-carbon electricity reduces gross emissions by another 5-10X. Google provides real-time maps highlighting its renewable energy percentage by facility.</li>
</ul>
<p>Together, these practices created drastic compound efficiency gains. For example, optimizing the Transformer AI model on TPUs in a sustainable data center location cut energy use by a factor of 83 and lowered <span class="math inline">\(\textrm{CO}_2\)</span> emissions by a factor of 747.</p>
</section>
<section id="significant-results" class="level3" data-number="17.10.2">
<h3 data-number="17.10.2" class="anchored" data-anchor-id="significant-results"><span class="header-section-number">17.10.2</span> Significant Results</h3>
<p>Google’s efforts to improve the carbon efficiency of ML have produced measurable gains helping to restrain overall energy appetite, despite exponential growth in AI adoption across products and services. One key datapoint highlighting this progress is that AI workloads have remained a steady 10% to 15% of total company energy use from 2019 to 2021. As AI became integral to ever more Google offerings, overall compute cycles dedicated to AI grew substantially. However, efficiencies on algorithms, specialized hardware, data center design and flexible geography allowed sustainability to keep pace—with AI representing just a fraction of total data center electricity over years of expansion.</p>
<p>Other case studies further underscore how an engineering focus on sustainable AI development patterns enabled rapid quality improvements in lockstep with environmental gains. For example, the natural language processing model GPT-3 was viewed as state-of-the-art in mid-2020. Yet its successor GLaM improved accuracy while cutting training compute needs and using cleaner data center energy–cutting CO2 emissions by a factor of 14 in just 18 months of model evolution.</p>
<p>Similarly, Google found past published speculation missing the mark on ML’s energy appetite by factors of 100 to 100,000X due to lacking real-world metrics. By transparently tracking optimization impact, Google hoped to motivate efficiency while preventing overestimated extrapolations about ML’s environmental toll.</p>
<p>Together these data-driven case studies show how companies like Google are steering AI advancements toward sustainable trajectories and driving efficiency improvements to outpace adoption growth. And with further efforts around lifecycle analysis, inference optimization, and renewable expansion, companies can aim to accelerate progress—giving evidence that ML’s clean potential is only just being unlocked by current gains.</p>
</section>
<section id="further-improvements" class="level3" data-number="17.10.3">
<h3 data-number="17.10.3" class="anchored" data-anchor-id="further-improvements"><span class="header-section-number">17.10.3</span> Further Improvements</h3>
<p>While Google has made measurable progress in restraining the carbon footprint of its AI operations, the company recognizes further efficiency gains will be vital for responsible innovation given the technology’s ongoing expansion.</p>
<p>One area of focus is showing how advances often incorrectly viewed as increasing unsustainable computing—like neural architecture search (NAS) to find optimized models—actually spur downstream savings outweighing their upfront costs. Despite expending more energy for model discovery rather than hand-engineering, NAS cuts lifetime emissions by producing efficient designs callable across countless applications.</p>
<p>Additionally, analysis reveals focusing sustainability efforts on data center and server-side optimization makes sense given the dominant energy draw versus consumer devices. Though Google aims to shrink inference impacts across processors like mobile phones, priority rests on improving training cycles and data center renewables procurement for maximal effect.</p>
<p>To that end, Google’s progress in pooling compute in efficiently designed cloud facilities highlights the value of scale and centralization. As more workloads shift away from inefficient on-premise servers, internet giants’ prioritization of renewable energy—with Google and Facebook matched 100% by renewables since 2017 and 2020 respectively—unlocks compounding emissions cuts.</p>
<p>Together these efforts emphasize that while no resting on laurels is possible, Google’s multipronged approach shows AI efficiency improvements are only accelerating. Cross-domain initiatives around lifecycle assessment, carbon-conscious development patterns, transparency, and matching rising AI demand with clean electricity supply pave a path toward bending the curve further as adoption grows. The company’s results compel the broader field towards replicating these integrated sustainability pursuits.</p>
</section>
</section>
<section id="embedded-ai-internet-of-trash" class="level2" data-number="17.11">
<h2 data-number="17.11" class="anchored" data-anchor-id="embedded-ai-internet-of-trash"><span class="header-section-number">17.11</span> Embedded AI - Internet of Trash</h2>
<p>While much attention has focused on making the immense data centers powering AI more sustainable, an equally pressing concern is the movement of AI capabilities into smart edge devices and endpoints. Edge/embedded AI allows near real-time responsiveness without connectivity dependencies. It also reduces transmission bandwidth needs. However, the increase of tiny devices leads to other risks.</p>
<p>Tiny computers, microcontrollers, and custom ASICs powering edge intelligence face size, cost and power limitations that rule out high-end GPUs used in data centers. Instead, they require optimized algorithms and extremely compact, energy-efficient circuitry to run smoothly. But engineering for these microscopic form factors opens up risks around planned obsolescence, disposability, and waste. <a href="#fig-iot-devices" class="quarto-xref">Figure&nbsp;<span>17.8</span></a> shows that the number of IoT devices is projected to <a href="https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/">reach 30 billion connected devices by 2030</a>.</p>
<div id="fig-iot-devices" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-iot-devices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/statista_chip_growth.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-iot-devices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.8: Number of Internet of Things (IoT) connected devices worldwide from 2019 to 2023. Credit: <a href="https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/">Statista.</a>
</figcaption>
</figure>
</div>
<p>End-of-life handling of internet-connected gadgets embedded with sensors and AI remains an often overlooked issue during design, though these products permeate consumer goods, vehicles, public infrastructure, industrial equipment and more.</p>
<section id="e-waste" class="level4">
<h4 class="anchored" data-anchor-id="e-waste">E-waste</h4>
<p>Electronic waste, or e-waste, refers to discarded electrical equipment and components that enter the waste stream. This includes devices that have to be plugged in, have a battery, or electrical circuitry. With the rising adoption of internet-connected smart devices and sensors, e-waste volumes are rapidly increasing each year. These proliferating gadgets contain toxic heavy metals like lead, mercury, and cadmium that become environmental and health hazards when improperly disposed.</p>
<p>The amount of electronic waste being produced is growing at an alarming rate. Today, <a href="https://www.unep.org/news-and-stories/press-release/un-report-time-seize-opportunity-tackle-challenge-e-waste">we already produce 50 million tons per year</a>. By 2030, that figure is projected to jump to a staggering 75 million tons as consumer electronics consumption continues to accelerate. Global e-waste production is on track to reach 120 million tonnes per year by 2050 <span class="citation" data-cites="un2019circular">(<a href="../../references.html#ref-un2019circular" role="doc-biblioref">Un and Forum 2019</a>)</span>. From smartphones and tablets to internet-connected devices and home appliances, the soaring production and short lifecycles of our gadgets is fueling this crisis.</p>
<p>Developing nations are being hit the hardest as they lack the infrastructure to safely process obsolete electronics. In 2019, formal e-waste recycling rates in poorer countries ranged from just 13% to 23%. The remainder ends up illegally dumped, burned, or crudely dismantled–releasing toxic materials into the environment and harming workers as well as local communities. Clearly more needs to be done to build global capacity for ethical and sustainable e-waste management or we risk irreversible damage.</p>
<p>The danger is that crude handling of electronics to strip valuables exposes marginalized workers and communities to noxious burnt plastics/metals. Lead poisoning poses especially high risks to child development if ingested or inhaled. Overall, only about 20% of e-waste produced was collected using environmentally sound methods according to UN estimates <span class="citation" data-cites="un2019circular">(<a href="../../references.html#ref-un2019circular" role="doc-biblioref">Un and Forum 2019</a>)</span>. So solutions for responsible lifecycle management are urgently required to contain the unsafe disposal as volume soars higher.</p>
</section>
<section id="disposable-electronics" class="level4">
<h4 class="anchored" data-anchor-id="disposable-electronics">Disposable Electronics</h4>
<p>Rapidly falling costs of microcontrollers, tiny rechargeable batteries, and compact communication hardware has enabled embedding intelligent sensor systems throughout everyday consumer goods. These internet-of-things (IoT) devices monitor product conditions, user interactions, and environment factors in order to enable real-time responsiveness, personalization, and data-driven business decisions in the evolving connected marketplace.</p>
<p>However, these embedded electronics face little oversight or planning around sustainably handling their eventual disposal once the often plastic-encased products get thrown out following brief lifetimes. IoT sensors now commonly reside in single-use items like water bottles, food packaging, prescription bottles, and cosmetic containers that overwhelmingly enter landfill waste streams after a few weeks to months of consumer use.</p>
<p>The problem accelerates as more manufacturers rush to integrate mobile chips, power sources, Bluetooth modules and other modern silicon ICs costing under US$1 into various merchandise without protocols for recycling, replacing batteries or component reusability. Despite their small individual size, collectively the volumes of these devices and lifetime waste burden loom large. Unlike regulating larger electronics, few policy constraints currently exist around materials requirements or toxicity in tiny disposable gadgets.</p>
<p>While offering convenience when working, the unsustainable combination of difficult retrievability and limited safe breakdown mechanisms causes disposable connected devices to contribute outsized shares of future e-waste volumes needing urgent attention.</p>
</section>
<section id="planned-obsolescence" class="level4">
<h4 class="anchored" data-anchor-id="planned-obsolescence">Planned Obsolescence</h4>
<p>Planned obsolescence refers to the intentional design strategy of manufacturing products with artificially limited lifetimes that quickly become non-functional or outdated. This spurs faster replacement purchase cycles as consumers find devices no longer meeting needs within a few years. However, electronics designed for premature obsolescence contribute to unsustainable e-waste volumes.</p>
<p>For example, gluing smartphone batteries and components together hinders repairability compared to using modular, accessible assemblies. Or rolling out software updates that deliberately slow system performance creates a perception worth upgrading devices produced only several years earlier.</p>
<p>Likewise, fashionable introductions of new product generations with minor but exclusive feature additions makes prior versions rapidly seem dated. These tactics compel buying new gadgets (<a href="https://www.cnbc.com/2020/12/08/the-psychology-of-new-iphone-releases-apple-marketing.html">e.g.&nbsp;Iphones</a>) long before operational endpoints. When multiplied across fast-paced electronics categories, the result is billions of barely worn items being discarded annually.</p>
<p>Planned obsolescence thus intensifies resource utilization and waste creation in making products with no intention for long lifetimes. This contradicts sustainability principles around durability, reuse and material conservation. While stimulating continuous sales and gains for manufacturers in the short term, the strategy externalizes environmental costs and toxins onto communities lacking proper e-waste processing infrastructure.</p>
<p>Policy and consumer action is crucial to counter gadget designs that are needlessly disposable by default. Companies should also invest in product stewardship programs supporting responsible reuse and reclamation.</p>
<p>Consider the real world example. <a href="https://undergradlawreview.blog.fordham.edu/consumer-protection/the-product-ecosystem-and-planned-obsolescence-apples-threats-to-consumer-rights/">Apple has faced scrutiny</a> over the years for allegedly engaging in planned obsolescence to encourage customers to buy new iPhone models. The company was allegedly designing its phones so that performance degrades over time or existing features become incompatible with new operating systems, which critics argue is meant to spur more rapid upgrade cycles. In 2020, Apple paid a 25 million Euros in fine to settle a case in France where regulators found the company guilty of intentionally slowing down older iPhones without clearly informing customers via iOS updates.</p>
<p>By failing to be transparent about power management changes that reduced device performance, Apple participated in deceptive activities that reduced product lifespan to drive sales. The company claimed it was done to “smooth out” peaks that could cause older batteries to shut down suddenly. But this is an example that clearly highlights the legal risks around employing planned obsolescence and not properly disclosing when functionality changes impact device usability over time–even leading brands like Apple can run into trouble if perceived to be intentionally shortening product life cycles.</p>
</section>
</section>
<section id="policy-and-regulatory-considerations" class="level2" data-number="17.12">
<h2 data-number="17.12" class="anchored" data-anchor-id="policy-and-regulatory-considerations"><span class="header-section-number">17.12</span> Policy and Regulatory Considerations</h2>
<section id="measurement-and-reporting-mandates" class="level3" data-number="17.12.1">
<h3 data-number="17.12.1" class="anchored" data-anchor-id="measurement-and-reporting-mandates"><span class="header-section-number">17.12.1</span> Measurement and Reporting Mandates</h3>
<p>One policy mechanism with increasing relevance for AI systems is measurement and reporting requirements regarding energy consumption and carbon emissions. Mandated metering, auditing, disclosures, and more rigorous methodologies aligned to sustainability metrics can help address information gaps hindering efficiency optimizations.</p>
<p>On the simple end, national or regional policies may require companies above a certain size utilizing AI in their products or backend systems to report energy consumption or emissions associated with major AI workloads. Organizations like the Partnership on AI, IEEE, and NIST could help shape standardized methodologies. More complex proposals involve defining consistent ways to measure computational complexity, data center PUE, carbon intensity of energy supply, and efficiencies gained through AI-specific hardware.</p>
<p>Reporting obligations for public sector users procuring AI services–such as through proposed legislation in Europe–could also increase transparency. However, regulators must balance the additional measurement burden such mandates place on organizations versus ongoing carbon reductions from ingraining sustainability-conscious development patterns.</p>
<p>To be most constructive, any measurement and reporting policies should focus on enabling continuous refinement rather than simplistic restrictions or caps. As AI advancements unfold rapidly, nimble governance guardrails that embed sustainability considerations into normal evaluation metrics can motivate positive change. But overprescription risks constraining innovation if requirements grow outdated. By combining flexibility with appropriate transparency guardrails, AI efficiency policy aims to accelerate progress industry-wide.</p>
</section>
<section id="restriction-mechanisms" class="level3" data-number="17.12.2">
<h3 data-number="17.12.2" class="anchored" data-anchor-id="restriction-mechanisms"><span class="header-section-number">17.12.2</span> Restriction Mechanisms</h3>
<p>In addition to reporting mandates, policymakers have several restriction mechanisms that could directly shape how AI systems are developed and deployed to curb emissions:</p>
<p>Caps on Computing Emissions: The <a href="https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence">European Commission’s proposed AI Act</a> takes a horizontal approach that could allow setting economy-wide caps on the volume of computing power available for training AI models. Similar to emissions trading systems, caps aim to indirectly disincentivize extensive computing over sustainability. However, model quality could suffer absent pathways for procuring additional capacity.</p>
<p>Conditioning Access to Public Resources: Some experts have proposed incentives like only allowing access to public datasets or computing power for developing fundamentally efficient models rather than extravagant architectures. For example, the <a href="https://mlcommons.org/">MLCommons benchmarking consortium</a> founded by major tech firms could formally integrate efficiency into its standardized leaderboard metrics. However, conditioned access risks limiting innovation.</p>
<p>Financial Mechanisms: Analogous to carbon taxes on polluting industries, fees applied per unit of AI-related compute consumption could discourage unnecessary model scaling while funding efficiency innovations. Tax credits could alternatively reward organizations pioneering more accurate but compact AI techniques. But financial tools require careful calibration between revenue generation, fairness, and not over-penalizing productive uses of AI.</p>
<p>Technology Bans: If measurement consistently pinned extreme emissions on specific applications of AI without paths for remediation, outright bans present a tool of last resort for policymakers. However, given AI’s dual use, defining harmful versus beneficial deployments proves complex, necessitating holistic impact assessment before concluding no redeeming value exists. Banning promising technologies risks unintended consequences and requires caution.</p>
</section>
<section id="government-incentives" class="level3" data-number="17.12.3">
<h3 data-number="17.12.3" class="anchored" data-anchor-id="government-incentives"><span class="header-section-number">17.12.3</span> Government Incentives</h3>
<p>It is a common practice for governments to provide tax or other incentives to consumers or businesses when contributing to more sustainable practices in technology. Such incentives already exist in the US for <a href="https://www.irs.gov/credits-deductions/residential-clean-energy-credit">adopting solar panels</a> or <a href="https://www.energy.gov/eere/buildings/179d-commercial-buildings-energy-efficiency-tax-deduction">energy efficient buildings</a>. To the best of our knowledge, no such tax incentives exist for AI specific development practices yet.</p>
<p>Another potential incentive program that is beginning to be explored is the use of government grants to fund Green AI projects. For example, in Spain, <a href="https://www.state.gov/artificial-intelligence-for-accelerating-progress-on-the-sustainable-development-goals-addressing-societys-greatest-challenges/">300 million euros have been allocated</a> to specifically fund projects in AI and sustainability. Government incentives are a promising avenue to encourage sustainable practices in business and consumer behavior, but they require careful thought into how those incentives will fit into market demands <span class="citation" data-cites="maxime2016impact">(<a href="../../references.html#ref-maxime2016impact" role="doc-biblioref">Cohen, Lobel, and Perakis 2016</a>)</span>.</p>
</section>
<section id="self-regulation" class="level3" data-number="17.12.4">
<h3 data-number="17.12.4" class="anchored" data-anchor-id="self-regulation"><span class="header-section-number">17.12.4</span> Self-Regulation</h3>
<p>Complimentary to potential government action, voluntary self-governance mechanisms allow the AI community to pursue sustainability ends without top-down intervention:</p>
<p>Renewables Commitments: Large AI practitioners like Google, Microsoft, Amazon and Facebook have pledged to procure enough renewable electricity to match 100% of their energy demands. These commitments unlock compounding emissions cuts as compute scales up. Formalizing such programs incentivizes green data center regions. However, there are critiques to whether these pledges are enough <span class="citation" data-cites="monyei2018electrons">(<a href="../../references.html#ref-monyei2018electrons" role="doc-biblioref">Monyei and Jenkins 2018</a>)</span>.</p>
<p>Internal Carbon Prices: Some organizations utilize shadow prices on carbon emissions to represent environmental costs in capital allocation decisions between AI projects. If modeled effectively, theoretical charges on development carbon footprints steer funding toward efficient innovations rather than solely accuracy gains.</p>
<p>Efficiency Development Checklists: Groups like the AI Sustainability Coalition suggest voluntary checklist templates highlighting model design choices, hardware configurations, and other factors architects can tune per application to restrain emissions. By ingraining sustainability as a primary success metric alongside accuracy and cost, organizations can drive change.</p>
<p>Independent Auditing: Even absent public disclosure mandates, firms specializing in technology sustainability audits help AI developers identify waste, create efficiency roadmaps, and benchmark progress via impartial reviews. Structuring such audits into internal governance procedures or the procurement process expands accountability.</p>
</section>
<section id="global-considerations" class="level3" data-number="17.12.5">
<h3 data-number="17.12.5" class="anchored" data-anchor-id="global-considerations"><span class="header-section-number">17.12.5</span> Global Considerations</h3>
<p>While measurement, restrictions, incentives, and self-regulation all represent potential policy mechanisms for furthering AI sustainability, fragmentation across national regimes risks unintended consequences. As with other technology policy domains, divergence between regions must be carefully managed.</p>
<p>For example, OpenAI barred access to its viral ChatGPT chatbot for European users over data privacy concerns in the region. This came after the EU’s proposed AI Act signaled a precautionary approach allowing the EC to ban certain AI uses deemed high-risk, enforcing transparency rules that create uncertainty for release of brand new models. However, it would be wise to caution regulator action as it could inadvertently limit European innovation if regimes with lighter touch regulation attract more private sector AI research spending and talent. Finding common ground is key.</p>
<p>The OECD principles on AI and the United Nations frameworks underscore universally agreed tenets all national policies should uphold: transparency, accountability, bias mitigation, and more. Constructively embedding sustainability as a core principle for responsible AI within such international guidance can motivate unified action without sacrificing flexibility across divergent legal systems. Avoiding race-to-the-bottom dynamics hinges on enlightened multilateral cooperation.</p>
</section>
</section>
<section id="public-perception-and-engagement" class="level2" data-number="17.13">
<h2 data-number="17.13" class="anchored" data-anchor-id="public-perception-and-engagement"><span class="header-section-number">17.13</span> Public Perception and Engagement</h2>
<p>As societal attention and policy efforts aimed at environmental sustainability ramp up worldwide, there is growing enthusiasm around leveraging AI to help address ecological challenges. However, public understanding and attitudes towards the role of AI systems in sustainability contexts remain mixed and clouded by misconceptions. On one hand, people hope advanced algorithms can provide new solutions for green energy, responsible consumption, decarbonization pathways and ecosystem preservation. But on the other, fears regarding risks of uncontrolled AI also seep into the environmental domain and undermine constructive discourse. Furthermore, lack of public awareness on key issues like transparency in development of sustainability-focused AI tools as well as potential biases in data or modeling also threaten to limit inclusive participation and degrade public trust.</p>
<p>Tackling complex, interdisciplinary priorities like environmental sustainability requires informed, nuanced public engagement along with responsible advances in AI innovation itself. The path forward demands careful, equitable collaborative efforts between experts in fields like ML, climate science, environmental policy, social science and communication. Mapping the landscape of public perceptions, identifying pitfalls, and charting strategies to cultivate understandable, accessible and trustworthy AI systems targeting shared ecological priorities will prove essential to realizing sustainability goals. This complex terrain warrants deep examination into the sociotechnical dynamics involved.</p>
<section id="ai-awareness" class="level3" data-number="17.13.1">
<h3 data-number="17.13.1" class="anchored" data-anchor-id="ai-awareness"><span class="header-section-number">17.13.1</span> AI Awareness</h3>
<p>In May 2022, <a href="https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/">Pew Research Center polled 5,101 U.S. adults</a> finding 60% had heard or read “a little” about AI while 27% heard “a lot”–indicating decent broad recognition, but likely limited comprehension about details or applications. However, among those with some AI familiarity, concerns emerge regarding risks of personal data misuse according to agreed terms. Still 62% felt AI could potentially ease modern life if applied responsibly. Yet specific understanding of sustainability contexts remains lacking.</p>
<p>Studies attempting to categorize online discourse sentiments find a nearly even split between optimism and caution regarding deployment of AI for sustainability goals. Factors driving positivity include hopes around better forecasting of ecological shifts using ML models. Negativity arises from lack of confidence in self-supervised algorithms avoiding unintended consequences due to unpredictable human impacts on complex natural systems during training.</p>
<p>The most prevalent public belief remains that while AI does harbor potential for accelerating solutions on issues like emission reductions and wildlife protections, inadequate safeguarding around data biases, ethical blindspots and privacy considerations pose underappreciated risks if pursued carelessly, especially at scale. This leads to hesitancy around unconditional support without evidence of deliberate, democratically guided development.</p>
</section>
<section id="messaging" class="level3" data-number="17.13.2">
<h3 data-number="17.13.2" class="anchored" data-anchor-id="messaging"><span class="header-section-number">17.13.2</span> Messaging</h3>
<p><a href="https://www.climatechange.ai/">Optimistic efforts</a> are highlighting AI’s sustainability promise emphasize potential for advanced ML to radically accelerate decarbonization effects from smart grids, personalized carbon tracking apps, automated building efficiency optimizations, and predictive analytics guiding targeted conservation efforts. More comprehensive real-time modeling of complex climate and ecological shifts using self-improving algorithms offers hope for mitigating biodiversity losses and averting worst case scenarios.</p>
<p>However, <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">cautionary perspectives</a>, such as the <a href="https://futureoflife.org/open-letter/ai-principles/">Asilomar AI Principles</a>, question whether AI itself could exacerbate sustainability challenges if improperly constrained. Rising energy demands of large scale computing systems and increasingly massive neural network model training conflicts with clean energy ambitions. Lack of diversity in data inputs or priorities of developers might inadvertently downplay urgent environmental justice considerations. Near term skeptical public engagement likely hinges on lack of perceivable safeguards against uncontrolled AI systems that are running amok on core ecological processes before our eyes.</p>
<p>In essence, polarized framings either promote AI as an indispensable tool for sustainability problem-solving–if compassionately directed toward people and planet–or present AI as an amplifier of existing harms insidiously dominating hidden facets of natural systems central to all life. Overcoming such impasses demands balancing honest trade-off discussions with shared visions for equitable, democratically governed technological progress targeting restoration.</p>
</section>
<section id="equitable-participation" class="level3" data-number="17.13.3">
<h3 data-number="17.13.3" class="anchored" data-anchor-id="equitable-participation"><span class="header-section-number">17.13.3</span> Equitable Participation</h3>
<p>Ensuring equitable participation and access should form a cornerstone of any sustainability initiative with potential for major societal impacts. This principle applies equally to AI systems targeting environmental goals. However, commonly excluded voices like frontline, rural or indigenous communities and future generations not present to consent could suffer disproportionate consequences from technology transformations. For instance, the <a href="https://partnershiponai.org">Partnership on AI</a> has launched events expressly targeting input from marginalized communities on deploying AI responsibly.</p>
<p>Ensuring equitable access and participation should form a cornerstone of any sustainability initiative with potential for major societal impacts be it AI or otherwise. However, inclusive engagement on environmental AI relies partly on availability and understanding of fundamental computing resources. As the recent <a href="https://www.oecd.org/">OECD</a> report on <a href="https://www.oecd.org/economy/a-blueprint-for-building-national-compute-capacity-for-artificial-intelligence-876367e3-en.htm">National AI Compute Capacity</a> highlights <span class="citation" data-cites="oecd2023blueprint">(<a href="../../references.html#ref-oecd2023blueprint" role="doc-biblioref">OECD 2023</a>)</span>, many countries currently lack data or strategic plans mapping needs for the infrastructure required to fuel AI systems. This policy blind-spot could constrain economic goals and exacerbate barriers to entry for marginalized populations. Their blueprint urges developing national AI compute capacity strategies along dimensions of capacity, accessibility, innovation pipelines and resilience to anchor innovation. Otherwise inadequacies in underlying data storage, model development platforms or specialized hardware could inadvertently concentrate AI progress in the hands of select groups. Therefore, planning for balanced expansion of fundamental AI computing resources via policy initiatives ties directly to hopes for democratized sustainability problem-solving using equitable and transparent ML tools.</p>
<p>The key idea is that equitable participation in AI systems targeting environmental challenges relies in part on getting the underlying computing capacity and infrastructure right, which requires proactive policy planning from a national perspective.</p>
</section>
<section id="transparency" class="level3" data-number="17.13.4">
<h3 data-number="17.13.4" class="anchored" data-anchor-id="transparency"><span class="header-section-number">17.13.4</span> Transparency</h3>
<p>As public sector agencies and private companies alike rush towards adopting AI tools to help tackle pressing environmental challenges, calls for transparency around the development and functionality of these systems has began to amplify. Explainable and interpretable ML features grow more crucial for building trust in emerging models aiming to guide consequential sustainability policies. Initiatives like the <a href="https://unfccc.int/news/montreal-carbon-pledge">Montreal Carbon Pledge</a> brought tech leaders together to commit to publishing impact assessments before launching environmental systems, as pledged below:</p>
<p>*“As institutional investors, we have a duty to act in the best long-term interests of our beneficiaries. In this fiduciary role, we believe that there are long-term investment risks associated with greenhouse gas emissions, climate change and carbon regulation.</p>
<p>In order to better understand, quantify and manage the carbon and climate change related impacts, risks and opportunities in our investments, it is integral to measure our carbon footprint. Therefore, we commit, as a first step, to measure and disclose the carbon footprint of our investments annually with the aim of using this information to develop an engagement strategy and/or identify and set carbon footprint reduction targets.”*</p>
<p>We need a similar pledge for AI sustainability and responsibility. Widespread acceptance and impact of AI sustainability solutions will partly on deliberate communication of validation schemes, metrics, and layers of human judgment applied before live deployment. Efforts like <a href="https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26746">NIST’s Principles for Explainable AI</a> can be helpful for fostering transparency into AI systems. The National Institute of Standards and Technology (NIST) has published an influential set of guidelines dubbed the Principles for Explainable AI <span class="citation" data-cites="phillips2020four">(<a href="../../references.html#ref-phillips2020four" role="doc-biblioref">Phillips et al. 2020</a>)</span>. This framework articulates best practices for designing, evaluating and deploying responsible AI systems with transparent and interpretable features that build critical user understanding and trust.</p>
<p>It delineates four core principles: Firstly, AI systems should provide contextually relevant explanations justifying the reasoning behind their outputs to appropriate stakeholders. Secondly, these AI explanations must communicate information in a truly meaningful way for their target audience’s appropriate comprehension level. Next, there is the accuracy principle which dictates explanations should faithfully reflect the actual process and logic informing an AI model’s internal mechanics for generating given outputs or recommendations based on inputs. Finally, a knowledge limits principle compels explanations to clarify an AI model’s boundaries in capturing the full breadth of real-world complexity, variance and uncertainties within a problem space.</p>
<p>Altogether, these NIST principles offer AI practitioners and adopters guidance on key transparency considerations vital for developing accessible solutions that prioritize user autonomy and trust rather than simply maximizing predictive accuracy metrics alone. As AI rapidly advances across sensitive social contexts like healthcare, finance, employment and beyond, such human centered design guidelines will continue growing in importance for anchoring innovation to public interests.</p>
<p>This applies equally to the environmental ability domain. Overall, responsible and democratically guided AI innovation targeting shared ecological priorities depends on maintaining public vigilance, understanding, and oversight over otherwise opaque systems taking prominent roles in societal decisions. Prioritizing explainable algorithm designs and radical transparency practices per global standards can help sustain collective confidence that these tools improve rather than imperil hopes for AI driven future.</p>
</section>
</section>
<section id="future-directions-and-challenges" class="level2" data-number="17.14">
<h2 data-number="17.14" class="anchored" data-anchor-id="future-directions-and-challenges"><span class="header-section-number">17.14</span> Future Directions and Challenges</h2>
<p>As we look towards the future, the role of AI in environmental sustainability is poised to grow even more significant. The potential of AI to drive advancements in renewable energy, climate modeling, conservation efforts, and more is immense. However, it is a two-sided coin, as we need to overcome several challenges and direct our efforts towards sustainable and responsible AI development.</p>
<section id="future-directions" class="level3" data-number="17.14.1">
<h3 data-number="17.14.1" class="anchored" data-anchor-id="future-directions"><span class="header-section-number">17.14.1</span> Future Directions</h3>
<p>One of the key future directions is the development of more energy-efficient AI models and algorithms. This involves ongoing research and innovation in areas like model pruning, quantization, and the use of low-precision numerics, and developing the hardware to enable full profitability of these innovations. Even further, we look at alternative computing paradigms which do not rely on von-Neumann architectures. More on this topic can be found in the hardware acceleration chapter. The goal is to create AI systems that deliver high performance while minimizing energy consumption and carbon emissions.</p>
<p>Another important direction is the integration of renewable energy sources into AI infrastructure. As data centers continue to be major contributors to AI’s carbon footprint, transitioning to renewable energy sources like solar and wind is crucial. Developments in long-term, sustainable energy storage, such as <a href="https://ambri.com/">Ambri</a>, an MIT spinoff, could enable this transition. This requires significant investment and collaboration between tech companies, energy providers, and policymakers.</p>
</section>
<section id="challenges" class="level3" data-number="17.14.2">
<h3 data-number="17.14.2" class="anchored" data-anchor-id="challenges"><span class="header-section-number">17.14.2</span> Challenges</h3>
<p>Despite these promising directions, several challenges need to be addressed. One of the major challenges is the lack of consistent standards and methodologies for measuring and reporting the environmental impact of AI. It is essential that the complexity of life cycles of both AI models and system hardware are captured by these methods. Next, efficient and environmentally-sustainable AI infrastructure and system hardware is needed. This consists of three components. Aimed at maximizing the utilization of accelerator and system resources, prolonging the lifetime of AI infrastructure, and designing systems hardware with environmental impact in mind.</p>
<p>On the software side, we should make a trade-off between experimentation and the subsequent training cost. Techniques such as neural architecture search and hyperparameter optimization can be used for design space exploration. However, these are often very resource-intensive. Efficient experimentation can reduce the environmental footprint overhead significantly. Next, methods to reduce wasted training efforts should be explored.</p>
<p>To improve model quality, we often scale the dataset. However, the increased system resources required for data storage and ingestion caused by this scaling has a significant environmental impact <span class="citation" data-cites="wu2022sustainable">(<a href="../../references.html#ref-wu2022sustainable" role="doc-biblioref">Wu et al. 2022</a>)</span>. A thorough understanding of the rate at which data loses its predictive value and devising data sampling strategies is important.</p>
<p>Data gaps also pose a significant challenge. Without companies and governments openly sharing detailed and accurate data on energy consumption, carbon emissions, and other environmental impacts, it is difficult to develop effective strategies for sustainable AI.</p>
<p>Finally, the fast pace of AI development requires an agile approach to the policy imposed on these systems. The policy should ensure sustainable development without constraining innovation. This requires experts in all domains of AI, environmental sciences, energy and policy to work together to achieve a sustainable future.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="17.15">
<h2 data-number="17.15" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">17.15</span> Conclusion</h2>
<p>As AI continues rapidly expanding across industries and society, we must address sustainability considerations. AI promises breakthrough innovations, yet its environmental footprint threatens its widespread growth. This chapter analyzes multiple facets, from energy and emissions to waste and biodiversity impacts, that AI/ML developers must weigh when creating responsible AI systems.</p>
<p>Fundamentally, we require elevating sustainability as a primary design priority rather than an afterthought. Techniques like energy-efficient models, renewable-powered data centers, and hardware recycling programs offer solutions, but holistic commitment remains vital. We need standards around transparency, carbon accounting, and supply chain disclosures to supplement technical gains. Still, examples like Google’s 4M efficiency practices containing ML energy use highlight that with concerted effort, we can advance AI in lockstep with environmental objectives. We achieve this harmonious balance by having researchers, corporations, regulators and users collaborate across domains. The aim is not perfect solutions but rather continuous improvement as we integrate AI across new sectors.</p>
</section>
<section id="sec-sustainable-ai-resource" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="sec-sustainable-ai-resource">Resources</h2>
<p>Here is a curated list of resources to support both students and instructors in their learning and teaching journey. We are continuously working on expanding this collection and will be adding new exercises in the near future.</p>
<div class="callout callout-style-simple callout-slide no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>These slides serve as a valuable tool for instructors to deliver lectures and for students to review the material at their own pace. We encourage both students and instructors to leverage these slides to enhance their understanding and facilitate effective knowledge transfer.</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1wGKWV-speisH6V-g-u_w8xFwEjZjqp7u2YXs27flmiM/edit#slide=id.ge93ee14fb9_0_0">Transparency and Sustainability.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1rdJ82YlvD66JDATtj-KUQkJ6tkuAfFAs1w6-njvp6zM/edit#slide=id.ge93ee14fb9_0_0">Sustainability of TinyML.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1ndDzSwnSMNwUShW-RyIN29T9KeEoM_I14qsExPehW70/edit#slide=id.ge947b43ef5_0_0">Model Cards for Transparency.</a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-exercise no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercises
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To reinforce the concepts covered in this chapter, we have curated a set of exercises that challenge students to apply their knowledge and deepen their understanding.</p>
<p>Coming soon.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-lab no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Labs
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In addition to exercises, we also offer a series of hands-on labs that allow students to gain practical experience with embedded AI technologies. These labs provide step-by-step guidance, enabling students to develop their skills in a structured and supportive environment. We are excited to announce that new labs will be available soon, further enriching the learning experience.</p>
<p>Coming soon.</p>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-anthony2020carbontracker" class="csl-entry" role="listitem">
Anthony, Lasse F. Wolff, Benjamin Kanding, and Raghavendra Selvan. 2020. ICML Workshop on Challenges in Deploying and monitoring Machine Learning Systems.
</div>
<div id="ref-barroso2019datacenter" class="csl-entry" role="listitem">
Barroso, Luiz André, Urs Hölzle, and Parthasarathy Ranganathan. 2019. <em>The Datacenter as a Computer: Designing Warehouse-Scale Machines</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-01761-2">https://doi.org/10.1007/978-3-031-01761-2</a>.
</div>
<div id="ref-bohr2020rise" class="csl-entry" role="listitem">
Bohr, Adam, and Kaveh Memarzadeh. 2020. <span>“The Rise of Artificial Intelligence in Healthcare Applications.”</span> In <em>Artificial Intelligence in Healthcare</em>, 25–60. Elsevier. <a href="https://doi.org/10.1016/b978-0-12-818438-7.00002-2">https://doi.org/10.1016/b978-0-12-818438-7.00002-2</a>.
</div>
<div id="ref-bondi2018spot" class="csl-entry" role="listitem">
Bondi, Elizabeth, Ashish Kapoor, Debadeepta Dey, James Piavis, Shital Shah, Robert Hannaford, Arvind Iyer, Lucas Joppa, and Milind Tambe. 2018. <span>“Near Real-Time Detection of Poachers from Drones in AirSim.”</span> In <em>Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, <span>IJCAI</span> 2018, July 13-19, 2018, Stockholm, Sweden</em>, edited by Jérôme Lang, 5814–16. ijcai.org. <a href="https://doi.org/10.24963/ijcai.2018/847">https://doi.org/10.24963/ijcai.2018/847</a>.
</div>
<div id="ref-buyya2010energyefficient" class="csl-entry" role="listitem">
Buyya, Rajkumar, Anton Beloglazov, and Jemal Abawajy. 2010. <span>“Energy-Efficient Management of Data Center Resources for Cloud Computing: <span>A</span> Vision, Architectural Elements, and Open Challenges.”</span> <a href="https://arxiv.org/abs/1006.0308">https://arxiv.org/abs/1006.0308</a>.
</div>
<div id="ref-cenci2021ecofriendly" class="csl-entry" role="listitem">
Cenci, Marcelo Pilotto, Tatiana Scarazzato, Daniel Dotto Munchen, Paula Cristina Dartora, Hugo Marcelo Veit, Andrea Moura Bernardes, and Pablo R. Dias. 2021. <span>“<span>Eco-Friendly</span> <span>Electronics<span></span>A</span> Comprehensive Review.”</span> <em>Adv. Mater. Technol.</em> 7 (2): 2001263. <a href="https://doi.org/10.1002/admt.202001263">https://doi.org/10.1002/admt.202001263</a>.
</div>
<div id="ref-challenge2021supply" class="csl-entry" role="listitem">
Challenge, WEF Net-Zero. 2021. <span>“The Supply Chain Opportunity.”</span> In <em>World Economic Forum: Geneva, Switzerland</em>.
</div>
<div id="ref-chen2006gallium" class="csl-entry" role="listitem">
Chen, H.-W. 2006. <span>“Gallium, Indium, and Arsenic Pollution of Groundwater from a Semiconductor Manufacturing Area of <span>Taiwan</span>.”</span> <em>B. Environ. Contam. Tox.</em> 77 (2): 289–96. <a href="https://doi.org/10.1007/s00128-006-1062-3">https://doi.org/10.1007/s00128-006-1062-3</a>.
</div>
<div id="ref-chua1971memristor" class="csl-entry" role="listitem">
Chua, L. 1971. <span>“Memristor-the Missing Circuit Element.”</span> <em>#IEEE_J_CT#</em> 18 (5): 507–19. <a href="https://doi.org/10.1109/tct.1971.1083337">https://doi.org/10.1109/tct.1971.1083337</a>.
</div>
<div id="ref-jaewon2023perseus" class="csl-entry" role="listitem">
Chung, Jae-Won, Yile Gu, Insu Jang, Luoxi Meng, Nikhil Bansal, and Mosharaf Chowdhury. 2023. <span>“Perseus: Removing Energy Bloat from Large Model Training.”</span> <em>ArXiv Preprint</em> abs/2312.06902. <a href="https://arxiv.org/abs/2312.06902">https://arxiv.org/abs/2312.06902</a>.
</div>
<div id="ref-maxime2016impact" class="csl-entry" role="listitem">
Cohen, Maxime C., Ruben Lobel, and Georgia Perakis. 2016. <span>“The Impact of Demand Uncertainty on Consumer Subsidies for Green Technology Adoption.”</span> <em>Manage. Sci.</em> 62 (5): 1235–58. <a href="https://doi.org/10.1287/mnsc.2015.2173">https://doi.org/10.1287/mnsc.2015.2173</a>.
</div>
<div id="ref-cooper2011semiconductor" class="csl-entry" role="listitem">
Cooper, Tom, Suzanne Fallender, Joyann Pafumi, Jon Dettling, Sebastien Humbert, and Lindsay Lessard. 2011. <span>“A Semiconductor Company’s Examination of Its Water Footprint Approach.”</span> In <em>Proceedings of the 2011 IEEE International Symposium on Sustainable Systems and Technology</em>, 1–6. IEEE; IEEE. <a href="https://doi.org/10.1109/issst.2011.5936865">https://doi.org/10.1109/issst.2011.5936865</a>.
</div>
<div id="ref-cope2009pure" class="csl-entry" role="listitem">
Cope, Gord. 2009. <span>“Pure Water, Semiconductors and the Recession.”</span> <em>Global Water Intelligence</em> 10 (10).
</div>
<div id="ref-davies2011endangered" class="csl-entry" role="listitem">
Davies, Emma. 2011. <span>“Endangered Elements: <span>Critical</span> Thinking.”</span> <a href="https://www.rsc.org/images/Endangered\%20Elements\%20-\%20Critical\%20Thinking\_tcm18-196054.pdf">https://www.rsc.org/images/Endangered\%20Elements\%20-\%20Critical\%20Thinking\_tcm18-196054.pdf</a>.
</div>
<div id="ref-davis2022uptime" class="csl-entry" role="listitem">
Davis, Jacqueline, Daniel Bizo, Andy Lawrence, Owen Rogers, and Max Smolaks. 2022. <span>“Uptime Institute Global Data Center Survey 2022.”</span> Uptime Institute.
</div>
<div id="ref-dayarathna2015data" class="csl-entry" role="listitem">
Dayarathna, Miyuru, Yonggang Wen, and Rui Fan. 2016. <span>“Data Center Energy Consumption Modeling: <span>A</span> Survey.”</span> <em>IEEE Communications Surveys &amp;Amp; Tutorials</em> 18 (1): 732–94. <a href="https://doi.org/10.1109/comst.2015.2481183">https://doi.org/10.1109/comst.2015.2481183</a>.
</div>
<div id="ref-ebrahimi2014review" class="csl-entry" role="listitem">
Ebrahimi, Khosrow, Gerard F. Jones, and Amy S. Fleischer. 2014. <span>“A Review of Data Center Cooling Technology, Operating Conditions and the Corresponding Low-Grade Waste Heat Recovery Opportunities.”</span> <em>Renewable Sustainable Energy Rev.</em> 31: 622–38. <a href="https://doi.org/10.1016/j.rser.2013.12.007">https://doi.org/10.1016/j.rser.2013.12.007</a>.
</div>
<div id="ref-grossman2007high" class="csl-entry" role="listitem">
Grossman, Elizabeth. 2007. <em>High Tech Trash: <span>Digital</span> Devices, Hidden Toxics, and Human Health</em>. Island press.
</div>
<div id="ref-gupta2022" class="csl-entry" role="listitem">
Gupta, Udit, Mariam Elgamal, Gage Hills, Gu-Yeon Wei, Hsien-Hsin S. Lee, David Brooks, and Carole-Jean Wu. 2022. <span>“Act: Designing Sustainable Computer Systems with an Architectural Carbon Modeling Tool.”</span> In <em>Proceedings of the 49th Annual International Symposium on Computer Architecture</em>, 784–99. ACM. <a href="https://doi.org/10.1145/3470496.3527408">https://doi.org/10.1145/3470496.3527408</a>.
</div>
<div id="ref-henderson2020towards" class="csl-entry" role="listitem">
Henderson, Peter, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan Jurafsky, and Joelle Pineau. 2020. <span>“Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning.”</span> <em>The Journal of Machine Learning Research</em> 21 (1): 10039–81.
</div>
<div id="ref-hsu2016accumulation" class="csl-entry" role="listitem">
Hsu, Liang-Ching, Ching-Yi Huang, Yen-Hsun Chuang, Ho-Wen Chen, Ya-Ting Chan, Heng Yi Teah, Tsan-Yao Chen, Chiung-Fen Chang, Yu-Ting Liu, and Yu-Min Tzou. 2016. <span>“Accumulation of Heavy Metals and Trace Elements in Fluvial Sediments Received Effluents from Traditional and Semiconductor Industries.”</span> <em>Scientific Reports</em> 6 (1): 34250. <a href="https://doi.org/10.1038/srep34250">https://doi.org/10.1038/srep34250</a>.
</div>
<div id="ref-irimiavladu2014textquotedblleftgreentextquotedblright" class="csl-entry" role="listitem">
Irimia-Vladu, Mihai. 2014. <span>“<span><span>“</span>Green<span>”</span></span> Electronics: <span>Biodegradable</span> and Biocompatible Materials and Devices for Sustainable Future.”</span> <em>Chem. Soc. Rev.</em> 43 (2): 588–610. <a href="https://doi.org/10.1039/c3cs60235d">https://doi.org/10.1039/c3cs60235d</a>.
</div>
<div id="ref-jha2014rare" class="csl-entry" role="listitem">
Jha, A. R. 2014. <em>Rare Earth Materials: Properties and Applications</em>. CRC Press. <a href="https://doi.org/10.1201/b17045">https://doi.org/10.1201/b17045</a>.
</div>
<div id="ref-kaplan2020scaling" class="csl-entry" role="listitem">
Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. <span>“Scaling Laws for Neural Language Models.”</span> <em>ArXiv Preprint</em> abs/2001.08361. <a href="https://arxiv.org/abs/2001.08361">https://arxiv.org/abs/2001.08361</a>.
</div>
<div id="ref-kim2018chemical" class="csl-entry" role="listitem">
Kim, Sunju, Chungsik Yoon, Seunghon Ham, Jihoon Park, Ohun Kwon, Donguk Park, Sangjun Choi, Seungwon Kim, Kwonchul Ha, and Won Kim. 2018. <span>“Chemical Use in the Semiconductor Manufacturing Industry.”</span> <em>Int. J. Occup. Env. Heal.</em> 24 (3-4): 109–18. <a href="https://doi.org/10.1080/10773525.2018.1519957">https://doi.org/10.1080/10773525.2018.1519957</a>.
</div>
<div id="ref-kurth2023fourcastnet" class="csl-entry" role="listitem">
Kurth, Thorsten, Shashank Subramanian, Peter Harrington, Jaideep Pathak, Morteza Mardani, David Hall, Andrea Miele, Karthik Kashinath, and Anima Anandkumar. 2023. <span>“<span>FourCastNet:</span> <span>Accelerating</span> Global High-Resolution Weather Forecasting Using Adaptive <span>Fourier</span> Neural Operators.”</span> In <em>Proceedings of the Platform for Advanced Scientific Computing Conference</em>, 1–11. ACM. <a href="https://doi.org/10.1145/3592979.3593412">https://doi.org/10.1145/3592979.3593412</a>.
</div>
<div id="ref-lam2023learning" class="csl-entry" role="listitem">
Lam, Remi, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato, Ferran Alet, Suman Ravuri, et al. 2023. <span>“Learning Skillful Medium-Range Global Weather Forecasting.”</span> <em>Science</em>, eadi2336. <a href="https://doi.org/10.1126/science.adi2336">https://doi.org/10.1126/science.adi2336</a>.
</div>
<div id="ref-lannelongue2021green" class="csl-entry" role="listitem">
Lannelongue, Loı̈c, Jason Grealey, and Michael Inouye. 2021. <span>“Green Algorithms: Quantifying the Carbon Footprint of Computation.”</span> <em>Advanced Science</em> 8 (12): 2100707.
</div>
<div id="ref-poff2002aquatic" class="csl-entry" role="listitem">
LeRoy Poff, N, MM Brinson, and JW Day. 2002. <span>“Aquatic Ecosystems &amp; Global Climate Change.”</span> <em>Pew Center on Global Climate Change</em>.
</div>
<div id="ref-liu2020energy" class="csl-entry" role="listitem">
Liu, Yanan, Xiaoxia Wei, Jinyu Xiao, Zhijie Liu, Yang Xu, and Yun Tian. 2020. <span>“Energy Consumption and Emission Mitigation Prediction Based on Data Center Traffic and <span>PUE</span> for Global Data Centers.”</span> <em>Global Energy Interconnection</em> 3 (3): 272–82. <a href="https://doi.org/10.1016/j.gloei.2020.07.008">https://doi.org/10.1016/j.gloei.2020.07.008</a>.
</div>
<div id="ref-maslej2023artificial" class="csl-entry" role="listitem">
Maslej, Nestor, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, et al. 2023. <span>“Artificial Intelligence Index Report 2023.”</span> <em>ArXiv Preprint</em> abs/2310.03715. <a href="https://arxiv.org/abs/2310.03715">https://arxiv.org/abs/2310.03715</a>.
</div>
<div id="ref-mills1997overview" class="csl-entry" role="listitem">
Mills, Andrew, and Stephen Le Hunte. 1997. <span>“An Overview of Semiconductor Photocatalysis.”</span> <em>J. Photochem. Photobiol., A</em> 108 (1): 1–35. <a href="https://doi.org/10.1016/s1010-6030(97)00118-4">https://doi.org/10.1016/s1010-6030(97)00118-4</a>.
</div>
<div id="ref-monyei2018electrons" class="csl-entry" role="listitem">
Monyei, Chukwuka G., and Kirsten E. H. Jenkins. 2018. <span>“Electrons Have No Identity: <span>Setting</span> Right Misrepresentations in Google and Apple<span>’</span>s Clean Energy Purchasing.”</span> <em>Energy Research &amp;Amp; Social Science</em> 46: 48–51. <a href="https://doi.org/10.1016/j.erss.2018.06.015">https://doi.org/10.1016/j.erss.2018.06.015</a>.
</div>
<div id="ref-nakano2021geopolitics" class="csl-entry" role="listitem">
Nakano, Jane. 2021. <em>The Geopolitics of Critical Minerals Supply Chains</em>. JSTOR.
</div>
<div id="ref-oecd2023blueprint" class="csl-entry" role="listitem">
OECD. 2023. <span>“A Blueprint for Building National Compute Capacity for Artificial Intelligence,”</span> no. 350. https://doi.org/<a href="https://doi.org/https://doi.org/10.1787/876367e3-en">https://doi.org/https://doi.org/10.1787/876367e3-en</a>.
</div>
<div id="ref-patterson2022carbon" class="csl-entry" role="listitem">
Patterson, David, Joseph Gonzalez, Urs Holzle, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David R. So, Maud Texier, and Jeff Dean. 2022. <span>“The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink.”</span> <em>Computer</em> 55 (7): 18–28. <a href="https://doi.org/10.1109/mc.2022.3148714">https://doi.org/10.1109/mc.2022.3148714</a>.
</div>
<div id="ref-phillips2020four" class="csl-entry" role="listitem">
Phillips, P Jonathon, Carina A Hahn, Peter C Fontana, David A Broniatowski, and Mark A Przybocki. 2020. <span>“Four Principles of Explainable Artificial Intelligence.”</span> <em>Gaithersburg, Maryland</em> 18.
</div>
<div id="ref-prakash2022cfu" class="csl-entry" role="listitem">
Prakash, Shvetank, Tim Callahan, Joseph Bushagour, Colby Banbury, Alan V. Green, Pete Warden, Tim Ansell, and Vijay Janapa Reddi. 2022. <span>“<span>CFU</span> Playground: <span class="nocase">Full-stack</span> Open-Source Framework for Tiny Machine Learning <span>(TinyML)</span> Acceleration on <span>FPGAs</span>.”</span> In <em>ArXiv Preprint</em>. Vol. abs/2201.01863. <a href="https://arxiv.org/abs/2201.01863">https://arxiv.org/abs/2201.01863</a>.
</div>
<div id="ref-prakash2023tinyml" class="csl-entry" role="listitem">
Prakash, Shvetank, Matthew Stewart, Colby Banbury, Mark Mazumder, Pete Warden, Brian Plancher, and Vijay Janapa Reddi. 2023. <span>“Is <span>TinyML</span> Sustainable? Assessing the Environmental Impacts of Machine Learning on Microcontrollers.”</span> <em>ArXiv Preprint</em>. <a href="https://arxiv.org/abs/2301.11899">https://arxiv.org/abs/2301.11899</a>.
</div>
<div id="ref-schwartz2021deployment" class="csl-entry" role="listitem">
Schwartz, Daniel, Jonathan Michael Gomes Selman, Peter Wrege, and Andreas Paepcke. 2021. <span>“Deployment of Embedded Edge-<span>AI</span> for Wildlife Monitoring in Remote Regions.”</span> In <em>2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)</em>, 1035–42. IEEE; IEEE. <a href="https://doi.org/10.1109/icmla52953.2021.00170">https://doi.org/10.1109/icmla52953.2021.00170</a>.
</div>
<div id="ref-schwartz2020green" class="csl-entry" role="listitem">
Schwartz, Roy, Jesse Dodge, Noah A. Smith, and Oren Etzioni. 2020. <span>“Green <span>AI</span>.”</span> <em>Commun. ACM</em> 63 (12): 54–63. <a href="https://doi.org/10.1145/3381831">https://doi.org/10.1145/3381831</a>.
</div>
<div id="ref-shehabi2016united" class="csl-entry" role="listitem">
Shehabi, Arman, Sarah Smith, Dale Sartor, Richard Brown, Magnus Herrlin, Jonathan Koomey, Eric Masanet, Nathaniel Horner, Inês Azevedo, and William Lintner. 2016. <span>“United States Data Center Energy Usage Report.”</span>
</div>
<div id="ref-siddik2021environmental" class="csl-entry" role="listitem">
Siddik, Md Abu Bakar, Arman Shehabi, and Landon Marston. 2021. <span>“The Environmental Footprint of Data Centers in the United States.”</span> <em>Environ. Res. Lett.</em> 16 (6): 064017. <a href="https://doi.org/10.1088/1748-9326/abfba1">https://doi.org/10.1088/1748-9326/abfba1</a>.
</div>
<div id="ref-silvestro2022improving" class="csl-entry" role="listitem">
Silvestro, Daniele, Stefano Goria, Thomas Sterner, and Alexandre Antonelli. 2022. <span>“Improving Biodiversity Protection Through Artificial Intelligence.”</span> <em>Nature Sustainability</em> 5 (5): 415–24. <a href="https://doi.org/10.1038/s41893-022-00851-6">https://doi.org/10.1038/s41893-022-00851-6</a>.
</div>
<div id="ref-singh2022disentangling" class="csl-entry" role="listitem">
Singh, Narendra, and Oladele A. Ogunseitan. 2022. <span>“Disentangling the Worldwide Web of e-Waste and Climate Change Co-Benefits.”</span> <em>Circular Economy</em> 1 (2): 100011. <a href="https://doi.org/10.1016/j.cec.2022.100011">https://doi.org/10.1016/j.cec.2022.100011</a>.
</div>
<div id="ref-strubell2019energy" class="csl-entry" role="listitem">
Strubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. <span>“Energy and Policy Considerations for Deep Learning in <span>NLP</span>.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 3645–50. Florence, Italy: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P19-1355">https://doi.org/10.18653/v1/P19-1355</a>.
</div>
<div id="ref-sudhakar2023data" class="csl-entry" role="listitem">
Sudhakar, Soumya, Vivienne Sze, and Sertac Karaman. 2023. <span>“Data Centers on Wheels: <span>Emissions</span> from Computing Onboard Autonomous Vehicles.”</span> <em>IEEE Micro</em> 43 (1): 29–39. <a href="https://doi.org/10.1109/mm.2022.3219803">https://doi.org/10.1109/mm.2022.3219803</a>.
</div>
<div id="ref-thompson2021deep" class="csl-entry" role="listitem">
Thompson, Neil C., Kristjan Greenewald, Keeheon Lee, and Gabriel F. Manso. 2021. <span>“Deep Learning’s Diminishing Returns: <span>The</span> Cost of Improvement Is Becoming Unsustainable.”</span> <em>IEEE Spectr.</em> 58 (10): 50–55. <a href="https://doi.org/10.1109/mspec.2021.9563954">https://doi.org/10.1109/mspec.2021.9563954</a>.
</div>
<div id="ref-till2019fish" class="csl-entry" role="listitem">
Till, Aaron, Andrew L. Rypel, Andrew Bray, and Samuel B. Fey. 2019. <span>“Fish Die-Offs Are Concurrent with Thermal Extremes in North Temperate Lakes.”</span> <em>Nat. Clim. Change</em> 9 (8): 637–41. <a href="https://doi.org/10.1038/s41558-019-0520-y">https://doi.org/10.1038/s41558-019-0520-y</a>.
</div>
<div id="ref-uddin2012energy" class="csl-entry" role="listitem">
Uddin, Mueen, and Azizah Abdul Rahman. 2012. <span>“Energy Efficiency and Low Carbon Enabler Green <span>IT</span> Framework for Data Centers Considering Green Metrics.”</span> <em>Renewable Sustainable Energy Rev.</em> 16 (6): 4078–94. <a href="https://doi.org/10.1016/j.rser.2012.03.014">https://doi.org/10.1016/j.rser.2012.03.014</a>.
</div>
<div id="ref-un2019circular" class="csl-entry" role="listitem">
Un, and World Economic Forum. 2019. <em>A New Circular Vision for Electronics, Time for a Global Reboot</em>. PACE - Platform for Accelerating the Circular Economy. <a href="https://www3.weforum.org/docs/WEF\_A\_New\_Circular\_Vision\_for\_Electronics.pdf">https://www3.weforum.org/docs/WEF\_A\_New\_Circular\_Vision\_for\_Electronics.pdf</a>.
</div>
<div id="ref-wald1987semiconductor" class="csl-entry" role="listitem">
Wald, Peter H., and Jeffrey R. Jones. 1987. <span>“Semiconductor Manufacturing: <span>An</span> Introduction to Processes and Hazards.”</span> <em>Am. J. Ind. Med.</em> 11 (2): 203–21. <a href="https://doi.org/10.1002/ajim.4700110209">https://doi.org/10.1002/ajim.4700110209</a>.
</div>
<div id="ref-lecocq2022mitigation" class="csl-entry" role="listitem">
Winkler, Harald, Franck Lecocq, Hans Lofgren, Maria Virginia Vilariño, Sivan Kartha, and Joana Portugal-Pereira. 2022. <span>“Examples of Shifting Development Pathways: <span>Lessons</span> on How to Enable Broader, Deeper, and Faster Climate Action.”</span> <em>Climate Action</em> 1 (1). <a href="https://doi.org/10.1007/s44168-022-00026-1">https://doi.org/10.1007/s44168-022-00026-1</a>.
</div>
<div id="ref-wu2022sustainable" class="csl-entry" role="listitem">
Wu, Carole-Jean, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, et al. 2022. <span>“Sustainable Ai: <span>Environmental</span> Implications, Challenges and Opportunities.”</span> <em>Proceedings of Machine Learning and Systems</em> 4: 795–813.
</div>
<div id="ref-jie2023zeus" class="csl-entry" role="listitem">
You, Jie, Jae-Won Chung, and Mosharaf Chowdhury. 2023. <span>“Zeus: Understanding and Optimizing <span>GPU</span> Energy Consumption of <span>DNN</span> Training.”</span> In <em>20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)</em>, 119–39. Boston, MA: USENIX Association. <a href="https://www.usenix.org/conference/nsdi23/presentation/you">https://www.usenix.org/conference/nsdi23/presentation/you</a>.
</div>
<div id="ref-zafrir2019q8bert" class="csl-entry" role="listitem">
Zafrir, Ofir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. 2019. <span>“<span>Q8BERT:</span> <span>Quantized</span> <span>8Bit</span> <span>BERT</span>.”</span> In <em>2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS)</em>, 36–39. IEEE; IEEE. <a href="https://doi.org/10.1109/emc2-nips53020.2019.00016">https://doi.org/10.1109/emc2-nips53020.2019.00016</a>.
</div>
<div id="ref-zhang2018review" class="csl-entry" role="listitem">
Zhang, Dongxia, Xiaoqing Han, and Chunyu Deng. 2018. <span>“Review on the Research and Practice of Deep Learning and Reinforcement Learning in Smart Grids.”</span> <em>CSEE Journal of Power and Energy Systems</em> 4 (3): 362–70. <a href="https://doi.org/10.17775/cseejpes.2018.00520">https://doi.org/10.17775/cseejpes.2018.00520</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../contents/responsible_ai/responsible_ai.html" class="pagination-link  aria-label=" &lt;span="" ai&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Responsible AI</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../contents/ai_for_good/ai_for_good.html" class="pagination-link" aria-label="<span class='chapter-number'>18</span>&nbsp; <span class='chapter-title'>AI for Good</span>">
        <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">AI for Good</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Edited by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/main/contents/sustainable_ai/sustainable_ai.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/main/contents/sustainable_ai/sustainable_ai.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>