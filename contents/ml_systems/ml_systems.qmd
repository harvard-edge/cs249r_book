---
bibliography: ml_systems.bib
---

# ML Systems

::: {.content-visible when-format="html"}
Resources: [Slides](#sec-embedded-systems-resource), [Labs](#sec-embedded-systems-resource), [Exercises](#sec-embedded-systems-resource)
:::

![_DALLÂ·E 3 Prompt: Illustration in a rectangular format depicting the merger of embedded systems with Embedded AI. The left half of the image portrays traditional embedded systems, including microcontrollers and processors, detailed and precise. The right half showcases the world of artificial intelligence, with abstract representations of machine learning models, neurons, and data flow. The two halves are distinctly separated, emphasizing the individual significance of embedded tech and AI, but they come together in harmony at the center._](./images/png/cover_embedded_ai.png)

In the domain of machine learning (ML) systems, embedded systems serve as the bedrock, providing a robust platform where intelligent algorithms can function both efficiently and effectively. Defined by their specialized roles and real-time computational capabilities, these systems act as the convergence point where data and computation intersect on a micro-scale. Tailored to meet the demands of specific tasks, they excel in optimizing performance, energy usage, and spatial efficiency-key considerations in the successful implementation of ML systems.

As we journey further into this chapter, we will demystify the intricate yet captivating realm of embedded systems, gaining insights into their structural design, operational features, and the crucial part they play in enabling ML systems applications. From an introduction to the fundamentals of microcontroller units to a deep dive into the interfaces and peripherals that amplify their capabilities, this chapter aims to be a comprehensive guide for understanding the nuanced aspects of embedded systems within the ML systems landscape.

::: {.callout-tip}

## Learning Objectives

* Acquire a comprehensive understanding of ML systems, including their definitions, architecture, and programming languages, with a focus on the evolution and significance of TinyML.

* Explore the design and operational principles of ML systems, including microcontroller versus microprocessor use, memory management, System on Chip (SoC) integration, and the development and deployment of machine learning models.

* Examine the interfaces, power management, and real-time operating characteristics essential for efficient ML systems, alongside considerations for energy efficiency, reliability, and security.

* Investigate the distinctions, benefits, challenges, and use cases for Cloud ML, Edge ML, and TinyML, emphasizing the selection of the appropriate machine learning approach based on specific application needs and the evolving landscape of embedded systems in machine learning.

:::

## Embedded Systems

### Definition and Characteristics

Embedded systems are specialized forms of computing that do not resemble traditional computers. These systems are dedicated to particular tasks and integrate as components within larger devices. Unlike general-purpose computers capable of running a multitude of applications, embedded systems are designed to execute predefined tasks, often with stringent requirements. Due to their task-specific nature, their architecture is optimized for performance and reliability. The defining traits of these systems include:

1. **Dedicated Functionality**: These systems are engineered to carry out a specific function or a cluster of closely related functions. This specialization allows for optimization, resulting in enhanced performance and reliability.

2. **Real-Time Operation**: A large number of embedded systems function in real-time, necessitating immediate responses to environmental inputs or changes within a set time frame.

3. **Integration with Physical Hardware**: Unlike general-purpose computing systems, embedded systems are tightly integrated with physical components, making them more mechanically oriented.

4. **Long Lifecycle**: Typically, these systems have an extended lifecycle, continuing to operate for many years post their initial deployment.

5. **Resource Constraints**: Often operating under resource limitations, embedded systems require efficient algorithms and software due to restricted computational power and memory.

### Historical Background

The lineage of embedded systems dates back to the 1960s, marked by the introduction of the first microprocessor, labeled as @fig-Intel4004. This groundbreaking development led to the creation of the inaugural embedded system used in the Apollo Guidance Computer, the primary navigational system for the Apollo spacecraft. Over subsequent years, the domain has expanded remarkably, finding utility in diverse sectors such as automotive electronics, consumer electronics, telecommunications, and healthcare.

![Intel 4004.](https://spectrum.ieee.org/media-library/photo-intel.jpg?id=25586036&width=500){#fig-Intel4004 width=70%}

### Importance in TinyML

Within the TinyML framework, embedded systems constitute a vital frontier. The direct integration of machine learning algorithms into these systems enables intelligent, edge-based decision-making, thereby minimizing latency and bolstering security. Here are several factors that underscore the importance of embedded systems in the TinyML ecosystem:

1. **Edge Computing**: By localizing computation near the data source, embedded systems amplify efficiency and diminish the need for continuous interaction with centralized data repositories.

2. **Low Power Consumption**: Designed for minimal energy usage, embedded systems in TinyML are particularly suited for battery-dependent devices and Internet of Things applications.

3. **Real-Time Analysis and Decision Making**: These systems can conduct instantaneous data analysis, facilitating immediate decisions based on the generated insights.

4. **Security and Privacy**: Local data processing on embedded systems enhances security and privacy by reducing the likelihood of data interception during transmission.

5. **Cost-Effective**: The deployment of machine learning models on embedded systems can be economically advantageous, particularly when data transmission and cloud storage could incur substantial costs.

As we progress further into this chapter, we will uncover the complexities that dictate the operations of embedded systems and examine how they serve as the foundational layer upon which TinyML is built, heralding a future filled with integrated, intelligent, and efficient devices and systems.

## Embedded System Architecture

The architectural layout of embedded systems serves as the schematic that outlines the structure and operations of these specialized entities. It sheds light on the interactions and collaborations among various components within an embedded system. This section will dissect the key elements of the architecture, including microcontrollers, microprocessors, diverse types of memory and their management, as well as the complexities of System on Chip (SoC).

### Microcontrollers vs Microprocessors

Comprehending the distinctions between microcontrollers and microprocessors is essential for understanding the basics of embedded system architecture. In this section, we will explore the unique attributes of each:

* **Microcontrollers**

  Microcontrollers are compact, integrated circuits engineered to control specific functions within an embedded system. They incorporate a processor, memory, and input/output peripherals within a single unit, as depicted in @fig-microcontroller, simplifying the overall system design. Microcontrollers are generally employed in applications where computational demands are moderate and cost-effectiveness is a primary consideration.

  **Characteristics**:
  * Single-chip solution
  * On-chip memory and peripherals
  * Minimal energy consumption
  * Well-suited for control-oriented tasks

![Microcontrollers](https://electronicsforu.com/wp-contents/uploads/2016/05/8c2acbb3d9c4ab2807cec1275225fec7.jpg){#fig-microcontroller width=70%}

* **Microprocessors**

  In contrast, microprocessors are more intricate and serve as the central processing unit within a system. They lack the integrated memory and input/output peripherals commonly found in microcontrollers. These processors are typically present in systems requiring elevated computational power and adaptability. They are suitable for devices where high processing power is a necessity and the tasks are data-intensive.

  **Characteristics**:
  * Necessitates external components like memory and input/output peripherals
  * Elevated processing power in comparison to microcontrollers
  * Greater flexibility for connectivity with diverse components
  * Well-suited for data-intensive tasks

![Microcontrollers vs Microprocessors Comparison](images/png/microprocessor_vs_microcontroller.png)

### Memory Types and Management

Embedded systems utilize a variety of memory types, each fulfilling specific roles. Efficient memory management is vital for optimizing both performance and resource utilization. The following section elaborates on different types of memory and their management within the context of embedded systems:

* **ROM (Read-Only Memory)**: This non-volatile memory retains data written during the manufacturing process and remains unaltered throughout the lifespan of the device. It houses firmware and boot-up instructions.

* **RAM (Random Access Memory)**: This volatile memory stores transient data generated during system operation. It is faster and permits read-write operations, but data is lost when power is disconnected.

* **Flash Memory**: This is a type of non-volatile memory that can be electrically erased and reprogrammed. It is commonly used for storing firmware or data that must be retained between system reboots.

**Memory Management**:

* **Static Memory Allocation**: In this approach, memory is allocated prior to runtime and remains fixed throughout system operation.

* **Dynamic Memory Allocation**: Here, memory is allocated during runtime, offering flexibility but introducing the risk of increased complexity and potential memory leaks.

### System on Chip (SoC)

The majority of embedded systems are Systems on Chip (SoCs). An SoC embodies an advanced level of integration technology, incorporating most components required to construct a complete system onto a single chip. It often includes a microprocessor or microcontroller, blocks of memory, peripheral interfaces, and other requisite components for a fully operational system. Below is a detailed examination of its characteristics and applications:

* **Integration of Multiple Components**: SoCs consolidate multiple components like CPUs, memory, and peripherals onto a single chip, facilitating higher levels of integration and reducing the need for external components.

* **Power Efficiency**: The high degree of integration often results in SoCs being more power-efficient compared to systems assembled from separate chips.

* **Cost-Effectiveness**: The integrated nature leads to reduced manufacturing expenses, as fewer individual components are needed.

* **Applications**: SoCs are employed in a diverse range of sectors including mobile computing, automotive electronics, and Internet of Things devices where compact form factors and energy efficiency are highly valued.

Here is a list of widely recognized SoCs that have found substantial applications across various domains:

1. **Qualcomm Snapdragon**: Predominantly used in smartphones and tablets, these SoCs offer a blend of processing power, graphics, and connectivity features.

2. **Apple A-series**: Custom-developed SoCs by Apple, used in their lineup of iPhones, iPads, and in certain versions of Apple TV and HomePod. Notable examples include the A14 Bionic and A15 Bionic chips.

3. **Samsung Exynos**: Developed by Samsung, these SoCs are extensively used in their range of smartphones, tablets, and other electronic devices.

4. **NVIDIA Tegra**: Initially intended for mobile devices, these SoCs have found significant applications in automotive and gaming consoles, such as the Nintendo Switch. A visual representation can be seen below in @fig-soc.

5. **Intel Atom**: Employed in a wide array of systems including netbooks, smartphones, and even embedded systems, these SoCs are known for their power efficiency.

6. **MediaTek Helio**: Commonly found in budget to mid-range smartphones, these chips offer a balanced mix of power efficiency and performance.

7. **Broadcom SoCs**: Extensively used in networking equipment, Broadcom provides a variety of SoCs with diverse functionalities, including those optimized for wireless communications and data processing.

8. **Texas Instruments (TI) OMAP**: Previously popular in smartphones and tablets, these SoCs offered a range of functionalities including multimedia processing and connectivity.

9. **Xilinx Zynq**: Mainly used in embedded systems for industrial automation and in applications requiring high levels of data processing, such as advanced driver-assistance systems (ADAS).

10. **Altera SoC FPGA**: Now a part of Intel, these SoCs combine FPGA technology with ARM cores, offering flexibility and performance for a range of applications including automotive and industrial systems.

![NVIDIA's Tegra 2 combines two ARM Cortex-A9 cores with an ARM7 for SoC management tasks.](https://www.bdti.com/sites/default/files/insidedsp/articlepix/201110/Tegra2.jpg){#fig-soc width=70%}

Each of these Systems on Chip (SoCs) offers a unique array of features and capabilities, tailored to meet the diverse demands of an ever-evolving technological landscape. They consolidate multiple components onto a single chip, delivering power efficiency, cost-effectiveness, and compact solutions suitable for contemporary electronic devices.

## Embedded System Programming

Programming for embedded systems differs significantly from traditional software development, being specifically designed to navigate the constraints of limited resources and real-time requirements commonly associated with embedded hardware. This section aims to shed light on the distinct programming languages employed, delve into the subtleties of firmware development, and explore the pivotal role of Real-time Operating Systems (RTOS) in this specialized domain.

### Programming Languages: C, C++, Python, etc

Choosing the right programming languages is essential in embedded systems, often emphasizing direct hardware interaction and memory usage optimization. Here, we will examine the unique attributes of these languages and how they differ from those commonly used in more conventional computing systems:

* **C**: Often considered the bedrock of embedded systems programming, the C language enables direct engagement with hardware, providing capabilities for bit-wise operations and memory address manipulation. Its procedural nature and low-level functionalities make it the preferred choice for resource-constrained environments, particularly for firmware development.

* **C++**: Building upon the foundational principles of C, C++ incorporates object-oriented features, promoting organized and modular code development. Despite its inherent complexity, it is employed in scenarios where higher-level abstractions do not undermine the detailed control offered by C.

* **Python**: Although not a traditional choice for embedded systems due to its higher memory consumption and runtime delays, Python is gradually gaining traction in the embedded sphere, particularly in systems with less stringent resource limitations. A specialized variant known as MicroPython has been developed, optimized for microcontrollers and retaining the simplicity and ease of Python. This flexible programming paradigm facilitates quick prototyping and development, as illustrated by the code snippet below that interfaces with pins on a [PyBoard](https://store.micropython.org/).

```python
import pyb # Package from PyBoard

# turn on an LED
pyb.LED(1).on()

# print some text to the serial console
print('Hello MicroPython!')
```

**Comparison with Traditional Systems**:
In contrast to mainstream computing systems, where languages like Java, Python, or JavaScript are lauded for their ease of development and extensive libraries, embedded systems favor languages that provide fine-grained control over hardware and opportunities for optimization, all while carefully navigating resource constraints.

### Firmware Development

Firmware development in embedded systems involves creating programs that are permanently stored in the device's non-volatile memory, ensuring consistent operation. This section outlines how firmware development diverges from software development in traditional computing systems:

1. **Resource Optimization**: The imperative for continual optimization is paramount, enabling the code to operate within the limitations of restricted memory and processing capabilities.

2. **Hardware Interaction**: Firmware often maintains a close relationship with hardware, requiring an in-depth understanding of hardware components and their functionalities.

3. **Lifecycle Management**: Firmware updates are less frequent than software updates in traditional systems, necessitating rigorous testing to prevent failures that could lead to hardware malfunctions.

4. **Security Concerns**: Given its integral role, firmware is a potential target for security breaches, necessitating meticulous attention to security aspects, including secure coding practices and encryption protocols.

### Real-time Operating Systems (RTOS)

RTOSs serve as the backbone for real-time embedded systems, managing task execution in a predictable and deterministic manner. This is a marked departure from operating systems in general-purpose computing, as outlined below:

1. **Deterministic Timing**: RTOSs are designed to respond to inputs or events within a well-defined time frame, fulfilling the stringent time-sensitive requirements of many embedded systems.

2. **Task Prioritization**: These systems enable task prioritization, allowing critical tasks to receive preferential processing time over less crucial tasks.

3. **Microkernel Architecture**: Many RTOSs employ a microkernel architecture, epitomizing efficiency and minimalism by focusing solely on essential functionalities.

4. **Memory Management**: Memory management in RTOSs is often more streamlined compared to their counterparts in traditional operating systems, contributing to quick response times and operational efficiency.

**Examples of RTOS**: Notable instances in this category include [FreeRTOS](https://www.freertos.org/index.html), [RTEMS](https://www.rtems.org/), and [VxWorks](https://en.wikipedia.org/wiki/VxWorks), each providing unique features tailored to meet the varied needs of different embedded systems applications.

## Interfaces and Peripherals

Embedded systems engage with the external environment through a range of interfaces and peripherals, which are often more specialized and streamlined than those in general-purpose systems. Let us explore these in detail:

### Digital I/O

Digital Input/Output (I/O) interfaces are fundamental to embedded systems, enabling interaction with other devices and components. For instance, a digital I/O pin may be used to read a binary signal (0 or 1) from sensors or to control actuators. In embedded systems, these I/O ports often operate under strict timing constraints, a

 requirement less common in general-purpose computing systems. Moreover, these systems are usually programmed for specific, optimized operations on digital signals, sometimes needing to function in real-time or near-real-time settings.

### Analog Interfaces

Analog interfaces in embedded systems are vital for interacting with a predominantly analog world. These interfaces may include components like Analog-to-Digital Converters (ADCs) and Digital-to-Analog Converters (DACs). For example, ADCs can be employed to read sensor data from environmental sensors such as temperature or humidity sensors, converting real-world analog data into a digital format that the microcontroller can process.

In contrast to general-purpose systems, embedded systems often utilize analog interfaces more directly and frequently, especially in sensor-integrated applications that require the conversion of a broad range of analog signals into digital data for further processing and analysis.

If you examine @fig-nicla-io closely, you will notice indications of I/O pinouts for analog, digital, and communication layouts.

![Nicla Vision pinout](https://content.arduino.cc/assets/ABX00051-pinout.png){#fig-nicla-io}

### Communication Protocols (SPI, I2C, UART, etc.)

Communication protocols act as the channels that enable communication between various components within or connected to an embedded system. Let us examine some commonly used ones:

* **SPI (Serial Peripheral Interface)**: This synchronous serial communication protocol is primarily used for short-distance communication in embedded systems. For instance, it is frequently employed in communications with SD cards and TFT displays.

* **I2C (Inter-Integrated Circuit)**: This multi-master, multi-slave, packet-switched, single-ended, serial communication bus is widely used in embedded systems to connect low-speed peripherals to motherboards, embedded systems, or cell phones. It is valued for its simplicity and low pin count.

* **UART (Universal Asynchronous Receiver-Transmitter)**: This protocol enables asynchronous serial communication between devices. It is commonly used in embedded systems to transmit data between devices over a serial port, such as sending data logs from a sensor node to a computer.

Compared to general-purpose systems, communication protocols in embedded systems are often more finely tuned for speed and reliability, especially in critical applications where data transmission integrity is crucial. Additionally, these protocols may be directly integrated into the microcontroller, facilitating more cohesive and seamless interactions between components, a feature less commonly observed in general-purpose systems.

## Power Management in Embedded Systems

Power management is a critical focus area in the design of embedded systems, influencing both the system's efficiency and its applicability in real-world scenarios. The wide range of applications for embedded systems, from handheld devices to industrial equipment, highlights the need for meticulous power management. Let us explore this essential aspect of embedded systems:

### Power Consumption Considerations

In embedded systems, power consumption is a key factor that dictates both performance and longevity. Microcontrollers in these systems usually operate within a voltage range of 1.8V to 5V, with current consumption varying from microamperes (uA) to milliamperes (mA) during active states. In sleep or standby modes, the current consumption can drop to nanoamperes (nA), extending battery life.

In contrast, general-purpose computing systems like desktop computers consume power on the scale of tens to hundreds of watts, several orders of magnitude higher than embedded systems. This significant difference underscores the need for careful power management in embedded systems, where the power budget is often much more limited.

Managing power consumption involves a complex interplay of factors such as operating voltage, clock frequency, and the specific tasks the system performs. Engineers often find themselves balancing power consumption against performance and responsiveness, navigating a complex landscape of trade-offs.

### Energy-Efficient Design

Incorporating energy efficiency into the design phase is crucial for the successful deployment of embedded systems. Techniques like dynamic voltage and frequency scaling (DVFS) are often employed, allowing the system to adjust voltage and frequency dynamically based on processing needs, thereby optimizing power consumption.

Additionally, the use of low-power modes, where non-essential peripherals are deactivated or clock frequencies are reduced, can significantly conserve energy. For example, deep sleep modes that consume as little as 100 nA can dramatically extend battery life, particularly in battery-operated embedded systems.

The architecture of the microcontroller, especially its instruction set architecture (ISA), is often highly specialized to eliminate unnecessary complexities that could increase power consumption. This specialization allows operations to be executed in fewer cycles compared to general-purpose processors, reducing the power consumed per operation. Moreover, these specialized ISAs are designed to efficiently execute the specific tasks that the embedded system is intended to perform, optimizing the execution path and thereby saving energy.

### Battery Management

Managing batteries is an integral component of power management strategies in embedded systems. The goal is to maximize battery life without sacrificing performance. Battery-powered embedded systems often use lithium-ion or lithium-polymer batteries due to their high energy density and rechargeable features. These batteries typically have a voltage range of 3.7V to 4.2V per cell. For example, the [Nicla Vision](https://store.arduino.cc/products/nicla-vision) utilizes a 3.7V battery, as shown in @fig-battery.

![Nicla Vision battery](https://content.arduino.cc/assets/nicla_vision_battery.png){#fig-battery}

By focusing on these elements, engineers can create systems that not only meet functional requirements but do so in a manner that reflects a deep understanding of the broader impacts of technology on society and the environment.

Engineers are tasked with implementing methods such as effective charge regulation, protection against voltage spikes, and thermal monitoring to ensure the longevity and health of the battery. Additionally, the incorporation of systems that can tap into renewable energy sources like solar or kinetic energy can augment battery reserves, leading to enduring and eco-friendly solutions.

The emphasis on power management is driven by the imperative to make the most of available resources, prolong battery longevity, and minimize operational expenditures. In scenarios where the embedded systems are situated in remote or hard-to-reach locations, adept power management can substantially cut down on the frequency of maintenance visits, thereby guaranteeing continuous and seamless functionality.

It's fair to assert that power management goes beyond being a mere technical specification in embedded systems; it serves as an important factor that can either make or break the success of a project. Significant engineering effort is channeled into fine-tuning power management approaches, aiming to develop systems that are not just operationally efficient but also environmentally sustainable. This reflects a profound dedication to both technological innovation and excellence within the realm of embedded systems.

## Real-Time Characteristics

Within the complex tapestry of embedded systems, real-time attributes serve as essential threads, interlacing various components and tasks into a unified, responsive whole. This element, often specific to embedded systems, occupies a vital role in both their architecture and functionality, endowing them with the nimbleness and accuracy needed for timely interaction with their surroundings. Let's examine the nuances that underscore the real-time attributes of embedded systems:

### Real-time Clocks

Real-time clocks (RTCs) hold a central position in embedded systems, offering an accurate time benchmark that directs the system's activities. These clocks frequently come with battery backups to maintain reliable timekeeping, even when the primary power source is compromised. The role of RTCs is more critical and widespread in embedded systems compared to general-purpose computing, where timekeeping, while important, usually doesn't govern the core operations of the system.

For example, in the realm of industrial automation, RTCs facilitate the precise coordination of tasks, ensuring synchronized and timely processes. They are particularly crucial in scenarios requiring time-stamped data, such as environmental monitoring systems where the accuracy and time relevance of data are imperative.

### Timing and Synchronization

Timing and synchronization stand as defining features of embedded systems, requiring various components and processes to operate in concert. The essence of a real-time embedded system is shaped by its capability to execute tasks within a specified time window. Such systems often have rigorous timing constraints, necessitating synchronization methods that are both sturdy and exact.

In the context of automotive control systems, the synchronized and timely operation of diverse sensors and actuators is imperative for both safety and peak performance. This sharply contrasts with general-purpose systems, where timing, though managed, usually lacks immediate and critical consequences.

### Task Management and Scheduling

In the world of embedded systems, the management and scheduling of tasks are crucial for effective real-time responses. Task schedulers in these systems often use techniques like priority scheduling, where tasks are ranked by importance, allowing higher-priority tasks to interrupt those of lower priority. This is especially critical in systems where some functions have greater urgency.

For example, in medical devices such as pacemakers, the punctual delivery of electrical impulses is a high-priority task, and the scheduler must give it precedence over all other activities to ensure patient safety. This level of refined scheduling and task management sets embedded systems apart from the more adaptable but less deterministic scheduling seen in general-purpose systems.

### Error Handling and Fault Tolerance

To enhance their real-time features, embedded systems frequently incorporate mechanisms for error detection and fault resilience. These are engineered to swiftly identify and rectify errors or to sustain system functionality even when faults occur. In aviation control systems, for instance, real-time fault tolerance is essential for maintaining the stability and safety of drones. This meticulous approach to error management is somewhat unique to embedded systems, accentuating the critical nature of many such applications.

The real-time attributes of embedded systems distinguish them, creating an environment where accuracy, synchrony, and prompt responses are not optional but obligatory. These attributes resonate across a wide range of applications, from automotive systems to industrial automation and healthcare devices, highlighting the role of embedded systems as quiet yet potent conductors of a technologically synchronized world. Through their real-time features, embedded systems offer solutions that not only satisfy functional needs but do so with a degree of precision and dependability that is both extraordinary and essential in today's world.

## Security and Reliability

In an increasingly interconnected and tech-dependent world, the issues of security and reliability have risen to become primary considerations in system engineering. This is especially true for embedded systems, which often serve as key components in critical infrastructures and applications, thereby raising the stakes considerably. Let's explore the crucial elements that fortify the bastion of security and reliability in embedded systems:

### Secure Boot and Root of Trust

Embedded systems are increasingly central to a variety of critical applications, making it imperative to assure their authenticity and integrity from the moment they boot up. The secure boot sequence serves as a foundational element in this security framework, permitting the system to run only code that has been authenticated and deemed trustworthy. This is often augmented by a "Root of Trust," a stable and secure environment, typically hardware-based, that validates the initial firmware and each subsequent layer of software during the boot-up sequence.

For example, in financial settings involving Point-of-Sale (POS) terminals, a secure boot mechanism guarantees that the firmware remains intact and secure, thereby preventing any malicious alterations that could lead to significant data breaches. Likewise, in the realm of home automation, a strong secure boot process acts as a barrier to unauthorized access, thereby protecting user data and privacy.

### Fault Tolerance

Fault tolerance is an essential quality in embedded systems, granting them the ability to maintain functionality even when faced with faults or system failures. This resilience is achieved through various means such as redundancy, where vital components are replicated to assume control in the event of a failure, or via sophisticated error detection and correction methods.

In sectors like aerospace and aviation, fault tolerance is not merely an advantageous feature but an obligatory specification. For instance, aircraft control systems utilize multiple redundant configurations that operate in parallel to assure uninterrupted functionality, even if a component fails. This degree of fault tolerance provides a heightened level of reliability, enabling the system to endure failures without disastrous outcomes, a feature that distinguishes it from conventional computing systems.

### Safety-Critical Systems

Safety-critical systems are defined as those where a malfunction could lead to loss of life, substantial property damage, or environmental degradation. Such systems demand rigorous design protocols to guarantee the highest levels of reliability and safety. Embedded systems falling under this classification often comply with stringent development guidelines and are subject to exhaustive testing to confirm their safety and reliability metrics.

For instance, in automotive safety features like Anti-lock Braking Systems (ABS) and Electronic Stability Control (ESC), embedded controllers are crucial. These controllers are engineered in accordance with rigorous standards like [ISO 26262](https://www.iso.org/standard/43464.html), ensuring they meet the elevated safety and reliability criteria essential for safeguarding lives. In the healthcare sector, devices such as pacemakers and infusion pumps are categorized as safety-critical, where the dependability of embedded systems can quite literally be life-altering.

The focus on security and reliability in embedded systems is of paramount importance, a point that is often underestimated by many. As these systems become increasingly woven into the fabric of our everyday lives and critical infrastructure, the principles of security and reliability serve as guiding lights in their development and deployment. Through features like secure booting and fault tolerance, these systems offer not just operational efficiency but also a layer of trust and security, providing a steadfast and secure anchor in a rapidly evolving technological landscape. These foundational tenets shape today's embedded systems, molding them into dependable stewards and proficient operators in various critical domains of contemporary society.

## Future Trends and Challenges

Arm, the leading producer of microcontrollers, has reached a milestone by shipping an unprecedented 8.0 billion chips, either directly or through its partners. This takes the total number of chips shipped to date to an astounding quarter of a trillion, or 250 billion [@armcomfuture]!

As we find ourselves at the threshold of a new era marked by extraordinary growth in the embedded systems sector, it becomes both exhilarating and imperative to scrutinize the emerging trends and challenges that lie ahead. From the expanding horizons of edge computing to the imperatives of scalability, the landscape is poised for transformation, unveiling new realms of both opportunities and challenges. Let's explore the evolving frontier that awaits embedded systems:

### Edge Computing and IoT

With the rapid expansion of the Internet of Things (IoT), edge computing is gaining increasing prominence. Essentially, edge computing enables data to be processed closer to its source, thereby reducing latency and alleviating the burden on centralized data centers. This shift in computing paradigms is anticipated to revolutionize embedded systems, endowing them with enhanced processing power and the intelligence to perform intricate tasks on-site.

Additionally, as the IoT is projected to include billions of interconnected devices worldwide, embedded systems are slated to be the linchpin in ensuring smooth connectivity and interoperability among a diverse set of devices. This interconnected ecosystem is expected to enable real-time analytics and decision-making, laying the groundwork for more intelligent cities, industries, and households. The challenge resides in crafting systems that are secure, energy-efficient, and adept at managing the anticipated data deluge effectively.

### Scalability and Upgradation

As the landscape of embedded systems continues its evolutionary trajectory, the focus will increasingly turn towards scalability and ease of upgradation. Systems will be required to adapt to evolving technologies and user needs without undergoing extensive modifications. This necessitates modular architectures and adherence to open standards, facilitating the effortless incorporation of new functionalities and features.

Moreover, in light of rapid technological advancements, embedded systems will need to incorporate capabilities for remote updates and maintenance to ensure their continued relevance and longevity. The responsibility will fall on the shoulders of developers and manufacturers to engineer systems that not only satisfy current needs but are also prepared for future enhancements, thereby securing a path for sustainable and progressive development.

### Market Opportunities

The market landscape for embedded systems is on the cusp of dynamic changes. As various industries accelerate their adoption of automation and digital transformation, the demand for advanced embedded systems is set to skyrocket. The integration of Artificial Intelligence (AI) and Machine Learning (ML) into embedded systems is expected to offer unparalleled levels of intelligence and automation.

At the same time, burgeoning opportunities are emerging in sectors like consumer electronics, automotive, healthcare, and industrial applications. While this growth presents enormous potential for innovation, it also introduces challenges such as heightened competition and the necessity for adherence to evolving regulatory frameworks. Companies entering this arena will need to exhibit agility, innovation, and adaptability to the shifting market conditions in order to establish a competitive edge.

The table provides a side-by-side comparison between these two distinct types of computing systems, covering a range of categories including processing power, memory capabilities, user interface, and real-time functionalities, among others. The aim of this comparative analysis is to offer readers a concise yet thorough understanding of the unique attributes and specificities of both conventional and embedded computing systems. This, in turn, enables a more nuanced and informed grasp of their respective roles in today's computing landscape.

| Category                    | Traditional Computing System            | Embedded System Architecture            |
|-----------------------------|-----------------------------------------|------------------------------------------|
| **Hardware Characteristics**|                                         |                                          |
| Processing Power            | High (Multi-core processors)            | Moderate to Low (Single/Multi-core, optimized for specific tasks) |
| Memory                      | High (Upgradable)                        | Limited (Fixed)                          |
| Storage                     | High (Upgradable)                        | Limited (Fixed or expandable to a certain extent) |
| Hardware Scalability        | High (Can upgrade various components)   | Low (Hardware is often fixed and focused)|
| **Software Characteristics**|                                         |                                          |
| Operating System            | General Purpose (Windows, Linux, macOS) | Real-Time Operating System (RTOS) or No OS |
| Development Flexibility     | High (Supports multiple programming languages and frameworks) | Moderate (Focused on specific programming languages and tools) |
| **Performance & Efficiency**|                                        |                                         |
| Power Consumption           | High                                    | Low (Optimized for energy efficiency)   |
| Real-Time Capabilities      | Limited (Not optimized for real-time tasks) | High (Designed for real-time tasks)   |
| **User Interaction**        |                                         |                                         |
| User Interface              | Complex (GUI-Based)                     | Simple or None (Can be GUI, command-line, or none) |
| Connectivity                | Extensive (Multiple ports and connectivity options) | Limited (Focused on necessary connectivity options) |
| **Lifecycle & Maintenance** |                                         |                                         |
| Maintenance                 | Regular Maintenance Required            | Low Maintenance (Set up to run specific tasks consistently) |
| Lifecycle                   | Shorter (Due to rapid technological advancements) | Longer (Designed to perform specific tasks over a long period) |
| **Cost and Use Cases**      |                                         |                                         |
| Cost                        | Variable (Can be high depending on specifications) | Generally Lower (Due to focused functionalities) |
| Use Cases                   | General (Various applications across sectors) | Specific (Dedicated to particular tasks or applications) |

As we gaze into the future, it's clear that the realm of embedded systems stands on the cusp of a transformative era, characterized by groundbreaking innovations, abundant opportunities, and formidable challenges. The horizon is replete with the promise of enhanced connectivity, heightened intelligence, and superior efficiency, carving out a trajectory where embedded systems will serve as the guiding force behind society's technological progress. The path forward is one of discovery and adaptability, where the confluence of technological prowess and creative ingenuity will sculpt a future that is not only rich in technological advancements but also attuned to the intricate and continually shifting needs of a dynamic global landscape. It's a field teeming with possibilities, inviting trailblazers to embark on a journey to define the parameters of a bright and flourishing future.

## Machine Learning Systems

ML is rapidly evolving, with new paradigms emerging that are reshaping how these algorithms are developed, trained, and deployed. In particular, the area of embedded machine learning is experiencing significant innovation, driven by the proliferation of smart sensors, edge devices, and microcontrollers. This chapter explores the landscape of embedded machine learning, covering the key approaches of Cloud ML, Edge ML, and TinyML (@fig-cloud-edge-tinyml-comparison).

![Cloud vs. Edge vs. TinyML: The Spectrum of Distributed Intelligence](images/png/cloud-edge-tiny.png){#fig-cloud-edge-tinyml-comparison}

We begin by outlining the features or characteristics, benefits, challenges, and use cases for each embedded ML variant. This provides context on where these technologies do well and where they face limitations. We then bring all three approaches together into a comparative analysis, evaluating them across critical parameters like latency, privacy, computational demands, and more. This side-by-side perspective highlights the unique strengths and tradeoffs involved in selecting among these strategies.

Next, we trace the evolution timeline of embedded systems and machine learning, from the origins of wireless sensor networks to the integration of ML algorithms into microcontrollers. This historical lens enriches our understanding of the rapid pace of advancement in this domain. Finally, practical hands-on exercises offer an opportunity to experiment first-hand with embedded computer vision applications.

By the end of this multipronged exploration of embedded ML, you will possess the conceptual and practical knowledge to determine the appropriate ML implementation for your specific use case constraints. The chapter aims to equip you with the contextual clarity and technical skills to navigate this quickly shifting landscape, empowering impactful innovations.

## Cloud ML

### Characteristics

Cloud ML is a specialized branch of the broader machine learning field that operates within cloud computing environments. It offers a virtual platform for the development, training, and deployment of machine learning models, providing both flexibility and scalability.

At its foundation, Cloud ML utilizes a powerful blend of high-capacity servers, expansive storage solutions, and robust networking architectures, all located in data centers around the world (@fig-cloudml-example). This setup centralizes computational resources, simplifying the management and scaling of machine learning projects.

The cloud environment excels in data processing and model training, designed to manage large data volumes and complex computations. Models crafted in Cloud ML can leverage vast amounts of data, processed and analyzed centrally, thereby enhancing the model's learning and predictive performance.

![Cloud ML Example: Cloud TPU accelerator supercomputers in google data center (Source: [Google](https://blog.google/technology/ai/google-gemini-ai/#scalable-efficient))](images/png/cloud_ml_tpu.png){#fig-cloudml-example}

### Benefits

Cloud ML is synonymous with immense computational power, adept at handling complex algorithms and large datasets. This is particularly advantageous for machine learning models that demand significant computational resources, effectively circumventing the constraints of local setups.

A key advantage of Cloud ML is its dynamic scalability. As data volumes or computational needs grow, the infrastructure can adapt seamlessly, ensuring consistent performance.

Cloud ML platforms often offer a wide array of advanced tools and algorithms. Developers can utilize these resources to accelerate the building, training, and deployment of sophisticated models, thereby fostering innovation.

### Challenges

Despite its capabilities, Cloud ML can face latency issues, especially in applications that require real-time responses. The time taken to send data to centralized servers and back can introduce delays, a significant drawback in time-sensitive scenarios.

Centralizing data processing and storage can also create vulnerabilities in data privacy and security. Data centers become attractive targets for cyber-attacks, requiring substantial investments in security measures to protect sensitive data.

Additionally, as data processing needs escalate, so do the costs of using cloud services. Organizations dealing with large data volumes may encounter rising costs, potentially affecting the long-term scalability and feasibility of their operations.

### Example Use Cases

Cloud ML plays an important role in powering virtual assistants like Siri and Alexa. These systems harness the cloud's computational prowess to analyze and process voice inputs, delivering intelligent and personalized responses to users.

It also serves as the foundation for advanced recommendation systems in platforms like Netflix and Amazon. These systems sift through extensive datasets to identify patterns and preferences, offering personalized content or product suggestions to boost user engagement.

In the financial realm, Cloud ML has been instrumental in creating robust fraud detection systems. These systems scrutinize vast amounts of transactional data to flag potential fraudulent activities, enabling timely interventions and reducing financial risks.

In summary, it's virtually impossible to navigate the internet today without encountering some form of Cloud ML, either directly or indirectly. From the personalized ads that appear on your social media feed to the predictive text features in email services, Cloud ML is deeply integrated into our online experiences. It powers smart algorithms that recommend products on e-commerce sites, fine-tunes search engines to deliver accurate results, and even automates the tagging and categorization of photos on platforms like Facebook.

Furthermore, Cloud ML bolsters user security through anomaly detection systems that monitor for unusual activities, potentially shielding users from cyber threats. Essentially, it acts as the unseen powerhouse, continuously operating behind the scenes to refine, secure, and personalize our digital interactions, making the modern internet a more intuitive and user-friendly environment.

## Edge ML

### Characteristics

**Definition of Edge ML**

Edge Machine Learning (Edge ML) is the practice of running machine learning algorithms directly on endpoint devices or closer to where the data is generated, rather than relying on centralized cloud servers. This approach aims to bring computation closer to the data source, reducing the need to send large volumes of data over networks, which often results in lower latency and improved data privacy.

**Decentralized Data Processing**

In Edge ML, data processing happens in a decentralized fashion. Instead of sending data to remote servers, the data is processed locally on devices like smartphones, tablets, or IoT devices (@fig-edgeml-example). This local processing allows devices to make quick decisions based on the data they collect, without having to rely heavily on a central server's resources. This decentralization is particularly important in real-time applications where even a slight delay can have significant consequences.

**Local Data Storage and Computation**

Local data storage and computation are key features of Edge ML. This setup ensures that data can be stored and analyzed directly on the devices, thereby maintaining the privacy of the data and reducing the need for constant internet connectivity. Moreover, this often leads to more efficient computation, as data doesn't have to travel long distances, and computations are performed with a more nuanced understanding of the local context, which can sometimes result in more insightful analyses.

![Edge ML Example: Data is processed locally on Internet of Things (IoT) devices (Source: [Edge Impulse](https://docs.edgeimpulse.com/docs/concepts/what-is-edge-machine-learning))](images/jpg/edge_ml_iot.jpg){#fig-edgeml-example}

### Benefits

**Reduced Latency**

One of the main advantages of Edge ML is the significant reduction in latency compared to Cloud ML. In situations where milliseconds count, such as in autonomous vehicles where quick decision-making can mean the difference between safety and an accident, this reduced latency can be a critical benefit.

**Enhanced Data Privacy**

Edge ML also offers improved data privacy, as data is primarily stored and processed locally. This minimizes the risk of data breaches that are more common in centralized data storage solutions. This means sensitive information can be kept more secure, as it's not sent over networks where it could potentially be intercepted.

**Lower Bandwidth Usage**

Operating closer to the data source means that less data needs to be sent over networks, reducing bandwidth usage. This can result in cost savings and efficiency gains, especially in environments where bandwidth is limited or costly.

### Challenges

**Limited Computational Resources Compared to Cloud ML**

However, Edge ML is not without its challenges. One of the main concerns is the limited computational resources compared to cloud-based solutions. Endpoint devices may not have the same processing power or storage capacity as cloud servers, which can limit the complexity of the machine learning models that can be deployed.

**Complexity in Managing Edge Nodes**

Managing a network of edge nodes can introduce complexity, especially when it comes to coordination, updates, and maintenance. Ensuring that all nodes are operating seamlessly and are up-to-date with the latest algorithms and security protocols can be a logistical challenge.

**Security Concerns at the Edge Nodes**

While Edge ML offers enhanced data privacy, edge nodes can sometimes be more vulnerable to physical and cyber-attacks. Developing robust security protocols that protect data at each node, without compromising the system's efficiency, remains a significant challenge in deploying Edge ML solutions.

### Example Use Cases

Edge ML has a wide range of applications, from autonomous vehicles and smart homes to industrial IoT. These examples were chosen to highlight scenarios where real-time data processing, reduced latency, and enhanced privacy are not just beneficial but often critical to the operation and success of these technologies. They serve to demonstrate the pivotal role that Edge ML can play in driving advancements in various sectors, fostering innovation, and paving the way for more intelligent, responsive, and adaptive systems.

**Autonomous Vehicles**

Autonomous vehicles stand as a prime example of Edge ML's potential. These vehicles rely heavily on real-time data processing to navigate and make decisions. Localized machine learning models assist in quickly analyzing data from various sensors to make immediate driving decisions, essentially ensuring safety and smooth operation.

**Smart Homes and Buildings**

In smart homes and buildings, Edge ML plays a crucial role in efficiently managing various systems, from lighting and heating to security. By processing data locally, these systems can operate more responsively and in harmony with the occupants' habits and preferences, creating a more comfortable living environment.

**Industrial IoT**

The Industrial Internet of Things (IoT) leverages Edge ML to monitor and control complex industrial processes. Here, machine learning models can analyze data from numerous sensors in real-time, enabling predictive maintenance, optimizing operations, and enhancing safety measures. This brings about a revolution in industrial automation and efficiency.

The applicability of Edge ML is vast and not limited to these examples. Various other sectors, including healthcare, agriculture, and urban planning, are exploring and integrating Edge ML to develop solutions that are both innovative and responsive to real-world needs and challenges, heralding a new era of smart, interconnected systems.

## Tiny ML

### Characteristics

**Definition of TinyML**

TinyML sits at the crossroads of embedded systems and machine learning, representing a burgeoning field that brings smart algorithms directly to tiny microcontrollers and sensors. These microcontrollers operate under severe resource constraints, particularly in terms of memory, storage, and computational power (see a TinyML kit example in @fig-tinyml-example).

**On-Device Machine Learning**

In TinyML, the focus is on on-device machine learning. This means that machine learning models are not just deployed but also trained right on the device, eliminating the need for external servers or cloud infrastructures. This allows TinyML to enable intelligent decision-making right where the data is generated, making real-time insights and actions possible, even in settings where connectivity is limited or unavailable.

**Low Power and Resource-Constrained Environments**

TinyML excels in low-power and resource-constrained settings. These environments require solutions that are highly optimized to function within the available resources. TinyML meets this need through specialized algorithms and models designed to deliver decent performance while consuming minimal energy, thus ensuring extended operational periods, even in battery-powered devices.

![Tiny ML Example: (Left) A TinyML kit that includes Arduino Nano 33 BLE Sense, an OV7675 camera module, and TinyML shield. (Right) The Nano 33 BLE includes a host of onboard integrated sensors, a Bluetooth Low Energy module, and an Arm Cortex-M microcontroller that can run neural-network models using TensorFlow Lite for Microcontrollers. (Source: [Widening Access to Applied Machine Learning with TinyML](https://arxiv.org/pdf/2106.04008.pdf)))](images/jpg/tiny_ml.jpg){#fig-tinyml-example}

### Benefits

**Extremely Low Latency**

One of the standout benefits of TinyML is its ability to offer ultra-low latency. Since computation occurs directly on the device, the time required to send data to external servers and receive a response is eliminated. This is crucial in applications requiring immediate decision-making, enabling quick responses to changing conditions.

**High Data Security**

TinyML inherently enhances data security. Because data processing and analysis happen on the device itself, the risk of data interception during transmission is virtually eliminated. This localized approach to data management ensures that sensitive information stays on the device, thereby strengthening user data security.

**Energy Efficiency**

TinyML operates within an energy-efficient framework, a necessity given the resource-constrained environments in which it functions. By employing lean algorithms and optimized computational methods, TinyML ensures that devices can execute complex tasks without rapidly depleting battery life, making it a sustainable option for long-term deployments.

### Challenges

**Limited Computational Capabilities**

However, the shift to TinyML comes with its set of hurdles. The primary limitation is the constrained computational capabilities of the devices. The need to operate within such limits means that deployed models must be simplified, which could affect the accuracy and sophistication of the solutions.

**Complex Development Cycle**

TinyML also introduces a complicated development cycle. Crafting models that are both lightweight and effective demands a deep understanding of machine learning principles, along with expertise in embedded systems. This complexity calls for a collaborative development approach, where multi-domain expertise is essential for success.

**Model Optimization and Compression**

A central challenge in TinyML is model optimization and compression. Creating machine learning models that can operate effectively within the limited memory and computational power of microcontrollers requires innovative approaches to model design. Developers often face the challenge of striking a delicate balance, optimizing models to maintain effectiveness while fitting within stringent resource constraints.

### Example Use Cases

**Wearable Devices**

In wearables, TinyML opens the door to smarter, more responsive gadgets. From fitness trackers offering real-time workout feedback to smart glasses processing visual data on the fly, TinyML is transforming how we engage with wearable tech, delivering personalized experiences directly from the device.

**Predictive Maintenance**

In industrial settings, TinyML plays a significant role in predictive maintenance. By deploying TinyML algorithms on sensors that monitor equipment health, companies can preemptively identify potential issues, reducing downtime and preventing costly breakdowns. On-site data analysis ensures quick responses, potentially stopping minor issues from becoming major problems.

**Anomaly Detection**

TinyML can be employed to create anomaly detection models that identify unusual data patterns. For instance, a smart factory could use TinyML to monitor industrial processes and spot anomalies, helping prevent accidents and improve product quality. Similarly, a security company could use TinyML to monitor network traffic for unusual patterns, aiding in the detection and prevention of cyber attacks. In healthcare, TinyML could monitor patient data for anomalies, aiding early disease detection and better patient treatment.

**Environmental Monitoring**

In the field of environmental monitoring, TinyML enables real-time data analysis from various field-deployed sensors. These could range from air quality monitoring in cities to wildlife tracking in protected areas. Through TinyML, data can be processed locally, allowing for quick responses to changing conditions and providing a nuanced understanding of environmental patterns, crucial for informed decision-making.

In summary, TinyML serves as a trailblazer in the evolution of machine learning, fostering innovation across various fields by bringing intelligence directly to the edge. Its potential to transform our interaction with technology and the world is immense, promising a future where devices are not just connected but also intelligent, capable of making real-time decisions and responses.

## Comparison

Up to this point, we've explored each of the different ML variants individually. Now, let's bring them all together for a comprehensive view. Below is a table offering a comparative analysis of Cloud ML, Edge ML, and TinyML based on various features and aspects. This comparison aims to provide a clear perspective on the unique advantages and distinguishing factors of each, aiding in making informed decisions based on the specific needs and constraints of a given application or project.

| Feature/Aspect           | Cloud ML                                              | Edge ML                                              | TinyML                                              |
|--------------------------|--------------------------------------------------------|------------------------------------------------------|------------------------------------------------------|
| **Processing Location**     | Centralized servers (Data Centers)                       | Local devices (closer to data sources)                 | On-device (microcontrollers, embedded systems)         |
| **Latency**                | High (Depends on internet connectivity)                 | Moderate (Reduced latency compared to Cloud ML)        | Low (Immediate processing without network delay)       |
| **Data Privacy**           | Moderate (Data transmitted over networks)               | High (Data remains on local networks)                  | Very High (Data processed on-device, not transmitted)  |
| **Computational Power**    | High (Utilizes powerful data center infrastructure)     | Moderate (Utilizes local device capabilities)          | Low (Limited to the power of the embedded system)      |
| **Energy Consumption**     | High (Data centers consume significant energy)          | Moderate (Less than data centers, more than TinyML)    | Low (Highly energy-efficient, designed for low power)  |
| **Scalability**            | High (Easy to scale with additional server resources)   | Moderate (Depends on local device capabilities)        | Low (Limited by the hardware resources of the device)  |
| **Cost**                   | High (Recurring costs for server usage, maintenance)    | Variable (Depends on the complexity of local setup)    | Low (Primarily upfront costs for hardware components)  |
| **Connectivity Dependence**| High (Requires stable internet connectivity)            | Low (Can operate with intermittent connectivity)      | Very Low (Can operate without any network connectivity)|
| **Real-time Processing**   | Moderate (Can be affected by network latency)           | High (Capable of real-time processing locally)         | Very High (Immediate processing with minimal latency)  |
| **Application Examples**   | Big Data Analysis, Virtual Assistants                   | Autonomous Vehicles, Smart Homes                       | Wearables, Sensor Networks                             |
| **Development Complexity** | Moderate to High (Requires knowledge in cloud computing) | Moderate (Requires knowledge in local network setup)   | Moderate to High (Requires expertise in embedded systems)|

## Evolution Timeline

### Late 1990s - Early 2000s: The Dawn of Wireless Sensor Networks

During the late 1990s and early 2000s, wireless sensor networks (WSNs) marked a significant milestone in information technology. These networks consisted of sensor nodes that could collect and wirelessly transmit data. With capabilities to monitor various environmental conditions like temperature and humidity, WSNs found applications across diverse sectors, including industrial automation, healthcare, and environmental monitoring. This era also saw the development of standardized protocols like Zigbee, which facilitated secure and reliable data transmission.

### Mid-2000s: The Rise of the Internet of Things (IoT)

Moving into the mid-2000s, the Internet of Things (IoT) began to take shape. IoT expanded upon the principles of WSNs, connecting a variety of devices and enabling them to communicate and share data over the internet. The incorporation of embedded systems in IoT devices led to smarter operations, as these devices could now not only collect but also process data for intelligent decision-making. This era witnessed the widespread adoption of smart homes and industrial IoT, transforming our interaction with devices and systems.

### Late 2000s - Early 2010s: The Smartphone Revolution and Mobile Computing

The late 2000s ushered in the smartphone revolution, significantly impacting the evolution of embedded systems. Smartphones evolved into powerful computing devices, equipped with various sensors and embedded systems capable of executing complex tasks. This integration laid the foundation for mobile computing, with applications ranging from gaming and navigation to health monitoring.

### Mid-2010s: The Era of Big Data and Edge Computing

By the mid-2010s, the enormous volume of data generated by interconnected devices necessitated new data processing strategies. Big Data technologies emerged to manage this data influx, and alongside, the concept of edge computing gained prominence. Edge computing brought data processing closer to the data source, reducing latency and bandwidth usage. Embedded systems adapted to support edge computing, enabling substantial local data processing and lessening the reliance on centralized data centers.

### Late 2010s - Early 2020s: Integration of Machine Learning and AI

As we approached the late 2010s and early 2020s, machine learning and AI became integral to embedded systems. This integration led to the development of smart devices with enhanced decision-making and predictive capabilities. Advances in natural language processing, computer vision, and predictive analytics were notable, as embedded systems became capable of supporting complex AI algorithms.

### Early 2020s: The Advent of TinyML

Entering the 2020s, the field saw the emergence of TinyML, bringing machine learning capabilities to ultra-low-power microcontrollers. This development enabled the deployment of ML models directly onto small embedded devices, allowing for intelligent edge data processing even on devices with limited computational resources. This has expanded the possibilities for IoT devices, making them smarter and more autonomous.

### 2023 and Beyond: Towards a Future of Ubiquitous Embedded AI

As we move further into this decade, we foresee a transformative phase where embedded AI and TinyML transition from being innovative concepts to pervasive forces integral to our technological landscape. This promises a future where the lines between artificial intelligence and daily functionalities increasingly blur, heralding a new era of innovation and efficiency.

## Conclusion

In this chapter, we've offered a panoramic view of the evolving landscape of embedded machine learning, covering cloud, edge, and tiny ML paradigms. Cloud-based machine learning leverages the immense computational resources of cloud platforms to enable powerful and accurate models but comes with its own set of limitations, including latency and privacy concerns. Edge ML mitigates these limitations by bringing ML inference directly to edge devices, offering lower latency and reduced connectivity needs. TinyML takes this a step further by miniaturizing ML models to run directly on highly resource-constrained devices, opening up a new category of intelligent applications.

Each approach comes with its own set of trade-offs, including model complexity, latency, privacy, and hardware costs. Over time, we anticipate a convergence of these embedded ML approaches, with cloud pre-training facilitating more sophisticated edge and tiny ML implementations. Advances like federated learning and on-device learning will also enable embedded devices to refine their models by learning from real-world data.

The embedded ML landscape is in a state of rapid evolution, poised to enable intelligent applications across a broad spectrum of devices and use cases. This chapter serves as a snapshot of the current state of embedded ML, and as algorithms, hardware, and connectivity continue to improve, we can expect embedded devices of all sizes to become increasingly capable, unlocking transformative new applications for artificial intelligence.

## Resources {#sec-embedded-systems-resource .unnumbered}

Here is a curated list of resources to support both students and instructors in their learning and teaching journey. We are continuously working on expanding this collection and will be adding new exercises in the near future.

:::{.callout-slide collapse="false"}
# Slides

These slides serve as a valuable tool for instructors to deliver lectures and for students to review the material at their own pace. We encourage both students and instructors to leverage these slides to enhance their understanding and facilitate effective knowledge transfer.

* [Embedded Systems Overview.](https://docs.google.com/presentation/d/1Lgrn7bddHYxyrOmk0JfSVmEBimRePqI7WSliUKRPK9E/edit?resourcekey=0-c5JvfDeqHIdV9A5RMAMAyw#slide=id.g94db9f9f78_0_8)

* [Embedded Computer Hardware.](https://docs.google.com/presentation/d/1hDCFcOrZ08kZPhY4DA3gVikGUo47HwNyvqNrLW-t-Tg/edit?resourcekey=0-J6ix5AYvZMGbFFOa7ae4Hw#slide=id.g94db9f9f78_0_8)

* [Embedded I/O.](https://docs.google.com/presentation/d/1rnWh9XC6iCKSx_hQd4xq2iIDlpc-GkBQw_GjzlP5mQc/edit#slide=id.g94db9f9f78_0_8)

* [Embedded systems software.](https://docs.google.com/presentation/d/1TApZn9xxPWCRY-D-soJ8YOSsfysnccR5UjOyspzeTuU/edit?resourcekey=0-BRWIyCKPLNQFnIfG0fJJ9A#slide=id.g94db9f9f78_0_8)

* [Embedded ML software.](https://docs.google.com/presentation/d/17wgAfoF24Rcx7uPrbau0c8FyzXIUWbe48qGGBOXXT-g/edit?resourcekey=0-Uv29DvmF7gYzKdOoRtn0vw#slide=id.g94db9f9f78_0_8)

* [Embedded Inference.](https://docs.google.com/presentation/d/1FOUQ9dbe3l_qTa2AnroSbOz0ykuCz5cbTNO77tvFxEs/edit?usp=drive_link)

* [TinyML on Microcontrollers.](https://docs.google.com/presentation/d/1jwAZz3UOoJTR8PY6Wa34FxijpoDc9gBM/edit?usp=drive_link&ouid=102419556060649178683&rtpof=true&sd=true)

* TinyML as a Service (TinyMLaaS):
    * [TinyMLaaS: Introduction.](https://docs.google.com/presentation/d/1O7bxb36SnexfDI3iE_p0C8JI_VYXAL8cyAx3JKDfeUo/edit?usp=drive_link)

    * [TinyMLaaS: Design Overview.](https://docs.google.com/presentation/d/1ZUUHtTbKlzeTwVteQMSztscQmdmMxT1A24pBKSys7g0/edit#slide=id.g94db9f9f78_0_2)

:::

:::{.callout-exercise collapse="false"}
# Exercises

To reinforce the concepts covered in this chapter, we have curated a set of exercises that challenge students to apply their knowledge and deepen their understanding. 

Coming soon.
:::

:::{.callout-lab collapse="false"}
# Labs

In addition to exercises, we also offer a series of hands-on labs that allow students to gain practical experience with embedded AI technologies. These labs provide step-by-step guidance, enabling students to develop their skills in a structured and supportive environment. We are excited to announce that new labs will be available soon, further enriching the learning experience.

Coming soon.
:::
