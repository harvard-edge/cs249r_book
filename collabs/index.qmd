---
title: "Co-Labs"
subtitle: "Interactive ML Systems Simulations"
page-layout: full
toc: false
---

::: {.hero-banner}

# Co-Labs {.hero-title}

### Systematic Explorations Aligned with the Textbook {.hero-subtitle}

::: {.coming-soon-badge}
Coming 2026
:::

:::

## What I'm Building

There are many excellent Colab notebooks out there for ML. So why create more?

The challenge is that most notebooks exist in isolation. They demonstrate a technique, but don't connect to a broader learning journey. You finish one and wonder: *What should I explore next? How does this fit into the bigger picture?*

Co-Labs are different. Each notebook is **systematically aligned with the textbook chapters**, designed to let you experiment with the exact concepts you just read about. When Chapter 10 explains quantization tradeoffs, there's a Co-Lab where you can actually *see* what happens when you quantize a model from FP32 to INT8 to INT4. When Chapter 7 discusses memory hierarchies, there's a Co-Lab where you can measure cache effects yourself.

The goal isn't to replace the great resources that already exist. It's to create a curated, progressive learning path that reinforces the textbook material through hands-on exploration.

*— Vijay*

## The Learning Journey

Co-Labs bridge the gap between **reading about ML systems** (the textbook) and **building them from scratch** (TinyTorch).

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│                 │     │                 │     │                 │
│    Textbook     │────▶│     Co-Labs     │────▶│    TinyTorch    │
│                 │     │                 │     │                 │
│  Concepts &     │     │  Experiment &   │     │  Build from     │
│  Theory         │     │  Explore        │     │  Scratch        │
│                 │     │                 │     │                 │
└─────────────────┘     └─────────────────┘     └─────────────────┘
      READ                    EXPLORE                  BUILD
```

| Phase | Resource | What You Do |
|-------|----------|-------------|
| **Understand** | [Textbook](../book/) | Learn concepts, theory, and system design principles |
| **Experiment** | Co-Labs | Explore tradeoffs, tweak parameters, see decisions ripple through systems |
| **Build** | [TinyTorch](../tinytorch/) | Implement everything from scratch, own every line of code |

## Why This Matters

ML systems are where algorithms meet hardware. A model that works perfectly in theory can fail in practice due to memory limits, latency constraints, or numerical precision. Co-Labs help you develop intuition for these algorithm-system interactions.

- **See the tradeoffs** — How does batch size affect memory? How does quantization affect accuracy?
- **Explore interactively** — Adjust parameters and watch how changes ripple through the system
- **Build intuition** — Understand *why* systems behave the way they do
- **Zero setup** — Run directly in your browser via Google Colab

## Example Topics

Each Co-Lab will map directly to textbook chapters:

::: {.grid}

::: {.g-col-6}
### Memory & Compute
- Batch size vs memory footprint
- Gradient checkpointing tradeoffs
- Mixed precision training
:::

::: {.g-col-6}
### Model Efficiency
- Quantization effects (FP32 → INT8 → INT4)
- Pruning strategies comparison
- Knowledge distillation
:::

::: {.g-col-6}
### Visualization
- Attention head patterns
- Loss landscape navigation
- Gradient flow analysis
:::

::: {.g-col-6}
### Deployment
- Latency vs throughput
- Batching strategies
- Hardware utilization
:::

:::

## Stay Updated

I'm actively working on this. To be notified when Co-Labs launch:

::: {.cta-buttons}
[Subscribe for Updates](#subscribe){.btn .btn-primary}
[Star on GitHub](https://github.com/harvard-edge/cs249r_book){.btn .btn-secondary}
[Join Discussions](https://github.com/harvard-edge/cs249r_book/discussions){.btn .btn-secondary}
:::

---

::: {.text-center}
**Read. Explore. Build.**
:::
