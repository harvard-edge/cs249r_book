parts:
  - key: "frontmatter"
    division: "frontmatter"
    type: "division"
    numbered: false
    title: "Frontmatter"
    description: >
      Welcome to the Hardware Kits labs. This section provides an introduction
      to the hands-on laboratory exercises that connect theory to practice
      in embedded machine learning.

  - key: "labs"
    division: "mainmatter"
    type: "division"
    numbered: false
    title: "Labs"
    description: >
      This part provides hands-on learning experiences that connect theory to practice
      in embedded machine learning. It introduces the pedagogical approach, hardware
      platforms, and development tools used throughout the exercises. These labs bridge
      the conceptual material in the book with real-world engineering, emphasizing
      practical implementation on resource-constrained devices.

  - key: "arduino"
    division: "mainmatter"
    type: "lab"
    numbered: true
    title: "Arduino Labs"
    description: >
      This part contains laboratory exercises for Arduino-based platforms, with a focus
      on the Arduino Nicla Vision. The labs illustrate computer vision, audio, and sensor
      fusion applications, emphasizing the engineering trade-offs of microcontroller-class
      hardware and the constraints of real-time, battery-powered systems.

  - key: "xiao"
    division: "mainmatter"
    type: "lab"
    numbered: true
    title: "Seeed XIAO Labs"
    description: >
      This part presents exercises for the Seeed XIAO ESP32S3 platform, demonstrating
      compact and wireless-enabled embedded ML applications. The labs showcase image
      classification, keyword spotting, and motion sensing on ultra-low-power devices,
      highlighting the potential of small-form-factor AI systems.

  - key: "grove"
    division: "mainmatter"
    type: "lab"
    numbered: true
    title: "Grove Vision Labs"
    description: >
      This part explores the Grove Vision AI V2 platform, which incorporates dedicated
      neural processing hardware. The labs demonstrate hardware-accelerated ML inference
      and simplified no-code workflows, illustrating how specialized AI chips can
      deliver performance far beyond general-purpose microcontrollers.

  - key: "raspberry"
    division: "mainmatter"
    type: "lab"
    numbered: true
    title: "Raspberry Pi Labs"
    description: >
      This part contains advanced exercises using Raspberry Pi platforms, showing how
      edge computing resources enable sophisticated ML applications. The labs explore
      projects such as vision-language models and real-time perception, demonstrating
      the leap from microcontroller-class constraints to edge-scale capabilities.

  - key: "shared"
    division: "mainmatter"
    type: "lab"
    numbered: true
    title: "Shared Labs"
    description: >
      This part offers cross-platform exercises and core techniques that apply across
      all embedded ML hardware. It includes digital signal processing, feature
      engineering, and comparative evaluations, reinforcing the principles that
      underpin embedded and edge AI regardless of the device used.

  - key: "backmatter"
    division: "backmatter"
    type: "division"
    numbered: false
    title: "References"
    description: >
      This division contains reference materials and supplementary information
      for the Hardware Kits labs.
