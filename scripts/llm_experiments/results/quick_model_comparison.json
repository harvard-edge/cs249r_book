{
  "qwen2.5:7b": {
    "success_rate": 1.0,
    "avg_words": 6.5,
    "avg_time": 1.661225,
    "examples": [
      "enables error propagation during training",
      "boosts training speed significantly for deep learning models."
    ]
  },
  "llama3.1:8b": {
    "success_rate": 1.0,
    "avg_words": 5.5,
    "avg_time": 9.226294000000001,
    "examples": [
      "optimizes weights by minimizing error gradients.",
      "graphics processors greatly accelerate computations."
    ]
  },
  "mistral:7b": {
    "success_rate": 1.0,
    "avg_words": 9.0,
    "avg_time": 9.075219,
    "examples": [
      "learning the error to adjust weights in a network",
      "speeds up deep learning computations using parallel processing power."
    ]
  },
  "gemma2:9b": {
    "success_rate": 1.0,
    "avg_words": 6.0,
    "avg_time": 2.208236,
    "examples": [
      "how neural networks learn from data.",
      "faster training with parallel processing power."
    ]
  },
  "phi3:3.8b": {
    "success_rate": 1.0,
    "avg_words": 11.0,
    "avg_time": 1.229989,
    "examples": [
      "backpropagation adjusts weights by calculating error gradients backward from output to input layers.",
      "see also: How GPUs boost AI processing times significantly."
    ]
  }
}