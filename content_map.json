{
  "figures": {},
  "tables": {},
  "listings": {
    "lst-conv_layer_compute": {
      "original_caption": "System reality – nested loops of computation",
      "current_caption": "System reality – nested loops of computation",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "System reality – nested loops of computation",
          "full_text": "::: {#lst-conv_layer_compute .callout-important title=\"System reality – nested loops of computation\"}",
          "start": 135959,
          "end": 136060,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "System reality - nested loops of computation",
          "full_text": "```{python}\n#| lst-label: lst-conv_layer_compute\n#| lst-cap: System reality - nested loops of computation\n#| eval: false\n\ndef conv_layer_compute(input, kernel, bias):\n  # Loop 1: Process each image in batch\n  for image in range(batch_size):\n\n    # Loop 2&3: Move across image spatially\n    for y in range(height):\n      for x in range(width):\n\n       # Loop 4: Compute each output feature\n       for out_channel in range(num_output_channels):\n         result = bias[out_channel]\n\n         # Loop 5&6: Move across kernel window\n         for ky in range(kernel_height):\n           for kx in range(kernel_width):\n\n             # Loop 7: Process each input feature\n             for in_channel in range(num_input_channels):\n             # Get input value from correct window position\n              in_y = y + ky\n              in_x = x + kx\n              # Perform multiply-accumulate operation\n              result += (\n                input[image, in_y, in_x, in_channel]\n                * kernel[ky, kx, in_channel, out_channel]\n              )\n\n         # Store result for this output position\n         output[image, y, x, out_channel] = result\n```",
          "start": 137146,
          "end": 138292,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": [
        "Inconsistent captions found: ['System reality - nested loops of computation', 'System reality – nested loops of computation']",
        "Using HTML callout caption: 'System reality – nested loops of computation'"
      ]
    },
    "lst-rnn_layer_compute": {
      "original_caption": "Core computational pattern",
      "current_caption": "Core computational pattern",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Core computational pattern",
          "full_text": "::: {#lst-rnn_layer_compute .callout-important title=\"Core computational pattern\"}",
          "start": 154024,
          "end": 154106,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Core computational pattern",
          "full_text": "```{python}\n#| lst-label: lst-rnn_layer_compute\n#| lst-cap: Core computational pattern\n#| eval: false\n\ndef rnn_layer_compute(x_t, h_prev, W_hh, W_xh, b):\n    # Initialize next hidden state\n    h_t = np.zeros_like(h_prev)\n\n    # Loop 1: Process each sequence in the batch\n    for batch in range(batch_size):\n        # Loop 2: Compute recurrent contribution\n        # (h_prev × W_hh)\n        for i in range(hidden_dim):\n            for j in range(hidden_dim):\n                h_t[batch,i] += h_prev[batch,j] * W_hh[j,i]\n\n        # Loop 3: Compute input contribution (x_t × W_xh)\n        for i in range(hidden_dim):\n            for j in range(input_dim):\n                h_t[batch,i] += x_t[batch,j] * W_xh[j,i]\n\n        # Loop 4: Add bias and apply activation\n        for i in range(hidden_dim):\n            h_t[batch,i] = activation(h_t[batch,i] + b[i])\n\n    return h_t\n```",
          "start": 154937,
          "end": 155809,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    },
    "lst-attention_layer_compute": {
      "original_caption": "Mathematical abstraction in code",
      "current_caption": "Mathematical abstraction in code",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Mathematical abstraction in code",
          "full_text": "::: {#lst-attention_layer_compute .callout-important title=\"Mathematical abstraction in code\"}",
          "start": 178542,
          "end": 178636,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Mathematical abstraction in code",
          "full_text": "```{python}\n#| lst-label: lst-attention_layer_compute\n#| lst-cap: Mathematical abstraction in code\n#| eval: false\n\ndef attention_layer_matrix(Q, K, V):\n    # Q, K, V: (batch_size × seq_len × d_model)\n    scores = matmul(Q, K.transpose(-2, -1)) / \\\n             sqrt(d_k)           # Compute attention scores\n    weights = softmax(scores)    # Normalize scores\n    output = matmul(weights, V)  # Combine values\n    return output\n\n# Core computational pattern\ndef attention_layer_compute(Q, K, V):\n    # Initialize outputs\n    scores = np.zeros((batch_size, seq_len, seq_len))\n    outputs = np.zeros_like(V)\n\n    # Loop 1: Process each sequence in batch\n    for b in range(batch_size):\n        # Loop 2: Compute attention for each query position\n        for i in range(seq_len):\n            # Loop 3: Compare with each key position\n            for j in range(seq_len):\n                # Compute attention score\n                for d in range(d_model):\n                    scores[b,i,j] += Q[b,i,d] * K[b,j,d]\n                scores[b,i,j] /= sqrt(d_k)\n\n        # Apply softmax to scores\n        for i in range(seq_len):\n            scores[b,i] = softmax(scores[b,i])\n\n        # Loop 4: Combine values using attention weights\n        for i in range(seq_len):\n            for j in range(seq_len):\n                for d in range(d_model):\n                    outputs[b, i, d] += (\n                       scores[b, i, j]\n                       * V[b, j, d]\n                    )\n\n    return outputs\n```",
          "start": 180082,
          "end": 181578,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    },
    "lst-self_attention_layer": {
      "original_caption": "Self-attention mechanism in Transformers",
      "current_caption": "Self-attention mechanism in Transformers",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Self-attention mechanism in Transformers",
          "full_text": "::: {#lst-self_attention_layer .callout-important title=\"Self-attention mechanism in Transformers\"}",
          "start": 196648,
          "end": 196747,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Self-attention mechanism in Transformers",
          "full_text": "```{python}\n#| lst-label: lst-self_attention_layer\n#| lst-cap: Self-attention mechanism in Transformers\n#| eval: false\n\ndef self_attention_layer(X, W_Q, W_K, W_V, d_k):\n    # X: input tensor (batch_size × seq_len × d_model)\n    # W_Q, W_K, W_V: weight matrices (d_model × d_k)\n\n    Q = matmul(X, W_Q)\n    K = matmul(X, W_K)\n    V = matmul(X, W_V)\n\n    scores = matmul(Q, K.transpose(-2, -1)) / sqrt(d_k)\n    attention_weights = softmax(scores, dim=-1)\n    output = matmul(attention_weights, V)\n\n    return output\n\ndef multi_head_attention(\n    X, W_Q, W_K, W_V, W_O, num_heads, d_k\n):\n    outputs = []\n    for i in range(num_heads):\n        head_output = self_attention_layer(\n            X, W_Q[i], W_K[i], W_V[i], d_k\n        )\n        outputs.append(head_output)\n\n    concat_output = torch.cat(outputs, dim=-1)\n    final_output = matmul(concat_output, W_O)\n\n    return final_output\n```",
          "start": 197580,
          "end": 198468,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    },
    "lst-mlp_layer_matrix": {
      "original_caption": "Mathematical abstraction in code",
      "current_caption": "Mathematical abstraction in code",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Mathematical abstraction in code",
          "full_text": "::: {#lst-mlp_layer_matrix .callout-important title=\"Mathematical abstraction in code\"}",
          "start": 14979,
          "end": 15066,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Mathematical abstraction in code",
          "full_text": "```{python}\n#| lst-label: lst-mlp_layer_matrix\n#| lst-cap: Mathematical abstraction in code\n#| eval: false\n\ndef mlp_layer_matrix(X, W, b):\n    # X: input matrix (batch_size × num_inputs)\n    # W: weight matrix (num_inputs × num_outputs)\n    # b: bias vector (num_outputs)\n    H = activation(matmul(X, W) + b)\n    # One clean line of math\n    return H\n```",
          "start": 15377,
          "end": 15731,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    },
    "lst-rnn_layer_step": {
      "original_caption": "Mathematical abstraction in code",
      "current_caption": "Mathematical abstraction in code",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Mathematical abstraction in code",
          "full_text": "::: {#lst-rnn_layer_step .callout-important title=\"Mathematical abstraction in code\"}",
          "start": 152769,
          "end": 152854,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Mathematical abstraction in code",
          "full_text": "```{python}\n#| lst-label: lst-rnn_layer_step\n#| lst-cap: Mathematical abstraction in code\n#| eval: false\n\ndef rnn_layer_step(x_t, h_prev, W_hh, W_xh, b):\n  # x_t: input at time t (batch_size × input_dim)\n  # h_prev: previous hidden state (batch_size × hidden_dim)\n  # W_hh: recurrent weights (hidden_dim × hidden_dim)\n  # W_xh: input weights (input_dim × hidden_dim)\n  h_t = activation(\n    matmul(h_prev, W_hh)\n    + matmul(x_t, W_xh)\n    + b\n  )\n  return h_t\n```",
          "start": 153274,
          "end": 153738,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    },
    "lst-conv_layer_spatial": {
      "original_caption": "Mathematical abstraction - simple and clean",
      "current_caption": "Mathematical abstraction - simple and clean",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Mathematical abstraction - simple and clean",
          "full_text": "::: {#lst-conv_layer_spatial .callout-important title=\"Mathematical abstraction - simple and clean\"}",
          "start": 135058,
          "end": 135158,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Mathematical abstraction - simple and clean",
          "full_text": "```{python}\n#| lst-label: lst-conv_layer_spatial\n#| lst-cap: Mathematical abstraction - simple and clean\n#| eval: false\n\ndef conv_layer_spatial(input, kernel, bias):\n    output = convolution(input, kernel) + bias\n    return activation(output)\n```",
          "start": 135348,
          "end": 135594,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    },
    "lst-mlp_layer_compute": {
      "original_caption": "Core computational pattern",
      "current_caption": "Core computational pattern",
      "new_caption": "",
      "type": "listing",
      "language": "python",
      "source_file": "contents/core/dnn_architectures/dnn_architectures.qmd",
      "instances": [
        {
          "format": "html_callout",
          "caption": "Core computational pattern",
          "full_text": "::: {#lst-mlp_layer_compute .callout-important title=\"Core computational pattern\"}",
          "start": 16124,
          "end": 16206,
          "pattern_type": "callout"
        },
        {
          "format": "pdf_code",
          "caption": "Core computational pattern",
          "full_text": "```{python}\n#| lst-label: lst-mlp_layer_compute\n#| lst-cap: Core computational pattern\n#| eval: false\n\ndef mlp_layer_compute(X, W, b):\n    # Process each sample in the batch\n    for batch in range(batch_size):\n        # Compute each output neuron\n        for out in range(num_outputs):\n            # Initialize with bias\n            Z[batch,out] = b[out]\n            # Accumulate weighted inputs\n            for in_ in range(num_inputs):\n                Z[batch,out] += X[batch,in_] * W[in_,out]\n\n    H = activation(Z)\n    return H\n```",
          "start": 16703,
          "end": 17238,
          "pattern_type": "code_block",
          "language": "python"
        }
      ],
      "consistency_warnings": []
    }
  },
  "metadata": {
    "creation_time": "2025-07-24T11:55:51.055026",
    "source": "qmd_direct_scan",
    "directories": [
      "contents/core/dnn_architectures"
    ],
    "qmd_files_scanned": 1,
    "extraction_stats": {
      "figures_found": 0,
      "tables_found": 0,
      "listings_found": 8,
      "markdown_figures": 0,
      "tikz_figures": 0,
      "r_figures": 0,
      "code_figures": 0,
      "extraction_failures": 0,
      "failed_extractions": [],
      "files_with_issues": []
    }
  }
}