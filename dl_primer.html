<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="keywords" content="open-source, embedded systems, machine learning, tinyML">

<title>Embedded AI: Principles, Algorithms, and Applications - 3&nbsp; Deep Learning Primer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./embedded_ml.html" rel="next">
<link href="./embedded_sys.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./dl_primer.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Embedded AI: Principles, Algorithms, and Applications</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/harvard-edge/cs249r_book.git" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Embedded-AI--Principles,-Algorithms,-and-Applications.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Embedded-AI--Principles,-Algorithms,-and-Applications.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./front.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FRONT MATTER</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dedication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedication</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./copyright.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About This Book</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./embedded_sys.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Embedded Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dl_primer.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./embedded_ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Embedded ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlworkflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">ML Workflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ML Frameworks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Model Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Efficient AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimizations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deployment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Deployment</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">On-Device Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hardware Acceleration</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">MLOps</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Privacy and Security</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">AI Sustainability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Responsible AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generative_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Generative AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Tools</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zoo_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zoo_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Model Zoo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learning_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./community.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Communities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./case_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Case Studies</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">3.1</span> Overview</a>
  <ul class="collapse">
  <li><a href="#definition-and-importance" id="toc-definition-and-importance" class="nav-link" data-scroll-target="#definition-and-importance"><span class="header-section-number">3.1.1</span> Definition and Importance</a></li>
  <li><a href="#brief-history-of-deep-learning" id="toc-brief-history-of-deep-learning" class="nav-link" data-scroll-target="#brief-history-of-deep-learning"><span class="header-section-number">3.1.2</span> Brief History of Deep Learning</a></li>
  <li><a href="#applications-of-deep-learning" id="toc-applications-of-deep-learning" class="nav-link" data-scroll-target="#applications-of-deep-learning"><span class="header-section-number">3.1.3</span> Applications of Deep Learning</a></li>
  <li><a href="#relevance-to-embedded-ai" id="toc-relevance-to-embedded-ai" class="nav-link" data-scroll-target="#relevance-to-embedded-ai"><span class="header-section-number">3.1.4</span> Relevance to Embedded AI</a></li>
  </ul></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks"><span class="header-section-number">3.2</span> Neural Networks</a>
  <ul class="collapse">
  <li><a href="#perceptrons" id="toc-perceptrons" class="nav-link" data-scroll-target="#perceptrons"><span class="header-section-number">3.2.1</span> Perceptrons</a></li>
  <li><a href="#multi-layer-perceptrons" id="toc-multi-layer-perceptrons" class="nav-link" data-scroll-target="#multi-layer-perceptrons"><span class="header-section-number">3.2.2</span> Multi-layer Perceptrons</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions"><span class="header-section-number">3.2.3</span> Activation Functions</a></li>
  <li><a href="#computational-graphs" id="toc-computational-graphs" class="nav-link" data-scroll-target="#computational-graphs"><span class="header-section-number">3.2.4</span> Computational Graphs</a></li>
  <li><a href="#training-concepts" id="toc-training-concepts" class="nav-link" data-scroll-target="#training-concepts"><span class="header-section-number">3.2.5</span> Training Concepts</a></li>
  <li><a href="#model-architectures" id="toc-model-architectures" class="nav-link" data-scroll-target="#model-architectures"><span class="header-section-number">3.2.6</span> Model Architectures</a></li>
  </ul></li>
  <li><a href="#libraries-and-frameworks" id="toc-libraries-and-frameworks" class="nav-link" data-scroll-target="#libraries-and-frameworks"><span class="header-section-number">3.3</span> Libraries and Frameworks</a>
  <ul class="collapse">
  <li><a href="#tensorflow" id="toc-tensorflow" class="nav-link" data-scroll-target="#tensorflow"><span class="header-section-number">3.3.1</span> TensorFlow</a></li>
  <li><a href="#pytorch" id="toc-pytorch" class="nav-link" data-scroll-target="#pytorch"><span class="header-section-number">3.3.2</span> PyTorch</a></li>
  <li><a href="#onnx-runtime" id="toc-onnx-runtime" class="nav-link" data-scroll-target="#onnx-runtime"><span class="header-section-number">3.3.3</span> ONNX Runtime</a></li>
  <li><a href="#keras" id="toc-keras" class="nav-link" data-scroll-target="#keras"><span class="header-section-number">3.3.4</span> Keras</a></li>
  <li><a href="#tvm" id="toc-tvm" class="nav-link" data-scroll-target="#tvm"><span class="header-section-number">3.3.5</span> TVM</a></li>
  </ul></li>
  <li><a href="#embedded-ai-challenges" id="toc-embedded-ai-challenges" class="nav-link" data-scroll-target="#embedded-ai-challenges"><span class="header-section-number">3.4</span> Embedded AI Challenges</a>
  <ul class="collapse">
  <li><a href="#memory-constraints" id="toc-memory-constraints" class="nav-link" data-scroll-target="#memory-constraints"><span class="header-section-number">3.4.1</span> Memory Constraints</a></li>
  <li><a href="#computational-limitations" id="toc-computational-limitations" class="nav-link" data-scroll-target="#computational-limitations"><span class="header-section-number">3.4.2</span> Computational Limitations</a></li>
  <li><a href="#energy-efficiency" id="toc-energy-efficiency" class="nav-link" data-scroll-target="#energy-efficiency"><span class="header-section-number">3.4.3</span> Energy Efficiency</a></li>
  <li><a href="#data-privacy-and-security" id="toc-data-privacy-and-security" class="nav-link" data-scroll-target="#data-privacy-and-security"><span class="header-section-number">3.4.4</span> Data Privacy and Security</a></li>
  <li><a href="#real-time-processing-requirements" id="toc-real-time-processing-requirements" class="nav-link" data-scroll-target="#real-time-processing-requirements"><span class="header-section-number">3.4.5</span> Real-Time Processing Requirements</a></li>
  <li><a href="#model-robustness-and-generalization" id="toc-model-robustness-and-generalization" class="nav-link" data-scroll-target="#model-robustness-and-generalization"><span class="header-section-number">3.4.6</span> Model Robustness and Generalization</a></li>
  <li><a href="#integration-with-existing-systems" id="toc-integration-with-existing-systems" class="nav-link" data-scroll-target="#integration-with-existing-systems"><span class="header-section-number">3.4.7</span> Integration with Existing Systems</a></li>
  <li><a href="#scalability" id="toc-scalability" class="nav-link" data-scroll-target="#scalability"><span class="header-section-number">3.4.8</span> Scalability</a></li>
  </ul></li>
  <li><a href="#limitations-of-deep-learning" id="toc-limitations-of-deep-learning" class="nav-link" data-scroll-target="#limitations-of-deep-learning"><span class="header-section-number">3.5</span> Limitations of Deep Learning</a>
  <ul class="collapse">
  <li><a href="#the-predicament" id="toc-the-predicament" class="nav-link" data-scroll-target="#the-predicament"><span class="header-section-number">3.5.1</span> The Predicament</a></li>
  <li><a href="#traditional-ml-vs-deep-learning" id="toc-traditional-ml-vs-deep-learning" class="nav-link" data-scroll-target="#traditional-ml-vs-deep-learning"><span class="header-section-number">3.5.2</span> Traditional ML vs Deep Learning</a></li>
  <li><a href="#choosing-traditional-ml-vs.-dl" id="toc-choosing-traditional-ml-vs.-dl" class="nav-link" data-scroll-target="#choosing-traditional-ml-vs.-dl"><span class="header-section-number">3.5.3</span> Choosing Traditional ML vs.&nbsp;DL</a></li>
  <li><a href="#making-an-informed-choice" id="toc-making-an-informed-choice" class="nav-link" data-scroll-target="#making-an-informed-choice"><span class="header-section-number">3.5.4</span> Making an Informed Choice</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/harvard-edge/cs249r_book.git/edit/main/dl_primer.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/harvard-edge/cs249r_book.git/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/harvard-edge/cs249r_book.git/blob/main/dl_primer.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Deep Learning Primer</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="overview" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">3.1</span> Overview</h2>
<section id="definition-and-importance" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="definition-and-importance"><span class="header-section-number">3.1.1</span> Definition and Importance</h3>
<p>Deep learning, a subset of machine learning and artificial intelligence (AI), involves algorithms inspired by the structure and function of the human brain, called artificial neural networks. It stands as a cornerstone in the field of AI, spearheading advancements in various domains including computer vision, natural language processing, and autonomous vehicles. Its relevance in embedded AI systems is underscored by its ability to facilitate complex computations and predictions, leveraging the limited resources available in embedded environments.</p>
<p><img src="https://1394217531-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LvBP1svpACTB1R1x_U4%2F-LvCh0IFvnfX-S1za_GI%2F-LvD0gbfAKEIMXcVxdqQ%2Fimage.png?alt=media&amp;token=d6ca58f0-ebe3-4188-a90a-dc68256e1b0a" class="img-fluid"></p>
</section>
<section id="brief-history-of-deep-learning" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="brief-history-of-deep-learning"><span class="header-section-number">3.1.2</span> Brief History of Deep Learning</h3>
<p>The concept of deep learning has its roots in the early artificial neural networks. It has witnessed several waves of popularity, starting with the introduction of the Perceptron in the 1950s <span class="citation" data-cites="rosenblatt1957perceptron">(<a href="references.html#ref-rosenblatt1957perceptron" role="doc-biblioref">Rosenblatt 1957</a>)</span>, followed by the development of backpropagation algorithms in the 1980s <span class="citation" data-cites="rumelhart1986learning">(<a href="references.html#ref-rumelhart1986learning" role="doc-biblioref">Rumelhart, Hinton, and Williams 1986</a>)</span>.</p>
<p>The term <em>deep learning</em> emerged in the 2000s, marked by breakthroughs in computational power and data availability. Key milestones include the successful training of deep networks such as AlexNet <span class="citation" data-cites="krizhevsky2012imagenet">(<a href="references.html#ref-krizhevsky2012imagenet" role="doc-biblioref">Krizhevsky, Sutskever, and Hinton 2012</a>)</span> by <a href="https://amturing.acm.org/award_winners/hinton_4791679.cfm">Geoffrey Hinton</a>, one of the god fathers of AI, and the resurgence of neural networks as a potent tool for data analysis and modeling.</p>
<p>In recent years, deep learning has witnessed exponential growth, becoming a transformative force across various industries. <a href="#fig-trends">Figure&nbsp;<span>3.1</span></a> shows that we are currently in the third era of deep learning. From 1952 to 2010, computational growth followed an 18-month doubling pattern. This dramatically accelerated to a 6-month cycle from 2010 to 2022. At the same time, we witnessed the advent of major-scale models between 2015 and 2022; these appeared 2 to 3 orders of magnitude faster and followed a 10-month doubling cycle.</p>
<div id="fig-trends" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://epochai.org/assets/images/posts/2022/compute-trends.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3.1: Growth of deep learning models.</figcaption>
</figure>
</div>
<p>A confluence of factors has fueled this surge, including advancements in computational power, the proliferation of big data, and improvements in algorithmic designs. Firstly, the expansion of computational capabilities, particularly the advent of Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs) <span class="citation" data-cites="jouppi2017datacenter">(<a href="references.html#ref-jouppi2017datacenter" role="doc-biblioref">Jouppi et al. 2017</a>)</span>, has significantly accelerated the training and inference times of deep learning models. These hardware advancements have made it feasible to construct and train more complex, deeper networks than were possible in the earlier years.</p>
<p>Secondly, the digital revolution has brought forth an abundance of “big” data, providing rich material for deep learning models to learn from and excel in tasks such as image and speech recognition, language translation, and game playing. The availability of large, labeled datasets has been instrumental in the refinement and successful deployment of deep learning applications in real-world scenarios.</p>
<p>Additionally, collaborations and open-source initiatives have fostered a vibrant community of researchers and practitioners, propelling rapid advancements in deep learning techniques. Innovations such as deep reinforcement learning, transfer learning, and generative adversarial networks have expanded the boundaries of what is achievable with deep learning, opening new avenues and opportunities in various fields including healthcare, finance, transportation, and entertainment.</p>
<p>Companies and organizations worldwide are recognizing the transformative potential of deep learning, investing heavily in research and development to harness its power in offering innovative solutions, optimizing operations, and creating new business opportunities. As deep learning continues its upward trajectory, it is poised to revolutionize how we interact with technology, making our lives more convenient, safe, and connected.</p>
</section>
<section id="applications-of-deep-learning" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="applications-of-deep-learning"><span class="header-section-number">3.1.3</span> Applications of Deep Learning</h3>
<p>Deep learning is widely used in many industries today. It is used in finance for things such as stock market prediction, risk assessment, and fraud detection. It is also used in marketing for things such as customer segmentation, personalization, and content optimization. In healthcare, machine learning is used for tasks such as diagnosis, treatment planning, and patient monitoring. It has had a transformational impact on our society.</p>
<p>An example of the transformative impact that machine learning has had on society is how it has saved money and lives. For example, as mentioned earlier, deep learning algorithms can make predictions about stocks, like predicting whether they will go up or down. These predictions guide investment strategies and improve financial decisions. Similarly, deep learning can also make medical predictions to improve patient diagnosis and save lives. The possibilities are endless and the benefits are clear. Machine learning is not only able to make predictions with greater accuracy than humans but it is also able to do so at a much faster pace.</p>
<p>Deep learning has been applied to manufacturing to great effect. By using software to constantly learn from the vast amounts of data collected throughout the manufacturing process, companies are able to increase productivity while reducing wastage through improved efficiency. Companies are benefiting financially from these effects while customers are receiving better quality products at lower prices. Machine learning enables manufacturers to constantly improve their processes to create higher quality goods faster and more efficiently than ever before.</p>
<p>Deep learning has also improved products that we use daily like Netflix recommendations or Google Translate’s text translations, but it also allows companies such as Amazon and Uber to save money on customer service costs by quickly identifying unhappy customers.</p>
</section>
<section id="relevance-to-embedded-ai" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="relevance-to-embedded-ai"><span class="header-section-number">3.1.4</span> Relevance to Embedded AI</h3>
<p>Embedded AI, which involves integrating AI algorithms directly into hardware devices, naturally benefits from the capabilities of deep learning. The synergy of deep learning algorithms with embedded systems has paved the way for intelligent, autonomous devices capable of sophisticated on-device data processing and analysis. Deep learning facilitates the extraction of intricate patterns and information from input data, making it a vital tool in the development of smart embedded systems, ranging from household appliances to industrial machines. This union aims to foster a new era of smart, interconnected devices that can learn and adapt to user behaviors and environmental conditions, optimizing performance and offering unprecedented levels of convenience and efficiency.</p>
</section>
</section>
<section id="neural-networks" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="neural-networks"><span class="header-section-number">3.2</span> Neural Networks</h2>
<p>Deep learning takes inspiration from the human brain’s neural networks to create patterns utilized in decision-making. This section explores the foundational concepts that comprise deep learning, offering insights into the underpinnings of more complex topics explored later in this primer.</p>
<p>Neural networks form the basis of deep learning, drawing inspiration from the biological neural networks of the human brain to process and analyze data in a hierarchical manner. Below, we dissect the primary components and structures commonly found in neural networks.</p>
<section id="perceptrons" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="perceptrons"><span class="header-section-number">3.2.1</span> Perceptrons</h3>
<p>At the foundation of neural networks is the perceptron, a basic unit or node that forms the basis of more complex structures. A perceptron receives various inputs, applies weights and a bias to these inputs, and then employs an activation function to produce an output as shown below in <a href="#fig-perceptron">Figure&nbsp;<span>3.2</span></a>.</p>
<div id="fig-perceptron" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Rosenblattperceptron.png/500px-Rosenblattperceptron.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3.2: Perceptron</figcaption>
</figure>
</div>
<p>Initially conceptualized in the 1950s, perceptrons paved the way for the development of more intricate neural networks, serving as a fundamental building block in the field of deep learning.</p>
</section>
<section id="multi-layer-perceptrons" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="multi-layer-perceptrons"><span class="header-section-number">3.2.2</span> Multi-layer Perceptrons</h3>
<p>Multi-layer perceptrons (MLPs) evolve from the single-layer perceptron model, incorporating multiple layers of nodes connected in a feedforward manner. These layers include an input layer to receive data, several hidden layers to process this data, and an output layer to generate the final results. MLPs excel in identifying non-linear relationships, utilizing a backpropagation technique for training, wherein the weights are optimized through a gradient descent algorithm.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.nomidl.com/wp-content/uploads/2022/04/image-7.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Multilayer Perceptron</figcaption>
</figure>
</div>
</section>
<section id="activation-functions" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="activation-functions"><span class="header-section-number">3.2.3</span> Activation Functions</h3>
<p>Activation functions stand as vital components in neural networks, providing the mathematical equations that determine a network’s output. These functions introduce non-linearity to the network, facilitating the learning of complex patterns by allowing the network to adjust weights based on the error during the learning process. Popular activation functions encompass the sigmoid, tanh, and ReLU (Rectified Linear Unit) functions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://1394217531-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LvBP1svpACTB1R1x_U4%2F-LvNWUoWieQqaGmU_gl9%2F-LvO3qs2RImYjpBE8vln%2Factivation-functions3.jpg?alt=media&amp;token=f96a3007-5888-43c3-a256-2dafadd5df7c" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Activation Function</figcaption>
</figure>
</div>
</section>
<section id="computational-graphs" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="computational-graphs"><span class="header-section-number">3.2.4</span> Computational Graphs</h3>
<p>Deep learning employs computational graphs to illustrate the various operations and their interactions within a neural network. This subsection explores the essential phases of computational graph processing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">TensorFlow Computational Graph</figcaption>
</figure>
</div>
<section id="forward-pass" class="level4" data-number="3.2.4.1">
<h4 data-number="3.2.4.1" class="anchored" data-anchor-id="forward-pass"><span class="header-section-number">3.2.4.1</span> Forward Pass</h4>
<p>The forward pass denotes the initial phase where data progresses through the network from the input to the output layer. During this phase, each layer conducts specific computations on the input data, utilizing weights and biases before passing the resulting values onto subsequent layers. The ultimate output of this phase is employed to compute the loss, representing the disparity between the predicted output and actual target values.</p>
</section>
<section id="backward-pass-backpropagation" class="level4" data-number="3.2.4.2">
<h4 data-number="3.2.4.2" class="anchored" data-anchor-id="backward-pass-backpropagation"><span class="header-section-number">3.2.4.2</span> Backward Pass (Backpropagation)</h4>
<p>Backpropagation signifies a pivotal algorithm in the training of deep neural networks. This phase involves computing the gradient of the loss function with respect to each weight using the chain rule, effectively maneuvering backwards through the network. The gradients calculated in this step guide the adjustment of weights with the objective of minimizing the loss function, thereby enhancing the network’s performance with each iteration of training.</p>
<p>Grasping these foundational concepts paves the way to understanding more intricate deep learning architectures and techniques, fostering the development of more sophisticated and efficacious applications, especially within the realm of embedded AI systems.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aircAruvnKk?si=qfkBf8MJjC2WSyw3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
</section>
</section>
<section id="training-concepts" class="level3" data-number="3.2.5">
<h3 data-number="3.2.5" class="anchored" data-anchor-id="training-concepts"><span class="header-section-number">3.2.5</span> Training Concepts</h3>
<p>In the realm of deep learning, it’s crucial to comprehend various key concepts and terms that set the foundation for creating, training, and optimizing deep neural networks. This section clarifies these essential concepts, providing a straightforward path to delve deeper into the intricate dynamics of deep learning. Overall, ML training is an iterative process. An untrained neural network model takes some features as input and makes a forward prediction pass. Given some ground truth about the prediction, which is known during the training process, we can compute a loss using a loss function and update the neural network parameters during the backward pass. We repeat this process until the network converges towards correct predictions with satisfactory accuracy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://developers.google.com/static/machine-learning/crash-course/images/GradientDescentDiagram.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">An iterative approach to training a model.</figcaption>
</figure>
</div>
<section id="loss-functions" class="level4" data-number="3.2.5.1">
<h4 data-number="3.2.5.1" class="anchored" data-anchor-id="loss-functions"><span class="header-section-number">3.2.5.1</span> Loss Functions</h4>
<p>Loss functions, also known as cost functions, quantify how well a neural network is performing by calculating the difference between the actual and predicted outputs. The objective during the training process is to minimize this loss function to improve the model’s accuracy. As <a href="#fig-loss">Figure&nbsp;<span>3.3</span></a> shows, models can either have high loss or low loss depending on where in the training phase the network is in.</p>
<div id="fig-loss" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://developers.google.com/machine-learning/crash-course/images/LossSideBySide.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3.3: High loss in the left model; low loss in the right model.</figcaption>
</figure>
</div>
<p>Various loss functions are employed depending on the specific task, such as <a href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss">mean squared error</a>, log loss and cross-entropy loss for regression tasks and categorical crossentropy for classification tasks.</p>
</section>
<section id="optimization-algorithms" class="level4" data-number="3.2.5.2">
<h4 data-number="3.2.5.2" class="anchored" data-anchor-id="optimization-algorithms"><span class="header-section-number">3.2.5.2</span> Optimization Algorithms</h4>
<p>Optimization algorithms play a crucial role in the training process, aiming to minimize the loss function by adjusting the model’s weights. These algorithms navigate through the model’s parameter space to find the optimal set of parameters that yield the minimum loss. Some commonly used optimization algorithms are:</p>
<ul>
<li><strong>Gradient Descent:</strong> A first-order optimization algorithm that uses the gradient of the loss function to move the weights in the direction that minimizes the loss.</li>
<li><strong>Stochastic Gradient Descent (SGD):</strong> A variant of gradient descent that updates the weights using a subset of the data, thus accelerating the training process.</li>
<li><strong>Adam:</strong> A popular optimization algorithm that combines the benefits of other extensions of gradient descent, often providing faster convergence.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://developers.google.com/static/machine-learning/crash-course/images/GradientDescentGradientStep.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Minimizing loss during the training process.</figcaption>
</figure>
</div>
</section>
<section id="regularization-techniques" class="level4" data-number="3.2.5.3">
<h4 data-number="3.2.5.3" class="anchored" data-anchor-id="regularization-techniques"><span class="header-section-number">3.2.5.3</span> Regularization Techniques</h4>
<p>To prevent <a href="https://www.mathworks.com/discovery/overfitting.html">overfitting</a> and help the model generalize better to unseen data, regularization techniques are employed. These techniques penalize the complexity of the model, encouraging simpler models that can perform better on new data.</p>
<p><img src="https://www.mathworks.com/discovery/overfitting/_jcr_content/mainParsys/image.adapt.full.medium.svg/1686825007300.svg" class="img-fluid"></p>
<p>Common regularization techniques include:</p>
<ul>
<li><strong>L1 and L2 Regularization:</strong> These techniques add a penalty term to the loss function, discouraging large weights and promoting simpler models.</li>
<li><strong>Dropout:</strong> A technique where randomly selected neurons are ignored during training, forcing the network to learn more robust features.</li>
<li><strong>Batch Normalization:</strong> This technique normalizes the activations of the neurons in a given layer, improving the stability and performance of the network.</li>
</ul>
<p>Understanding these fundamental concepts and terms forms the backbone of deep learning, setting the stage for a more in-depth exploration into the intricacies of various deep learning architectures and their applications, particularly in embedded AI systems.</p>
</section>
</section>
<section id="model-architectures" class="level3" data-number="3.2.6">
<h3 data-number="3.2.6" class="anchored" data-anchor-id="model-architectures"><span class="header-section-number">3.2.6</span> Model Architectures</h3>
<p>Deep learning architectures refer to the various structured approaches that dictate how neurons and layers are organized and interact in neural networks. These architectures have evolved to address different problems and data types efficiently. This section provides an overview of some prominent deep learning architectures and their characteristics.</p>
<section id="multi-layer-perceptrons-mlps" class="level4" data-number="3.2.6.1">
<h4 data-number="3.2.6.1" class="anchored" data-anchor-id="multi-layer-perceptrons-mlps"><span class="header-section-number">3.2.6.1</span> Multi-Layer Perceptrons (MLPs)</h4>
<p>MLPs are fundamental deep learning architectures, consisting of three or more layers: an input layer, one or more hidden layers, and an output layer. These layers are fully connected, meaning every neuron in a layer is connected to every neuron in the preceding and succeeding layers. MLPs can model complex functions and find applications in a wide range of tasks, including regression, classification, and pattern recognition. Their ability to learn non-linear relationships through backpropagation makes them a versatile tool in the deep learning arsenal.</p>
<p>In embedded AI systems, MLPs can serve as compact models for simpler tasks, such as sensor data analysis or basic pattern recognition, where computational resources are constrained. Their capability to learn non-linear relationships with relatively less complexity makes them a viable option for embedded systems.</p>
</section>
<section id="convolutional-neural-networks-cnns" class="level4" data-number="3.2.6.2">
<h4 data-number="3.2.6.2" class="anchored" data-anchor-id="convolutional-neural-networks-cnns"><span class="header-section-number">3.2.6.2</span> Convolutional Neural Networks (CNNs)</h4>
<p>CNNs are primarily used in image and video recognition tasks. This architecture uses convolutional layers that apply a series of filters to the input data to identify various features such as edges, corners, and textures. A typical CNN also includes pooling layers that reduce the spatial dimensions of the data, and fully connected layers for classification. CNNs have proven highly effective in tasks like image recognition, object detection, and computer vision applications.</p>
<p>In the realm of embedded AI, CNNs are pivotal for image and video recognition applications, where real-time processing is often required. They can be optimized for embedded systems by employing techniques such as quantization and pruning to reduce memory usage and computational demands, enabling efficient object detection and facial recognition functionalities in devices with limited computational resources.</p>
</section>
<section id="recurrent-neural-networks-rnns" class="level4" data-number="3.2.6.3">
<h4 data-number="3.2.6.3" class="anchored" data-anchor-id="recurrent-neural-networks-rnns"><span class="header-section-number">3.2.6.3</span> Recurrent Neural Networks (RNNs)</h4>
<p>RNNs are suited for sequential data analysis, such as time series forecasting and natural language processing. In this architecture, connections between nodes form a directed graph along a temporal sequence, allowing information to be carried across sequences through hidden state vectors. Variations of RNNs include Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), which are designed to capture longer dependencies in sequence data.</p>
<p>In embedded systems, these networks can be implemented in voice recognition systems, predictive maintenance, or in IoT devices where sequential data patterns are prevalent. Optimizations specific to embedded platforms can help in managing their typically high computational and memory requirements.</p>
</section>
<section id="generative-adversarial-networks-gans" class="level4" data-number="3.2.6.4">
<h4 data-number="3.2.6.4" class="anchored" data-anchor-id="generative-adversarial-networks-gans"><span class="header-section-number">3.2.6.4</span> Generative Adversarial Networks (GANs)</h4>
<p>GANs consist of two networks, a generator and a discriminator, that are trained simultaneously through adversarial training <span class="citation" data-cites="goodfellow2020generative">(<a href="references.html#ref-goodfellow2020generative" role="doc-biblioref">Goodfellow et al. 2020</a>)</span>. The generator produces data that tries to mimic the real data distribution, while the discriminator aims to distinguish between real and generated data. GANs are widely used in image generation, style transfer, and data augmentation.</p>
<p>In embedded contexts, GANs could be used for on-device data augmentation to enhance the training of models directly on the embedded device, facilitating continual learning and adaptation to new data without the need for cloud computing resources.</p>
</section>
<section id="autoencoders" class="level4" data-number="3.2.6.5">
<h4 data-number="3.2.6.5" class="anchored" data-anchor-id="autoencoders"><span class="header-section-number">3.2.6.5</span> Autoencoders</h4>
<p>Autoencoders are neural networks used for data compression and noise reduction <span class="citation" data-cites="bank2023autoencoders">(<a href="references.html#ref-bank2023autoencoders" role="doc-biblioref">Bank, Koenigstein, and Giryes 2023</a>)</span>. They are structured to encode input data into a lower-dimensional representation and then decode it back to the original form. Variations like Variational Autoencoders (VAEs) introduce probabilistic layers that allow for generative properties, finding applications in image generation and anomaly detection.</p>
<p>Implementing autoencoders can assist in efficient data transmission and storage, enhancing the overall performance of embedded systems with limited computational and memory resources.</p>
</section>
<section id="transformer-networks" class="level4" data-number="3.2.6.6">
<h4 data-number="3.2.6.6" class="anchored" data-anchor-id="transformer-networks"><span class="header-section-number">3.2.6.6</span> Transformer Networks</h4>
<p>Transformer networks have emerged as a powerful architecture, especially in the field of natural language processing <span class="citation" data-cites="vaswani2017attention">(<a href="references.html#ref-vaswani2017attention" role="doc-biblioref">Vaswani et al. 2017</a>)</span>. These networks use self-attention mechanisms to weigh the influence of different input words on each output word, facilitating parallel computation and capturing complex patterns in data. Transformer networks have led to state-of-the-art results in tasks such as language translation, summarization, and text generation.</p>
<p>These networks can be optimized to perform language-related tasks directly on-device. For instance, transformers can be utilized in embedded systems for real-time translation services or voice-assisted interfaces, where latency and computational efficiency are critical factors. Techniques such as model distillation which we will discss later on can be employed to deploy these networks on embedded devices with constrained resources.</p>
<p>Each of these architectures serves specific purposes and excel in different domains, offering a rich toolkit for tackling diverse problems in the realm of embedded AI systems. Understanding the nuances of these architectures is vital in designing effective and efficient deep learning models for various applications.</p>
</section>
</section>
</section>
<section id="libraries-and-frameworks" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="libraries-and-frameworks"><span class="header-section-number">3.3</span> Libraries and Frameworks</h2>
<p>In the world of deep learning, the availability of robust libraries and frameworks has been a cornerstone in facilitating the development, training, and deployment of models, particularly in embedded AI systems where efficiency and optimization are key. These libraries and frameworks are often equipped with pre-defined functions and tools that allow for rapid prototyping and deployment. This section sheds light on popular libraries and frameworks, emphasizing their utility in embedded AI scenarios.</p>
<section id="tensorflow" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="tensorflow"><span class="header-section-number">3.3.1</span> TensorFlow</h3>
<p><a href="https://www.tensorflow.org/">TensorFlow</a>, developed by Google <span class="citation" data-cites="abadi2016tensorflow">(<a href="references.html#ref-abadi2016tensorflow" role="doc-biblioref">Abadi et al. 2016</a>)</span>, stands as one of the premier frameworks for developing deep learning models. Its ability to work seamlessly with embedded systems comes from <a href="https://www.tensorflow.org/lite">TensorFlow Lite</a>, a lightweight solution designed to run on mobile and embedded devices. TensorFlow Lite enables the execution of optimized models on a variety of platforms, making it easier to integrate AI functionalities in embedded systems. For TinyML we will be dealing with <a href="https://www.tensorflow.org/lite/microcontrollers">TensorFlow Lite for Microcontrollers</a>.</p>
</section>
<section id="pytorch" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="pytorch"><span class="header-section-number">3.3.2</span> PyTorch</h3>
<p><a href="https://pytorch.org/">PyTorch</a>, an open-source library developed by Facebook <span class="citation" data-cites="paszke2019pytorch">(<a href="references.html#ref-paszke2019pytorch" role="doc-biblioref">Paszke et al. 2019</a>)</span>, is praised for its dynamic computation graph and ease of use. For embedded AI, PyTorch can be a suitable choice for research and prototyping, offering a seamless transition from research to production with the use of the TorchScript scripting language. PyTorch Mobile further facilitates the deployment of models on mobile and embedded devices, offering tools and workflows to optimize performance.</p>
</section>
<section id="onnx-runtime" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="onnx-runtime"><span class="header-section-number">3.3.3</span> ONNX Runtime</h3>
<p>The <a href="https://onnx.ai/">Open Neural Network Exchange (ONNX)</a> Runtime is a cross-platform, high-performance engine for running machine learning models. It is not particularly developed for embedded AI systems, though it supports a wide range of hardware accelerators and is capable of optimizing computations to improve performance in resource-constrained environments.</p>
</section>
<section id="keras" class="level3" data-number="3.3.4">
<h3 data-number="3.3.4" class="anchored" data-anchor-id="keras"><span class="header-section-number">3.3.4</span> Keras</h3>
<p>Keras <span class="citation" data-cites="chollet2015">(<a href="references.html#ref-chollet2015" role="doc-biblioref">Chollet 2015</a>)</span> serves as a high-level neural networks API, capable of running on top of TensorFlow, and other frameworks like Theano, or CNTK. For developers venturing into embedded AI, Keras offers a simplified interface for building and training models. Its ease of use and modularity can be especially beneficial in the rapid development and deployment of models in embedded systems, facilitating the integration of AI capabilities with minimal complexity.</p>
</section>
<section id="tvm" class="level3" data-number="3.3.5">
<h3 data-number="3.3.5" class="anchored" data-anchor-id="tvm"><span class="header-section-number">3.3.5</span> TVM</h3>
<p>TVM is an open-source machine learning compiler stack that aims to enable efficient deployment of deep learning models on a variety of platforms <span class="citation" data-cites="chen2018tvm">(<a href="references.html#ref-chen2018tvm" role="doc-biblioref">Chen et al. 2018</a>)</span>. Particularly in embedded AI, TVM and µTVM (Micro TVM) can be crucial in optimizing and streamlining models to suit the restricted computational and memory resources, thus making deep learning more accessible and feasible on embedded devices.</p>
<p>These libraries and frameworks are pivotal in leveraging the capabilities of deep learning in embedded AI systems, offering a range of tools and functionalities that enable the development of intelligent and optimized solutions. Selecting the appropriate library or framework, however, is a crucial step in the development pipeline, aligning with the specific requirements and constraints of embedded systems.</p>
</section>
</section>
<section id="embedded-ai-challenges" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="embedded-ai-challenges"><span class="header-section-number">3.4</span> Embedded AI Challenges</h2>
<p>Embedded AI systems often operate within environments with constrained resources, posing unique challenges in implementing the deep learning algorithms we discussed above efficiently. In this section, we explore various challenges encountered in the deployment of deep learning in embedded systems and potential solutions to navigate these complexities.</p>
<section id="memory-constraints" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="memory-constraints"><span class="header-section-number">3.4.1</span> Memory Constraints</h3>
<ul>
<li><strong>Challenge</strong>: Embedded systems usually have limited memory, which can be a bottleneck when deploying large deep learning models.</li>
<li><strong>Solution</strong>: Employing model compression techniques such as pruning and quantization to reduce the memory footprint without significantly affecting performance.</li>
</ul>
</section>
<section id="computational-limitations" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="computational-limitations"><span class="header-section-number">3.4.2</span> Computational Limitations</h3>
<ul>
<li><strong>Challenge</strong>: The computational capacity in embedded systems can be limited, hindering the deployment of complex deep learning models.</li>
<li><strong>Solution</strong>: Utilizing hardware acceleration through GPUs or dedicated AI chips to boost computational power, and optimizing models for inference through techniques like layer fusion.</li>
</ul>
</section>
<section id="energy-efficiency" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="energy-efficiency"><span class="header-section-number">3.4.3</span> Energy Efficiency</h3>
<ul>
<li><strong>Challenge</strong>: Embedded systems, particularly battery-powered devices, require energy-efficient operations to prolong battery life.</li>
<li><strong>Solution</strong>: Implementing energy-efficient neural networks that are designed to minimize energy consumption during operation, and employing dynamic voltage and frequency scaling to adjust the power consumption dynamically.</li>
</ul>
</section>
<section id="data-privacy-and-security" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="data-privacy-and-security"><span class="header-section-number">3.4.4</span> Data Privacy and Security</h3>
<ul>
<li><strong>Challenge</strong>: Embedded AI systems often process sensitive data, raising concerns regarding data privacy and security.</li>
<li><strong>Solution</strong>: Employing on-device processing to keep sensitive data on the device itself, and incorporating encryption and secure channels for any necessary data transmission.</li>
</ul>
</section>
<section id="real-time-processing-requirements" class="level3" data-number="3.4.5">
<h3 data-number="3.4.5" class="anchored" data-anchor-id="real-time-processing-requirements"><span class="header-section-number">3.4.5</span> Real-Time Processing Requirements</h3>
<ul>
<li><strong>Challenge</strong>: Many embedded AI applications demand real-time processing to provide instantaneous responses, which can be challenging to achieve with deep learning models.</li>
<li><strong>Solution</strong>: Streamlining the model through methods such as model distillation to reduce complexity and employing real-time operating systems to ensure timely processing.</li>
</ul>
</section>
<section id="model-robustness-and-generalization" class="level3" data-number="3.4.6">
<h3 data-number="3.4.6" class="anchored" data-anchor-id="model-robustness-and-generalization"><span class="header-section-number">3.4.6</span> Model Robustness and Generalization</h3>
<ul>
<li><strong>Challenge</strong>: Ensuring that deep learning models are robust and capable of generalizing well to unseen data in embedded AI settings.</li>
<li><strong>Solution</strong>: Incorporating techniques like data augmentation and adversarial training to enhance model robustness and improve generalization capabilities.</li>
</ul>
</section>
<section id="integration-with-existing-systems" class="level3" data-number="3.4.7">
<h3 data-number="3.4.7" class="anchored" data-anchor-id="integration-with-existing-systems"><span class="header-section-number">3.4.7</span> Integration with Existing Systems</h3>
<ul>
<li><strong>Challenge</strong>: Integrating deep learning capabilities into existing embedded systems can pose compatibility and interoperability issues.</li>
<li><strong>Solution</strong>: Adopting modular design approaches and leveraging APIs and middleware solutions to facilitate smooth integration with existing systems and infrastructures.</li>
</ul>
</section>
<section id="scalability" class="level3" data-number="3.4.8">
<h3 data-number="3.4.8" class="anchored" data-anchor-id="scalability"><span class="header-section-number">3.4.8</span> Scalability</h3>
<ul>
<li><strong>Challenge</strong>: Scaling deep learning solutions to cater to a growing number of devices and users in embedded AI ecosystems.</li>
<li><strong>Solution</strong>: Utilizing cloud-edge computing paradigms to distribute computational loads effectively and ensuring that the models can be updated seamlessly to adapt to changing requirements.</li>
</ul>
<p>Understanding and addressing these challenges are vital in the successful deployment of deep learning solutions in embedded AI systems. By adopting appropriate strategies and solutions, developers can navigate these hurdles effectively, fostering the creation of reliable, efficient, and intelligent embedded AI systems.</p>
</section>
</section>
<section id="limitations-of-deep-learning" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="limitations-of-deep-learning"><span class="header-section-number">3.5</span> Limitations of Deep Learning</h2>
<p>Choosing the right approach between traditional machine learning and deep learning hinges on various factors that delineate the complexity and nature of the problem at hand. This section aims to provide a balanced perspective that assists practitioners, researchers, and enthusiasts in making well-informed decisions while selecting between traditional machine learning and deep learning approaches for their specific tasks and projects.</p>
<section id="the-predicament" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="the-predicament"><span class="header-section-number">3.5.1</span> The Predicament</h3>
<p>Deep learning, although powerful, is not a universal solution for every problem. Its effectiveness often comes at the cost of requiring substantial data and computational resources. Moreover, deep learning models, especially deep neural networks, are often perceived as “black boxes”, offering no clear insight into their decision-making process, which can be a significant downside in sectors where interpretability is critical.</p>
<p>Traditional machine learning, encompassing various algorithms and methodologies like decision trees, support vector machines, and logistic regression, retains significant value in data analytics and predictive modeling. It often presents several advantages including better interpretability, efficiency, and suitability for smaller datasets.</p>
</section>
<section id="traditional-ml-vs-deep-learning" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="traditional-ml-vs-deep-learning"><span class="header-section-number">3.5.2</span> Traditional ML vs Deep Learning</h3>
<p>To succinctly highlight the differences, a comparative table illustrates the contrasting characteristics between traditional ML and deep learning:</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 38%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Traditional ML</th>
<th>Deep Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Data Requirements</td>
<td>Low to Moderate (efficient with smaller datasets)</td>
<td>High (requires large datasets for nuanced learning)</td>
</tr>
<tr class="even">
<td>Model Complexity</td>
<td>Moderate (suitable for well-defined problems)</td>
<td>High (detects intricate patterns, suited for complex tasks)</td>
</tr>
<tr class="odd">
<td>Computational Resources</td>
<td>Low to Moderate (cost-effective, less resource-intensive)</td>
<td>High (demands substantial computational power and resources)</td>
</tr>
<tr class="even">
<td>Deployment Speed</td>
<td>Fast (quicker training and deployment cycles)</td>
<td>Slow (prolonged training times, especially with larger datasets)</td>
</tr>
<tr class="odd">
<td>Interpretability</td>
<td>High (clear insights into decision pathways)</td>
<td>Low (complex layered structures, “black box” nature)</td>
</tr>
<tr class="even">
<td>Maintenance</td>
<td>Easier (simple to update and maintain)</td>
<td>Complex (requires more efforts in maintenance and updates)</td>
</tr>
</tbody>
</table>
</section>
<section id="choosing-traditional-ml-vs.-dl" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="choosing-traditional-ml-vs.-dl"><span class="header-section-number">3.5.3</span> Choosing Traditional ML vs.&nbsp;DL</h3>
<section id="data-availability-and-volume" class="level4" data-number="3.5.3.1">
<h4 data-number="3.5.3.1" class="anchored" data-anchor-id="data-availability-and-volume"><span class="header-section-number">3.5.3.1</span> Data Availability and Volume</h4>
<ul>
<li><p><strong>Quantity of Data</strong>: Traditional machine learning models, like decision trees or Naive Bayes, are often favorable when data availability is limited, providing robust predictions even with smaller datasets. This is evident in scenarios such as disease prediction in medical diagnostics and customer segmentation in marketing.</p></li>
<li><p><strong>Data Diversity and Quality</strong>: Traditional machine learning models are versatile in handling various data types, often requiring less preprocessing compared to deep learning models. They may also offer more robust predictions in scenarios with noisy data.</p></li>
</ul>
</section>
<section id="complexity-of-the-problem" class="level4" data-number="3.5.3.2">
<h4 data-number="3.5.3.2" class="anchored" data-anchor-id="complexity-of-the-problem"><span class="header-section-number">3.5.3.2</span> Complexity of the Problem</h4>
<ul>
<li><p><strong>Problem Granularity</strong>: Simple to moderately complex problems, which can have linear or polynomial relationships between variables, often find a better match with traditional machine learning techniques.</p></li>
<li><p><strong>Hierarchical Feature Representation</strong>: Deep learning models excel in tasks requiring hierarchical feature representation like image and speech recognition. However, not all problems demand this level of complexity, and traditional machine learning algorithms might sometimes provide more straightforward and equally accurate solutions.</p></li>
</ul>
</section>
<section id="hardware-and-computational-resources" class="level4" data-number="3.5.3.3">
<h4 data-number="3.5.3.3" class="anchored" data-anchor-id="hardware-and-computational-resources"><span class="header-section-number">3.5.3.3</span> Hardware and Computational Resources</h4>
<ul>
<li><p><strong>Resource Constraints</strong>: The availability of computational resources often dictates the choice between traditional ML and deep learning, with the former being less resource-intensive and thereby preferable in environments with hardware limitations or budget constraints.</p></li>
<li><p><strong>Scalability and Speed</strong>: Traditional machine learning models, like support vector machines (SVM), often allow for quicker training times and graceful scalability, especially advantageous in projects with tight timelines and increasing data volumes.</p></li>
</ul>
</section>
<section id="regulatory-compliance" class="level4" data-number="3.5.3.4">
<h4 data-number="3.5.3.4" class="anchored" data-anchor-id="regulatory-compliance"><span class="header-section-number">3.5.3.4</span> Regulatory Compliance</h4>
<p>Regulatory compliance is paramount in several industries, necessitating adherence to guidelines and best practices such as GDPR in the EU. Traditional ML models, due to their inherent interpretability, often align better with these regulations, especially in sectors like finance and healthcare.</p>
</section>
<section id="interpretability" class="level4" data-number="3.5.3.5">
<h4 data-number="3.5.3.5" class="anchored" data-anchor-id="interpretability"><span class="header-section-number">3.5.3.5</span> Interpretability</h4>
<p>Understanding the decision-making process is simpler with traditional machine learning techniques, as opposed to deep learning models that function as a “black box”, making the tracing of decision pathways challenging.</p>
</section>
</section>
<section id="making-an-informed-choice" class="level3" data-number="3.5.4">
<h3 data-number="3.5.4" class="anchored" data-anchor-id="making-an-informed-choice"><span class="header-section-number">3.5.4</span> Making an Informed Choice</h3>
<p>Given the constraints of embedded AI systems, understanding the nuances between traditional ML techniques and deep learning becomes critical. Both avenues offer unique advantages, and their distinct characteristics often dictate the choice of one over the other in different scenarios.</p>
<p>With all that said, deep learning has been steadily outpacing traditional machine learning methods in several critical areas due to a combination of data abundance, computational advancements, and proven efficacy in complex tasks.</p>
<p>Here are a few concrete reasons why we are centering our attention on deep learning in this text:</p>
<ol type="1">
<li><p><strong>Superior Performance in Complex Tasks</strong>: Deep learning models, especially deep neural networks, excel in tasks where the relationships between data points are incredibly complex. Tasks such as image and speech recognition, language translation, and playing intricate games like Go and Chess have seen breakthroughs primarily through deep learning algorithms.</p></li>
<li><p><strong>Efficient Handling of Unstructured Data</strong>: Unlike traditional machine learning methods, deep learning can process unstructured data more effectively. This is a vital asset in the modern data landscape where a vast majority of data is unstructured, including text, images, and videos.</p></li>
<li><p><strong>Leveraging Big Data</strong>: With the availability of big data, deep learning models have the ability to continually learn and improve. These models are adept at utilizing large datasets to enhance their predictive accuracy, something that can be limiting in traditional machine learning approaches.</p></li>
<li><p><strong>Hardware Advancements and Parallel Computing</strong>: The development of powerful GPUs and the availability of cloud computing platforms have enabled the rapid training of deep learning models. These advancements have addressed one of the significant hurdles of deep learning – the requirement of substantial computational resources.</p></li>
<li><p><strong>Dynamic Adaptability and Continuous Learning</strong>: Deep learning models are capable of adapting to new information or data dynamically. They can be trained to generalize their learning to new, unseen data, which is essential in rapidly evolving fields such as autonomous driving or real-time language translation.</p></li>
</ol>
<p>Despite the traction gained by deep learning, it’s imperative to understand that traditional machine learning is not obsolete. While we delve deeper into the nuances of deep learning, we will also highlight situations where traditional machine learning methods may be more appropriate due to their simplicity, efficiency, and ease of interpretation. By focusing on deep learning in this text, we aim to equip readers with the knowledge and tools necessary to tackle modern, complex problems in various domains, while also offering insights into the comparative advantages and suitable application scenarios for both deep learning and traditional machine learning methods.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-abadi2016tensorflow" class="csl-entry" role="listitem">
Abadi, Martı́n, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, et al. 2016. <span>“<span class="math inline">\(\{\)</span>TensorFlow<span class="math inline">\(\}\)</span>: A System for <span class="math inline">\(\{\)</span>Large-Scale<span class="math inline">\(\}\)</span> Machine Learning.”</span> In <em>12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</em>, 265–83.
</div>
<div id="ref-bank2023autoencoders" class="csl-entry" role="listitem">
Bank, Dor, Noam Koenigstein, and Raja Giryes. 2023. <span>“Autoencoders.”</span> <em>Machine Learning for Data Science Handbook: Data Mining and Knowledge Discovery Handbook</em>, 353–74.
</div>
<div id="ref-chen2018tvm" class="csl-entry" role="listitem">
Chen, Tianqi, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Haichen Shen, Meghan Cowan, et al. 2018. <span>“<span class="math inline">\(\{\)</span>TVM<span class="math inline">\(\}\)</span>: An Automated <span class="math inline">\(\{\)</span>End-to-End<span class="math inline">\(\}\)</span> Optimizing Compiler for Deep Learning.”</span> In <em>13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)</em>, 578–94.
</div>
<div id="ref-chollet2015" class="csl-entry" role="listitem">
Chollet, François. 2015. <span>“Keras.”</span> <em>GitHub Repository</em>. <a href="https://github.com/fchollet/keras" class="uri">https://github.com/fchollet/keras</a>; GitHub.
</div>
<div id="ref-goodfellow2020generative" class="csl-entry" role="listitem">
Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. <span>“Generative Adversarial Networks.”</span> <em>Communications of the ACM</em> 63 (11): 139–44.
</div>
<div id="ref-jouppi2017datacenter" class="csl-entry" role="listitem">
Jouppi, Norman P, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, et al. 2017. <span>“In-Datacenter Performance Analysis of a Tensor Processing Unit.”</span> In <em>Proceedings of the 44th Annual International Symposium on Computer Architecture</em>, 1–12.
</div>
<div id="ref-krizhevsky2012imagenet" class="csl-entry" role="listitem">
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. <span>“Imagenet Classification with Deep Convolutional Neural Networks.”</span> <em>Advances in Neural Information Processing Systems</em> 25.
</div>
<div id="ref-paszke2019pytorch" class="csl-entry" role="listitem">
Paszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, et al. 2019. <span>“Pytorch: An Imperative Style, High-Performance Deep Learning Library.”</span> <em>Advances in Neural Information Processing Systems</em> 32.
</div>
<div id="ref-rosenblatt1957perceptron" class="csl-entry" role="listitem">
Rosenblatt, Frank. 1957. <em>The Perceptron, a Perceiving and Recognizing Automaton Project Para</em>. Cornell Aeronautical Laboratory.
</div>
<div id="ref-rumelhart1986learning" class="csl-entry" role="listitem">
Rumelhart, David E, Geoffrey E Hinton, and Ronald J Williams. 1986. <span>“Learning Representations by Back-Propagating Errors.”</span> <em>Nature</em> 323 (6088): 533–36.
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> <em>Advances in Neural Information Processing Systems</em> 30.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./embedded_sys.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Embedded Systems</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./embedded_ml.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Embedded ML</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Embedded AI edited by Prof.&nbsp;Vijay Janapa Reddi (Harvard University) and Prof.&nbsp;Song Han (MIT).</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This book was built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>