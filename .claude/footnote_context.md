# FOOTNOTE CATALOG AND CONTEXT

## Book-Wide Footnote Statistics

- Total footnotes defined: 369
- Footnotes with bold terms: 364
- Average definition length: 351 characters
- Common ID prefixes: {'fn': 369}
- Total unique terms: 337

## ⚠️ IMPORTANT: Terms Already Defined

These terms have already been defined in other chapters. DO NOT redefine them:

- **imagenet**: defined in benchmarking, efficient_ai, introduction
- **alexnet**: defined in benchmarking, efficient_ai, introduction, training
- **resnet**: defined in benchmarking, efficient_ai
- **tensor processing unit (tpu)**: defined in benchmarking, dl_primer, efficient_ai, introduction, ml_systems
- **gpt-3**: defined in benchmarking, efficient_ai
- **mixed-precision training**: defined in benchmarking, training
- **data parallelism**: defined in benchmarking, efficient_ai
- **model parallelism**: defined in benchmarking, efficient_ai
- **data versioning challenges**: defined in data_engineering, workflow
- **perceptron**: defined in dl_primer, introduction
- **backpropagation**: defined in dl_primer, introduction
- **flops**: defined in dl_primer, efficient_ai
- **backpropagation algorithm**: defined in dnn_architectures, training
- **ensemble methods**: defined in efficient_ai, robust_ai
- **pruning**: defined in efficient_ai, optimizations
- **knowledge distillation**: defined in efficient_ai, optimizations
- **moore's law**: defined in efficient_ai, introduction
- **transfer learning**: defined in efficient_ai, introduction, introduction, workflow
- **foundation models**: defined in efficient_ai, introduction

## Footnote Style Guidelines

Based on existing footnotes, follow these patterns:
1. Use ID format: [^fn-term-name] (lowercase, hyphens)
2. Definition format: **Bold Term**: Clear definition. Optional analogy.
3. Keep definitions concise (avg ~200 characters)
4. Avoid redefining terms from other chapters
5. Focus on technical terms that need clarification

## All Terms Currently Defined in Book

- e-waste from computing, fbnet, model uncertainty, infrastructure as code, cray-1 vector legacy
- eliza, data sanitization, hot spares, jupyter notebooks, connection machine cm-5
- ai compute explosion, real-time grid carbon intensity, uci machine learning repository, edge computing origins, meltdown/spectre impact
- universal approximation theorem, microcontrollers, cifar-10, neural processing unit (npu), ibm system/360
- voice recognition evolution, self-supervised learning, ml apis, principle of least privilege, jenkins origins
- data versioning challenges, dartmouth conference (1956), google data centers, risc-v for ai, sequential neural networks
- nas evaluation metrics, core ml, plantvillage nuru real-world impact, structured pruning, alexnet's gpu revolution
- diabetic retinopathy global impact, training profiling tools, parameter scaling, regularization, glitches
- resnet revolution, tinyml, active learning, black box, data lake origins
- gpu manufacturing impact, systems thinking in ai, ml team role evolution, lottery ticket hypothesis, gpus for deep learning
- "attention is all you need", google's carbon-free commitment, data-centric ai, cascade of classifiers, edge latency advantage
- data augmentation, blas (basic linear algebra subprograms), autopilot, mnist dataset, systolic array architecture
- generative ai breakthrough, whetstone, columnar format revolution, beam testing, minimax
- pay-as-you-go pricing, gpt-4, knowledge distillation, energy efficiency metrics, batch size effects
- tensor core breakthrough, foundation models, gradient descent, pytorch, transformer batch size scaling
- vision transformers (vits), critical material scarcity, model drift phenomenon, lstm origins, principal component analysis (pca)
- shap in production, model drift detection, combinational logic, lora technology, model quantization
- parameter-efficient fine-tuning, service level objectives (slos), backpropagation, resnet, netflix deanonymization
- tpu (tensor processing unit), perplexity, feature store scale, flops, ensemble methods
- arm trustzone, tensorflow lite, f1 score, mobile system-on-chip, tensor cores
- microsoft fpga deployment, 3dmark, eniac (electronic numerical integrator and computer), ml hardware cost spectrum, relu hardware efficiency
- cudnn, mobile power constraints, tensor operations, learning rate schedules, puf market growth
- hdfs origins, etl evolution, data as code, experiment tracking evolution, systolic array renaissance
- pruning, latency-critical applications, bert, speculative execution, medical data annotation costs
- alexnet, demographic parity origins, devops origins, autoregressive, lapack (linear algebra package)
- on-device training constraints, tinytl memory breakthrough, chinese rare earth dominance, jax, energy-aware ai frameworks
- data centers, technical debt origins, backpropagation (historical context), viola-jones algorithm, hardware-aware nas
- sdg global impact, concept drift challenge, google carbon-aware scheduling results, multimodal sensor data, tensorflow
- gpt-3 training scale, quantization, cdc 6600, google tensor soc architecture, ai vs industrial emissions
- arduino edge computing reality, tvm (tensor virtual machine), computational graphs, basic linear algebra subprograms (blas), artificial neurons
- green500, data parallelism, tensorrt optimization, nlp computational demands, microcontroller power budget reality
- operator fusion, youtube recommendation impact, support vector machines (svms), mobilenet, energy star
- nvidia triton inference server, ai's sdg impact potential, iot hubs, large-scale training challenges, moore's law
- cloud infrastructure evolution, cloud ml training economics, hipaa violations, nuclear power for ai data centers, dual-use dilemma
- mixed-precision training, hyperscale data center scale, systems integration philosophy, sparse energy savings, scan chains
- model scaling explosion, billion-parameter models, ml vs. traditional problem definition, intel 8087 impact, zero-day etymology
- nvidia ai gpus, activation checkpointing trade-offs, medical ai privacy complexity, distilbert, zillow ibuying failure
- smpc performance, memory scale comparison, esp32 capabilities, hazardous chemical quantities, model parallelism
- backpropagation algorithm, error-correcting codes, gdpr article 22, data drift, privacy regulation timeline
- brittleness in ai systems, data drift discovery, compas algorithm controversy, multi-agent system, imagenet revolution
- edge processor, learning rate, arm cortex architecture spectrum, efficientnet, energy efficiency in tinyml
- social good resource paradox, medical imaging ai revolution, mirai botnet scale, sigmoid computational cost, model extraction threat
- github actions for ml, tensor processing unit (tpu), double modular redundancy (dmr), ultra-long battery life, convolutional neural network (cnn)
- cough analysis technology, data quality reality, prometheus at scale, kubeflow production usage, huber loss
- ci/cd for machine learning, the lab-to-clinic performance gap, paradigm shift, gdpr's ml impact, onnx deployment
- production alert thresholds, computer engineering, quantization-aware training, squeezenet, apple's neural engine strategy
- mnist, overfitting, federated learning birth, batch processing evolution, "hey siri" technical reality
- checkpoint and restart mechanisms, spec cpu, mobilemark, dvc creation story, jevon's paradox
- gradient accumulation impact, differential privacy, theano, cassava disease impact, cloudsuite
- stochastic computing, model parallelism memory scaling, household energy comparison, kserve (formerly kfserving), nvidia nccl (collective communications library)
- bayesian neural networks, perceptron, data center climate impact, data parallelism scaling, wafer-scale engine specifications
- mlops business impact, kubernetes origins, mobile device constraints, apple neural engine evolution, spec power
- iot device growth, ibm watson health, transformer, tinyml model compression, gpt-3
- tinyml device scale, dp-sgd industry adoption, synapses, coin-cell batteries, google tpus
- hsm performance, mobilenet innovation, ml reproducibility crisis, parameters, tokens
- moore's law origins, bert compression, mechanical turk origins, ml autoscaling at scale, gpt-3 energy consumption
- service level agreements (slas), healthcare ai deployment reality, memory optimization, automatic differentiation, computational photography
- microsoft farmbeats, xla (accelerated linear algebra), curriculum learning, hardware lottery, tensor processing units
- brain energy efficiency, dhrystone, crisp-dm (cross-industry standard process for data mining), scaling laws, yann lecun and cnns
- global fishing watch impact, depthwise separable convolutions, tinyml market reality, healthcare algorithm scale, triple modular redundancy (tmr)
- memory hierarchy challenge, hyperscale data centers, linpack, stochastic gradient descent (sgd), efficientnet pruning
- cloud inference latency, covid-19 ml impact, endpoint device constraints, mlperf, power usage effectiveness
- tpu origins, intel sgx constraints, mobile storage evolution, wireless communication reality, training-serving skew impact
- industrial iot, inference attack, 2014-2016 ebola outbreak, lookup table, transfer learning
- stuxnet discovery, mlops emergence, esp32 edge computing, data center cooling costs, feature store evolution
- mosquito species detection, application-specific integrated circuit (asic), a11 bionic breakthrough, distributed training, von neumann architecture
- smallholder farmers global impact, semiconductor water consumption scale, model inversion attack, stm32f4 microcontroller reality, imagenet
- simd evolution, tensorflow serving