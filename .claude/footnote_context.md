# FOOTNOTE CATALOG AND CONTEXT

## Book-Wide Footnote Statistics

- Total footnotes defined: 383
- Footnotes with bold terms: 383
- Average definition length: 383 characters
- Common ID prefixes: {'fn': 383}
- Total unique terms: 355

## ⚠️ IMPORTANT: Terms Already Defined

These terms have already been defined in other chapters. DO NOT redefine them:

- **imagenet**: defined in benchmarking, efficient_ai, introduction
- **alexnet**: defined in benchmarking, efficient_ai, introduction, training
- **resnet**: defined in benchmarking, efficient_ai
- **tensor processing unit (tpu)**: defined in benchmarking, dl_primer, efficient_ai, introduction, ml_systems
- **gpt-3**: defined in benchmarking, efficient_ai
- **mixed-precision training**: defined in benchmarking, training
- **data parallelism**: defined in benchmarking, efficient_ai
- **model parallelism**: defined in benchmarking, efficient_ai
- **data versioning challenges**: defined in data_engineering, workflow
- **perceptron**: defined in dl_primer, introduction
- **backpropagation**: defined in dl_primer, introduction
- **flops**: defined in dl_primer, efficient_ai
- **backpropagation algorithm**: defined in dnn_architectures, training
- **pruning**: defined in efficient_ai, optimizations
- **knowledge distillation**: defined in efficient_ai, optimizations
- **moore's law**: defined in efficient_ai, introduction
- **transfer learning**: defined in efficient_ai, introduction, introduction, workflow
- **foundation models**: defined in efficient_ai, introduction
- **tinyml**: defined in efficient_ai, ml_systems
- **adversarial examples discovery**: defined in responsible_ai, robust_ai

## Footnote Style Guidelines

Based on existing footnotes, follow these patterns:
1. Use ID format: [^fn-term-name] (lowercase, hyphens)
2. Definition format: **Bold Term**: Clear definition. Optional analogy.
3. Keep definitions concise (avg ~200 characters)
4. Avoid redefining terms from other chapters
5. Focus on technical terms that need clarification

## All Terms Currently Defined in Book

- tpu origins, parameters, tinyml, data center climate impact, billion-parameter models
- federated learning birth, mnist, batch processing evolution, energy-aware ai frameworks, latency-critical applications
- model parallelism memory scaling, endpoint device constraints, ml autoscaling at scale, cosmic ray impact, tensorflow lite
- 3dmark, hardware lottery, sgd (stochastic gradient descent), google tpus, mechanical turk origins
- microsoft farmbeats, tensor processing unit (tpu), lapack (linear algebra package), hdfs origins, medical imaging ai revolution
- feature store scale, system design trade-offs, activation checkpointing, service level agreements (slas), data parallelism scaling
- data-centric ai, adversarial training overhead, ml reproducibility crisis, microsoft fpga deployment, memory optimization
- self-supervised learning, tensorrt optimization, imagenet, hyperscale data centers, sigmoid computational cost
- tpu (tensor processing unit), hipaa violations, a11 bionic breakthrough, lstm origins, tensor cores
- crisp-dm (cross-industry standard process for data mining), automatic differentiation, multi-agent system, data drift, mosquito species detection
- model parallelism, learning rate schedules, label flipping attack impact, energy efficiency in tinyml, distilbert
- tinytl memory breakthrough, plantvillage nuru real-world impact, stochastic computing resilience, tinyml model compression, ml apis
- structured pruning, mobilemark, mlops emergence, power usage effectiveness, cifar-10
- learning rate, computer engineering, tinyml market reality, activation checkpointing trade-offs, microcontroller power budget reality
- active learning, neural processing unit (npu), mirai botnet scale, on-device training constraints, memory scale comparison
- real-time grid carbon intensity, healthcare ai deployment reality, lottery ticket hypothesis, columnar format revolution, data as code
- transformer, c&w attack effectiveness, hyperscale data center scale, dram bit flip rates, support vector machines (svms)
- cloud infrastructure evolution, jupyter notebooks, von neumann architecture, flops, data centers
- parameter scaling, e-waste from computing, curriculum learning, memory hierarchy challenge, cudnn
- etl evolution, batch size effects, privacy regulation timeline, transfer learning, arduino edge computing reality
- smpc performance, onnx deployment, coin-cell batteries, parameter-efficient fine-tuning, scaling laws
- arm cortex architecture spectrum, model extraction threat, gpt-3 energy consumption, sdg global impact, ai vs industrial emissions
- differential privacy, ml vs. traditional problem definition, computational photography, google's carbon-free commitment, voice recognition evolution
- hazardous chemical quantities, defensive distillation effectiveness, bert compression, tvm (tensor virtual machine), adversarial patch success
- mobile system-on-chip, ensemble methods, ibm watson health, prometheus at scale, activation function
- sequential neural networks, online learning vulnerability, speculative execution, youtube recommendation impact, 2014-2016 ebola outbreak
- fab water usage vs cities, application-specific integrated circuit (asic), jax, data center cooling costs, data augmentation
- medical data annotation costs, covid-19 ml impact, mini-batch gpu optimization, the lab-to-clinic performance gap, spec cpu
- quantization-aware training, fault injection tool ecosystem, iot device growth, stuck-at faults in ml, ultra-long battery life
- data lake origins, edge latency advantage, alexnet's gpu revolution, adam (adaptive moment estimation), concept drift challenge
- kubernetes origins, operator fusion, spec power, data poisoning detection challenge, tensor core breakthrough
- gdpr's ml impact, backdoor attack effectiveness, risc-v for ai, intel 8087 impact, eniac (electronic numerical integrator and computer)
- ibm system/360, gdpr, alexnet, dartmouth conference (1956), dp-sgd industry adoption
- social good resource paradox, model drift detection, "hey siri" technical reality, fdiv bug economic impact, relu hardware efficiency
- overfitting, single vs multi-bit fault impact, jenkins origins, hardware vs software injection, hsm performance
- stop sign attack precision, model quantization, model drift phenomenon, jevon's paradox, adversarial examples discovery
- production alert thresholds, blas (basic linear algebra subprograms), convolutional neural network (cnn), backpropagation algorithm, ci/cd for machine learning
- mnist dataset, shap in production, tensorflow serving, puf market growth, gradient descent
- model inversion attack, xla (accelerated linear algebra), gpus for deep learning, medical ai privacy complexity, mathematical convolution
- mobile device constraints, feature store evolution, brain energy efficiency, rmsprop (root mean square propagation), microcontrollers
- training-serving skew impact, systems integration philosophy, systems thinking in ai, ml hardware cost spectrum, black box
- training profiling tools, pgd attack strength, transformer batch size scaling, kserve (formerly kfserving), cray-1 vector legacy
- core ml, tensor operations, mixed-precision training, artificial neurons, wireless communication reality
- mobilenet innovation, uci machine learning repository, simd evolution, gdpr article 22, mlperf
- pytorch, intel sgx constraints, edge computing, fbnet, sparse energy savings
- gpt-4, perplexity, compas algorithm controversy, mobile power constraints, pruning
- moore's law, nuclear power for ai data centers, wafer-scale engine specifications, smallholder farmers global impact, adversarial transferability
- distributed training, green500, edge processor, resnet revolution, principal component analysis (pca)
- ai compute explosion, data parallelism, eliza, tinyml device scale, nas evaluation metrics
- efficientnet pruning, generative ai breakthrough, yann lecun and cnns, efficientnet, cassava disease impact
- viola-jones algorithm, project natick underwater data centers, diabetic retinopathy global impact, knowledge distillation, quantization
- cascade of classifiers, resnet, backpropagation (historical context), zero-day etymology, lora technology
- global fishing watch impact, paradigm shift, industrial iot, depthwise separable convolutions, model scaling explosion
- household energy comparison, inference attack, autoregressive, gpu manufacturing impact, synapses
- squeezenet, nvidia nccl (collective communications library), systolic array architecture, vision transformers (vits), nvidia triton inference server
- stuxnet discovery, bert, cdc 6600, large-scale training challenges, cloud inference latency
- critical material scarcity, foundation models, demographic parity origins, mobilenet, data poisoning emergence
- gpt-3, cough analysis technology, cloudsuite, energy efficiency metrics, github actions for ml
- tensor processing units, computational graphs, pay-as-you-go pricing, stochastic gradient descent (sgd), chinese rare earth dominance
- dhrystone, mlops business impact, energy star, netflix deanonymization, nlp computational demands
- edge computing origins, electromigration in ai hardware, brittleness in ai systems, data versioning challenges, apple neural engine evolution
- tokens, ml security threat taxonomy, basic linear algebra subprograms (blas), stm32f4 microcontroller reality, data quality reality
- value alignment problem, semiconductor water consumption scale, tensorflow, silent data corruption challenge, ml team role evolution
- hardware-aware nas, experiment tracking evolution, healthcare algorithm scale, esp32 edge computing, safety-critical computing evolution
- google data centers, fault injection framework evolution, esp32 capabilities, universal approximation theorem, apple's neural engine strategy
- fgsm breakthrough, google tensor soc architecture, single event upset rates, technical debt origins, "attention is all you need"
- dvc creation story, nvidia ai gpus, federated learning scale, systolic array renaissance, moore's law origins
- devops origins, arm trustzone, theano, linpack, backpropagation
- imagenet revolution, iot hubs, mobile storage evolution, connection machine cm-5, gpt-3 training scale
- google carbon-aware scheduling results, zillow ibuying failure, service level objectives (slos), kubeflow production usage, gradient accumulation impact
- whetstone, meltdown/spectre impact, perceptron, ai's sdg impact potential, cloud ml training economics