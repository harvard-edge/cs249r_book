# FOOTNOTE CATALOG AND CONTEXT

## Book-Wide Footnote Statistics

- Total footnotes defined: 758
- Footnotes with bold terms: 753
- Average definition length: 377 characters
- Common ID prefixes: {'fn': 749, 'immutable': 1, 'stateless': 1, 'jit': 1, 'pure': 1, 'gradient': 1, 'batch': 1}
- Total unique terms: 692

## ⚠️ IMPORTANT: Terms Already Defined

These terms have already been defined in other chapters. DO NOT redefine them:

- **imagenet**: defined in benchmarking, efficient_ai, introduction
- **alexnet**: defined in benchmarking, efficient_ai, introduction, training
- **resnet**: defined in benchmarking, efficient_ai
- **tensor processing unit (tpu)**: defined in benchmarking, dl_primer, efficient_ai, frontiers, introduction, ml_systems
- **flops**: defined in benchmarking, dl_primer, efficient_ai
- **gpt-3**: defined in benchmarking, efficient_ai
- **mixed-precision training**: defined in benchmarking, ondevice_learning, training
- **data parallelism**: defined in benchmarking, efficient_ai, frameworks
- **model parallelism**: defined in benchmarking, efficient_ai, frameworks
- **neural processing unit (npu)**: defined in benchmarking, ml_systems
- **operator fusion**: defined in benchmarking, optimizations
- **ml reproducibility crisis**: defined in data_engineering, ops
- **data versioning challenges**: defined in data_engineering, workflow
- **perceptron**: defined in dl_primer, introduction
- **backpropagation**: defined in dl_primer, introduction
- **mnist dataset**: defined in dl_primer, dnn_architectures
- **batch processing**: defined in dl_primer, efficient_ai
- **backpropagation algorithm**: defined in dnn_architectures, training
- **systolic array**: defined in dnn_architectures, frameworks
- **scaling laws**: defined in efficient_ai, frontiers
- **memory bandwidth**: defined in efficient_ai, hw_acceleration, optimizations
- **ensemble methods**: defined in efficient_ai, robust_ai
- **stochastic gradient descent (sgd)**: defined in efficient_ai, ondevice_learning
- **moore's law**: defined in efficient_ai, hw_acceleration, introduction
- **transfer learning**: defined in efficient_ai, introduction, introduction, workflow
- **foundation models**: defined in efficient_ai, introduction
- **microcontrollers**: defined in efficient_ai, introduction, ml_systems
- **just-in-time (jit) compilation**: defined in frameworks, frameworks
- **automatic differentiation**: defined in frameworks, training
- **flops (floating-point operations)**: defined in frontiers, ondevice_learning, sustainable_ai
- **dennard scaling**: defined in hw_acceleration, sustainable_ai
- **data centers**: defined in introduction, ml_systems
- **embedded systems**: defined in ml_systems, robust_ai
- **ml apis**: defined in ml_systems, privacy_security
- **tensorflow lite**: defined in ml_systems, ondevice_learning
- **federated learning**: defined in ml_systems, responsible_ai
- **federated learning architecture**: defined in ml_systems, workflow
- **quantization-aware training**: defined in ondevice_learning, optimizations
- **lora (low-rank adaptation)**: defined in ondevice_learning, optimizations
- **differential privacy**: defined in ondevice_learning, responsible_ai, responsible_ai
- **programmable logic controllers (plcs)**: defined in ops, privacy_security
- **data poisoning**: defined in privacy_security, robust_ai
- **backdoor attacks**: defined in privacy_security, robust_ai

## Footnote Style Guidelines

Based on existing footnotes, follow these patterns:
1. Use ID format: [^fn-term-name] (lowercase, hyphens)
2. Definition format: **Bold Term**: Clear definition. Optional analogy.
3. Keep definitions concise (avg ~200 characters)
4. Avoid redefining terms from other chapters
5. Focus on technical terms that need clarification

## All Terms Currently Defined in Book

- zero-day etymology, raspberry pi development advantages, application-specific integrated circuit (asic), fbnet, tensor processing units
- training profiling tools, data lake origins, esp32 edge computing, directed acyclic graph (dag), mobile power constraints
- dhrystone, kubeflow production usage, bayesian optimization, alexa voice service (avs), real-time grid carbon intensity
- ml hardware cost spectrum, rate limiting, datasheets for datasets, overfitting, hyperparameter optimization
- human-in-the-loop (hitl), theano, data lineage systems, kserve (formerly kfserving), ci/cd security
- epoch, adversarial inputs, hdfs origins, ai safety, ml apis
- diabetic retinopathy global impact, batch normalization, jax, ultra-long battery life, tiny ml
- esp32 capabilities, multi-agent system, programmable logic controllers (plcs), model parallelism, cuda (compute unified device architecture)
- scale-invariant feature transform (sift), stochastic gradient descent (sgd), differential privacy, mode collapse, nuclear power for ai data centers
- activation checkpointing trade-offs, biological efficiency, global fishing watch impact, neural processing unit (npu), eliza
- activation functions, wafer-scale integration, mirai botnet scale, artificial neurons, hyperscale data center scale
- asic (application-specific integrated circuit), distributed systems, proxy metrics, uci machine learning repository, nvlink
- ibm watson health, saliency maps, scaling laws, activation caching, inference latency
- fp16 dynamic range, static model problem, billion-parameter models, pure function, computational photography
- quantization, byzantine failures, mobilemark, aws sagemaker, mobile storage evolution
- nccl (nvidia collective communications library), xor problem, synthetic data growth, backpropagation, mosquito species detection
- ml reproducibility crisis, lidar, kubernetes origins, docker, nas evaluation metrics
- data center cooling costs, foundation models, medical ai privacy complexity, ai economic transformation, curriculum learning
- support vector machines (svms), imagenet, agi infrastructure scale, google carbon-aware scheduling results, vanishing gradients
- modular reasoning gains, columnar format revolution, resnet, systolic array renaissance, electromagnetic interference (emi)
- stuxnet discovery, regularization, real-time latency requirements, transfer learning for tinyml, model parallelism memory scaling
- tensorrt optimization, tokens, convolutional neural network (cnn), combinational logic, carlini and wagner (c&w) attack
- pseudonymization under gdpr, tensor core breakthrough, yann lecun and cnns, waze crowdsourcing model, cloud inference latency
- satellite disaster monitoring, memory bandwidth, cloud ml training economics, wireless communication reality, federated learning birth
- model memorization, ddos attacks, adversarial examples, energy efficiency in tinyml, distilbert
- systolic array architecture, serverless computing for ml, youtube recommendation impact, internet's long tail, healthcare ai deployment reality
- mutual tls (mtls), tensor processing unit (tpu), demographic parity origins, safety-critical applications, computer engineering
- hyperparameter optimization complexity, imagenet revolution, memory architecture gap, xla (accelerated linear algebra), e-waste from computing
- fairness impossibility theorems, linpack, portrait mode photography, tensor cores, principal component analysis (pca)
- attention memory scaling, inference attack, probabilistic vs. deterministic systems, data drift, cloud infrastructure evolution
- robotic system requirements, membership inference attacks, on-device training constraints, fips 140-2 standard, transfer learning attacks
- glitches, crowdsourcing risks, vanishing gradient problem, batch size effects, protected attributes
- few-shot learning, perspective api, jevon's paradox, whetstone, neural processing units (npus)
- model watermarking, domain-specific architectures (dsa), predictive maintenance, infrastructure as code, cuda cores
- tensorflow serving, automl (automated machine learning), tinyml in fitness trackers, tinyml scale, semiconductor water consumption scale
- self-supervised learning, gpu (graphics processing unit), ibm system/360, federated learning architecture, mobilenets evolution
- recaptcha evolution, transfer learning, data exhaustion timeline, inference in ai, coprocessor
- edge tpu, memory coherence, scan chains, etl vs elt in ml, cassava disease impact
- tvm (tensor virtual machine), fpga for ml, dp-sgd industry adoption, data drift discovery, data cards framework
- docker's revolution, gpt-3 training scale, computer architecture perspective, data parallelism scaling, backpropagation (historical context)
- human feedback bottlenecks, batch processing, gradient-based attacks, gradient sparsification, elk stack
- hot spares, the 80/20 rule in ml, petabytes, structural inequities, edge ml
- brain energy efficiency, nhtsa cybersecurity guidelines, flops vs flops, etl evolution, mlops emergence
- flops (floating-point operations per second), debug port vulnerabilities, infrastructure efficiency gap, resnet revolution, rfm analysis origins
- constitutional ai method, spec cpu, data centers, ml vs. traditional problem definition, open images dataset
- minimax, data versioning challenges, eager execution, fp16, hardening strategies
- nvidia jetson ecosystem, fairlearn, healthcare algorithm scale, privacy regulation timeline, smart cities
- active learning, bert compression, ai compute explosion, apple's neural engine strategy, mechanical turk origins
- google tensor soc architecture, training cost explosion, data drift in production, reinforcement learning nas, mixed-precision training
- relu hardware efficiency, the bitter lesson, ci/cd for machine learning, static computational graph, crisp-dm (cross-industry standard process for data mining)
- field-programmable gate arrays (fpgas), cloud genomics scale, energy efficiency metrics, data evolution in production, memory usage
- gpu manufacturing impact, algorithmic fairness in healthcare, burst buffers, ml framework evolution, arm processors
- application-specific integrated circuits (asics), latency-critical applications, ml system scaling complexity, pay-as-you-go pricing, federated averaging (fedavg)
- lstm origins, gpt-4, github actions for ml, allreduce algorithm, memory planning
- large language models (llms), social good resource paradox, deep learning frameworks, fault models, blockchain for ml governance
- real-time translation, stochastic computing, risc-v for ai, intel sgx constraints, mlflow's creation
- rlhf development, pytorch, continual learning approaches, feature store evolution, simd (single instruction, multiple data)
- smart glasses with tinyml, cudnn, cifar-10, lifecycle assessment (lca), gdpr (general data protection regulation)
- bigquery serverless power, household energy comparison, hsm certification, network protocols, mlperf
- distributed infrastructure, gradient clipping, automotive cybersecurity recalls, gdpr article 22, google crowdsource
- high-stakes domains, service level agreements (slas), microcontrollers, gradient quantization, kernel fusion
- hardware-aware nas, memory scale comparison, service level objectives (slos), sha-256 hashing, sigmoid computational cost
- im2col (image to column), fast gradient sign method (fgsm), cross-entropy loss, ai vs industrial emissions, checkpoint and restart mechanisms
- large-scale training challenges, microsoft fpga deployment, crosstalk, general data protection regulation (gdpr), kaggle
- federated learning at scale, universal approximation theorem, cloudsuite, beam testing, arm trustzone
- smpc performance, medical imaging ai revolution, dual-use dilemma, iot hubs, gradient descent
- a/b testing for ml, memory organization challenge, labelme project, cdc 6600, edge computing
- reasoning performance cliff, gemm (general matrix multiply), personalization technical foundations, squeezenet, medical data annotation costs
- accelerator performance comparison, hazardous chemical quantities, training objective mismatch, dartmouth conference (1956), federated learning
- parameter-efficient fine-tuning, activation function, moe mechanism, edge computing in healthcare, query-key-value attention
- parameters, critical material scarcity, snappy compression trade-offs, ml autoscaling at scale, industrial iot
- stm32f4 microcontroller reality, gradient accumulation, triple modular redundancy (tmr), moore's law, lora (low-rank adaptation)
- phi training strategy, receptive field, silent data corruption (sdc), "hey siri" technical reality, lapack (linear algebra package)
- edge computing for ai, pipeline jungle metaphor, memory hierarchy in ml, netflix deanonymization, transformer
- agi scale requirements, tinyml device scale, gpus for deep learning, histogram of oriented gradients (hog), latency
- field-programmable gate array (fpga), mnist dataset, edge network coordination, redis performance, value alignment
- symbol grounding problem, tops (tera operations per second), smart electrical grids, concept drift challenge, software development lifecycle evolution
- stateless function, latency vs throughput, mobile face detection, tensorrt, vision transformers (vits)
- parameter scaling, 3dmark, jenkins origins, simd evolution, nvidia ai gpus
- iot data explosion, agi definition, model uncertainty, automatic differentiation, efficientnet
- softmax function, tvm, api keys, microclimate monitoring, data parallelism
- data sanitization, heterogeneous computing, just-in-time (jit) compilation, apple neural engine evolution, hsm performance
- connection machine cm-5, parallelism strategies, alexnet's gpu revolution, gpt-4 energy consumption, nlp computational demands
- evolutionary nas, perceptron, synthetic data revolution, smallholder farmers global impact, exploratory data analysis (eda)
- speculative execution, tensorflow serving origins, intermediate representation (ir), superhuman ai capabilities, microsoft farmbeats
- dvc creation story, constitutional ai, generative ai breakthrough, richard sutton, prometheus at scale
- zillow ibuying failure, role-based access control (rbac), training-serving skew impact, mlops maturity models, equalized odds
- depthwise separable convolutions, ai-generated phishing, learning rate, double modular redundancy (dmr), model inversion attack
- internet of things (iot), cough analysis technology, tpu origins, failsafe mechanisms, particle accelerator data
- f1 score, tinyml market reality, ai hypercomputers, core ml, blas (basic linear algebra subprograms)
- voice recognition evolution, "attention is all you need", structured pruning, serverless ai, mobilenet
- principle of least privilege, embodied carbon, basic linear algebra subprograms (blas), ml runtimes, model scaling explosion
- ml workflow complexity, relu (rectified linear unit), autopilot, brittleness in ai systems, transferability
- compas algorithm controversy, power usage effectiveness, pruning, model drift detection, hardware lottery
- multimodal sensor data, iot ecosystems, roofline model, tensor operations, edge latency advantage
- mobile system-on-chip, hipaa violations, model cards, collaborative filtering, self-play beyond games
- white-box attacks, ml team role evolution, alphago zero achievement, high-bandwidth memory (hbm), immutable data structures
- attention maps, dp-sgd (differentially private stochastic gradient descent), batch processing evolution, tensorflow vs pytorch, uci ml repository
- alignment failure modes, dense model inefficiency, intel 8087 impact, sdg global impact, nvidia triton inference server
- ml-based fraud detection evolution, neurosymbolic ai, arduino edge computing reality, nvidia nccl (collective communications library), the lab-to-clinic performance gap
- ai carbon footprint, acoustic gunshot detection, energy-aware ai frameworks, puf market growth, data augmentation
- imagenet competition progress, data drift detection, huber loss, computational graphs, workflow automation scale
- viola-jones algorithm, catastrophic forgetting severity, ml systems, canary deployment history, iot device vulnerabilities
- covid-19 ml impact, data poisoning, embedded systems, ml audit requirements, gpt-4 moe implementation
- categorical encoding impact, sparse energy savings, medical device security, 2014-2016 ebola outbreak, edge processor
- 32-bit floating point precision, architectural paradigm shifts, gdpr's ml impact, mlops business impact, matrix multiplication in neural networks
- systems integration philosophy, microcontroller power budget reality, alexnet, batching in neural networks, cuda programming model
- data center climate impact, emergent capabilities at scale, data processing scale, systolic array, local explanations
- lookup table, google data centers, automatic vectorization, rlhf pipeline complexity, google's carbon-free commitment
- hipaa (health insurance portability and accountability act), green500, ensemble methods, phase transition, learning rate schedules
- power usage effectiveness (pue), mlperf benchmarking, mobilenet innovation, onnx deployment, gradient checkpointing
- model repositories, gpu operational costs, backdoor attacks, production alert thresholds, dennard scaling
- tensorflow, perplexity, carbon-aware computing, cascade of classifiers, rag implementation scale
- gpt-3 energy consumption, fp32, flops, lora technology, feature engineering
- tinyml, wafer-scale engine specifications, experiment tracking evolution, quantization-aware training, chinese rare earth dominance
- oauth protocol, autoregressive, operation fusion, cray-1 vector legacy, carbon emissions
- model distillation, advanced encryption standard (aes), tinytl memory breakthrough, medical ai performance metrics, technical debt origins
- spec power, synapses, distributed training costs, strassen's algorithm, bert
- operator fusion, plantvillage nuru real-world impact, translation invariance, data as code, euv lithography
- iot device growth, parameter sharing, single event upsets (seus), obd-ii ports, efficientnet pruning
- eniac (electronic numerical integrator and computer), stochastic gradient descent, shap in production, tensorflow model optimization, attention scaling
- tensorflow lite, model quantization, mysql at scale, differential power analysis (dpa), a11 bionic breakthrough
- ai's sdg impact potential, transformer + nas environmental impact, train-serve split economics, normalization in ml, tinyml model compression
- model serialization, ai for climate action, gpt-3, click-through rate (ctr) optimization, energy star
- flops (floating-point operations), gpt-4 tool use, alignment technical challenges, memory optimization, thermal imaging in disaster response
- memory hierarchy challenge, model compression, lightweight transformers, transient vs permanent faults, onnx runtime
- explainability market growth, google tpus, post-hoc explanations, knowledge distillation, reasoning architecture requirements
- mnist, tpu (tensor processing unit), jupyter notebooks, healthcare ml compliance, data quality reality
- chain-of-thought emergence, transformer batch size scaling, deployment environments, systemic bias, air-gapped systems
- gans for adversarial attacks, apache beam architecture, devops origins, systemic vulnerabilities, formula 1 engineering
- mainframes, feature store scale, paradigm shift, rlhf effectiveness, meltdown/spectre impact
- ml telemetry, sequential neural networks, backpropagation algorithm, coin-cell batteries, chiplet
- hyperscale data centers, model drift phenomenon, etl vs elt performance, lottery ticket hypothesis, cryptographic hashing
- gradient accumulation impact, arm cortex architecture spectrum, global explanations, non-iid (non-independent and identically distributed), int8
- embodied cognition, usb attack vectors, cybersecurity regulations, error-correcting codes, industry 4.0
- reasoning error propagation, reward hacking, endpoint device constraints, mel-frequency cepstral coefficients (mfccs), moore's law origins
- multi-agent intelligence, data-centric ai, mobile device constraints, distributed training, von neumann architecture
- microservices in ml, black box, near-memory computing, chatgpt user adoption, linear transformations
- bayesian neural networks, model extraction threat