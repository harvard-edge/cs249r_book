# Data Engineering

::: {.callout-note collapse="true"}
## Learning Objectives

* coming soon.

:::

## Introduction

Explanation: This section establishes the groundwork, defining data engineering and explaining its importance and role in Embedded AI. A well-rounded introduction will help in establishing the foundation for the readers.

- Definition and Importance of Data Engineering in AI
- Role of Data Engineering in Embedded AI
- Synergy with Machine Learning and Deep Learning
- Example: keyword spotting

## Problem

Explanation: This section is a crucial starting point in any data engineering project, as it lays the groundwork for the project's trajectory and ultimate success. Here's a brief explanation of why each subsection within the "Problem Definition" is important:

- Identifying the Problem
- Setting Clear Objectives
- Benchmarks for Success
- Stakeholder Engagement and Understanding
- Understanding the Constraints and Limitations of Embedded Systems
  
## Data Sourcing
The quality and type of data gathered can significantly affect the performance of both the trained model and its downstream applications. This is particularly true in embedded systems where computational resources may be limited, necessitating models that are both accurate and efficient. Despite its critical importance, the issue of data quality and sourcing is often overlooked in favor of focusing on model architecture and performance metrics. Generally, data can be sourced from various places depending on the project's objectives. Some common data sources include pre-existing datasets, web scraping, sensors, APIs, and crowdsourcing.

While pre-existing datasets, accessible from platforms like [Kaggle](https://www.kaggle.com/datasets) and [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php), serve as a convenient starting point, they come with their challenges. Often, these datasets are well-curated, documented, and ready for consumption. However, the question remains as to how these datasets were created, labeled, and validated. The methodologies employed in their curation and their inter-annotator reliability metrics are rarely scrutinized, leaving questions of bias, validity, and reproducibility unanswered.

Crowdsourcing is an effective method, particularly suited for tasks requiring human judgment. Platforms like [Amazon's Mechanical Turk](https://www.mturk.com/) enable the distribution of micro-tasks to a broad audience who can assist in labeling or annotating data. However, it's crucial to note the importance of transparency in how data is sourced and validated. Detailed information about annotation criteria and protocols should be readily available to ensure both accountability and interpretability.

This method is widely used for various tasks such as sentiment analysis and image recognition, which may require human interpretation for nuanced understanding. For example, the [ImageNet project](http://www.image-net.org/) sourced candidate images online and then used crowdsourcing to categorize them into thousands of object classes. While this approach leverages massive parallelism for time-efficiency, challenges persist in ensuring consistent quality across annotations.

Another example is [Mozilla's Common Voice project](https://commonvoice.mozilla.org/en), which has successfully gathered a publicly accessible dataset of diverse voice recordings. Volunteers contribute by recording phrases in different languages and accents and also validate the submissions of others.

Data can also be directly sourced from the field through sensors or devices, especially in the context of embedded systems or IoT devices. For instance, a weather station might collect real-time data on temperature, humidity, and wind speed. Such data is often raw and must be pre-processed before it can be utilized in a machine learning model. It's crucial to maintain a high standard of data quality for reliable machine learning outcomes. Documentation of the origin and methods used for data collection can enhance transparency and accountability.

APIs offer another channel for data collection. Various services like [Twitter](https://developer.twitter.com/en/docs/twitter-api), [Google](https://developers.google.com/products), or financial platforms provide APIs through which data can be collected programmatically. This allows for real-time data sourcing and can be customized to collect only the information that is relevant to the project.


## Data Processing
Once data is collected, it must be processed to transform it into a usable format. For instance, the Multilingual Spoken Words Corpus (MSWC) used a forced alignment method that extracts individual word recordings to train keyword spotting models, from the Common Voice project which features crowdsourced sentence-level recordings.

The MSWC serves as an example of data pipelines - systematic and automated workflows that handle the transformation, storage, and processing of data for machine learning tasks. By streamlining the entire data flow, from raw data to usable datasets, data pipelines enhance productivity and facilitate the rapid development of machine learning models.

Generally, since data often comes from diverse sources and can be unstructured or semi-structured, it's essential to process and standardize it to ensure it adheres to a uniform format. Such transformations may include normalizing numerical variables, encoding categorical variables, and even using techniques like dimensionality reduction.

The process of data cleaning and transformation involves refining data to remove inconsistencies, duplications, and inaccuracies. For instance, in the MSWC data, the underlying crowd-sourced recordings are conducted in uncontrolled environments using computers and mobile devices. These recordings frequently feature background noises such as static, wind, mouse clicks, and other voices. Depending on the requirements of the models being trained, unwanted noise or malfunctions can either be removed or intentionally retained.

Data Validation ensures that the dataset adheres to certain standards, like temperature values not falling below absolute zero. Handling Missing Values involves filling gaps in the dataset through techniques such as mean imputation or interpolation to ensure models train effectively. Outlier Detection focuses on spotting and managing anomalous data points that could adversely affect model performance. Data Provenance keeps track of the origins of each data point for improved transparency and analysis.

Maintaining the integrity of the data infrastructure is a continuous endeavor. This encompasses data storage, security, error handling, and stringent version control. Periodic updates are crucial, especially in dynamic realms like keyword spotting, to adjust to evolving linguistic trends and device integrations.

As the data sources and types proliferate, the demand for more data pipelines intensifies, emphasizing the need for robust support and maintenance. Hence, it's imperative to employ consistent design patterns and automation, which aid in seamless debugging and upkeep should challenges emerge.



## Feature Engineering

Explanation: Feature engineering involves selecting and transforming variables to improve the performance of AI models. It's vital in embedded AI systems where computational resources are limited, and optimized feature sets can significantly improve performance.

- Importance of Feature Engineering 
- Techniques of Feature Selection 
- Feature Transformation for Embedded Systems
- Embeddings
- Real-time Feature Engineering in Embedded Systems

## Data Labeling

Explanation: Labeling is an essential part of preparing data for supervised learning. This section focuses on various strategies and tools available for data labeling, a vital process in the data preparation phase.

- Manual Data Labeling 
- Ethical Considerations (e.g. OpenAI issues)
- Automated Data Labeling 
- Labeling Tools 

## Data Version Control

Explanation: Version control is critical for managing changes and tracking versions of datasets during the development of AI models, facilitating reproducibility and collaboration.

- Version Control Systems 
- Metadata 

## Optimizing Data for Embedded AI

Explanation: This section concentrates on optimization techniques specifically suited for embedded systems, focusing on strategies to reduce data volume and enhance storage and retrieval efficiency, crucial for resource-constrained embedded environments.

- Low-Resource Data Challenges
- Data Reduction Techniques 
- Optimizing Data Storage and Retrieval 

## Challenges in Data Engineering

Explanation: Understanding potential challenges can help in devising strategies to mitigate them. This section discusses common challenges encountered in data engineering, particularly focusing on embedded systems.

- Scalability 
- Data Security and Privacy 
- Data Bias and Representativity 

## Promoting Transparency

Explanation: We explain that as we increasingly use these systems built on the foundation of data, we need to have more transparency in the ecosystem.

- Definition and Importance of Transparency in Data Engineering
- Transparency in Data Collection and Sourcing
- Transparency in Data Processing and Analysis
- Transparency in Model Building and Deployment
- Transparency in Data Sharing and Usage
- Tools and Techniques for Ensuring Transparency

## Licensing

Explanation: This section emphasizes why one must understand data licensing issues before they start using the data to train the models.

- Metadata
- Data Nutrition Project
- Understanding Licensing 

## Conclusion

Explanation: Close up the chapter with a summary of the key topics that we have covered in this section.

- The Future of Data Engineering in Embedded AI 
- Key Takeaways

## Helpful References
1. [DataPerf: Benchmarks for Data-Centric AI Development](https://arxiv.org/abs/2207.10062)
2. [Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993)
3. [Multilingual Spoken Words Corpus](https://openreview.net/pdf?id=c20jiJ5K2H)
4. [Common Voice: A Massively-Multilingual Speech Corpus](https://arxiv.org/abs/1912.06670)
5. [Data Engineering for Everyone](https://arxiv.org/abs/2102.11447)

