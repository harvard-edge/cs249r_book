Chapter,Figure Number,Label,Caption,Alt-Text
"Introduction","1.1","fig-ai-timeline","**AI Development Timeline.** A chronological curve traces AI research activity from the 1950s to the 2020s, with gray bands marking the two AI Winter periods (1974 to 1980, 1987 to 1993). Callout boxes highlight key milestones including the Turing Test [@turing1950computing], the Dartmouth conference [@mccarthy1955dartmouth], the Perceptron, ELIZA, Deep Blue, and GPT-3.","Timeline from 1950 to 2020 with red line showing AI publication frequency. Gray bands mark two AI Winters (1974-1980, 1987-1993). Callout boxes mark milestones: Turing 1950, Dartmouth 1956, Perceptron 1957, ELIZA 1966, Deep Blue 1997, GPT-3 2020."
"Introduction","1.2","fig-alexnet","**AlexNet Architecture.** The network that launched the deep learning revolution at ImageNet 2012. Two parallel GPU streams process 224x224 input images through convolutional layers (green blocks) that extract spatial features at decreasing resolutions, converging through three fully connected layers to 1,000 output classes. With 60 million parameters trained across two GTX 580 GPUs, AlexNet achieved 15.3% top-5 error, a 42% relative improvement over the second-place entry.","3D diagram of AlexNet with two parallel GPU streams. Green blocks show convolutional layers decreasing from 224x224 input. Red kernels overlay green blocks. Right side shows three dense layers converging to 1000 outputs."
"Introduction","1.3","fig-ai-triad","**The AI Triad**: Interdependent relationship between Data, Algorithm, and Machine. Each node (dataset, model, and infrastructure) constrains the capabilities of the others. ML systems engineering is the discipline of balancing this triad; optimizing one component in isolation often shifts the system bottleneck to another vertex rather than eliminating it.","Triangle diagram with three circles at vertices labeled Model, Data, and Machine. Double-headed purple arrows connect all three nodes, showing bidirectional dependencies. Icons inside circles depict neural network, database cylinders, and cloud."
"Introduction","1.4","fig-evolution-efficiency","**Historical Efficiency Trends.** A three-track timeline from 1980 to 2023 shows parallel progress in Algorithmic Efficiency (blue), Compute Efficiency (yellow), and Data Selection (green). Each track progresses through distinct eras: algorithms advance from early methods through deep learning to modern efficiency techniques; compute evolves from general-purpose CPUs through accelerated hardware to sustainable computing; data practices shift from scarcity through big data to data-centric AI.","Timeline with three horizontal tracks from 1980 to 2023. Blue track shows Algorithmic Efficiency progressing through Deep Learning Era to Modern Efficiency. Yellow shows Compute Efficiency from General-Purpose through Accelerated to Sustainable Computing. Green shows Data Selection from Scarcity through Big Data to Data-Centric AI."
"Introduction","1.5","fig-ml_lifecycle_overview","**ML System Lifecycle.** A six-box flowchart depicting Data Collection, Preparation, Model Training, Evaluation, Deployment, and Monitoring. Two feedback loops distinguish this cycle from linear software development: evaluation returns to preparation when results is insufficient, and monitoring triggers new data collection when performance degrades.","Flowchart showing cyclical ML lifecycle. Six boxes: Data Collection, Preparation, Model Training, Evaluation, Deployment, Monitoring. Two loops: evaluation returns to preparation; monitoring triggers collection."
"Introduction","1.6","fig-pillars","Five-Pillar Framework.\index{Five-Pillar Framework!disciplines} Five labeled columns represent Data Engineering, Training Systems, Deployment Infrastructure, Operations and Monitoring, and Ethics and Governance. The pillars rest on a shared foundation labeled Performance Optimization and Hardware Acceleration, indicating the technical imperatives that support all five disciplines.","Five pillars diagram: Data Engineering, Training Systems, Deployment Infrastructure, Operations and Monitoring, Ethics and Governance. Pillars rest on foundation labeled Performance Optimization and Hardware Acceleration."
"Ml Systems","2.1","fig-cloud-edge-TinyML-comparison","**Distributed Intelligence Spectrum**: Machine learning deployment spans from centralized cloud infrastructure to resource-constrained TinyML devices, each balancing processing location, device capability, and network dependence. Source: [@abiresearch2024tinyml].","Horizontal spectrum showing 5 deployment tiers from left to right: ultra-low-power devices and sensors, intelligent device, gateway, on-premise servers, and cloud. Arrows indicate TinyML, Edge AI, and Cloud AI spans across the spectrum."
"Ml Systems","2.2","fig-cloud-ml","**Cloud ML Decomposition.** Characteristics, benefits, challenges, and representative applications of cloud machine learning, where centralized infrastructure and specialized hardware address scale, complexity, and resource management for large datasets and complex computations.","Tree diagram with Cloud ML branching to four categories: Characteristics, Benefits, Challenges, and Examples. Each lists items like computational power, scalability, vendor lock-in, and virtual assistants."
"Ml Systems","2.3","fig-cloudml-example","Cloud Data Center Scale: Rows of server racks illuminated by blue LEDs extend across a Google Cloud TPU data center floor, housing thousands of specialized AI accelerator chips that collectively deliver petaflop-scale training throughput. Source: [@google2024gemini].","Aerial view of Google Cloud TPU data center with long rows of server racks illuminated by blue LEDs extending toward the horizon across a large facility floor."
"Ml Systems","2.4","fig-edge-ml","**Edge ML Decomposition.** Characteristics, benefits, challenges, and representative applications of edge machine learning, where decentralized processing on nearby hardware reduces latency and network dependence at the cost of constrained compute and memory.","Tree diagram with Edge ML branching to four categories: Characteristics, Benefits, Challenges, and Examples, listing items like decentralized processing, reduced latency, security concerns, and industrial IoT."
"Ml Systems","2.5","fig-edgeml-example","Edge Device Deployment: Diverse IoT devices, from wearables to home appliances, enable decentralized machine learning by performing inference locally, reducing reliance on cloud connectivity and improving response times. Source: Edge Impulse.","Collection of IoT devices arranged on a surface: smart home sensors, fitness wearables, environmental monitors, and connected appliances in various sizes and form factors."
"Ml Systems","2.6","fig-mobile-ml","**Mobile ML Decomposition.** Characteristics, benefits, challenges, and representative applications of mobile machine learning, where on-device processing and hardware acceleration balance computational efficiency, battery life, and model performance on smartphones and tablets.","Tree diagram with Mobile ML branching to four categories: Characteristics, Benefits, Challenges, and Examples. Each lists items like on-device processing, real-time response, battery constraints, and voice recognition."
"Ml Systems","2.7","fig-TinyML-example","TinyML System Scale: Small development boards, including Arduino Nano BLE Sense and similar microcontroller kits approximately 2 to 5 cm in length, with visible processor chips and pin connectors that enable sensor integration for always-on ML inference at milliwatt power budgets. Source: [@warden2018speech]","Small development boards including Arduino Nano BLE Sense and similar microcontroller kits arranged on a surface, each approximately 2-5 cm in length with visible chips and connectors."
"Ml Systems","2.8","fig-tiny-ml","**TinyML Decomposition.** Characteristics, benefits, challenges, and representative applications of TinyML, where milliwatt power budgets and kilobyte memory limits enable always-on sensing and localized intelligence in embedded applications.","Tree diagram with TinyML branching to four categories: Characteristics, Benefits, Challenges, and Examples, listing items like low-power operation, always-on capability, resource limitations, and predictive maintenance."
"Ml Systems","2.9","fig-op_char","**Paradigm Comparison Radar Plots.** Two radar plots quantify performance and operational characteristics across cloud, edge, mobile, and TinyML paradigms. The left plot contrasts compute power, latency, scalability, and energy efficiency; the right plot contrasts connectivity, privacy, real-time capability, and offline operation.","Two radar plots with four overlapping polygons each. Left plot axes: compute power, latency, scalability, energy. Right plot axes: connectivity, privacy, real-time, offline capability."
"Ml Systems","2.10","fig-mlsys-playbook-flowchart","**Deployment Decision Logic**: This flowchart guides selection of an appropriate machine learning deployment paradigm by systematically evaluating privacy requirements and processing constraints, ultimately balancing performance, cost, and data security. Navigating the decision tree helps practitioners determine whether cloud, edge, mobile, or tiny machine learning best suits a given application.","Decision flowchart with four layers: Privacy, Performance, Compute Needs, and Cost. Each layer filters toward deployment options: Cloud ML, Edge ML, Mobile ML, or TinyML based on constraints."
"Ml Systems","2.11","fig-hybrid","**Hybrid System Interactions**: Data flows upward from sensors through processing layers to cloud analytics, while trained models deploy downward to edge, mobile, and TinyML inference points. Five connection types (deploy, data, results, assist, and sync) establish a distributed architecture where each paradigm contributes unique capabilities.","System diagram with four ML paradigms: TinyML sensors, Edge inference, Mobile processing, and Cloud training. Arrows show deploy, data, results, sync, and assist flows between tiers."
"Ml Systems","2.12","fig-ml-systems-convergence","**Convergence of ML Systems**: Three-layer structure showing how diverse deployments converge. The top layer lists four paradigms (Cloud, Edge, Mobile, TinyML); the middle layer identifies shared foundations (data pipelines, resource management, architecture principles); and the bottom layer presents cross-cutting concerns (optimization, operations, trustworthy AI) that apply across all paradigms.","Three-layer diagram. Top: Cloud, Edge, Mobile, TinyML implementations. Middle: data pipeline, resource management, architecture principles. Bottom: optimization, operations, trustworthy AI. Arrows connect layers."
"Workflow","3.1","fig-ml-lifecycle","**Dual-Pipeline ML Development**: The data pipeline (green, top) progresses from collection through ingestion, analysis, labeling, validation, and preparation. The model pipeline (blue, bottom) takes prepared datasets through training, evaluation, validation, and deployment. Feedback arrows show how monitoring insights inform data refinements, evaluation results trigger model improvements, and deployment experiences reshape collection strategies.","Two parallel pipelines: data pipeline (green, top) with 6 stages from collection to preparation; model pipeline (blue, bottom) with 4 stages. Curved feedback arrows connect deployment back to collection and training stages."
"Workflow","3.2","fig-ds-time","**Data Scientist Time Allocation**: Data preparation consumes up to 60% of data science effort, with data collection accounting for an additional 19%. Model-focused activities such as pattern mining, training set construction, and algorithm refinement together represent roughly 18% of total time. Source: CrowdFlower 2016 Data Science Report.","Pie chart showing data scientist time allocation: 60% cleaning and organizing data, 19% collecting datasets, 9% mining for patterns, 5% building training sets, 4% refining algorithms, 3% other tasks."
"Workflow","3.3","fig-lifecycle-overview","**Simplified Lifecycle with Feedback**: Six stages progress from problem definition through data collection, model development, evaluation, deployment, and monitoring. The feedback loop from monitoring back to data collection captures the essential insight that production insights drive continuous refinement across earlier stages, because data distributions shift, model performance drifts, and operational requirements evolve.","Linear flowchart with 6 boxes: Problem Definition, Data Collection, Model Development, Evaluation, Deployment, Monitoring. Feedback loop arrow curves from Monitoring back to Data Collection."
"Workflow","3.4","fig-eye-dr","Retinal Hemorrhages: Diabetic retinopathy causes visible hemorrhages in retinal images. While this appears to be straightforward image classification, the path from laboratory success to clinical deployment illustrates every aspect of AI lifecycle complexity. Source: Google.","Two side-by-side retinal fundus images: left shows healthy retina, right shows diabetic retinopathy with dark red hemorrhage spots scattered across the retina."
"Workflow","3.5","fig-ml-lifecycle-feedback","**Feedback Paths Across Lifecycle Stages**: Six labeled feedback arrows connect the lifecycle stages. Data gaps identified during evaluation flow back to collection. Validation issues inform training adjustments. Performance insights from monitoring trigger pipeline refinements. Model updates propagate from monitoring to training. Data quality issues feed back to preparation. Deployment constraints propagate backward to influence model design.","Diagram with 6 boxes: Data Collection, Preparation, Training, Evaluation, Deployment, Monitoring. Labeled feedback arrows show data gaps, validation issues, performance insights, and deployment constraints flowing between stages."
"Data Engineering","4.1","fig-cascades","**Data Quality Cascades**: Errors introduced early in the machine learning workflow amplify across subsequent stages, increasing costs and potentially leading to flawed predictions or harmful outcomes. Source: [@sambasivan2021everyone].","Timeline with 7 stages from problem statement to deployment. Colored arcs show errors from data collection propagating to evaluation and deployment stages."
"Data Engineering","4.2","fig-four-pillars","**The Four Pillars of Data Engineering**: Quality, Reliability, Scalability, and Governance form the foundational framework for ML data systems. Each pillar contributes essential capabilities (solid arrows), while trade-offs between pillars (dashed lines) require careful balancing: validation overhead affects throughput, consistency constraints limit distributed scale, privacy requirements impact performance, and bias mitigation may reduce available training data.","Four boxes labeled Quality, Reliability, Scalability, and Governance surround a central ML Data System circle. Solid arrows connect each box to center showing contributions; dashed lines between boxes indicate trade-offs."
"Data Engineering","4.3","fig-keywords","Keyword Spotting System: A voice-activated device uses a lightweight, always-on wake word detector that listens continuously and triggers the main voice assistant upon keyword detection.","Diagram showing voice-activated device with microphone, always-on wake word detector, and connection to main voice assistant that activates upon keyword detection."
"Data Engineering","4.4","fig-misalignment","**Shared Dataset Bias Propagation**: Five models (A through E) all train on a single central dataset repository. Arrows show how shared limitations, biases, and blind spots propagate from the common dataset to every downstream model, leading to correlated failures across the ecosystem.","Five model boxes labeled A through E at center all connect upward to one central training dataset repository. Arrows downward show shared limitations, biases, and blind spots propagating to all models."
"Data Engineering","4.5","fig-traffic-light","Data Source Noise: A black-and-white photograph from 1914 showing early manual semaphore traffic signals, illustrating how historical images can appear in modern web scraping results for contemporary queries. Such anachronistic content requires systematic validation and filtering to prevent spurious correlations in training data. Source: Vox.","Historical black-and-white photograph from 1914 showing early traffic control with manual semaphore signals, illustrating how outdated images can appear in modern web scraping results."
"Data Engineering","4.6","fig-synthetic-data","**Synthetic Data Augmentation**: A four-node pipeline where historical data and simulation outputs feed into a synthetic data generation process, producing an expanded combined training dataset with greater size and diversity than either source alone. Source: AnyLogic [@anylogic_synthetic].","Diagram showing historical data icon and simulation cloud icon both feeding into synthetic data generation process, producing an expanded combined training dataset."
"Data Engineering","4.7","fig-pipeline-flow","**Three-Stage Pipeline Flow**: Raw data sources and APIs feed into batch and stream ingestion at the middle layer, then flow to data warehouse and storage destinations at the bottom. Each stage scales independently, enabling modular quality control across the pipeline.","Three-tier flow diagram with raw data sources and APIs at top, batch and stream ingestion in middle layer, and data warehouse and storage destinations at bottom connected by arrows."
"Data Engineering","4.8","fig-etl-vs-elt","**ETL vs. ELT Comparison**: Side-by-side view of two pipeline paradigms. ETL transforms data before loading into a data warehouse, while ELT loads raw data first and transforms within the warehouse. The choice depends on data volume, transformation complexity, and target storage capabilities.","Side-by-side comparison showing ETL pipeline with extract, transform, then load sequence versus ELT pipeline with extract, load, then transform sequence within the data warehouse."
"Data Engineering","4.9","fig-spectrogram-example","Audio Feature Transformation: Advanced audio features compress raw audio waveforms into representations that emphasize perceptually relevant characteristics for machine learning tasks. This transformation reduces noise and data dimensionality while preserving essential speech information, improving model performance in applications like keyword spotting.","Two-panel visualization showing raw audio waveform on left transforming into spectrogram on right, with time on horizontal axis and frequency on vertical axis indicated by color intensity."
"Data Engineering","4.10","fig-tfx-pipeline-example","**TFX End-to-End Pipeline**: A TensorFlow Extended pipeline traces the complete flow from data ingestion through validation, transformation, training, evaluation, and deployment. Each component is independently versioned, tested, and scaled.","Linear flow diagram showing TensorFlow Extended pipeline: data ingestion, validation, transformation, training, evaluation, and deployment stages connected by arrows from left to right."
"Data Engineering","4.11","fig-labels","Data Annotation Granularity: Three versions of the same street scene show increasing annotation detail: a simple classification label, bounding boxes around vehicles and pedestrians, and pixel-level semantic segmentation with distinct colors. Each level increases labeling cost and storage requirements while providing richer training signal.","Three versions of same street scene showing increasing annotation detail: simple classification label, bounding boxes around vehicles and pedestrians, and pixel-level semantic segmentation with distinct colors."
"Data Engineering","4.12","fig-hard-labels","Labeling Ambiguity: How subjective or difficult examples, such as blurry images or rare species, can introduce errors during data labeling, highlighting the need for careful quality control and potentially expert annotation. Source: [@northcutt2021pervasive].","Grid of example images showing labeling challenges: blurred animal photos where species is unclear, rare specimens requiring expert knowledge, and ambiguous object boundaries causing annotator disagreement."
"Data Engineering","4.13","fig-weak-supervision","**AI-Augmented Labeling Decision Hierarchy**: A top-level question about obtaining labeled data branches into four paths: traditional supervision, semi-supervised learning, weak supervision, and transfer learning, with active learning as a cost-saving alternative. Lower-cost strategies trade labeling precision for throughput. Source: Stanford AI Lab.","Hierarchical diagram with question about getting labeled data at top. Four branches: traditional supervision, semi-supervised, weak supervision, and transfer learning. Active learning branches as cost-saving alternative."
"Data Engineering","4.14","fig-mswc","Multilingual Data Preparation: Forced alignment and segmentation transform paired audio-text data into labeled one-second segments, creating a large-scale corpus for training keyword spotting models across 50+ languages. This automated process enables scalable development of KWS systems by efficiently generating training examples from readily available speech resources like common voice and multilingual captioned content.","Pipeline showing audio waveform and text transcript inputs processed through forced alignment stage, then segmented into individual one-second labeled keyword samples for KWS training."
"Data Engineering","4.15","fig-debug-flowchart","**Data Pipeline Debugging Flowchart**: Four sequential decision nodes guide root cause diagnosis: (1) accuracy degrades over time leads to Data Drift, (2) training accuracy exceeds validation leads to Overfitting, (3) validation exceeds production accuracy leads to Training-Serving Skew, and (4) subgroup inconsistency leads to Bias. If all answers are no, the issue points to Model Architecture.","Vertical flowchart with four blue diamond decision nodes and red result boxes. Top diamond asks if accuracy degrades over time, leading to Data Drift result. Second asks if training accuracy exceeds validation, leading to Overfitting. Third asks if validation exceeds production accuracy, leading to Training-Serving Skew. Fourth asks about subgroup inconsistency, leading to Bias. Gray box at bottom shows Model Architecture issue if all answers are no."
"Dl Primer","5.1","fig-ai-ml-dl","AI Hierarchy: Neural networks form a core component of deep learning within machine learning and artificial intelligence by modeling patterns in large datasets. Machine learning algorithms enable systems to learn from data as a subset of the broader AI field.","Nested circles diagram showing AI as outermost circle containing Machine Learning, which contains Deep Learning, which contains Neural Networks at the center. Arrows indicate progression from broad AI concepts to specific neural network implementations."
"Dl Primer","5.2","fig-breakout","**Breakout Collision Rules**: The game program uses explicit if-then rules for collision detection, specifying ball direction reversal and brick removal upon contact. While effective for a game with clear physics and limited states, this approach illustrates how rule-based systems must anticipate every possible scenario.","Breakout game grid with 3 rows of 5 colored bricks at top, brown paddle at bottom, and ball with trajectory arrow. Code snippet shows explicit if-then rules for collision detection: removeBrick, update ball velocity."
"Dl Primer","5.3","fig-traditional","**Traditional Programming Flow**: Rules and data serve as inputs to a traditional program, which produces answers as output. This input-output pattern formed the basis for early AI systems but lacks the adaptability needed for complex pattern recognition tasks.","Flow diagram with three boxes: Rules and Data as inputs flowing into central Traditional Programming box, which outputs Answers. Arrows show data flow direction from inputs to output."
"Dl Primer","5.4","fig-activity-rules","Activity Classification Decision Tree: A rule-based decision tree classifies human activity by branching on speed thresholds, with values below 4 mph mapped to walking, 4 to 15 mph to running, and above 15 mph to biking. Real-world edge cases and transitions between activities demand increasingly complex branching logic.","Decision tree flowchart for activity classification. Branches split on conditions like speed less than 4 mph leading to walking, 4-15 mph to running, greater than 15 mph to biking. Additional branches handle edge cases and transitions."
"Dl Primer","5.5","fig-hog","HOG Method: Identifies edges in images to create a histogram of gradients, transforming pixel values into shape descriptors that are invariant to lighting changes.","Three-panel image showing HOG feature extraction: original grayscale photo of person on left, gradient magnitude visualization in center, and HOG descriptor grid overlay on right showing edge orientation histograms per cell."
"Dl Primer","5.6","fig-deeplearning","**Data-Driven Rule Discovery**: The flow diagram inverts the traditional programming pattern: data and answers serve as inputs to the machine learning process, which produces learned rules as output. This inversion eliminates the need for manually specified rules and enables automated feature extraction from raw inputs.","Flow diagram with three boxes: Answers and Data as inputs flowing into central Machine Learning box, which outputs Rules. Arrows show inverted flow compared to traditional programming, with rules as output rather than input."
"Dl Primer","5.7","fig-bio_nn2ai_nn","Biological-to-Artificial Neuron Mapping: Side-by-side comparison showing how biological neuron structures map to artificial neuron components. Dendrites correspond to inputs, synapses to weights, the cell body to the summation function, and the axon to the activation output. This mapping established the ""Compute-Aggregate-Activate"" pattern central to neural network design.","Side-by-side comparison of biological neuron and artificial neuron. Left shows biological cell with dendrites, cell body, and axon. Right shows mathematical model with inputs x, weights w, summation node, activation function, and output. Arrows map corresponding components between the two."
"Dl Primer","5.8","fig-trends","Computational Growth: Log-scale scatter plot showing training compute in FLOPS from 1952 to 2022. Computational power grew at a 1.4x rate from 1952 to 2010, then accelerated to a doubling every 3.4 months from 2012 to 2022. Large-scale models after 2015 followed an even faster 10-month doubling cycle, addressing the historical bottleneck of training complex neural networks.","Log-scale scatter plot showing training compute in FLOPS from 1950 to 2022. Points represent AI models, with different colors for pre-deep-learning era, deep learning era, and large-scale models. Trend lines show 1.4x growth before 2010 and 3.4-month doubling after 2012."
"Dl Primer","5.9","fig-virtuous-cycle","**Deep Learning Virtuous Cycle**: Three mutually reinforcing factors, data availability, algorithmic innovations, and computing infrastructure, form a self-reinforcing loop where breakthroughs in one area create opportunities in the others.","Three connected boxes in a cycle: green Data Availability flows to blue Algorithmic Innovations, which flows to red Computing Infrastructure, which loops back to Data Availability. Yellow background box labeled Key Breakthroughs contains all three elements."
"Dl Primer","5.10","fig-perceptron","**Perceptron Architecture**: The fundamental computational unit of neural networks, showing inputs multiplied by weights, summed with bias, and passed through an activation function to produce output.","Perceptron diagram with inputs x1 through xi on left, each connected to weight circles w1j through wij. Weights feed into red summation node, which receives bias b from below. Output z flows to blue sigma activation function box, producing output y-hat on right."
"Dl Primer","5.11","fig-activation-functions","**Common Activation Functions**: Four nonlinear activation functions plotted with their output ranges. Sigmoid maps inputs to $(0,1)$ with smooth gradients, tanh provides zero-centered outputs in $(-1,1)$, ReLU introduces sparsity by outputting zero for negative inputs, and softmax converts logits into probability distributions.","Four plots arranged in 2x2 grid. Top-left: Sigmoid S-curve from 0 to 1. Top-right: Tanh S-curve from -1 to 1. Bottom-left: ReLU showing zero for negative x, linear for positive x. Bottom-right: Softmax showing exponential curve approaching small positive values."
"Dl Primer","5.12","fig-nonlinear","**Linear vs. Nonlinear Decision Boundaries**: Two scatter plots compare classification with and without activation functions. Without activation, a straight line fails to separate the two classes. With a nonlinear activation function applied, the network produces a curved decision boundary that correctly separates the points.","Two scatter plots side by side. Left plot shows cyan and green points with straight red line failing to separate them, labeled NN without Activation Function. Right plot shows same points with curved red decision boundary successfully separating classes, labeled NN with Activation Function."
"Dl Primer","5.13","fig-layers","**Layered Network Architecture**: Deep neural networks transform data through successive layers, enabling the extraction of increasingly complex features and patterns. Each layer applies non-linear transformations to the outputs of the previous layer, ultimately mapping raw inputs to desired outputs.","Neural network diagram showing input layer on left with multiple nodes, two hidden layers in middle with interconnected nodes, and output layer on right. Arrows show data flow from left to right through fully connected layers."
"Dl Primer","5.14","fig-connections","**Fully-Connected Layers**: A three-layer network with dense connections between layers, where each neuron integrates information from all neurons in the preceding layer. Weight matrices between layers determine connection strengths, with labeled values shown on each edge alongside computed activation values at each node.","Three-layer network with 3 green input nodes, 4 blue hidden nodes, and 2 red output nodes. Labeled arrows show weight values on each connection. Input layer shows values 1.0, 5.0, 9.0. Hidden nodes show activation values. Bias values labeled at each layer."
"Dl Primer","5.15","fig-mnist-topology-1","**MNIST Network Topology**: Two panels show the network architecture for digit recognition. Panel (a) displays a 28x28 pixel image of a digit connected through hidden layers to 10 output nodes. Panel (b) shows the same architecture with the input image flattened into a 784-element vector, illustrating how spatial data enters the network.","Two panels showing MNIST digit recognition. Panel a: 28x28 pixel image of digit 7 connected to hidden layer circles, then to 10 output nodes with one highlighted for digit classification. Panel b: Same architecture with flattened 784-pixel vector representation of input image."
"Dl Primer","5.16","fig-forward-propagation","**Training Loop Architecture**: Complete neural network training flow showing forward propagation through layers to generate prediction, comparison with true value via loss function, and backward propagation of gradients through optimizer to update weights and biases.","Neural network training diagram. Left side shows input X flowing through blue, red, and green node layers via forward propagation (red arrow). Right side shows prediction and true value boxes feeding into loss function, which outputs loss score to optimizer, which updates weights and biases. Orange arrow shows backward propagation path."
"Dl Primer","5.17","fig-training-vs-inference","**Inference vs. Training Flow**: During inference, neural networks utilize learned weights for forward pass computation only, simplifying the data flow and reducing computational cost compared to training, which requires both forward and backward passes for weight updates. This streamlined process enables efficient deployment of trained models for real-time predictions.","Two parallel diagrams comparing inference and training. Both show stacked rectangles representing batches feeding into network layers and output nodes. Inference section shows smaller varied batch sizes with dashed outlines. Training section shows larger fixed batches with solid outlines. Network architecture identical in both with fully connected layers."
"Dl Primer","5.18","fig-usps-digit-examples","Handwritten Digit Variability: Real-world handwritten digits exhibit significant variations in stroke width, slant, and character formation, posing challenges for automated recognition systems like those used by the USPS. These examples demonstrate the need for effective feature extraction and model generalization to achieve high accuracy in optical character recognition (OCR) tasks.","Grid of handwritten digit samples from USPS dataset showing digits 0-9 in multiple rows. Each digit appears in several variations demonstrating different handwriting styles, stroke widths, slants, and character formations that OCR systems must recognize."
"Dl Primer","5.19","fig-usps-inference-pipeline","**USPS Inference Pipeline**: The mail sorting pipeline combines traditional computing stages (green) with neural network inference (blue). Raw envelope images undergo preprocessing, including thresholding, segmentation, and normalization, before the neural network classifies individual digits. Post-processing applies confidence thresholds and formats sorting instructions for the physical sorting machinery.","Linear pipeline with 6 boxes connected by arrows. From left: Raw Input and Pre-processing in green Traditional Computing section, Neural Network in orange Deep Learning section, then Raw Output, Post-processing, and Final Output in green Traditional Computing section."
"Dnn Architectures","6.1","fig-mlp","**Multi-Layer Perceptron Architecture**: Three fully-connected layers where every neuron connects to all neurons in adjacent layers. The highlighted neuron receives weighted contributions from all inputs, illustrating the dense $O(N \times M)$ connectivity pattern implemented through matrix multiplications. For MNIST classification, a 784-dimensional input connects to 100 hidden neurons through a $784 \times 100$ weight matrix, requiring 78,400 multiply-accumulate operations per sample. Adapted from [@reagen2017deep].","Three-layer neural network with 4 input nodes, 5 hidden nodes, and 2 output nodes. Lines connect every node to all nodes in adjacent layers. One highlighted node shows weighted connections from all inputs, demonstrating dense O(N x M) connectivity."
"Dnn Architectures","6.2","fig-cnn-spatial-processing","**Spatial Feature Extraction**: Convolutional neural networks identify patterns independent of their location in an image by applying learnable filters across the input, enabling robust object recognition. These filters detect local features, and their repeated application across the image creates translation invariance, the ability to recognize a pattern regardless of its position.","Two identical zebra images at different positions in input frames. Arrows show same filter applied to both, producing matching feature activations. Demonstrates translation invariance: detecting patterns regardless of spatial position in image."
"Dnn Architectures","6.3","fig-cnn","",""
"Dnn Architectures","6.4","fig-rnn","",""
"Dnn Architectures","6.5","fig-transformer-attention-visualized","**Attention Weights Visualization**: Attention head (layer 4, head 2) resolving the pronoun \","Sentence tokens listed vertically with cyan attention lines from highlighted word they connecting to all other tokens. Thick lines to student and finish show high attention weights. Demonstrates pronoun-referent linking across arbitrary distances."
"Dnn Architectures","6.6","fig-attention","**Query-Key-Value Attention Mechanism**: For a 6-token sequence, queries (cyan) match against keys (red) to produce a $6 \times 6$ attention matrix with $O(N^2)$ entries. Color intensity indicates attention weight: darker cells show stronger relationships. Each output position aggregates information from all values (green) weighted by its attention row. The matrix structure reveals both the computational pattern (36 similarity computations) and the memory bottleneck (storing $N^2$ attention weights). Source: Transformer Explainer [@transformer_explainer].","6x6 attention matrix with gradient coloring from blue to red indicating attention weights. Cyan query vectors enter from left, red key vectors from top, green value vectors from below. Output vectors exit right, showing weighted aggregation pattern."
"Dnn Architectures","6.7","fig-attention-weightcalc","**QKV Projection Computation**: The embedding matrix $(6 \times 768)$ multiplies with QKV weight matrices $(768 \times 2304)$ plus bias to produce combined projections $(6 \times 2304)$. The 2304 output dimension contains concatenated query, key, and value projections (each 768-dimensional). This single batched matrix multiplication, requiring $6 \times 768 \times 2304 = 10.6$ million MACs, replaces three separate projection operations for efficiency. Source: Transformer Explainer [@transformer_explainer].","Matrix multiplication: 6x768 embedding times 768x2304 QKV weights plus 2304 bias equals 6x2304 output. Blue and red regions show concatenated query, key, value projections. Token labels Data, visualization, em, powers, users, to."
"Dnn Architectures","6.8","fig-transformer","",""
"Dnn Architectures","6.9","fig-example-skip-connection","",""
"Dnn Architectures","6.10","fig-im2col-diagram","**im2col Transformation**: Converts convolution to GEMM by rearranging image patches into columns. The input feature maps (cyan/orange grids, $3 \times 3$) are unfolded so each sliding window position becomes a matrix column, while filter kernels (green/yellow, $2 \times 2$) become rows. The resulting $4 \times 8$ matrix multiplication produces all output positions in one operation. This transformation trades 2x memory overhead (duplicating overlapping pixels) for 5-10x speedup by leveraging decades of BLAS optimizations and enabling efficient GPU parallelization.","Left: two 3x3 input feature maps in cyan and orange. Center: 4x8 transformed matrix with unfolded patches as columns. Right: 8x1 filter kernel vector. Red boxes highlight how sliding windows become matrix columns for GEMM."
"Dnn Architectures","6.11","fig-collective-comm","**Data Movement Primitives**: Four fundamental patterns govern information flow in neural network computation. **Broadcast** (top-left) replicates a single value to all destinations, used when sharing weights across batch elements. **Scatter** (top-right) distributes distinct elements to different destinations, enabling work partitioning. **Gather** (bottom-left) collects distributed values to a single location, as in attention pooling. **Reduction** (bottom-right) combines multiple values through aggregation (sum, max), appearing in gradient synchronization and attention scoring. Moving data typically costs 100-1000x more energy than computation, making these patterns critical optimization targets.","Four diagrams with nodes and arrows. Broadcast: one red square to four nodes. Scatter: four colored squares to four nodes. Gather: four nodes with colored squares to one. Reduction: four colored nodes combine through aggregation to one."
"Dnn Architectures","6.12","fig-dnn-fm-framework","**Architecture Selection Decision Framework**: A systematic flowchart for choosing neural network architectures based on data characteristics and deployment constraints. The process begins with data type identification (text/sequences/images/tabular) to select initial architecture candidates (Transformers/RNNs/CNNs/MLPs), then iteratively evaluates memory budget, computational cost, inference speed, accuracy targets, and hardware compatibility.","Flowchart from Define Problem branching by data type to Transformers, RNNs, CNNs, or MLPs. Diamond nodes check memory, compute, speed, accuracy, deployment. No paths loop to scale down or increase capacity. Yes path leads to selected."
"Frameworks","7.1","fig-mlfm-timeline","**Computational Library Evolution**: Modern machine learning frameworks build upon decades of numerical computing advancements, transitioning from low-level routines like BLAS and LAPACK to high-level abstractions in NumPy and SciPy, and finally to deep learning frameworks such as Theano [@bergstra2010theano], TensorFlow, and PyTorch. SciPy was first released in 2001; the timeline shows its adoption alongside Theano in the 2007 period when both contributed to establishing Python","Horizontal timeline from 1979 to 2018 with colored boxes marking key years. Dashed arrows connect to milestones below: 1979 BLAS introduced, 1992 LAPACK extends BLAS, 2006 NumPy becomes Python"
"Frameworks","7.2","fig-comp-graph","**Simple Computational Graph.** A directed acyclic graph representing the computation $z = x \\times y$, where nodes define operations and edges specify the flow of data between them.","Simple directed graph with nodes x and y flowing into function f(x,y) which outputs z."
"Frameworks","7.3","fig-mlfm-comp-graph","**Computation Graph with System Interactions.** A neural network represented as a directed acyclic graph (left), with system components including memory management and device placement (right) that interact with the graph to optimize resource allocation before execution.","Left side shows computational graph with 6 operation nodes connected by data flow edges. Right side shows system components box with Memory Management and Device Placement nodes that interact with the computational graph."
"Frameworks","7.4","fig-mlfm-dynamic-graph-flow","**Dynamic Graph Execution Flow**: In eager execution, each operation is defined and immediately executed before the next operation begins. This define-by-run model enables natural debugging and data-dependent control flow at the cost of optimization opportunities.","Flow diagram showing Start to Operation 1 to Operation 1 Executed to Operation 2 to Operation 2 Executed to End. Above arrows show Define Operation, Execute Operation, Define Next Operation, Execute Operation, Repeat Until Done."
"Frameworks","7.5","fig-mlfm-static-graph","**Static Graph: Define then Execute.** The two phases of static graph execution. The definition phase (left) declares operations and builds the graph. The execution phase (right) loads data, runs the optimized graph, and produces results.","Flow diagram showing two phases. Definition Phase: Define Operations, Declare Variables, Build Graph. Execution Phase: Load Data, Run Graph, Get Results. Arrows connect boxes left to right."
"Frameworks","7.6","fig-tensor-data-structure-a","**Tensor Rank Hierarchy.** Four shapes illustrating tensor ranks from left to right: a single value (rank 0, scalar), a column of values (rank 1, vector), a grid of values (rank 2, matrix), and a cube of values (rank 3, three-dimensional tensor).","Four shapes showing tensor ranks left to right: single box labeled Rank 0, vertical column of numbers labeled Rank 1, 2D grid of numbers labeled Rank 2, and 3D cube labeled Rank 3."
"Frameworks","7.7","fig-tensor-data-structure-b","**Image as RGB Tensor.** Three stacked grids representing the red, green, and blue color channels of an image, with dimension labels showing width, height, and channel depth forming a rank-3 tensor. *Credit: Niklas Lang [https://towardsdatascience.com/what-are-tensors-in-machine-learning-5671814646ff](https://towardsdatascience.com/what-are-tensors-in-machine-learning-5671814646ff)*.","Three stacked 3x3 grids in red, green, and blue representing RGB color channels. Dimension labels show width 3 pixels, height 3 pixels, and 3 color channels forming a 3D tensor for image data."
"Frameworks","7.8","fig-tensor-memory-layout","**Tensor Memory Layout**: A 2×3 tensor can be stored in linear memory using either row-major (C-style) or column-major (Fortran-style) ordering. Strides define the number of elements to skip in each dimension when moving through memory, enabling frameworks to calculate memory addresses for tensor[i,j] as base_address + i×stride[0] + j×stride[1]. The choice of memory layout significantly impacts cache performance and computational efficiency.","Left: 2x3 tensor grid with values 1-6. Right: two linear arrays showing row-major layout (1,2,3,4,5,6) and column-major layout (1,4,2,5,3,6). Below: stride calculations for row-major [3,1] and column-major [1,2]."
"Frameworks","7.9","fig-3d-parallelism","**3D Parallelism.** A grid of eight accelerator clusters arranged in two rows and four columns, each containing stacked computational units. Distinct colors encode the three parallelism dimensions: data parallelism across columns, pipeline parallelism across rows, and model parallelism within each cluster.","Grid of 8 GPU clusters in 2 rows and 4 columns. Each cluster contains 4 stacked cubes. Colors vary: blue, red, green, orange in bottom row; olive, yellow, brown, pink in top row."
"Frameworks","7.10","fig-mlfm-core-ops","**Core Operations Stack.** Three grouped layers showing how frameworks bridge Python code to hardware. The top layer contains system-level operations (scheduling, memory management, resource optimization), the middle layer holds numerical operations (GEMM, BLAS, element-wise), and the bottom layer provides hardware abstraction (kernel management, memory abstraction, execution control).","Three grouped boxes connected by arrows. System-Level: Scheduling, Memory Management, Resource Optimization. Numerical: GEMM, BLAS, Element-wise Operations. Hardware: Kernel Management, Memory Abstraction, Execution Control."
"Frameworks","7.11","fig-tensorflow-architecture","**TensorFlow Training-to-Deployment Pipeline.** Two-column diagram showing the training path (left) from data preprocessing through tf.keras and distribution strategy across CPU, GPU, and TPU, and the deployment path (right) from SavedModel export to TensorFlow Serving, Lite, JS, and language bindings. Source: [TensorFlow.](https://blog.tensorflow.org/2019/01/whats-coming-in-tensorflow-2-0.html).","Two-column diagram. Training: data preprocessing, tf.keras, TensorFlow Hub, Premade Estimators, Distribution Strategy across CPU/GPU/TPU. Deployment via SavedModel to TensorFlow Serving, Lite, JS, and language bindings."
"Frameworks","7.12","fig-onnx","Framework Interoperability: ONNX enables model portability across frameworks, allowing training in one framework and deployment in another.","Hub diagram with ONNX logo at center. Left side: PyTorch, TensorFlow, Keras with arrows pointing inward. Right side: TF Lite, ONNX Runtime with arrows outward."
"Training","8.1","fig-activation-perf","**Activation Function Execution Time**: CPU benchmarks on Apple M2 hardware reveal significant variation: Tanh completes in 0.61 seconds, ReLU in 0.45 seconds, Softmax in 0.91 seconds, and Sigmoid in 1.10 seconds. These differences directly affect training throughput and real-time inference latency, making activation function selection a system-level design decision.","Bar chart comparing CPU execution times: Sigmoid at 1.1 seconds, Tanh at 0.61 seconds, ReLU at 0.45 seconds, and Softmax at 0.91 seconds."
"Training","8.2","fig-training-pipeline","**Training System Overview**: Machine learning systems organize training through interconnected data, training, and evaluation pipelines. Data flows sequentially through these components, with evaluation metrics providing feedback to guide iterative model refinement and ensure reproducible results.","Block diagram with three connected boxes: Data Pipeline, Training Loop, and Evaluation Pipeline. Arrows show data flow with feedback from evaluation."
"Training","8.3","fig-training-loop","**Single-GPU Training Loop**: The three sequential steps of one training iteration: the forward pass generates predictions, gradient computation propagates error signals backward, and the optimizer applies parameter updates. GPUs parallelize the underlying matrix operations, accelerating both the forward and backward passes.","Neural network diagram showing data cylinders feeding into a network of connected nodes. A GPU box at bottom processes the forward and backward pass computations."
"Training","8.4","fig-data-pipeline","**CPU-to-GPU Data Flow**: Three distinct zones compose the data pipeline: the storage zone houses raw data on disk, the CPU preprocessing zone handles format conversion, processing, and batching, and the GPU training zone distributes preprocessed batches across multiple GPU workers for parallel computation.","Block diagram showing data flow through three zones: Storage Zone with raw data, CPU Preprocessing Zone with format, process, and batch stages, and GPU Training Zone with three GPU workers."
"Training","8.5","fig-galore-llm-memory-breakdown","**Memory Footprint Breakdown**: Memory usage of LLaMA-7B across four optimizer configurations, decomposed into weights, activations, optimizer state, weight gradients, and other components. The dashed red line marks the RTX 4090 24 GB memory limit, illustrating how standard Adam exceeds single-GPU capacity while GaLoRE compression reduces optimizer state enough to fit within this budget.","Stacked horizontal bar chart comparing memory usage across four optimizers for LLaMA-7B. Shows components: others, weight gradient, optimization, activation, and weight. Dashed red line marks RTX 4090 memory limit at 24 GB."
"Training","8.6","fig-tf-bottleneck-trace","Data-Bound Profiler Trace: TensorFlow profiler output capturing a data loading bottleneck during training. The gaps in GPU activity (white regions between compute blocks) indicate periods where the device idles while waiting for input data, with utilization dropping to zero during data loading phases.","TensorFlow profiler screenshot showing GPU activity timeline. Colored blocks indicate computation periods with white gaps revealing idle time when GPU waits for data loading to complete."
"Training","8.7","fig-optimization-flowchart","**Training Optimization Decision Flowchart**: Systematic approach to optimization selection based on profiling results. Begin by measuring GPU utilization, then follow the decision path to identify whether the bottleneck is data-bound, memory-bound, or compute-bound. Each path leads to specific techniques that address the identified constraint.","Flowchart showing optimization decision tree starting from Profile Training Run, branching based on GPU utilization and memory pressure to different optimization techniques."
"Training","8.8","fig-fetching-naive","**Sequential Data Fetching**: File open, read, and train operations execute serially across two epochs, with the GPU remaining idle during all file operations. The full sequential pipeline spans approximately 90 seconds, establishing the baseline that overlapped prefetching improves upon.","Gantt chart showing sequential data pipeline over two epochs. Four rows: Open, Read, Train, and Epoch. Operations execute serially with gaps between phases, spanning from 00:00 to 01:30."
"Training","8.9","fig-fetching-optimized","**Overlapped Data Prefetching**: Read and train operations execute concurrently, with each time slice overlapping data loading for the next batch with computation on the current batch. Two epochs complete in approximately 55 seconds compared to 90 seconds with sequential fetching, a 40% speedup.","Gantt chart showing optimized pipeline with overlapping operations. Read and Train execute in parallel across time slices. Two epochs complete in approximately 55 seconds total."
"Training","8.10","fig-mixed-precision","**Mixed Precision Training**: The seven-step cycle: (1) FP32 master weights convert to FP16 for the forward pass, (2) loss is scaled to prevent gradient underflow, (3) backpropagation computes scaled FP16 gradients, (4) gradients copy to FP32, (5) loss scaling is removed, (6) FP32 gradients update master weights, and (7) the cycle repeats. This approach achieves Tensor Core speedups while preserving numerical stability.","Flowchart showing 7-step mixed precision training cycle. FP32 master weights convert to FP16 for forward pass, loss scaling protects gradients during backpropagation, then gradients update FP32 weights."
"Training","8.11","fig-grad-accumulation","**Gradient Accumulation**: Three micro-batches each compute independent losses and gradients, which sum into a single combined gradient for one parameter update. This simulates training with a batch three times larger without requiring the memory to hold all samples simultaneously.","Block diagram showing three batches computing individual losses and gradients. Arrows flow from Batch 1, 2, 3 through Losses to Gradients boxes, then combine into a single summed gradient output."
"Training","8.12","fig-activation-checkpointing","**Activation Checkpointing**: Trading memory usage for recomputation during backpropagation enables training deeper neural networks. By storing only a subset of activations from the forward pass and recomputing others on demand, this technique reduces peak memory requirements at the cost of increased training time.","Two-row diagram showing activation checkpointing. Top row: forward pass with checkpointed nodes (filled) and discarded nodes (dashed). Bottom row: backward pass recomputing discarded activations from checkpoints."
"Training","8.13","fig-evolution-systems","**Computing System Evolution**: Hardware advancements continuously adapted to the increasing demands of machine learning workloads, transitioning from centralized mainframes to specialized architectures optimized for parallel processing and massive datasets.","Timeline spanning 1950s to 2020s showing evolution from mainframes through HPC and warehouse-scale computing to AI hypercomputing with GPUs and TPUs."
"Training","8.14","fig-train-data-parallelism","**Data Parallelism**: Each GPU holds a complete model copy, processes different data batches, then synchronizes gradients. This approach scales training throughput linearly with GPU count when models fit in single-GPU memory.","Diagram showing input data splitting into 4 batches, each assigned to a GPU for forward/backward pass, with gradients aggregating for model update."
"Training","8.15","fig-model-parallelism","**Model Parallelism**: The model is partitioned across devices, with intermediate activations passing between them. This enables training models larger than single-GPU memory at the cost of sequential dependencies.","Diagram showing input flowing through model parts on different devices, with forward pass going right and backward pass returning left."
"Training","8.16","fig-layers-blocks","**Layer-wise Partitioning**: A 24-layer transformer distributed across four devices, with each device responsible for six consecutive transformer blocks. Communication occurs only at partition boundaries.","Diagram showing transformer blocks 1-6 on GPU 1, blocks 7-12 on GPU 2, blocks 13-18 on GPU 3, and blocks 19-24 on GPU 4."
"Data Selection","9.1","fig-running-out-of-human-data","Dataset Growth Approaching Limits: Foundation models are increasingly trained on vast datasets, approaching the total stock of human-generated text. Current projections suggest that high-quality public text data faces exhaustion on a near-term horizon, forcing a shift toward data selection, synthetic generation, and multimodal learning. Source: @villalobos_ho_sevilla_besiroglu_heim_hobbhahn_2024.","Line chart showing dataset size in tokens on y-axis from 10^10 to 10^14 versus year on x-axis from 2010 to 2030. Blue line shows training data growth with markers for models like GPT-2, GPT-3, and Chinchilla. Orange shaded region shows projected high-quality text exhaustion in the near term."
"Data Selection","9.2","fig-optimization-triad","**The Optimization Triad**: Machine learning performance relies on three pillars: Algorithms (models), Systems (hardware/software), and Data Selection. While algorithms and systems have traditionally received the most attention, optimizing data selection (Input Optimization) offers a third, powerful lever for scaling performance.","A triangular diagram with three nodes: Algorithms (Model), Systems (Hardware), and Data Selection. Bidirectional arrows connect all three with edge labels: Compute Bound between Algorithms and Systems, I/O Bound between Systems and Data Selection, and Sample Efficiency between Data Selection and Algorithms. Data Selection is highlighted with a bold border. ML Scale appears at the center."
"Data Selection","9.3","fig-data-selection-pipeline","**The Data Selection Pipeline**: A structured approach to increasing data value. Raw data is first pruned to remove redundancy (Static Pruning), then dynamically selected during training (Active Learning), and finally augmented to increase diversity (Synthesis). Each stage increases the Information-Compute Ratio (ICR).","A flow diagram showing the progression of data: Raw Data -> Static Pruning -> Dynamic Selection -> Synthetic Generation -> High Value Model. Arrows indicate the flow."
"Data Selection","9.4","fig-coreset-selection","**Coreset Selection Strategy**: Random sampling (left) selects uniformly, wasting budget on easy samples far from the decision boundary. Coreset selection (right) prioritizes samples near the boundary where the model is uncertain, capturing more information per sample.","Two scatter plots with a diagonal decision boundary. Left plot shows random dots selected. Right plot highlights dots near the boundary as selected."
"Data Selection","9.5","fig-active-learning-loop","**Active Learning Loop**: Instead of labeling all data, the model selects the most ","A cycle diagram: Unlabeled Pool -> Selection Strategy -> Oracle -> Labeled Set -> Model Training -> back to Selection Strategy."
"Data Selection","9.6","fig-amortization-comparison","**Cost Amortization in Foundation Models**: Training from scratch (left) requires 1,000 GPU-hours per task (10,000 total for 10 tasks). The foundation model approach (right) pays 10,000 GPU-hours upfront for pre-training but reduces each subsequent task to just 50 GPU-hours. At 10 tasks the totals are comparable (10,000 vs 10,500), but the per-task marginal cost drops by 20x, and the crossover favoring the foundation model occurs around 11 tasks.","Two bar charts side by side. Left (Train from Scratch) shows 10 equal bars of 1,000 GPU-hours each, totaling 10,000 hours. Right (Foundation Model) shows one tall pre-training bar of 10,000 GPU-hours followed by 10 short fine-tuning bars of 50 GPU-hours each, totaling 10,500 hours. The per-task marginal cost drops dramatically from 1,000 to 50 GPU-hours."
"Data Selection","9.7","fig-domain-gap","**The Domain Gap Problem**: Synthetic data (blue) and real data (orange) have different distributions. A model trained on synthetic data alone learns a boundary that fails on real data. Domain adaptation techniques aim to align these distributions or learn domain-invariant features.","Two overlapping bell curves representing synthetic and real data distributions, with a decision boundary that works for synthetic but misses real data."
"Data Selection","9.8","fig-technique-decision-tree","**Data Selection Technique Selection Tree**: Start at the top by identifying your primary bottleneck, then follow the branches to find the most appropriate technique. Leaf nodes show recommended methods. Multiple paths may apply; combine techniques as needed.","A decision tree flowchart with diamond decision nodes and rectangular technique recommendations. Starts with bottleneck identification and branches to specific techniques."
"Data Selection","9.9","fig-selection-inequality","",""
"Data Selection","9.10","fig-optimization-stack","**The Optimization Stack**: The complete pipeline from raw data to deployed system, showing how optimizations at each stage propagate downstream. Data artifacts (rounded boxes) flow through processing stages (rectangular boxes). Optimizations early in the pipeline---particularly data selection---have multiplicative effects because they reduce the workload for all subsequent stages.","Pipeline diagram with two rows. Top row shows Raw Data flowing through Data Selection to Curated Data, then through Training to produce a Model. Bottom row shows the Model flowing through Compression to a Compact Model, then through Hardware optimization to a Deployed System. Arrows indicate the flow direction between stages."
"Data Selection","9.11","fig-compute-optimal-frontier","**The Compute-Optimal Frontier**: For any training compute budget, there is a best achievable performance when data and model size are optimally balanced (green curve). Operating points below the frontier indicate inefficiency. **Data-starved** systems (orange) have compute capacity but insufficient quality data; the techniques in this chapter move them toward the frontier. **Compute-starved** systems (red) have quality data but insufficient training budget; hardware acceleration or distributed training helps here. The goal is to operate *on* the frontier, extracting maximum performance from available resources.","A log-log plot with Training Compute on x-axis and Model Performance on y-axis. A green curve shows the optimal frontier. Orange point below curve labeled Data-starved. Red point below curve labeled Compute-starved. Purple point on curve labeled Optimal."
"Data Selection","9.12","fig-ppd-curve","**Diminishing Returns of Data**: Random sampling (gray) versus data-efficient selection (blue). The efficient strategy achieves higher performance with less data, reaching the convergence plateau much earlier. The red arrow shows the efficiency gap at a fixed dataset size.","A plot with X-axis "
"Hw Acceleration","10.1","fig-timeline","**Hardware Specialization Timeline.** Computing architectures progressively incorporate specialized accelerators to address emerging performance bottlenecks, from floating-point units to graphics processors and machine learning accelerators. Each era produced hardware tailored to the dominant computational patterns of its period.","Timeline spanning 1980s to 2020s showing hardware evolution: floating-point units, GPUs with hardware transform and lighting, media codecs, TPUs with tensor cores, and application-specific AI engines."
"Hw Acceleration","10.2","fig-accelerator-anatomy","**Anatomy of a Modern AI Accelerator**: AI accelerators integrate specialized processing elements containing tensor cores, vector units, and special function units, supported by a hierarchical memory system from high-bandwidth memory down to local caches. This architecture maximizes data reuse and parallel execution while minimizing energy-intensive data movement, forming the foundation for 100-1000× performance improvements over general-purpose processors.","Block diagram showing AI accelerator architecture: CPU connects to DRAM stacks and processing element grid containing tensor cores, vector units, and local caches in hierarchical arrangement."
"Hw Acceleration","10.3","fig-ai-performance","GPU Performance Scaling: NVIDIA GPUs experienced approximately a ~1,000$\times$ increase in integer 8-bit TOPS (tera operations per second) over a decade, from 4 TOPS on the K20X to 4,000 TOPS on the H100. This three-orders-of-magnitude gain was driven by architectural innovations transitioning from floating-point to tensor core acceleration.","Line graph of NVIDIA GPU INT8 performance from 2012 to 2023 showing exponential growth from K20X at 4 TOPS to H100 at 4000 TOPS, a 1000x increase over the decade."
"Hw Acceleration","10.4","fig-sparse-formats","**Sparse Storage Formats**: Hardware efficiency depends on how sparse matrices are stored. **Dense** storage (top left) is simple but wasteful for zeros. **Block Sparse** (top right) and **CSR** (bottom) compress the matrix by storing only non-zero values and their indices. Structured sparsity (like N:M or Blocks) makes this indexing predictable, allowing hardware to fetch data and skip zeros efficiently.","Grid of 3x3 matrix blocks. Top left: Dense Matrix. Top right: Block Sparse Matrix showing dense sub-blocks. Bottom: Sparse Matrix (CSR) and Block Sparse (BSR) representations showing values and index arrays."
"Hw Acceleration","10.5","fig-systolic-array","**Systolic Array Dataflow**: A control unit feeds input data streams into a grid of processing elements, each performing multiply-accumulate operations. Data flows horizontally and vertically through the array in a pipelined manner, maximizing operand reuse and minimizing memory access, as exemplified by Google","Systolic array diagram with control unit feeding data streams into processing element grid. Elements perform multiply-accumulate operations with results flowing through accumulator chain."
"Hw Acceleration","10.6","fig-host-accelerator-data-movement","**Host-Accelerator Data Transfer**: AI workloads require frequent data movement between CPU memory and accelerators. The four sequential steps of copying input data, issuing execution instructions, parallel computation, and transferring results each introduce potential performance bottlenecks.","Four-step data flow diagram: (1) copy data from main memory to GPU memory, (2) CPU instructs GPU, (3) GPU executes in parallel, (4) results copy back to main memory."
"Hw Acceleration","10.7","fig-tiling-diagram","**Matrix Tiling**: Partitioning large matrices into smaller tiles optimizes data reuse and reduces memory access overhead during computation. This technique improves performance on AI accelerators by enabling efficient loading and processing of data in fast memory, minimizing transfers from slower main memory.","Three matrices A, B, C with highlighted tiles showing how matrix multiplication partitions into smaller blocks. Dimensions labeled M, N, K with corresponding tile sizes Mtile, Ntile, Ktile."
"Benchmarking","11.1","fig-imagenet-gpus","**GPU Adoption and Error Reduction**: As GPU entries in ImageNet surged from 0 to 110 between 2010 and 2014, top-5 error rates dropped from 28.2% to 7.3%, demonstrating the co-evolution of hardware capabilities and algorithmic advances.","Dual-axis chart with blue line showing top-5 error rate declining from 28% to 7% and green bars showing GPU entries rising from 0 to 110 between 2010 and 2014."
"Benchmarking","11.2","fig-granularity","**Benchmarking Granularity**: Four-panel block diagram showing micro, model, application, and end-to-end evaluation layers. Each panel maps a distinct scope of assessment, from isolated kernel operations through full-system deployment, enabling targeted optimization at every level of the ML stack.","Block diagram showing three evaluation layers: neural network nodes on left, model components in center, and end-to-end application with compute nodes on right, connected by dashed lines."
"Benchmarking","11.3","fig-benchmark-tradeoffs","**Isolation vs. Representativeness**: The core trade-off in benchmarking granularity. Micro-benchmarks provide high diagnostic precision but limited real-world relevance, while end-to-end benchmarks capture realistic system behavior but offer less precise component-level insights. Effective ML system evaluation requires strategic combination of all three levels.","Scatter plot with three labeled points along diagonal: micro-benchmarks at high isolation, macro-benchmarks at medium, and end-to-end benchmarks at high representativeness."
"Benchmarking","11.4","fig-benchmark-components","**Anomaly Detection Pipeline**: Nine-stage benchmark workflow applied to an industrial audio anomaly detection task. The pipeline progresses from problem definition through dataset selection, model training, quantization, and ARM embedded deployment, illustrating how each benchmark component feeds the next.","Workflow diagram showing nine stages from problem definition through deployment, with detailed views of anomaly detection system, model training, quantization, and ARM embedded implementation."
"Benchmarking","11.5","fig-mlperf-training-improve","**MLPerf Training Progress**: Standardized benchmarks reveal that machine learning training performance consistently surpasses Moore","Line chart with nine model benchmarks from 2018 to 2024 showing relative performance gains up to 48x for Mask R-CNN, all exceeding the Moore"
"Benchmarking","11.6","fig-power-diagram","**Power Measurement Boundaries**: MLPerf defines system boundaries for power measurement, ranging from single-chip devices to full data center nodes, to enable fair comparisons of energy efficiency across diverse hardware platforms. These boundaries delineate which components","System diagram showing four measurement boundaries: Tiny SoC with compute units, Inference SoC with accelerators and DRAM, Inference Node with cooling and NIC, and Training Rack with compute nodes."
"Benchmarking","11.7","fig-power-trends","**Energy Efficiency Gains**: Successive MLPerf inference benchmark versions show energy efficiency (samples per watt) improving up to 378x for datacenter workloads and 1070x for tinyML deployments across successive releases. Standardized measurement protocols enable meaningful cross-platform comparisons, driving sector-wide progress toward sustainable AI. Source: [@tschand2024mlperf].","Three line charts showing normalized energy efficiency across MLPerf versions: datacenter models up to 378x gain, edge models up to 4x, and tiny models up to 1070x improvement."
"Benchmarking","11.8","fig-hw-lottery","**Hardware-Dependent Accuracy**: Model performance varies significantly across hardware platforms, indicating that architectural efficiency is not solely determined by design but also by hardware compatibility. Multi-hardware models exhibit comparable accuracy to MobileNetV3 Large on CPU and GPU configurations, yet achieve substantial gains on EdgeTPU and DSP, emphasizing the importance of hardware-aware model optimization for specialized computing environments. Source: [@chu2021discovering].","Five scatter plots comparing model accuracy versus latency across CPU, GPU, EdgeTPU, and DSP platforms, with arrow showing MobileNetV3 gaining on EdgeTPU and DSP versus CPU and GPU."
"Benchmarking","11.9","fig-sciml-graph","**Performance Spectrum**: Scientific applications and edge devices demand vastly different computational resources, spanning multiple orders of magnitude in data rates and latency requirements. Consequently, traditional benchmarks focused solely on accuracy are insufficient; specialized evaluation metrics and benchmarks like MLPerf become essential for optimizing AI systems across diverse deployment scenarios. Source: [@duarte2022fastml].","Log-scale scatter plot of data rate versus computation time, showing scientific applications from LHC sensors at 10^14 B/s and nanoseconds to mobile devices at 10^4 B/s and seconds."
"Benchmarking","11.10","fig-model-vs-data","**Development Paradigms**: Model-centric AI prioritizes architectural innovation with fixed datasets, while data-centric AI systematically improves dataset quality (annotations, diversity, and bias) with consistent model architectures to achieve performance gains. Modern research indicates that strategic data enhancement often yields greater improvements than solely refining model complexity.","Side-by-side diagrams: model-centric AI shows data cylinders feeding CPU with feedback loop to model, data-centric AI shows feedback loop to data instead. Double arrow indicates complementary approaches."
"Benchmarking","11.11","fig-dataset-saturation","**Dataset Saturation**: AI systems surpass human performance on five benchmark capabilities: handwriting recognition, speech recognition, image recognition, reading comprehension, and language understanding, each crossing the human baseline between 1998 and 2020. This saturation underscores the need for dynamic benchmarks that remain challenging as model capabilities improve. Source: [@kiela2021dynabench].","Line chart showing five AI capabilities crossing human performance baseline from 1998 to 2020: handwriting, speech, image recognition, reading comprehension, and language understanding."
"Serving","12.1","fig-serving-inference-pipeline","**The Inference Pipeline**: ML serving systems transform raw inputs into final outputs through sequential stages: preprocessing, neural network computation, and postprocessing. The neural network represents just one component; preprocessing and postprocessing rely on traditional computing and often dominate total latency in optimized systems.","Flow diagram showing six connected boxes: Raw Input, Preprocessing, Neural Network, Raw Output, Postprocessing, Final Output. Preprocessing and postprocessing are labeled Traditional Computing; neural network is labeled Deep Learning."
"Serving","12.2","fig-server-anatomy","**Inference Server Anatomy**: A modern inference server decouples network handling from accelerator execution through a staged pipeline. Each stage isolates a concern, from absorbing bursty traffic to forming efficient batches, so the hardware accelerator stays highly utilized despite irregular arrival patterns.","Flowchart showing 6-stage inference server pipeline: Client to Network Ingress to Request Queue (cylinder) to Dynamic Batcher, then down to Inference Runner to Accelerator. Arrows connect stages sequentially."
"Serving","12.3","fig-serving-pipeline-timing","**Request Pipelining**: Pipelining hides latency by overlapping independent operations across different hardware resources. In pipelined execution (B), the CPU processes the next request","Two timing diagrams. A (Serial): alternating CPU preprocessing, GPU inference, and idle blocks in sequence. B (Pipelined): two parallel rows where CPU preprocessing overlaps with GPU inference, eliminating idle time."
"Ops","13.1","fig-mlops-diagram","**Iterative MLOps Loop.** MLOps extends DevOps principles to manage the unique challenges of machine learning systems, including data versioning, model retraining, and continuous monitoring. The iterative workflow encompasses data engineering, model development, and reliable deployment for sustained performance in production.","Infinity-loop diagram with three phases. Design phase: requirements, use-case prioritization, data availability. Model Development: data engineering, model engineering, testing. Operations: deployment, CI/CD pipeline, monitoring and triggering."
"Ops","13.2","fig-technical-debt","**Hidden Infrastructure of ML Systems.** Most engineering effort in a typical machine learning system concentrates on components surrounding the model itself: data collection, feature engineering, and system configuration rather than the model code. The distribution reveals the operational challenges and potential for technical debt arising from these often-overlooked surrounding components. Source: [@sculley2015hidden].","Hub-and-spoke diagram with ML system at center. Ten surrounding components connected by arrows: data collection, verification, feature extraction, configuration, resource management, serving infrastructure, monitoring, analysis tools, and ML code."
"Ops","13.3","fig-technical-debt-taxonomy","**ML Technical Debt Taxonomy.** Machine learning systems accumulate distinct forms of technical debt from data dependencies, model interactions, and evolving requirements. Six primary debt patterns radiate from a central hub: boundary erosion undermines modularity, correction cascades propagate fixes through dependencies, feedback loops create hidden coupling, while data, configuration, and pipeline debt reflect poorly managed artifacts and workflows.","Hub-and-spoke diagram with Hidden Technical Debt at center. Six debt categories radiate outward: Configuration Debt, Feedback Loops, Data Debt, Pipeline Debt, Correction Cascades, and Boundary Erosion, each annotated with specific failure patterns."
"Ops","13.4","fig-correction-cascades-flowchart","**Correction Cascades**: Iterative refinements in ML systems often trigger dependent fixes across the workflow, propagating from initial adjustments through data, model, and deployment stages. Color-coded arcs represent corrective actions stemming from sources of instability, while red arrows and the dotted line indicate escalating revisions, potentially requiring a full system restart.","Timeline diagram with seven ML stages from problem statement to deployment. Color-coded arcs show correction cascades: red for domain expertise gaps, blue for real-world brittleness, orange for poor documentation. Dashed arrows indicate restarts."
"Ops","13.5","fig-ops-layers","**MLOps Stack Layers.** Five tiers organize the ML system stack: ML Models at the top, followed by Frameworks, Orchestration, Infrastructure, and Hardware. MLOps spans orchestration tasks (data management through model serving) and infrastructure tasks (job scheduling through monitoring), enabling automation, reproducibility, and scalable deployment.","Layered architecture diagram. Top row: ML Models, Frameworks, Orchestration, Infrastructure, Hardware. MLOps section spans orchestration tasks (data management through model serving) and infrastructure tasks (job scheduling through monitoring)."
"Ops","13.6","fig-ops-cicd","**ML CI/CD Pipeline.** The pipeline begins with dataset and feature repositories, flows through data validation, transformation, training, evaluation, and model registration stages, then deploys to production. Retraining triggers initiate the cycle automatically, while metadata and artifact repositories ensure reproducibility and governance. Source: HarvardX.","Pipeline diagram showing continuous training workflow. Central box contains data validation, transformation, training, evaluation, and registration stages. Three repositories connect: dataset and feature, metadata and artifact, model."
"Ops","13.7","fig-data-drift","**Data Drift Impact**: Declining model performance over time results from data drift, where the characteristics of production data diverge from the training dataset. Monitoring key metrics longitudinally allows MLOps engineers to detect this drift and trigger model retraining or data pipeline adjustments to maintain accuracy.","Three-panel visualization over time. Top: incoming data samples coded green or orange. Middle: feature distribution shifting from online to offline sales channel. Bottom: line graph showing model accuracy declining as distribution shifts increase."
"Ops","13.8","fig-uptime-iceberg","**Uptime Dependency Stack.** An iceberg visualization where visible service uptime floats above the waterline, supported by hidden threats below: model accuracy degradation, data drift, concept drift, broken pipelines, schema changes, model bias, data outages, and underperforming segments. Labels group these threats into data health, model health, and service health categories.","Iceberg diagram with uptime visible above waterline. Hidden below: model accuracy, data drift, concept drift, broken pipelines, schema changes, model bias, data outages, underperforming segments. Labels indicate data, model, and service health."
"Ops","13.9","fig-clinaiops","**ClinAIOps Feedback Loops**: The cyclical framework coordinates data flow between patients, clinicians, and AI systems to support continuous model improvement and safe clinical integration. These interconnected loops enable iterative refinement of AI models based on real-world performance and clinical feedback, fostering trust and accountability in healthcare applications. Source: [@chen2023framework].","Circular diagram with three nodes: patient, clinician, and AI system. Arrows form cyclic flow: patient provides monitoring data, clinician sets therapy regimen, AI generates alerts and recommendations. Inner and outer loops show feedback pathways."
"Ops","13.10","fig-interactive-loop","**Hypertension Management Loops.** Three feedback loops operate in parallel: the patient-AI loop enables bounded self-management through blood pressure monitoring and titration recommendations; the clinician-AI loop provides oversight via trend summaries and clinical risk alerts; and the patient-clinician loop shifts appointments toward therapy trends and lifestyle modifiers. Source: [@chen2023framework].","Three-panel diagram showing ClinAIOps loops. Patient-AI loop: patient monitors blood pressure, AI recommends titrations. Clinician-AI loop: clinician sets limits, AI sends alerts. Patient-clinician loop: both discuss therapy trends and modifiers."
"Responsible Engr","14.1","fig-governance-layers","Responsible AI Governance Layers. Nested governance structures surround engineering practice. At the center, engineering teams implement technical safeguards. Successive layers represent organizational safety culture, industry certification and external review, and government regulation. Technical excellence at the center enables compliance with requirements flowing inward from outer layers.","Nested oval diagram showing governance layers from innermost to outermost: Team (reliable systems, software engineering), Organization (safety culture, organizational design), Industry (trustworthy certification, external reviews), and Government Regulation."
"Responsible Engr","14.2","fig-fairness-threshold","Threshold Effects on Subgroup Outcomes. A single classification threshold (vertical lines) applied to two subgroups with different score distributions produces disparate outcomes. Circles represent positive outcomes (loan repayment), crosses represent negative outcomes (default). The 75% threshold approves most of Subgroup A but rejects most of Subgroup B, even when qualified individuals exist in both groups. The 81.25% threshold shows how threshold adjustment changes the fairness-accuracy tradeoff. This visualization explains why aggregate accuracy can mask severe subgroup disparities.","Diagram showing two subgroups A and B with different score distributions. Vertical threshold lines at 75% and 81.25% show how the same threshold produces different approval rates for each group."
"Responsible Engr","14.3","fig-interpretability-spectrum","Model Interpretability Spectrum. A horizontal spectrum arranges model architectures from most interpretable on the left (decision trees, linear regression, logistic regression) to least interpretable on the right (random forests, neural networks, convolutional neural networks). Models on the left allow direct inspection of decision logic, while those on the right require post-hoc explanation techniques such as LIME or SHAP. High-stakes regulatory requirements may constrain model selection toward the interpretable end of this spectrum.","Horizontal spectrum showing model types from more interpretable (decision trees, linear regression, logistic regression) to less interpretable (random forest, neural network, convolutional neural network)."
"Responsible Engr","14.4","fig-data-governance-pillars","**Data Governance Pillars**: Robust data governance establishes ethical and reliable machine learning systems by prioritizing privacy, fairness, transparency, and accountability throughout the data lifecycle. These interconnected pillars address unique challenges in ML workflows, ensuring responsible data usage and auditable decision-making processes.","Central stacked database icon surrounded by four governance elements: privacy shield, security lock, compliance checklist, and transparency document. Gear icons show interconnections between all elements."
"Responsible Engr","14.5","fig-data-card","**Data Governance Documentation**: Data cards standardize critical dataset information, enabling transparency and accountability required for regulatory compliance with laws like GDPR and HIPAA. By providing a structured overview of dataset characteristics, intended uses, and potential risks, data cards facilitate responsible AI practices and support data subject rights.","Sample data card template showing structured fields: dataset name and description at top, authorship and funding details in middle sections, and intended uses with potential risks at bottom."
"Conclusion","15.1","fig-invariants-cycle","**The Cycle of ML Systems (The 12 Invariants)**: The complete systems engineering lifecycle. The meta-principle of *Conservation of Complexity* (center) unifies the process: complexity is neither created nor destroyed, only shifted between Data, Model, Hardware, and Operations. Each transition is governed by specific quantitative invariants that constrain valid engineering decisions.","Circular diagram with four phases: Foundations (Data) in green, Build (Model) in blue, Optimize (Hardware) in orange, and Deploy (Operations) in violet. Arrows connect each phase in a cycle, with the 12 invariants labeled on each transition. Conservation of Complexity is shown in the center as a dashed circle."
"Appendix Algorithm","A1.1","fig-broadcasting-rules","**Tensor Broadcasting Rules**: Two tensors are compatible if, starting from the trailing (rightmost) dimension, the dimensions are equal or one of them is 1. Dimensions of size 1 are ","Diagram showing two tensors (3,1) and (1,4) expanding to a shared (3,4) grid."
"Appendix Algorithm","A1.2","fig-backprop-graph","**Backpropagation Computational Graph**: A two-layer network showing the forward pass (black arrows) and backward pass (red dashed arrows). Each node caches values during the forward pass that are reused during the backward pass.","A computational graph with four nodes labeled x, h, y, and L connected left to right. Solid black arrows show the forward pass with weights W1 and W2. Dashed red arrows curve backward showing gradient flow with partial derivative notation."
"Appendix Data","A4.1","fig-row-vs-col","**Storage Layouts**: Row-oriented formats pack data together by record (good for transactions). Column-oriented formats pack data by feature (good for analytics).","Diagram contrasting Row Store vs Column Store. Row store shows Record 1 [ID, Name, Age] followed by Record 2. Column store shows Column 1 [ID1, ID2...] followed by Column 2 [Name1, Name2...]."
"Appendix Machine","A5.1","fig-roofline","**The Roofline Model**: Performance ceiling for a hypothetical accelerator. The sloped line represents memory bandwidth limits; the horizontal line represents peak compute. Every workload can be plotted on this diagram to determine its optimization strategy.","A plot with arithmetic intensity on the x-axis and performance on the y-axis. Two lines form a roofline shape: a diagonal line rising from the origin labeled Memory Bound, and a horizontal line labeled Compute Bound. They meet at the Ridge Point."
"Appendix Machine","A5.2","fig-memory-hierarchy","**The Memory Hierarchy**: Performance depends on data proximity. Accessing HBM is ~100x slower than registers; accessing SSD is ~100,000x slower.","Pyramid showing Registers at top, followed by Cache, HBM/DRAM, and Storage at bottom."
"Appendix Machine","A5.3","fig-float-formats","**Numerical Format Bit Layouts**: A visual comparison of bit allocations. Note how **BF16** (Brain Float 16) preserves the 8-bit exponent of **FP32**, ensuring the same dynamic range for training stability. **FP16** trades range for precision, often requiring loss scaling to prevent underflow.","Stacked horizontal bars showing bit breakdown. FP32: 1 Sign, 8 Exp, 23 Mantissa. BF16: 1 Sign, 8 Exp, 7 Mantissa. FP16: 1 Sign, 5 Exp, 10 Mantissa. INT8: 8 Integer bits."