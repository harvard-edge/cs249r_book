# About {.unnumbered}

## Overview {#sec-book-overview-c27b}

This section provides essential background about the purpose of this work, its development context, and what readers can expect from their learning journey.

### Purpose {#sec-book-purpose-book-5d4f}

The goal of this work is to provide a resource for educators and learners seeking to understand the principles and practices of machine learning systems. The content is continually updated to incorporate the latest insights and effective teaching strategies. We intend that it remains a valuable resource in this fast-evolving field. Please check back often!

### Context and Development {#sec-book-context-development-2824}

This work originated as a collaborative effort with contributions from students, researchers, and practitioners. While maintaining its academic rigor and real-world applicability, the content continues to evolve through regular updates and careful curation to reflect the latest developments in machine learning systems.

### What to Expect {#sec-book-expect-df55}

This textbook is organized into two volumes following the **Hennessy & Patterson pedagogical model**, the same approach that has guided generations of computer architecture students through progressively deeper understanding.

| Volume | Theme | Focus | Analogy |
|--------|-------|-------|---------|
| **Volume I** | Build, Optimize, Deploy | Single-machine ML systems, foundational principles | "Computer Organization and Design" |
| **Volume II** | Scale, Distribute, Govern | Distributed systems at production scale | "Computer Architecture" |

**Volume I** teaches you to *understand* ML systems. **Volume II** teaches you to *build* ML systems at scale.

**Volume I: Build, Optimize, Deploy** establishes the foundations through four progressive stages:

- **Foundations** (Part I): Build your conceptual foundation, establishing the mental models that underpin all effective systems work.

- **Development** (Part II): Engineer complete workflows, from data pipelines through training infrastructure.

- **Optimization** (Part III): Transform theoretical understanding into systems that run efficiently in resource-constrained environments.

- **Deployment** (Part IV): Navigate serving, operations, and responsible engineering practices.

**Volume II: Scale, Distribute, Govern** extends these foundations into production-scale systems:

- **Foundations of Scale** (Part V): Master infrastructure, storage, and communication for systems spanning multiple machines.

- **Distributed Systems** (Part VI): Address distributed training, fault tolerance, and inference at scale.

- **Production Challenges** (Part VII): Tackle on-device learning, security, privacy, and robust system design.

- **Responsible Deployment** (Part VIII): Explore responsible AI, sustainability, and emerging frontiers.

**Laboratory exercises** complement the core content, allowing you to apply concepts with hands-on experience across multiple embedded platforms. Throughout both volumes, **quizzes** provide quick self-checks to reinforce understanding at key learning milestones.

### Pedagogical Philosophy: Foundations First {#sec-book-pedagogical-philosophy-foundations-first-4f88-foundations-first-4f88}

Machine learning systems represent inherently complex engineering challenges. However, they are constructed from fundamental building blocks that must be thoroughly understood before advancing to sophisticated implementations. This pedagogical approach parallels established educational progressions: students master basic algorithms before tackling distributed systems, or develop proficiency in linear algebra before engaging with advanced machine learning theory. ML systems similarly possess essential foundational components that serve as the basis for all subsequent learning.

Our curriculum emphasizes mastery of these core building blocks:

- The interaction between models and hardware
- Data flow patterns through systems
- Computational pattern emergence
- Optimization principles within individual systems

Through comprehensive understanding of these fundamentals, students develop the analytical framework necessary to reason effectively about complex scenarios including distributed training architectures, multi-device coordination protocols, and emerging technological paradigms.

This foundations-first methodology prioritizes conceptual depth over topical breadth. This approach enables students to construct robust mental models that will serve as enduring intellectual resources throughout their professional careers as machine learning systems continue to evolve.

```{=latex}
\clearpage
```

## Learning Goals {#sec-book-learning-goals-bafe}

This section outlines the educational framework guiding the design of this work and the specific learning objectives readers will achieve.

### Key Learning Outcomes {#sec-book-key-learning-outcomes-624e}

Both volumes are structured with [Bloom's Taxonomy](https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/) in mind (@fig-bloom), which defines six levels of learning, ranging from foundational knowledge to advanced creative thinking:

![Bloom's Taxonomy (2021 edition).](images/png/bloom_revised_taxonomy.png){#fig-bloom}

1. **Remembering**: Recalling basic facts and concepts.

2. **Understanding**: Explaining ideas or processes.

3. **Applying**: Using knowledge in new situations.

4. **Analyzing**: Breaking down information into components.

5. **Evaluating**: Making judgments based on criteria and standards.

6. **Creating**: Producing original work or solutions.

### Learning Objectives {#sec-book-learning-objectives-b644}

This work supports readers in developing practical expertise across the ML systems lifecycle:

1. **Systems Thinking**: Understand how ML systems differ from traditional software, and reason about hardware-software interactions.

2. **Workflow Engineering**: Design end-to-end ML pipelines, from data engineering through deployment and maintenance.

3. **Performance Optimization**: Apply systematic approaches to make systems faster, smaller, and more resource-efficient.

4. **Production Deployment**: Address real-world challenges including reliability, security, privacy, and scalability.

5. **Responsible Development**: Navigate ethical implications and implement sustainable, socially beneficial AI systems.

6. **Future-Ready Skills**: Develop judgment to evaluate emerging technologies and adapt to evolving paradigms.

7. **Hands-On Implementation**: Gain practical experience across diverse embedded platforms and resource constraints.

8. **Self-Directed Learning**: Use integrated assessments and interactive tools to track progress and deepen understanding.

### AI Learning Companion {#sec-book-ai-learning-companion-8ec9}

Throughout this resource, you'll find **SocratiQ**, an AI learning assistant designed to enhance your learning experience. Inspired by the Socratic method of teaching, SocratiQ combines interactive quizzes, personalized assistance, and real-time feedback to help you reinforce your understanding and create new connections. As part of our integration of Generative AI technologies, SocratiQ encourages critical thinking and active engagement with the material.

SocratiQ is still a work in progress, and we welcome your feedback to make it better. For more details about how SocratiQ works and how to get the most out of it, visit the [AI Learning Companion page](../socratiq/socratiq.qmd).

## How to Use This Work {#sec-book-use-book-aca7}

### Structure {#sec-book-book-structure-0b7a}

This work takes you from understanding ML systems conceptually to building and deploying them in practice. The content is organized into two volumes following the Hennessy & Patterson pedagogical model, each containing four parts that develop specific capabilities.

**Volume I: Build, Optimize, Deploy**

1. **Part I: Foundations**
   *Master the fundamentals.* Build intuition for how ML systems differ from traditional software, understand the hardware-software stack, and gain fluency with essential architectures and mathematical foundations.

2. **Part II: Development**
   *Engineer complete workflows.* Learn to design end-to-end ML pipelines, manage complex data engineering challenges, select appropriate frameworks, and orchestrate training.

3. **Part III: Optimization**
   *Optimize for real constraints.* Develop skills to make systems faster, smaller, and more efficient through model optimization, hardware acceleration, and systematic performance analysis.

4. **Part IV: Deployment**
   *Deploy with confidence.* Master serving fundamentals, ML operations, responsible engineering practices, and the principles that ensure systems work reliably in production.

**Volume II: Scale, Distribute, Govern**

5. **Part V: Foundations of Scale**
   *Build for distributed systems.* Understand the infrastructure, storage systems, and communication patterns required when ML systems span multiple machines.

6. **Part VI: Distributed Systems**
   *Scale training and inference.* Master distributed training strategies, fault tolerance mechanisms, and inference optimization across diverse deployment targets.

7. **Part VII: Production Challenges**
   *Navigate real-world complexity.* Address on-device learning, edge intelligence, security and privacy requirements, and robust system design.

8. **Part VIII: Responsible Deployment**
   *Design for impact.* Explore responsible AI practices, sustainable computing, AI for societal benefit, and emerging frontiers in ML systems.

**Hands-On Learning:**

**Laboratory Exercises** complement both volumes, allowing you to implement concepts with hands-on experience across multiple embedded platforms, from microcontrollers to edge computing devices.

### Suggested Reading Paths {#sec-book-suggested-reading-paths-10b8}

- **Beginners**: Start with Volume I, Parts I and II to build conceptual understanding and workflow skills. Add laboratory exercises for hands-on experience before advancing to optimization topics.

- **Practitioners**: Complete Volume I for core competencies, then focus on Volume II Parts V through VII for distributed systems and production deployment insights relevant to industry work.

- **Researchers**: Work through Volume I for foundations, then explore Volume II for advanced topics including distributed training, robust systems, and emerging frontiers.

- **Graduate Courses**: Volume I serves as a complete semester-length course. Volume II provides material for an advanced seminar or second course.

- **Hands-On Learners**: Combine reading from either volume with the laboratory exercises across Arduino, Seeed, Grove Vision, and Raspberry Pi platforms.

### Prerequisites {#sec-book-prerequisites-4a7c}

This textbook assumes the following background:

**Required**:

- **Programming Proficiency**: Fluency in Python is essential. You should be comfortable with functions, classes, data structures, and basic file I/O. Familiarity with NumPy and basic data manipulation is helpful.

- **Mathematics Foundations**: Understanding of linear algebra (vectors, matrices, matrix multiplication), basic calculus (derivatives, gradients, chain rule), and probability/statistics (distributions, expectation, variance). These concepts are reviewed briefly where used but not taught from scratch.

**Recommended but Not Required**:

- **Computer Systems**: Familiarity with memory hierarchies, basic computer architecture, or operating systems concepts helps with optimization and deployment chapters. Students without this background will find explanatory footnotes and references throughout.

- **Machine Learning Basics**: Prior exposure to supervised learning concepts (training, validation, overfitting) is helpful but not required. Part I provides foundations for students new to ML.

**Volume II Additional Prerequisites**:

- Volume II assumes completion of Volume I or equivalent background in single-machine ML systems.
- Familiarity with distributed systems concepts (networking, parallelism) is helpful for Part V onward.

### For Students with Different Backgrounds {#sec-book-students-different-backgrounds-21ef}

This textbook welcomes students from diverse academic backgrounds, whether you come from computer science, engineering, mathematics, or other fields. Understanding how ML systems connect to your existing knowledge helps bridge theoretical concepts to practical implementation:

**Computer Science Students**: ML systems extend familiar concepts into new domains. If you've worked with algorithms and data structures, think of ML as learning algorithms that automatically optimize themselves based on data patterns rather than following fixed instructions.

Your experience with system design, memory management, parallel processing, and distributed systems directly applies to ML deployment. The underlying computational complexity analysis still applies. We analyze time and space complexity for training and inference phases separately.

**Electrical and Computer Engineering Students**: ML systems represent a natural evolution of signal processing and control systems principles. Machine learning can be viewed as advanced signal processing where we extract meaningful patterns from noisy, high-dimensional signals.

Neural networks perform operations similar to filters. Convolution layers in image processing are literally convolution operations you have studied. Your background in computer systems organization and architecture becomes essential for understanding how ML algorithms map to different hardware platforms, while your understanding of memory hierarchies helps optimize data movement in large-scale training systems.

**Students from Other Backgrounds**: Think of ML systems like a modern factory assembly line. Just as a factory transforms raw materials into finished products through coordinated stages, ML systems transform raw data into useful predictions through interconnected components.

The mathematics (linear algebra, probability, and calculus) are the "tools" of this factory, but you do not need to be a tool expert to understand how the assembly line works. Most concepts become clear through concrete examples, like understanding how a recommendation system works by thinking about how a librarian might suggest books based on your reading history.

The key skill is systems thinking: understanding how data pipelines, training processes, and deployment infrastructure work together, much like how supply chains, manufacturing, and distribution must coordinate in any complex operation.

### Modular Design {#sec-book-modular-design-8b30}

Both volumes are designed for flexible learning, allowing readers to explore chapters independently or follow suggested sequences. Each chapter integrates:

- **Interactive quizzes** for self-assessment and knowledge reinforcement
- **Practical exercises** connecting theory to implementation
- **Laboratory experiences** providing hands-on platform-specific learning

We embrace an iterative approach to content development, sharing valuable insights as they become available rather than waiting for perfection. Your feedback helps us continuously improve and refine this resource.

We also build upon the excellent work of experts in the field, fostering a collaborative learning ecosystem where knowledge is shared, extended, and collectively advanced.

## Transparency and Collaboration {#sec-book-transparency-collaboration-171f}

This work began as a community-driven project shaped by the collective efforts of students in CS249r, colleagues at Harvard and beyond, and the broader ML systems community. The content has evolved through open collaboration, thoughtful feedback, and modern editing tools including both rule-based scripts and generative AI technologies. In a fitting twist, the very systems we study in these pages have helped refine them, highlighting the interplay between human expertise and machine intelligence. Fortunately, they are not quite ready to engineer the systems themselves. At least, not yet.

As the primary author, editor, and curator, I (Prof. Vijay Janapa Reddi) provide human-in-the-loop oversight to ensure the material remains accurate, relevant, and of the highest quality. Still, no one is perfect, so errors may exist. Your feedback is welcome and encouraged. This collaborative model is essential for maintaining quality and ensuring that knowledge remains open, evolving, and globally accessible.

## Copyright and Licensing {#sec-book-copyright-licensing-33bd}

This work is open-source and developed collaboratively through GitHub. Unless otherwise stated, the content is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0).

Contributors retain copyright over their individual contributions, dedicated to the public domain or released under the same open license as the original project. For more information on authorship and contributions, visit the [GitHub repository](https://github.com/harvard-edge/cs249r_book).

## Join the Community {#sec-book-join-community-dd04}

This work is more than a resource. It is an invitation to collaborate and learn together. Engage in [community discussions](https://github.com/harvard-edge/cs249r_book/discussions) to share insights, tackle challenges, and learn alongside fellow students, researchers, and practitioners.

Whether you are a student starting your journey, a practitioner solving real-world challenges, or a researcher exploring advanced concepts, your contributions will enrich this learning community. Introduce yourself, share your goals, and let us collectively build a deeper understanding of machine learning systems.
