---
quiz: sustainable_ai_quizzes.json
concepts: sustainable_ai_concepts.yml
glossary: sustainable_ai_glossary.json
engine: jupyter
---

# Sustainable AI {#sec-sustainable-ai}
::: {layout-narrow}
::: {.column-margin}
\chapterminitoc
:::

\noindent
![](images/png/cover_sustainable_ai.png){fig-alt="Sustainable AI and energy-efficient computing." width=100%}

:::

## Purpose {.unnumbered}

\begin{marginfigure}
\mlfleetstack{60}{20}{20}{100}
\end{marginfigure}

_Why does energy consumption determine what machine learning systems can exist, not just what they cost to operate?_

Power is not merely an operational expense but a hard physical constraint that limits what can be built. A datacenter has a fixed power budget determined by its electrical infrastructure and cooling capacity; exceeding that budget is not expensive but impossible. Training runs that require more power than available cannot happen regardless of budget. Deployment locations are constrained by grid capacity and cooling feasibility, not just real estate prices. At frontier scale, the question shifts from "can we afford this" to "can this physically exist"—and the answer increasingly depends on energy efficiency rather than algorithmic capability. The organizations pushing machine learning forward are those that treat energy as a first-class engineering constraint alongside accuracy and latency, because sustainability is not about virtue but about the physics that determines which ambitious systems can actually be built and operated.

::: {.content-visible when-format="pdf"}
\newpage
:::

::: {.callout-tip title="Learning Objectives"}

- Explain the **sustainability paradox** where AI compute growth (350,000$\times$ from 2012-2019) outpaces hardware efficiency gains, and analyze how **Jevons Paradox** causes efficiency improvements to increase total resource consumption
- Calculate **Power Usage Effectiveness (PUE)** and **lifecycle carbon footprints** across training (60-80%), inference (15-25%), and manufacturing (5-15%) phases, differentiating **operational emissions** from **embodied carbon**
- Analyze geographic and temporal factors affecting **carbon intensity**, comparing emission differences across energy grids and applying these insights to workload scheduling decisions
- Evaluate algorithmic optimization techniques (pruning, quantization, knowledge distillation) and **edge deployment** strategies in terms of accuracy-energy trade-offs and lifecycle sustainability impacts
- Design **carbon-aware scheduling** strategies leveraging renewable energy availability and regional grid intensity to achieve 50-80% emission reductions while maintaining performance requirements
- Critique **carbon offset** approaches versus actual emissions reduction strategies, synthesizing multi-layer mitigation plans that integrate algorithmic efficiency, infrastructure optimization, and policy frameworks

:::

```{python}
#| label: sustainable-ai-setup
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ SUSTAINABLE AI: CHAPTER-WIDE CONSTANTS
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @sec-sustainable-ai — chapter-wide energy and carbon reference values
# │
# │ Goal: Establish GPU TDP (H100 700 W, A100 400 W), grid carbon intensities
# │       (US avg 429 gCO₂/kWh, Quebec 20 gCO₂/kWh), and the 350,000× compute
# │       growth vs ~80% battery/grid efficiency gain mismatch to ground the
# │       sustainability paradox argument throughout the chapter.
# │ Show: H100 ~700 W, A100 ~400 W; GPT-3 ~175B params; battery 12-yr gain ~80%
# │       vs compute growth 350,000× → energy wall gap ~195,000× — inline prose.
# │ How: Compound growth (1 + r)^12 for battery/grid; gap = compute_growth /
# │       battery_gain; format TDP via .to(watt).magnitude (class-level attribute).
# │
# │ Imports: mlsys.constants (H100_TDP, A100_TDP, GPT3_PARAMS, watt, BILLION,
# │           param, second, hour, TFLOPs, MILLION)
# │ Imports: mlsys.formatting (fmt, sci, check)
# │ Exports: h100_tdp_w, h100_tdp_kw, a100_tdp_w, gpt3_params_b,
# │          energy_wall_gap_str, battery_gain_pct, grid_gain_pct
# └─────────────────────────────────────────────────────────────────────────────
from mlsys.constants import (
    H100_TDP, A100_TDP, GPT3_PARAMS, GPT3_TRAINING_OPS,
    watt, BILLION, param, second, hour, TFLOPs, MILLION
)
from mlsys.formatting import fmt, sci, check

# ┌── P.I.C.O. ISOLATED SCENARIO ───────────────────────────────────────────────
class SustainableAISetup:
    """
    Namespace for Sustainability reference parameters.
    Scenario: Mapping the AI Energy Wall vs. Grid/Battery scaling.
    """

    # ┌── 1. PARAMETERS (Inputs) ───────────────────────────────────────────────
    # Hardware
    h100_tdp_raw = H100_TDP
    a100_tdp_raw = A100_TDP

    # Grid & Carbon
    grid_us_avg_g_kwh = 429
    grid_quebec_g_kwh = 20
    grid_coal_g_kwh = 1000

    # Scaling (2012 -> 2024)
    compute_growth_factor = 350000
    battery_density_growth_annual = 0.05 # 5% per year
    grid_efficiency_growth_annual = 0.02 # 2% per year

    # ┌── 2. CALCULATION (The Physics) ─────────────────────────────────────────
    # Compound growth over 12 years: (1 + r)^12
    battery_12yr_gain = (1 + battery_density_growth_annual) ** 12
    grid_12yr_gain = (1 + grid_efficiency_growth_annual) ** 12

    # The Gap: Compute Growth / Energy Infrastructure Growth
    energy_wall_gap = compute_growth_factor / battery_12yr_gain

    # ┌── 3. INVARIANTS (Guardrails) ───────────────────────────────────────────
    check(energy_wall_gap > 100000, f"Energy wall gap should be massive, got {energy_wall_gap:.0f}")
    check(battery_12yr_gain < 2.0, "Battery density doubles every ~15-20 years, not 12.")

    # ┌── 4. OUTPUTS (Formatting) ──────────────────────────────────────────────
    h100_tdp_w = f"{h100_tdp_raw.m_as(watt):.0f}"
    h100_tdp_kw = f"{h100_tdp_raw.m_as(watt) / 1000:.1f}"
    a100_tdp_w = f"{a100_tdp_raw.m_as(watt):.0f}"
    gpt3_params_b = f"{GPT3_PARAMS.m_as(param) / BILLION:.0f}"

    energy_wall_gap_str = fmt(energy_wall_gap, precision=0)
    battery_gain_pct = f"{(battery_12yr_gain - 1) * 100:.0f}"
    grid_gain_pct = f"{(grid_12yr_gain - 1) * 100:.0f}"

# ┌── EXPORTS (Bridge to Text) ─────────────────────────────────────────────────
h100_tdp_w = SustainableAISetup.h100_tdp_w
h100_tdp_kw = SustainableAISetup.h100_tdp_kw
a100_tdp_w = SustainableAISetup.a100_tdp_w
gpt3_params_b = SustainableAISetup.gpt3_params_b
energy_wall_gap_str = SustainableAISetup.energy_wall_gap_str
battery_gain_pct = SustainableAISetup.battery_gain_pct
grid_gain_pct = SustainableAISetup.grid_gain_pct
```

This chapter's position in the book's organizing framework, *the Fleet Stack*, clarifies why energy and environmental constraints are not external concerns but physical limits that bound what the entire system can achieve.

::: {.callout-note title="Connection: The Fleet Stack"}
This is the final component of the **Governance Layer**. Security protects against adversaries; Robustness protects against chaos; **Sustainability** protects against exhaustion. A system that burns through its energy budget or cannot be powered by the available grid is just as failed as one that crashes. Here, we ensure the fleet can *keep* running.
:::

## The Energy Ceiling {#sec-sustainable-ai-sustainable-ai-engineering-discipline-6d39}

When an engineer optimizes a database query to save 100 milliseconds, it is considered standard performance tuning. But when that same query is executed billions of times a day across a global data center, that 100-millisecond savings translates to megawatts of electrical power and tons of avoided carbon emissions. Sustainable AI ceases to be a theoretical ethical concern when you realize that power density is the absolute physical ceiling on your datacenter's computational capacity; energy is the ultimate currency of machine learning.

Security (@sec-security-privacy) protects ML systems from adversarial threats. Robustness (@sec-robust-ai) ensures they perform reliably under distribution shift. This chapter addresses a third operational concern that determines long-term viability: the resource constraints that govern whether systems remain economically and environmentally sustainable at scale.

Contemporary machine learning applications operate at unprecedented scales, with environmental impact now comparable to established heavy industries. Training a single state-of-the-art AI model can consume as much electricity as 100 U.S. homes do in an entire year. The exponential growth trajectory of computational demands significantly outpaces efficiency improvements in underlying hardware, establishing the **sustainability paradox** in artificial intelligence. This chapter formalizes these constraints into an engineering discipline: *Sustainable AI*.

::: {.callout-definition title="Sustainable AI"}

***Sustainable AI***\index{Sustainable AI!definition} is the engineering discipline that elevates **Environmental Impact** to a first-class design constraint alongside traditional performance and cost objectives.

1.  **Significance (Quantitative):** It treats energy consumption not as a cost, but as a **Resource Budget**. Within the **Iron Law**, Sustainable AI seeks to maximize the **Accuracy-per-Joule**, recognizing that the system's **Duty Cycle ($\eta$)** is ultimately constrained by the physical limits of power grids and heat rejection.
2.  **Distinction (Durable):** Unlike **Corporate Social Responsibility (CSR)** (which is often aspirational), Sustainable AI is an **Operational Requirement**: it involves the precise measurement and optimization of carbon intensity, water usage, and electronic waste across the full lifecycle.
3.  **Common Pitfall:** A frequent misconception is that sustainability is "just using green energy." In reality, it is a **Full-Lifecycle Problem**: over 50% of the carbon footprint of an edge device can come from its **Embodied Carbon** (manufacturing), regardless of how clean its operating energy source is.

:::

This chapter examines the environmental impact of AI systems through a rigorous engineering lens, analyzing the complete lifecycle—from semiconductor manufacturing and datacenter construction to model training, inference deployment, and electronic waste. By treating this full lifecycle as an engineering problem rather than a corporate responsibility exercise, we transform sustainability from a vague objective into a measurable engineering requirement. Before we can optimize this massive footprint, however, we must ground our intuition by calculating the raw physical energy required to produce state-of-the-art machine intelligence.

::: {.callout-checkpoint}
## The Energy of Intelligence
A 175B parameter model requires approximately $3.14 \times 10^{23}$ FLOPs to train. Assuming a datacenter PUE of 1.1 and hardware efficiency of 50 TFLOPs/Watt:
1. Calculate the total energy consumption in megawatt-hours (MWh).
2. If the average US household consumes 10.6 MWh per year, how many "household-years" does this single training run represent?
3. Discuss whether this metric captures the true environmental cost, considering the difference between energy consumption (MWh) and carbon intensity (gCO2/kWh).
:::

The measurement, modeling, and mitigation frameworks presented in this chapter represent essential engineering competencies alongside traditional performance optimization. Mastering them requires understanding the scale of the problem, the physics that constrain solutions, and the system-level interventions that move the needle.

### The Scale of Environmental Impact {#sec-sustainable-ai-scale-environmental-impact-ac9a}

The numbers become visceral when translated into familiar physical quantities. To appreciate the scale of the problem, consider the *carbon cost of training* a single frontier model.

::: {.callout-notebook title="The Carbon Cost of Training"}
**Problem**: You train a large model (GPT-3 size) consuming **1,287 MWh**. How much CO2 did you emit, and how does that compare to a trans-Atlantic flight?

**The Math**:

1.  **Energy**: 1,287 MWh = 1,287,000 kWh.
2.  **Carbon Intensity (US Average)**: $\approx 0.429 \text{ kg CO}_2\text{/kWh}$.
3.  **Total Emissions**: $1,287,000 \times 0.429 \approx \mathbf{552,000 \text{ kg CO}_2}$.
4.  **Comparison**:
    *   One passenger, NY to London (round trip): $\approx 1,000 \text{ kg CO}_2$.
    *   **Ratio**: $552,000 / 1,000 = \mathbf{552 \text{ flights}}$.

**The Systems Conclusion**: A single training run emits as much carbon as flying a Boeing 747 full of passengers across the Atlantic. **Optimization matters.** Moving this job to a hydro-powered region (0.02 kg/kWh) would reduce emissions by **20x** to just ~25 flights.
:::

AI systems consume resources at industrial scales that rival traditional heavy industries. Training a single large language model consumes thousands of megawatt-hours of electricity, equivalent to powering hundreds of households for months.[^fn-household-energy] Data centers that include AI workloads are projected to account for 8% of global power consumption by 2030, surpassing aviation at 2.1% and approaching cement production at 4% [@oecd2023blueprint].[^fn-industry-comparison] Computational demands increased 350,000$\times$ from 2012 to 2019 [@schwartz2020green], while hardware efficiency improved at a far slower rate, creating an unsustainable growth trajectory.

[^fn-household-energy]: **Household Energy Comparison**: The average U.S. household consumes 10,500 kWh annually (about 875 kWh monthly). While OpenAI has not released official GPT-4 training energy consumption data, estimates suggest it may have required significantly more energy than GPT-3's verified 1,287 MWh. For context, GPT-3's training consumed electricity equivalent to 122 average U.S. households' annual consumption.

[^fn-industry-comparison]: **AI vs Industrial Emissions**: Data centers (which include AI workloads) are projected to account for 8% of total power consumption by 2030, surpassing aviation (2.1%) and approaching cement production (4%). Current AI emissions already exceed those of Argentina (0.18 billion tons CO₂ annually). Training just the top 10 large language models in 2023 generated emissions equivalent to 40,000 round-trip flights from New York to London.

Beyond direct energy consumption, AI systems drive environmental impact through hardware manufacturing and resource utilization. Training and inference workloads depend on specialized processors that require rare earth metals whose extraction and processing generate pollution.[^fn-gpu-manufacturing] The growing demand for AI applications accelerates electronic waste production, with global e-waste reaching 54 million metric tons annually [@Forti2020]. AI hardware rapidly becomes obsolete due to accelerating performance requirements.[^fn-ewaste-scale]

[^fn-gpu-manufacturing]: **GPU Manufacturing Impact**: Producing a single high-end GPU like the NVIDIA H100 generates 300-500 kg of CO₂ before any computation occurs. Manufacturing requires 2,500+ liters of ultrapure water, 15+ rare earth elements, and energy-intensive processes reaching 1,000°C. TSMC's 4nm process is more energy-efficient per transistor but requires more complex manufacturing steps, increasing overall fab energy intensity compared to 7nm processes.

[^fn-ewaste-scale]: **E-Waste from Computing**: Global e-waste reached 53.6 million metric tons in 2019, with computing equipment contributing approximately 15%. AI hardware accelerates this trend: NVIDIA's GPU sales increased 200% from 2020-2023, with each high-end GPU weighing 1-2 kg and containing toxic materials requiring specialized disposal. The rapid obsolescence cycle means AI hardware often becomes e-waste within 3-5 years.

These environmental challenges require systematic understanding and coordinated response in technical, policy, and ethical dimensions to ensure AI development remains viable and responsible.

### Environmental Impact and Ethical Foundations {#sec-sustainable-ai-part-environmental-impact-ethical-foundations-7581}

Before examining measurement and mitigation strategies, we must understand the ethical framework guiding sustainable AI development. When training a single language model consumes electricity equivalent to thousands of homes annually, this creates urgent questions about who benefits from AI progress and who bears its ecological costs. The intersection of exponential computational demands with finite planetary resources demands that the field confront difficult choices about sustainable development pathways balancing innovation with environmental responsibility.

### Environmental Justice and Responsible Development {#sec-sustainable-ai-environmental-justice-responsible-development-3923}

The environmental impact of AI creates ethical responsibilities that extend beyond technical optimization. Environmental sustainability emerges as a critical component of trustworthy AI systems, extending the responsible AI principles examined in @sec-responsible-engineering to include ecological stewardship. The computational resources required for AI development concentrate environmental costs on specific communities while distributing benefits unequally across global populations. Data centers consume between 1 and 3 percent of global electricity and 760 billion liters of water annually for cooling, often in regions where energy grids rely on fossil fuels and water resources face stress from climate change.

This geographic concentration of environmental burden creates questions of environmental justice that align with broader responsible AI frameworks.[^fn-environmental-justice] Just as fairness considerations require examining who benefits from AI systems and who bears their risks, environmental responsibility demands understanding who pays the ecological costs of AI advancement. Communities hosting AI infrastructure bear disproportionate environmental burdens while having limited access to AI's economic benefits, exemplifying the need to extend ethical AI frameworks beyond algorithmic fairness to encompass environmental stewardship.

[^fn-environmental-justice]: **Environmental Justice**: Framework ensuring that environmental benefits and burdens are distributed fairly across all communities, regardless of race, color, or income. In AI context, this means data centers often locate in economically disadvantaged areas to access cheaper land and electricity, imposing environmental costs (pollution, water usage, heat) on communities with little political power to resist. Meanwhile, AI benefits (jobs, economic growth) concentrate in wealthy tech hubs. Examples: Microsoft's data center in rural Iowa uses 23 million liters of water daily while local farmers face drought restrictions.

### Exponential Growth vs Physical Constraints {#sec-sustainable-ai-exponential-growth-vs-physical-constraints-0f4e}

Exponential growth in computational demands challenges the long-term sustainability of AI training and deployment. Over the past decade, AI systems have scaled at an unprecedented rate, with compute requirements increasing 350,000$\times$ from 2012 to 2019 [@schwartz2020green].[^fn-ai-compute-growth] This trend continues as machine learning systems prioritize larger models with more parameters, larger training datasets, and higher computational complexity. Sustaining this trajectory poses sustainability challenges, as hardware efficiency gains fail to keep pace with rising AI workload demands.

[^fn-ai-compute-growth]: **AI Compute Explosion**: This 350,000$\times$ increase represents a doubling time of approximately 3.4 months, far exceeding Moore's Law's 2-year doubling cycle. For comparison, this is equivalent to going from the computational power of a smartphone to that of the world's largest supercomputer. The trend has only accelerated with large language models: GPT-4's training is estimated to have required 25$\times$ more compute than GPT-3, while models like PaLM-2 and Claude used even more computational resources.

Historically, computational efficiency improved with advances in semiconductor technology. Moore's Law predicted that the number of transistors on a chip would double approximately every two years, leading to continuous improvements in processing power and energy efficiency.[^fn-sustainable-moores-law] However, Moore's Law is now reaching core physical limits, making further transistor scaling difficult and costly. Dennard scaling, which once ensured that smaller transistors would operate at lower power levels, has also ended, leading to stagnation in energy efficiency improvements per transistor.[^fn-dennard-scaling]

[^fn-sustainable-moores-law]: **Moore's Law Origins**: Named after Intel co-founder Gordon Moore, who made this observation in a 1965 *Electronics* magazine article titled "Cramming More Components onto Integrated Circuits," Moore's Law has driven the semiconductor industry for nearly 60 years. Moore initially predicted a doubling every year, later revised to two years. The law's economic impact is staggering: it allowed the $4 trillion global electronics industry and made possible everything from smartphones to supercomputers. However, at 3nm process nodes, individual atoms become the limiting factor.

[^fn-dennard-scaling]: **Dennard Scaling**: Rule observed by IBM's Robert Dennard in 1974 that smaller transistors could run at the same power density by reducing voltage proportionally. Enabled 30 years of "free" performance gains until ~2005 when leakage current and voltage scaling limits ended the trend. Without Dennard scaling, modern CPUs would consume kilowatts instead of ~100W. Its end forced the shift to multi-core processors and specialized accelerators like GPUs for AI workloads.

While AI models continue to scale in size and capability, the hardware running these models no longer improves at the same exponential rate. This growing divergence between computational demand and hardware efficiency creates an unsustainable trajectory where AI consumes ever-increasing amounts of energy. This technical reality underscores why sustainable AI development requires coordinated action across the entire systems stack, from individual algorithmic choices to infrastructure design and policy frameworks.

::: {#fig-energy-wall-quantitative fig-env="figure" fig-pos="htb" fig-cap="The Energy Wall Quantified: The widening gap between the exponential growth of AI compute demand (approx. 3.4x/year) and the slower pace of hardware efficiency gains (approx. 1.5x/year) creates a massive energy deficit that defines the modern sustainable AI challenge." fig-alt="Log-scale plot of compute demand (3.4x/year) versus hardware efficiency (1.5x/year) from 2012 to 2025. Shaded energy deficit region. Milestones: AlexNet, GPT-3, GPT-4."}
```{python}
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ ENERGY WALL QUANTITATIVE (FIGURE)
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @fig-energy-wall-quantitative — demand vs efficiency divergence
# │
# │ Goal: Plot compute demand (3.4×/yr) vs hardware efficiency (1.5×/yr);
# │       show shaded energy deficit; AlexNet/GPT-3/GPT-4 milestones.
# │ Show: Two curves; fill_between; log-scale y.
# │ How: Exponential growth; matplotlib.
# │
# │ Imports: matplotlib.pyplot (plt), numpy (np)
# │ Exports: (figure only, no prose variables)
# └─────────────────────────────────────────────────────────────────────────────
import matplotlib.pyplot as plt
import numpy as np

plt.style.use('seaborn-v0_8-whitegrid')

years = np.linspace(2012, 2025, 100)
t = years - 2012

compute_growth = 3.4 ** t
efficiency_growth = 1.5 ** t

fig, ax = plt.subplots(figsize=(10, 6))

ax.plot(years, compute_growth, color='#C0392B', linewidth=3, label='AI Compute Demand (~3.4x/year)')
ax.plot(years, efficiency_growth, color='#27AE60', linewidth=3, linestyle='--', label='Hardware Efficiency (~1.5x/year)')

ax.fill_between(years, efficiency_growth, compute_growth, color='#E74C3C', alpha=0.2, label='The Energy Wall (Deficit)')

milestones = [
    (2012, 'AlexNet', 1.0),
    (2020, 'GPT-3', 3.4**(2020-2012)),
    (2023, 'GPT-4', 3.4**(2023-2012))
]

for year, name, y_val in milestones:
    ax.plot(year, y_val, 'o', color='#333333', markersize=6)
    ax.annotate(name,
                xy=(year, y_val),
                xytext=(-10, 15),
                textcoords='offset points',
                fontsize=10,
                fontweight='bold',
                arrowprops=dict(arrowstyle='-', color='#333333'))

ax.set_yscale('log')
ax.set_xlim(2012, 2025)
ax.set_ylim(0.8, 2e7)
ax.set_ylabel('Relative Scale (Log, 2012 = 1x)', fontsize=11)
ax.set_xlabel('Year', fontsize=11)
ax.set_title('The Energy Wall: Demand vs. Efficiency (2012-2025)', fontsize=13, pad=15)
ax.legend(fontsize=11, loc='upper left', frameon=True, framealpha=0.9)
ax.grid(True, which='major', alpha=0.6)
ax.grid(True, which='minor', alpha=0.2, linestyle=':')

fig = plt.gcf()
```
:::

@fig-datacenter-energy-usage projects data center electricity usage across three scenarios (best, expected, and worst case), revealing the stark range of potential outcomes depending on efficiency improvements.

::: {#fig-datacenter-energy-usage fig-env="figure" fig-pos="htb" fig-cap="**Data Center Energy Projections**: Global data center electricity consumption scenarios from 2010 to 2030. The three trajectories—best case, expected, and worst case—diverge significantly after 2018, highlighting the uncertainty and importance of efficiency improvements." fig-alt="Line graph projecting data center electricity usage from 2010 to 2030 in TWh. Three scenarios diverge after 2018: Best case reaches 700 TWh, Expected case reaches 3000 TWh, Worst case reaches 8000 TWh. Grid lines mark 2000 TWh intervals."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
\begin{axis}[
  axis line style={draw=none},
  width=16cm,
  height=10cm,
  table/col sep=comma,
  x tick label style={rotate=0, anchor=north},
  xmin=2009.5,xmax=2030,
  ymin=250, ymax=8300,
  ytick={2000,4000,6000,8000},
  ylabel={Electricity Usage (TWh)},
  xlabel={Year},
   legend style={at={(0.15,0.9)}, anchor=north},
   legend cell align=left,
   legend style={fill=BrownL!40,draw=BrownLine,row sep=1.85pt,
   font=\footnotesize\usefont{T1}{phv}{m}{n}},
  grid=both,
  minor tick num=1,
  major grid style={black!80},
  minor grid style={black!40},
    /pgf/number format/.cd,
  1000 sep={},
  nodes near coords align=right,
        tick label style={/pgf/number format/assume math mode=true},
        ticklabel style={font=\footnotesize\usefont{T1}{phv}{m}{n}},
    cycle multi list={
     red,blue,green\nextlist
     solid\nextlist
     mark=o,mark=none,mark=triangle,mark=none,mark=,mark=none
     },
]
\addplot+[mark=*,line width=2pt,
red] table[x=Date,y=Y, col sep=comma] {
Y,Date
500, 2010
510, 2012
520, 2014
540, 2016
560, 2018
580, 2020
600, 2022
630, 2024
660, 2026
690, 2028
700, 2030
};
\addplot+[mark=triangle*, mark size=3pt,cyan!90!black,
line width=2pt] table[x=Date,y=Y, col sep=comma] {
Y,Date
500, 2010
550, 2012
600, 2014
680, 2016
760, 2018
860, 2020
1000, 2022
1200, 2024
1600, 2026
2000, 2028
2967, 2030
};
\addplot+[mark=square*,line width=2pt, mark size=2.5pt,
green!70!black] table[x=Date,y=Y, col sep=comma] {
Y,Date
500, 2010
600, 2012
750, 2014
1000, 2016
1250, 2018
1600, 2020
2200, 2022
3000, 2024
4500, 2026
6000, 2028
7933, 2030
};
 \legend{Best, Expected, Worst}
\coordinate (legend) at (axis description cs:0.15,0.92);
\end{axis}
\node[fill=white,above=2pt of legend,anchor=center]{\small\bfseries Scenario};
\end{tikzpicture}
```
:::

### The Energy Wall: Divergent Scaling {#sec-sustainable-ai-energy-wall}

*Why* is AI sustainability a unique engineering challenge? It is a race between two fundamentally different physics: the **exponential scaling of logic** and the **linear scaling of energy infrastructure**.

::: {#fig-energy-wall fig-env="figure" fig-pos="htb" fig-cap="**The Energy Wall**. AI compute requirements (FLOPS) have grown ~350,000$\\times$ since 2012. In contrast, the physical substrate of energy—battery density and grid efficiency—improves at only ~2–5% annually. This `{python} energy_wall_gap_str`$\\times$ divergence creates the 'Energy Wall' where algorithmic ambition exceeds physical possibility." fig-alt="Log-scale plot showing AI compute growing exponentially while battery density and grid efficiency show nearly flat linear growth. Shaded region between curves marks the 'Sustainability Gap'."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
  \definecolor{AIColor}{HTML}{CB202D}
  \definecolor{GridColor}{HTML}{008F45}

  % Axes
  \draw[->, thick] (0,0) -- (8,0) node[right] {Year};
  \draw[->, thick] (0,0) -- (0,5.5) node[above] {Growth (Log Scale)};

  % Compute Growth (Steep)
  \draw[ultra thick, AIColor] (0,0.5) .. controls (2,1) and (5,4) .. (7,5) node[right] {AI Compute Demand};
  \node[AIColor, font=\tiny\bfseries] at (6, 4.5) {~350,000$\times$};

  % Grid/Battery Growth (Shallow)
  \draw[ultra thick, GridColor] (0,0.5) -- (7,1.5) node[right] {Grid/Battery Capacity};
  \node[GridColor, font=\tiny\bfseries] at (6, 1.0) {~20-80\%};

  % The Gap
  \draw[<->, ultra thick, OrangeLine] (6.5, 1.4) -- (6.5, 4.7);
  \node[OrangeLine, rotate=90, font=\bfseries] at (6.8, 3.0) {Sustainability Gap};

  % Ticks
  \node[below] at (0,0) {2012};
  \node[below] at (7,0) {2024};

\end{tikzpicture}
```
:::

While AI logic follows the "Iron Law" of software optimization, energy follows the laws of chemistry and thermodynamics. Over the last 12 years, battery energy density has improved by only ~`{python} battery_gain_pct`%, and grid efficiency by ~`{python} grid_gain_pct`%. The `{python} energy_wall_gap_str`$\times$ gap between these two curves is the **Sustainability Wall**—the point where we can no longer "buy our way out" of the efficiency problem with more power.

### Datacenter Grid Dynamics {#sec-sustainable-ai-grid-dynamics}

Sustainable AI requires looking beyond the server rack to the **Electrical Grid Interface**. Traditional datacenters are "Steady-State" loads; they pull constant power 24/7. ML training clusters, however, are **Transient Loads**.

#### The Power Ramp and Grid Stability
As discussed in @sec-compute-power-delivery, a 10,000-GPU cluster can swing its load by 5–10 Megawatts in milliseconds during an AllReduce synchronization step. For an electrical utility, this is a "Noise Event." *When* thousands of GPUs suddenly stop computing to wait for the network, they cause a "Voltage Spike" on the grid; *when* they resume, they cause a "Voltage Sag."
Managing these transients requires **Energy Buffering**: using on-site battery arrays or massive capacitors to smooth the training iterations, ensuring the ML Fleet doesn't destabilize the local municipal power grid.

#### Heat Reuse: Turning Waste into Fuel
A datacenter is physically a system that converts high-quality energy (electricity) into low-quality energy (waste heat). In a sustainable fleet, this heat is not "exhausted" into the atmosphere but "harvested."
*   **District Heating**: Modern facilities in Nordic regions (e.g., Meta's Odense facility) pipe waste heat into local municipal heating systems, providing enough thermal energy to warm thousands of homes.
*   **Industrial Coupling**: Using low-grade waste heat (~45°C) for greenhouse climate control or water desalination.

By treating heat as a **Byproduct** rather than a **Pollutant**, the fleet moves toward a "Circular Energy Economy."[^fn-history-pue]

[^fn-history-pue]: **The Evolution of PUE**: In the early 2000s, PUE values of 2.0–2.5 were common, meaning more power was used for cooling than for computing. Google's 2009 disclosure of PUE 1.21 was a watershed moment, proving that "free-air cooling" and efficient power conversion could halve datacenter footprints. Today, the focus has shifted from PUE (rate efficiency) to **CUE (Carbon Usage Effectiveness)** and **WUE (Water Usage Effectiveness)**, reflecting a holistic view of planetary boundaries.

Training complex AI systems demands high levels of computing power, resulting in significant energy consumption. OpenAI's GPT-3 exemplifies this scale: training required 1,287 megawatt-hours of electricity, equivalent to powering 130 U.S. homes for an entire year [@maslej2023artificial].[^fn-sustainable-gpt3] This energy consumption represents the computational algorithms trained on large datasets that characterize modern large language models.[^fn-training-process]

[^fn-training-process]: **Training Process**: Iterative optimization of model parameters through forward passes (computing predictions), loss calculation, and backward passes (gradient computation via backpropagation). Modern training runs millions of iterations across distributed hardware. GPT-4 training consumed an estimated 50+ GWh over several months, with gradient synchronization and checkpointing adding 15-30% communication overhead.

[^fn-sustainable-gpt3]: **GPT-3 Energy Consumption**: Training GPT-3 consumed approximately 1,287 MWh of electricity, equivalent to the annual energy consumption of 130 average American homes or the same amount of CO₂ as burning 227,000 kg of coal. At average US electricity prices, this training run cost roughly $130,000 in electricity alone. GPT-4, with estimated 25$\times$ more compute, likely consumed over 30,000 MWh, enough to power a small city for a month. The energy per parameter ratio reveals hardware-software co-design inefficiencies: GPT-3's `{python} gpt3_params_b` billion parameters required 7.4 kWh per billion parameters, while optimized architectures can achieve sub-1 kWh ratios through mixed precision and sparsity techniques.

This scale of energy consumption highlights the urgent need for efficiency improvements in AI systems. Generative AI models have gained increasing popularity in recent years, leading to more models being trained with growing parameter counts.

Research shows that increasing model size, dataset size, and compute used for training improves performance smoothly with no signs of saturation [@kaplan2020scaling]. @fig-model-scaling demonstrates that test loss decreases predictably as each of these three factors increases, with no apparent ceiling in sight. Beyond training, AI-powered applications such as large-scale recommender systems and generative models require continuous inference at scale, consuming energy even after training completes. As AI adoption grows across industries from finance to healthcare to entertainment, the cumulative energy burden of AI workloads continues to rise, raising concerns about the environmental impact of widespread deployment.

![**Model Scaling Laws**: Increasing model size, dataset size, and compute consistently reduces test loss, indicating that performance improvements continue to be achievable with greater resources and without evidence of saturation. These scaling laws suggest that larger models trained on more data with increased compute will likely yield further gains in performance, driving continued investment in these areas.](images/png/model_scaling.png){#fig-model-scaling fig-alt="Three line graphs showing test loss decreasing as model parameters, dataset tokens, and compute FLOPs increase. Each plot shows smooth power-law scaling with no saturation, indicating continued improvement with more resources."}

Beyond electricity consumption, the sustainability challenges of AI extend to hardware resource demands and the energy efficiency limitations of current architectures. Different processor types affect environmental impact through their energy characteristics. Central Processing Units consume approximately 100 picojoules per multiply-accumulate operation, Graphics Processing Units achieve 10 pJ/MAC, while specialized Tensor Processing Units reach 1 pJ/MAC, and specialized accelerators approach 0.1 pJ/MAC.[^fn-energy-metrics] These hardware platforms require rare earth metals and complex manufacturing processes with embodied carbon.

[^fn-energy-metrics]: **Energy Metrics (pJ/MAC)**: Picojoules per multiply-accumulate operation, the standard measure of computational energy efficiency. CPUs typically consume 20-100 pJ/MAC, GPUs achieve 0.5-2 pJ/MAC, and specialized TPUs reach 0.1-0.5 pJ/MAC. The human brain operates at ~1 fJ/op (1000$\times$ more efficient), establishing the theoretical ceiling for neuromorphic computing research.

The production of AI chips is energy-intensive, involving multiple fabrication steps that contribute significantly to Scope 3 emissions in the overall AI system lifecycle. As model sizes continue to grow, the demand for AI hardware increases, exacerbating the environmental impact of semiconductor production and disposal.

### Theoretical Efficiency Limits as a Sustainability Model {#sec-sustainable-ai-theoretical-efficiency-limits-d880}

To understand the scale of AI's energy challenge, it helps to compare current systems with the theoretical limits of computational efficiency. Modern large language models (LLMs) operate with an energy efficiency gap of $10^6\times$ compared to the most efficient known physical implementations of pattern recognition and reasoning. This disparity establishes a "Sustainability Wall" where industrial-scale energy infrastructure is required to achieve tasks that theoretically require only milliwatts of power.

Training a single model like GPT-3 creates a stark reminder of this gap: while silicon-based systems consume megawatts to process 10^12 tokens, theoretical models of distributed processing suggest that similar cognitive capabilities are achievable with power budgets comparable to a household light bulb. This motivates the search for alternative computing paradigms that prioritize energy-aware architecture over raw throughput.

#### Principles of High-Efficiency Computing {#sec-sustainable-ai-principles-highefficiency-computing-6a9b}

Physical efficiency in information processing stems from three key principles that differ from current AI systems:

1. **Selective, Event-Driven Activation**: Rather than processing all information continuously, high-efficiency systems are asynchronous. They activate only small portions of the network at any time and consume energy only when actively processing changing signals.[^fn-event-driven]

2. **Local Learning and Sample Efficiency**: Current architectures require training on trillions of tokens to achieve competence. High-efficiency models leverage strong *inductive biases* and self-supervised local learning to acquire capabilities from $10,000\times$ less data, reducing the cumulative energy cost of the training phase.

3. **Sparsity and Sparse Interconnects**: In modern GPUs, the majority of energy is spent on data movement and global synchronization. High-efficiency systems utilize sparse representations where only 1-2% of parameters are active for any given task, drastically reducing the bandwidth and switching energy required.

[^fn-event-driven]: **Event-Driven Computing**: A paradigm where computation is triggered by changes in input (events) rather than a continuous clock signal. This approach is the foundation of *Neuromorphic* hardware, which can achieve 100-1000$\times$ energy reductions for specific temporal tasks by remaining idle when data is static.

These insights point toward promising research directions for sustainable AI. Architectures that implement **Spiking Neural Networks (SNNs)** or sparse activation patterns can achieve significant energy reductions by mimicking these sparse communication models [@prakash2023tinyml].[^fn-spiking-networks] Similarly, local learning algorithms and self-supervised approaches offer pathways toward more sample-efficient and energy-conscious systems.

[^fn-spiking-networks]: **Spiking Neural Networks (SNNs)**: Third-generation artificial neural networks that communicate through discrete signals rather than continuous values. While harder to train than traditional deep networks, SNNs are naturally suited for event-driven data like audio and video, offering a pathway toward the theoretical efficiency ceiling.

Achieving sustainable AI requires a systematic shift in system design, moving from continuously active, dense architectures toward event-driven, sparse computation models. As compute demands outpace incremental efficiency improvements in silicon manufacturing, addressing AI's environmental impact demands rethinking the fundamental "Physics" of the algorithm based on these efficiency principles.

@fig-energy-intervention shows how three categories of intervention—algorithmic, hardware, and systemic—combine to reduce the energy gap by approximately 10,000$\times$, transforming an intractable divergence into an engineering challenge. No single lever is sufficient; closing the gap requires simultaneous progress across all three fronts.

::: {#fig-energy-intervention fig-env="figure" fig-pos="htb" fig-cap="**Energy Gap Intervention Cascade**: Three categories of efficiency improvement—algorithmic ($\\div$100 $\\times$), hardware ($\\div$10 $\\times$), and systemic ($\\div$10 $\\times$)—progressively reduce the 350,000 $\\times$ energy gap to an engineering-tractable 35 $\\times$. Bar widths reflect log-scale reduction at each stage." fig-alt="Four horizontal bars decreasing in width from top to bottom. Top bar labeled 350000x current gap in red, then 3500x after algorithmic in orange, 350x after hardware in blue, and 35x tractable gap in green. Brace annotation shows combined 10000x reduction."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
  \definecolor{RedLine}{HTML}{CB202D}
  \definecolor{OrangeLine}{HTML}{E67817}
  \definecolor{BlueLine}{HTML}{006395}
  \definecolor{GreenLine}{HTML}{008F45}
  \definecolor{VioletLine}{HTML}{7E317B}

  % Bar parameters
  \def\bh{0.55}   % bar height
  \def\vs{1.5}    % vertical spacing between bars

  % --- Bar 1: Current gap ---
  \fill[RedLine!70] (0, 0) rectangle (10, \bh);
  \node[white, font=\scriptsize\bfseries, anchor=west] at (0.15, \bh/2)
    {350,000$\times$ energy gap};
  \node[font=\scriptsize\bfseries, anchor=east] at (-0.15, \bh/2) {Current};

  % Intervention 1: Algorithmic
  \draw[->, >=stealth, thick, VioletLine] (6.4, -0.1) -- (6.4, -\vs+\bh+0.1);
  \node[VioletLine, font=\scriptsize\bfseries, anchor=west] at (6.6, -\vs/2+\bh/2+0.12)
    {Algorithmic Efficiency};
  \node[text=gray, font=\tiny, anchor=west] at (6.6, -\vs/2+\bh/2-0.2)
    {Sparse models, MoE, pruning};
  \node[VioletLine, font=\tiny\bfseries, anchor=east] at (6.2, -\vs/2+\bh/2)
    {$\div$100$\times$};

  % --- Bar 2: After algorithmic ---
  \fill[OrangeLine!70] (0, -\vs) rectangle (6.4, -\vs+\bh);
  \node[white, font=\scriptsize\bfseries, anchor=west] at (0.15, -\vs+\bh/2)
    {3,500$\times$};
  \node[font=\scriptsize\bfseries, anchor=east] at (-0.15, -\vs+\bh/2)
    {After Algo.};

  % Intervention 2: Hardware
  \draw[->, >=stealth, thick, BlueLine] (4.6, -\vs-0.1) -- (4.6, -2*\vs+\bh+0.1);
  \node[BlueLine, font=\scriptsize\bfseries, anchor=west] at (4.8, -3*\vs/2+\bh/2+0.12)
    {Hardware Efficiency};
  \node[text=gray, font=\tiny, anchor=west] at (4.8, -3*\vs/2+\bh/2-0.2)
    {Specialized accelerators, process nodes};
  \node[BlueLine, font=\tiny\bfseries, anchor=east] at (4.4, -3*\vs/2+\bh/2)
    {$\div$10$\times$};

  % --- Bar 3: After hardware ---
  \fill[BlueLine!70] (0, -2*\vs) rectangle (4.6, -2*\vs+\bh);
  \node[white, font=\scriptsize\bfseries, anchor=west] at (0.15, -2*\vs+\bh/2)
    {350$\times$};
  \node[font=\scriptsize\bfseries, anchor=east] at (-0.15, -2*\vs+\bh/2)
    {After HW};

  % Intervention 3: Systemic
  \draw[->, >=stealth, thick, GreenLine] (2.8, -2*\vs-0.1) -- (2.8, -3*\vs+\bh+0.1);
  \node[GreenLine, font=\scriptsize\bfseries, anchor=west] at (3.0, -5*\vs/2+\bh/2+0.12)
    {Systemic Efficiency};
  \node[text=gray, font=\tiny, anchor=west] at (3.0, -5*\vs/2+\bh/2-0.2)
    {Carbon-aware scheduling, renewables, heat reuse};
  \node[GreenLine, font=\tiny\bfseries, anchor=east] at (2.6, -5*\vs/2+\bh/2)
    {$\div$10$\times$};

  % --- Bar 4: Bridgeable gap ---
  \fill[GreenLine!70] (0, -3*\vs) rectangle (2.8, -3*\vs+\bh);
  \node[white, font=\scriptsize\bfseries, anchor=west] at (0.15, -3*\vs+\bh/2)
    {35$\times$};
  \node[font=\scriptsize\bfseries, anchor=east] at (-0.15, -3*\vs+\bh/2)
    {Tractable};

  % Right brace showing combined reduction
  \draw[decorate, decoration={brace, amplitude=5pt, mirror}, thick]
    (10.3, \bh) -- (10.3, -3*\vs)
    node[midway, right=7pt, align=left, font=\scriptsize]
    {Three levers\\reduce gap by\\$\sim$10,000$\times$};

\end{tikzpicture}
```
:::

The convergence of exponential computational demands with physical efficiency limits creates an unsustainable trajectory that threatens the long-term viability of AI development. Understanding these constraints provides the foundation for developing measurement frameworks and implementation strategies that can address the sustainability crisis systematically.

The convergence of exponential computational demands with hard physical efficiency limits creates an unsustainable trajectory that threatens the long-term viability of AI scaling. To alter this trajectory, we must move beyond back-of-the-envelope calculations and establish rigorous, systemic frameworks for measuring and assessing energy consumption across the entire ML infrastructure.

---

## Energy Measurement and Modeling {#sec-sustainable-ai-part-ii-measurement-assessment-fb0b}

You cannot optimize what you cannot measure. If your cluster consumes five megawatts of power during a large language model training run, how much of that power actually went into matrix multiplications, and how much was wasted spinning cooling fans to remove the resulting heat? Effective energy modeling requires decomposing the monolithic datacenter power bill into granular, component-level metrics that engineers can actually target for optimization.

The datacenter infrastructure foundations from @sec-compute-infrastructure established power and cooling as dominant engineering constraints. Systematic measurement now transforms these constraints into sustainability metrics. This part develops quantitative frameworks for three critical areas: energy consumption tracking during training and inference, carbon footprint analysis across system lifecycles, and resource utilization assessment for hardware and infrastructure. These measurement tools enable engineers to identify optimization opportunities, compare alternative designs, and validate that sustainability improvements achieve their intended effects. Just as performance engineering requires profiling before optimization, sustainable AI engineering requires measurement before mitigation.

### Carbon Footprint Analysis {#sec-sustainable-ai-carbon-footprint-analysis-ccc5}

Carbon footprint analysis provides the foundation for making informed design decisions about AI system sustainability. As AI systems continue to scale, systematic measurement of energy consumption and resource demands enables proactive approaches to environmental optimization. Developers and companies that build and deploy AI systems must consider not only performance and efficiency but also the environmental consequences of their design choices.

A central ethical challenge lies in balancing technological progress with ecological responsibility. The pursuit of increasingly large models often prioritizes accuracy and capability over energy efficiency, creating exponential increases in carbon emissions. While optimizing for sustainability may introduce trade-offs such as 10 to 30 percent longer development cycles or 1 to 5 percent accuracy reductions through techniques like pruning and quantization, these costs are substantially outweighed by environmental benefits. Integrating environmental considerations into AI system design has become an ethical imperative. This requires shifting industry norms toward sustainable computing practices such as energy-aware training techniques, low-power hardware designs, and carbon-conscious deployment strategies [@patterson2021carbon].

This ethical imperative extends beyond sustainability to encompass broader concerns related to transparency, fairness, and accountability. @fig-ethical-ai illustrates the ethical challenges associated with AI development, linking different types of concerns, including inscrutable evidence, unfair outcomes, and traceability, to issues like opacity, bias, and automation bias [@coe2023ethical]. These concerns extend to sustainability, as the environmental trade-offs of AI development are often opaque and difficult to quantify. The lack of traceability in energy consumption and carbon emissions can lead to unjustified actions, where companies prioritize performance gains without fully understanding or disclosing the environmental costs.

::: {#fig-ethical-ai fig-env="figure" fig-pos="htb" fig-cap="**Ethical AI Concerns**: AI systems introduce ethical challenges across transparency, fairness, and sustainability; these concerns interrelate and stem from issues like opacity, bias, and a lack of traceability in resource consumption. Addressing these challenges requires proactive design choices that prioritize accountability and minimize negative societal and environmental impacts. " fig-alt="Flowchart linking 6 types of AI concerns on left to 12 ethical challenges on right. Evidence concerns connect to opacity and bias. Unfair outcomes link to discrimination. Traceability connects to responsibility and auditing issues."}
```{.tikz}
\scalebox{0.75}{%
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
\tikzset{
  Line/.style={line width=1.0pt,BrownLine,text=black},
  Box/.style={inner xsep=2pt,
    node distance=0.2,
    draw=VioletLine2, line width=0.75pt,
    fill=VioletL2,
    text width=36mm,align=flush center,
    minimum width=36mm, minimum height=7.7mm
  },
    Box1/.style={inner xsep=2pt,
    node distance=0.2,
    draw=OrangeLine, line width=0.75pt,
    fill=OrangeL!70,
    text width=36mm,align=flush center,
    minimum width=36mm, minimum height=7.7mm
  },
  }
\node[Box](G1){Unjustified actions};
\node[Box,below =of G1](G2){Opacity};
\node[Box,below =of G2](G3){Bias};
\node[Box,below =of G3](G4){Discrimination};
\node[Box,below =of G4](G5){Autonomy};
\node[Box,below =of G5](G6){Informational privacy};
\node[Box,below =of G6](G7){Group privacy};
\node[Box,below =of G7](G8){Moral responsibility};
\node[Box,below =of G8](G9){Distributed responsibility};
\node[Box,below =of G9](G10){Automation bias};
\node[Box,below =of G10](G11){Safety and resilience};
\node[Box,below =of G11](G12){Ethical auditing};
%
\node[Box1,node distance=3.9,left =of G1](LG1){Inconclusive evidence};
\node[Box1,below =of LG1](LG2){Inscrutable evidence};
\node[Box1,below =of LG2](LG3){Misguided evidence};
\node[Box1,below =of LG3](LG4){Unfair outcomes};
%
\node[Box1,node distance=3.9,left =of G6](LG5){Transformative effects};
\node[Box1,node distance=3.9,left =of G10](LG6){Traceability};
\node[above=0.1 of G1]{\textbf{Ethical Challenges}};
\node[above=0.1 of LG1]{\textbf{Types of concerns}};
%
\foreach \x in {2,3,4,5,6}{
\draw[line width=1.5pt,BrownLine](LG1.west)--++(180:0.65)|-(LG\x);
}
%
\draw[thick,blue!80!black!99,decoration={brace,amplitude=6pt},decorate]
([yshift=0mm,xshift=1mm]LG1.north east)--([yshift=0mm,xshift=1mm]LG3.south east)
node [blue,midway,below=1mm] {};
%
\draw[thick,blue!80!black!99,decoration={brace,amplitude=6pt},decorate]
([yshift=0mm,xshift=1mm]LG4.north east)--([yshift=0mm,xshift=1mm]LG5.south east)
node [blue,midway,below=1mm] {};
%
\foreach \x in {8,...,12}{
\draw[Line,-latex,shorten <=5mm](LG6.east)--++(0:2)|-(G\x);
}

\foreach \x in {5,6,7}{
\draw[Line,-latex,shorten <=5mm](LG5.east)--++(0:2)|-(G\x);
}
\foreach \x in {1,2,3,4}{
\draw[Line,-latex,shorten <=5mm](LG\x.east)--(G\x);
}
\end{tikzpicture}}
```
:::

Addressing these concerns demands greater transparency and accountability from AI companies. Large technology firms operate extensive cloud infrastructures that power modern AI applications, yet their environmental impact remains opaque. Organizations must measure, report, and reduce their carbon footprint throughout the AI lifecycle, from hardware manufacturing to model training and inference. Voluntary self-regulation provides an initial step, but policy interventions and industry-wide standards may be necessary to ensure long-term sustainability. Reported metrics such as energy consumption, carbon emissions, and efficiency benchmarks can hold organizations accountable.

Ethical AI development requires open discourse on environmental trade-offs. Researchers must advocate for sustainability within their institutions and organizations, ensuring that environmental concerns are integrated into AI development priorities. The broader AI community has begun addressing these issues, as exemplified by the [open letter advocating a pause on large-scale AI experiments](https://futureoflife.org/open-letter/pause-giant-ai-experiments/), which highlights concerns about unchecked expansion. Fostering a culture of transparency and ethical responsibility allows the AI industry to align technological advancement with ecological sustainability.

AI has the potential to reshape industries and societies, but its long-term viability depends on responsible development practices. Ethical AI development involves preventing harm to individuals and communities while ensuring that AI-driven innovation does not occur at the cost of environmental degradation. As stewards of these technologies, developers and organizations must integrate sustainability into AI's future trajectory.

Preventing environmental harm requires us to hold AI systems accountable for their resource usage with the same rigor we apply to latency or accuracy. To achieve this transparency, we must translate abstract power consumption metrics into the universally recognized metric of environmental impact: the carbon footprint calculation.

::: {.callout-checkpoint}
## Carbon Footprint Calculation
Calculate the total carbon footprint for training a 70B parameter model.
**Parameters:** 2,048 H100 GPUs, 30 days, 700W TDP, PUE 1.3, Grid intensity 400g $CO_2$/kWh.
**Operational:** Power = $2048 \times 0.7 \text{kW} \times 1.3 \approx 1,864 \text{kW}$. Energy = $1,864 \text{kW} \times 24\text{h} \times 30 \approx 1.34 \text{M kWh}$. Emissions = $1.34 \text{M} \times 400\text{g} \approx 536 \text{ metric tons } CO_2$.
**Embodied:** Assume manufacturing footprint is $\approx 1500 \text{kg } CO_2$ per chip. Amortized for 1 month of a 3-year cycle: $(2048 \times 1500 \text{kg}) / 36 \text{ months} \approx 85 \text{ metric tons}$.
**Total:** $536 + 85 = 621 \text{ metric tons } CO_2$.
:::

Translating these ethical principles into practice requires concrete engineering solutions that demonstrate measurable environmental improvements. Before developing the measurement frameworks in detail, an illustrative case study demonstrates their practical impact. Google's collaboration with DeepMind shows how systematic measurement enables significant efficiency improvements, including optimization of Power Usage Effectiveness (PUE), the industry standard metric we will formalize in subsequent sections.

### Case Study: DeepMind Energy Efficiency {#sec-sustainable-ai-case-study-deepmind-energy-efficiency-84fd}

Google's data centers form the backbone of services such as Search, Gmail, and YouTube, handling billions of queries daily. These facilities require substantial electricity consumption, particularly for cooling infrastructure that ensures optimal server performance. Improving data center energy efficiency has long been a priority, but conventional engineering approaches faced diminishing returns due to cooling system complexity and highly dynamic environmental conditions. To address these challenges, Google collaborated with DeepMind to develop a machine learning optimization system that automates and enhances energy management at scale.

After more than a decade of efforts to optimize data center design, energy-efficient hardware, and renewable energy integration, DeepMind's AI approach targeted cooling systems, among the most energy-intensive aspects of data centers. Traditional cooling relies on manually set heuristics that account for server heat output, external weather conditions, and architectural constraints. These systems exhibit nonlinear interactions, so simple rule-based optimizations often fail to capture the full complexity of their operations. The result was suboptimal cooling efficiency, leading to unnecessary energy waste.

DeepMind's team trained a neural network model using Google's historical sensor data, which included real-time temperature readings, power consumption levels, cooling pump activity, and other operational parameters. Building on Jim Gao's earlier work demonstrating that machine learning could predict data center PUE with 99.6% accuracy [@gao2014machine], the model learned the intricate relationships between these factors and could dynamically predict the most efficient cooling configurations. Unlike traditional approaches that relied on human engineers periodically adjusting system settings, the AI model continuously adapted in real time to changing environmental and workload conditions.

The results demonstrated significant efficiency gains. When deployed in live data center environments, DeepMind's AI-driven cooling system reduced cooling energy consumption by 40%, leading to an overall 15% improvement in Power Usage Effectiveness (PUE)[^fn-pue-metric], a metric for data center energy efficiency that measures the ratio of total energy consumption to the energy used purely for computing tasks [@barroso2019datacenter; @evans2016deepmind]. These improvements were achieved without additional hardware modifications, demonstrating the potential of software-driven optimizations to reduce AI's carbon footprint.

[^fn-pue-metric]: PUE, established in @sec-compute-infrastructure, measures facility overhead relative to compute power. Google's best facilities achieve 1.08, demonstrating the optimization targets achievable through AI-driven efficiency improvements.

This case study exemplifies how AI can serve not just as a consumer of computational resources but as a tool for sustainability---machine learning optimizing the infrastructure that powers it. The framework is generalizable across facility designs and climate conditions, offering a scalable solution for global datacenter networks.

#### Three-Phase Lifecycle Assessment Framework {#sec-sustainable-ai-threephase-lifecycle-assessment-framework-883a}

Effective carbon footprint measurement requires systematic analysis across three distinct phases that collectively determine environmental impact:

The training phase (60-80% of emissions) represents the most carbon-intensive period involving parallel computation for mathematical optimization processes[^fn-optimization-process]. As demonstrated by the GPT-3 case study, large language model training runs exemplify this energy intensity. Geographic placement affects emissions: training in Quebec (hydro-powered, 0.01 kg CO₂/kWh) versus West Virginia (coal-powered, 0.75 kg CO₂/kWh) creates a 75$\times$ difference in carbon intensity[^fn-carbon-intensity].

[^fn-optimization-process]: **Optimization Process**: Mathematical procedures finding optimal parameters through gradient descent variants (SGD, Adam, AdaFactor) that iteratively adjust weights to minimize loss functions. Adam, introduced in 2014, maintains per-parameter learning rates and momentum estimates, requiring 3$\times$ memory overhead but enabling 2-10$\times$ faster convergence compared to vanilla SGD on modern transformer architectures.

[^fn-carbon-intensity]: **Carbon Intensity**: Measure of CO₂ emissions per unit of electricity consumed, typically expressed as kg CO₂/kWh. Varies dramatically by energy source: coal (~0.82 kg CO₂/kWh), natural gas (~0.36), wind (~0.01), nuclear (~0.006), hydro (~0.024). Grid carbon intensity changes by location (Iceland: 99% renewable, Poland: 77% coal) and time of day (solar peaks at noon, wind varies). This enables carbon-aware computing: scheduling AI workloads when/where electricity is cleanest.

The inference phase, which accounts for 15 to 25 percent of emissions, generates ongoing computational costs for model serving and prediction generation. While individual inferences require less computation than training, the cumulative impact scales with deployment breadth and usage frequency. Models serving millions of users generate ongoing emissions that can exceed training costs over extended deployment periods.

The manufacturing phase, which accounts for 5 to 15 percent of emissions, contributes embodied carbon from hardware production, including semiconductor fabrication, rare earth mining, and supply chain logistics.[^fn-embodied-carbon] Often overlooked, this phase represents irreducible baseline emissions independent of operational efficiency.

[^fn-embodied-carbon]: **Embodied Carbon**: Carbon emissions from manufacturing, transportation, and disposal phases of a product, distinct from operational emissions during use. For AI hardware, embodied carbon includes mining rare earth elements, semiconductor fabrication, packaging, and shipping. A single NVIDIA H100 GPU embodies 300-500 kg CO2 before first use, equivalent to 1,600-2,600 km of driving. For comparison, the GPU's `{python} h100_tdp_w`W power consumption generates 300 kg CO2 annually (assuming average U.S. grid), meaning manufacturing emissions equal 1-2 years of operation. Research indicates that manufacturing emissions alone can account for up to 30% of an AI system's total carbon footprint, with this number potentially growing as data centers improve their reliance on renewable energy sources.

#### Geographic and Temporal Optimization {#sec-sustainable-ai-geographic-temporal-optimization-492c}

Carbon intensity varies across geographic locations and time periods, creating optimization opportunities. Temporal scheduling can reduce emissions by 50-80% by aligning compute workloads with renewable energy availability, such as peak solar generation during daylight hours [@Patterson2022carbonaware]. Carbon-aware scheduling systems can automatically shift non-urgent training jobs to regions and times with lower carbon intensity.

Measuring carbon footprint during development requires integrating tracking tools into ML workflows. @lst-carbon-tracking demonstrates how the CodeCarbon library wraps model training to capture real-time emissions data, enabling data-driven sustainability decisions.

::: {#lst-carbon-tracking lst-cap="**Carbon Footprint Tracking**: Example implementation using CodeCarbon library to measure emissions during model training, enabling data-driven sustainability decisions."}
```{.python}
from codecarbon import EmissionsTracker
import torch

# Initialize carbon tracking
tracker = EmissionsTracker()
tracker.start()

# Your model training code
model = torch.nn.Linear(100, 10)
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(100):
    # Training step
    loss = model(data).mean()
    loss.backward()
    optimizer.step()

# Get emissions report
emissions = tracker.stop()
print(f"Training emissions: {emissions:.4f} kg CO2")
```
:::

This integration allows engineers to make informed decisions about model complexity versus environmental impact during development.

### Power Modeling Fundamentals {#sec-sustainable-ai-power-modeling-fundamentals-67cb-67cb}

Understanding where energy goes in AI systems requires grounding in the physics of digital computation. The CMOS power equation provides the foundation for reasoning about energy consumption in modern processors, explaining why different optimization techniques achieve their efficiency gains and enabling quantitative comparison of architectural choices.

#### The CMOS Power Equation {#sec-sustainable-ai-cmos-power-equation-a33a-a33a}

Every digital circuit consumes power through two fundamental mechanisms. Dynamic power arises from switching transistors between states, while static power results from leakage current that flows even when transistors are nominally off. @eq-cmos-power formalizes the total power consumption:

$$P_{total} = P_{dynamic} + P_{static} = \alpha C V^2 f + V I_{leak}$$ {#eq-cmos-power}

The dynamic power component $P_{dynamic} = \alpha C V^2 f$ depends on four parameters. The switching activity factor $\alpha$ represents the fraction of transistors changing state per clock cycle, ranging from 0 to 1. General-purpose CPUs typically exhibit $\alpha \approx 0.1$ to $0.3$ due to diverse instruction mixes, while specialized AI accelerators can achieve $\alpha \approx 0.6$ to $0.8$ through optimized dataflow that keeps more circuits active during computation. The load capacitance $C$ scales with transistor count and interconnect length. Supply voltage $V$ enters quadratically, making voltage reduction the most powerful lever for energy efficiency. Clock frequency $f$ determines operations per second.

The static power component $P_{static} = V \cdot I_{leak}$ represents leakage current that increases exponentially with temperature, approximately doubling for every 10 degrees Celsius rise. This thermal dependence creates a feedback loop: higher power generates heat, which increases leakage, which generates more heat. Managing this thermal runaway constrains the power density achievable in modern processors and explains why cooling infrastructure represents such a significant fraction of data center energy consumption.

The practical implications for AI systems are substantial. The quadratic voltage dependence means that reducing voltage from 1.0V to 0.8V decreases dynamic power by 36%, even before considering that lower voltages often enable frequency reduction with additional linear savings. This relationship explains why specialized AI accelerators operating at lower voltages but higher utilization can achieve order-of-magnitude efficiency improvements over general-purpose processors.

#### Why Optimization Techniques Save Energy {#sec-sustainable-ai-optimization-techniques-save-energy-832c}

The power equation illuminates why specific optimization techniques achieve their efficiency gains. Quantization reduces numerical precision from 32-bit floating point to 8-bit integers, which directly reduces datapath capacitance $C$ by approximately 4 times since narrower datapaths require fewer transistors and shorter interconnects. Additionally, lower precision arithmetic enables reduced supply voltage $V$ because the circuits have larger noise margins. The combined effect yields 6 to 10 times energy reduction per operation, closely matching published measurements of INT8 versus FP32 inference efficiency.

Pruning removes weights from neural networks, reducing the effective capacitance $C$ by eliminating computation paths that would otherwise consume switching energy. Structured pruning, which removes entire channels or attention heads, achieves larger efficiency gains than unstructured pruning because it eliminates complete circuit paths rather than individual operations that the hardware must still orchestrate.

Specialized accelerators improve the activity factor $\alpha$ by designing circuits specifically for matrix multiplication and convolution operations. Where a CPU might activate 10% of its transistors during typical ML workloads, a systolic array architecture can keep 70% or more of its compute units active, effectively performing more useful work per watt of power consumed.

#### Facility-Level Power Metrics {#sec-sustainable-ai-facilitylevel-power-metrics-5558}

Beyond chip-level power, data center infrastructure imposes additional energy overhead. @eq-pue captures this relationship through the Power Usage Effectiveness (PUE) metric:

$$PUE = \frac{P_{total\_facility}}{P_{IT\_equipment}}$$ {#eq-pue}

A PUE of 1.0 would indicate perfect efficiency where all energy powers computation, though this is physically impossible since cooling, power distribution, and lighting require nonzero energy. Industry-average data centers operate at PUE of 1.5 to 2.0, meaning that 50% to 100% additional energy beyond computation goes to infrastructure. Leading hyperscale facilities achieve PUE between 1.1 and 1.2 through advanced cooling techniques including free-air cooling in cold climates, liquid cooling for high-density GPU clusters, and optimized power distribution.

@eq-wue formalizes Water Usage Effectiveness (WUE), capturing the water consumption that evaporative cooling and other processes require:

$$WUE = \frac{W_{annual\_water\_usage}}{P_{IT\_equipment\_energy}}$$ {#eq-wue}

The units are liters per kilowatt-hour, with typical values ranging from 0.5 to 2.0 L/kWh depending on climate and cooling technology. A data center with WUE of 1.8 L/kWh training a model requiring 10,000 MWh would consume 18 million liters of water, equivalent to the annual water usage of approximately 500 households.

#### Carbon Intensity and Regional Variation {#sec-sustainable-ai-carbon-intensity-regional-variation-db41-regional-variation-db41}

The carbon impact of electricity consumption depends critically on the energy generation mix, quantified by carbon intensity measured in grams of CO2 equivalent per kilowatt-hour (gCO2eq/kWh). @tbl-carbon-intensity quantifies how dramatically these intensities vary across energy sources:

| **Energy Source** | **Carbon Intensity** **(gCO2eq/kWh)** | **Regional Examples**       |
|:------------------|--------------------------------------:|:----------------------------|
| **Coal**          |                          820 to 1,200 | Poland, West Virginia       |
| **Natural Gas**   |                            350 to 500 | Texas combined cycle plants |
| **Solar PV**      |                              20 to 50 | California, Arizona         |
| **Wind**          |                               7 to 15 | Denmark, Scotland           |
| **Hydroelectric** |                              10 to 30 | Quebec, Norway              |
| **Nuclear**       |                               5 to 20 | France, Ontario             |

: **Carbon Intensity by Energy Source**: Electricity generation carbon intensity varies by more than two orders of magnitude across energy sources. Geographic location of computation can dramatically affect emissions even for identical workloads, enabling 50 to 100 times emission reductions through strategic placement. {#tbl-carbon-intensity}

Geographic optimization can dramatically reduce carbon emissions by choosing training locations strategically.

::: {.callout-note title="Figure: Carbon Intensity Variation" collapse="false"}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
  \definecolor{LowC}{RGB}{200,255,200}
  \definecolor{MedC}{RGB}{255,255,200}
  \definecolor{HighC}{RGB}{255,200,200}

  \tikzset{
    region/.style={draw=black!70, thick, rounded corners=2pt, minimum width=2.5cm, minimum height=1.5cm, align=center}
  }

  % Regions
  \node[region, fill=LowC] (Quebec) at (0,0) {\textbf{Quebec}\\Hydro\\20g $CO_2$/kWh};
  \node[region, fill=MedC] (Texas) at (4,0) {\textbf{Texas}\\Gas + Wind\\350g $CO_2$/kWh};
  \node[region, fill=HighC] (Poland) at (8,0) {\textbf{Poland}\\Coal\\800g $CO_2$/kWh};

  % Scale Bar
  \draw[top color=HighC, bottom color=LowC, shading angle=0] (-1,-2) rectangle (9,-2.5);
  \node[left] at (-1,-2.25) {Low Carbon};
  \node[right] at (9,-2.25) {High Carbon};

  % Annotation
  \node[align=center] at (4, 2) {\textbf{Geographic Optimization}\\Training in Quebec vs Poland reduces emissions by 40$\times$.};
  \draw[->, thick] (4, 1.5) -- (Quebec);
  \draw[->, thick] (4, 1.5) -- (Poland);

\end{tikzpicture}
```
**Geographic Carbon Intensity**. The carbon footprint of a training job depends critically on *where* it runs. Regions with hydro or nuclear power (e.g., Quebec, France) have carbon intensities 10-50$\times$ lower than regions reliant on coal (e.g., Poland, West Virginia). Carbon-aware scheduling exploits this variance by moving non-urgent jobs to cleaner grids.
:::

### Systematic Energy Metrics {#sec-sustainable-ai-systematic-energy-metrics-5779-5779}

Quantifying energy efficiency requires systematic metrics that enable comparison across hardware architectures and algorithmic approaches. These metrics provide the foundation for reasoning about optimization trade-offs and identifying bottlenecks in AI system energy consumption.

#### Energy Per Operation {#sec-sustainable-ai-energy-per-operation-776a-776a}

The fundamental metric for computational energy efficiency is energy consumed per operation, typically measured in picojoules. For AI workloads, the most relevant metrics are energy per floating-point operation and energy per multiply-accumulate, where one MAC operation performs both a multiplication and addition, equivalent to two FLOPs.

Hardware architecture determines energy efficiency across orders of magnitude, spanning nearly four orders of magnitude from general-purpose CPUs to specialized analog accelerators. @tbl-energy-per-op quantifies these differences:

| **Architecture**             | **Energy Efficiency** **(pJ/FLOP or pJ/MAC)** | **Characteristics**                               |
|:-----------------------------|----------------------------------------------:|:--------------------------------------------------|
| **CPU (general)**            |                                   100 pJ/FLOP | Low utilization, high flexibility                 |
| **GPU (tensor cores)**       |                                    10 pJ/FLOP | High throughput, parallel execution               |
| **TPU (systolic array)**     |                                   1-2 pJ/FLOP | Specialized matrix operations, optimized dataflow |
| **Google Edge TPU**          |                                   2-4 pJ/FLOP | On-device inference, INT8 optimized               |
| **ARM Ethos-U55**            |                                  0.5-2 pJ/MAC | Microcontroller NPU, sub-watt TinyML              |
| **Maxim MAX78000**           |                                  0.3-1 pJ/MAC | CNN accelerator with local weight storage         |
| **ASIC (INT8)**              |                              0.1 pJ/operation | Fixed-function, low precision                     |
| **Analog/In-Memory Compute** |                               0.01-0.1 pJ/MAC | Emerging technology, compute in memory array      |

: **Energy Efficiency by Architecture**: Hardware specialization provides up to four orders of magnitude improvement in energy per operation. Datacenter accelerators (TPU, GPU) optimize for throughput, while edge accelerators (Ethos-U, MAX78000) optimize for energy per inference. Emerging analog compute approaches promise further efficiency gains. {#tbl-energy-per-op}

These differences reflect not just circuit-level efficiency but also architectural choices affecting utilization. CPUs execute diverse instruction mixes with low average utilization of arithmetic units. GPUs achieve higher utilization through massive parallelism. TPUs and ASICs maximize utilization through specialized datapaths optimized for specific operation types.

Precision significantly affects energy per operation. INT8 integer arithmetic consumes approximately one-sixteenth the energy of FP32 floating-point at the same frequency and voltage. This combines reduced datapath capacitance of 4$\times$ from bit width with lower voltage requirements of 2$\times$ from larger noise margins and simpler control logic of 2$\times$ from reduced complexity.

#### Energy Per Byte {#sec-sustainable-ai-energy-per-byte-5d87-5d87}

Data movement often dominates energy consumption in modern AI systems. The energy cost of memory access varies dramatically across the storage hierarchy:

@tbl-energy-per-byte reveals a critical insight: moving data from DRAM consumes 10 to 100 times more energy than performing arithmetic operations. For a GPU operating at 10 pJ/FLOP, accessing one FP32 operand from DRAM (4 bytes times 100 pJ/byte = 400 pJ) costs 40 times more than the computation itself. This energy gap drives architectural innovations including:

| **Memory Level** | **Energy Cost** **(pJ/byte)** |    **Access Latency** |
|:-----------------|------------------------------:|----------------------:|
| **Register**     |                   0.1 pJ/byte |               1 cycle |
| **L1 Cache**     |                     1 pJ/byte |            3-5 cycles |
| **L2 Cache**     |                     5 pJ/byte |          10-20 cycles |
| **DRAM**         |                   100 pJ/byte |        200-300 cycles |
| **NVMe SSD**     |                 1,000 pJ/byte | 50,000-100,000 cycles |
| **Network**      |               10,000+ pJ/byte |    Millions of cycles |

: **Memory Hierarchy Energy Costs**: Energy per byte increases by orders of magnitude moving down the memory hierarchy. Data movement can easily dominate computation energy. {#tbl-energy-per-byte}

- On-chip memory for data reuse (NVIDIA tensor cores with shared memory)
- Optimized data layouts minimizing DRAM access (Google TPU systolic arrays)
- Compression reducing data movement (sparse tensor representations)

#### Arithmetic Intensity and Energy Roofline {#sec-sustainable-ai-arithmetic-intensity-energy-roofline-6d13-roofline-6d13}

The balance between computation and data movement determines whether energy consumption is compute-bound or memory-bound. @eq-arithmetic-intensity defines arithmetic intensity (AI), the ratio that determines which resource dominates energy consumption:

$$AI = \frac{\text{Total FLOPs}}{\text{Total Bytes Moved}}$$ {#eq-arithmetic-intensity}

Arithmetic intensity measured in FLOPs per byte determines the dominant energy consumer. @eq-energy-roofline extends traditional performance rooflines to an *energy roofline model*, expressing total energy as the maximum of compute and memory energy:

$$E_{total} = \max\left(E_{compute}, E_{memory}\right) = \max\left(\text{FLOPs} \times e_{flop}, \text{Bytes} \times e_{byte}\right)$$ {#eq-energy-roofline}

where $e_{flop}$ is energy per FLOP and $e_{byte}$ is energy per byte moved. @eq-ai-crossover defines the crossover arithmetic intensity where compute and memory energy balance:

$$AI_{crossover} = \frac{e_{byte}}{e_{flop}}$$ {#eq-ai-crossover}

For a GPU with $e_{flop} = 10$ pJ/FLOP and $e_{byte} = 100$ pJ/byte (DRAM access):

$$AI_{crossover} = \frac{100 \text{ pJ/byte}}{10 \text{ pJ/FLOP}} = 10 \text{ FLOPs/byte}$$

The energy roofline model visualizes this relationship between arithmetic intensity and energy efficiency, revealing how different workload types are constrained by different bottlenecks.

::: {.callout-note title="Figure: Energy Roofline Model" collapse="false"}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}, scale=0.9]
  \definecolor{MemColor}{RGB}{200,220,255}
  \definecolor{CompColor}{RGB}{255,220,200}

  % Axes
  \draw[->, thick] (0,0) -- (8,0) node[right] {Arithmetic Intensity (FLOP/Byte)};
  \draw[->, thick] (0,0) -- (0,5) node[above] {Energy Efficiency (FLOP/Joule)};

  % Roofline
  \draw[thick, blue] (0,0) -- (4,4) node[midway, sloped, above] {Memory Bound};
  \draw[thick, red] (4,4) -- (8,4) node[midway, above] {Compute Bound};

  % Ridge Point
  \fill[black] (4,4) circle (2pt);
  \draw[dashed] (4,0) -- (4,4);
  \node[below] at (4,0) {$AI_{crossover}$};

  % Regions
  \fill[MemColor, opacity=0.3] (0,0) -- (4,4) -- (4,0) -- cycle;
  \node[blue, font=\tiny] at (2.5, 1) {Data Movement Dominates};

  \fill[CompColor, opacity=0.3] (4,0) -- (4,4) -- (8,4) -- (8,0) -- cycle;
  \node[red, font=\tiny] at (6, 2) {Arithmetic Dominates};

  % Workload dots
  \node[circle, fill=blue, inner sep=2pt, label={right:\tiny Element-wise}] at (1, 1) {};
  \node[circle, fill=red, inner sep=2pt, label={below:\tiny MatMul}] at (6, 4) {};

\end{tikzpicture}
```
**Energy Roofline Model**. Just as performance rooflines limit FLOPs/sec based on bandwidth, energy rooflines limit FLOPs/Joule. Workloads with low arithmetic intensity (left) are dominated by memory energy ($E_{byte}$), while compute-heavy workloads (right) are limited by arithmetic energy ($E_{flop}$). Optimizing the wrong metric yields diminishing returns.
:::

To make this framework concrete, we can apply it to the most common operation in deep learning: matrix multiplication.

::: {.callout-example title="MatMul Energy Analysis"}

Consider matrix multiplication $C = A \times B$ for $N \times N$ matrices in FP32 precision on a GPU with the energy characteristics above.

#### Step 1: Calculate FLOPs and Bytes {.unnumbered}

- FLOPs: $2N^3$ (one multiply-add for each of $N^2$ output elements, accumulating over $N$ elements)
- Bytes: $3N^2 \times 4$ bytes (read matrices $A$ and $B$, write matrix $C$, each FP32 = 4 bytes)
- Arithmetic intensity: $AI = \frac{2N^3}{12N^2} = \frac{N}{6}$ FLOPs/byte

#### Step 2: Determine Energy-Limiting Factor {.unnumbered}

For small matrices ($N = 60$):

- $AI = 60/6 = 10$ FLOPs/byte (at crossover)
- Compute energy: $2 \times 60^3 \times 10 \text{ pJ} = 4.32$ mJ
- Memory energy: $3 \times 60^2 \times 4 \times 100 \text{ pJ} = 4.32$ mJ
- Balanced: both compute and memory contribute equally

For large matrices ($N = 1000$):

- $AI = 1000/6 = 167$ FLOPs/byte (compute-bound)
- Compute energy: $2 \times 10^9 \times 10 \text{ pJ} = 20$ mJ (dominates)
- Memory energy: $3 \times 10^6 \times 4 \times 100 \text{ pJ} = 1.2$ mJ (negligible)
- Optimization priority: Focus on compute efficiency

For element-wise operations ($N = 1000$, vector addition):

- FLOPs: $N = 1000$ (one addition per element)
- Bytes: $3N \times 4 = 12,000$ bytes (read two vectors, write one)
- $AI = 1000 / 12000 = 0.083$ FLOPs/byte (memory-bound)
- Compute energy: $1000 \times 10 \text{ pJ} = 0.01$ mJ (negligible)
- Memory energy: $12000 \times 100 \text{ pJ} = 1.2$ mJ (dominates)
- Optimization priority: Reduce data movement through fusion

:::

The energy roofline model reveals why different optimization strategies suit different workloads. Large dense matrix operations benefit from faster arithmetic units. Memory-bound operations like element-wise kernels benefit from data layout optimization, kernel fusion to reduce memory round-trips, and on-chip memory utilization. This framework guides architectural and algorithmic choices for sustainable AI system design.

### Energy Measurement Techniques {#sec-sustainable-ai-energy-measurement-techniques-590e-techniques-590e}

Quantifying AI system energy consumption requires measurement at multiple levels of the hardware stack, from chip-level instrumentation to facility-wide monitoring. Each measurement approach offers different granularity, accuracy, and overhead trade-offs that practitioners must understand to select appropriate methods for their use case.

#### Hardware Power Counters {#sec-sustainable-ai-hardware-power-counters-0ec9}

Modern processors include dedicated circuitry for power measurement that software can query through manufacturer-provided interfaces. These hardware counters measure actual power draw rather than estimating from activity, providing ground-truth energy consumption data at microsecond resolution.

Intel's Running Average Power Limit (RAPL) interface exposes power measurements for CPU packages, DRAM, and integrated graphics through model-specific registers (MSRs). RAPL reports energy consumption in microjoules with updates every millisecond, enabling fine-grained attribution of energy to specific code regions. @lst-rapl-measurement demonstrates how to read RAPL counters and calculate average power draw during a training loop:

::: {#lst-rapl-measurement lst-cap="**RAPL Energy Measurement**: Reading Intel RAPL counters to measure CPU and DRAM energy consumption during model training."}
```{.python}
import subprocess
import time


def read_rapl_energy():
    """Read current RAPL energy counters.

    Requires root or perf permissions.
    """
    result = subprocess.run(
        [
            "cat",
            "/sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj",
        ],
        capture_output=True,
        text=True,
    )
    return int(result.stdout.strip())  # Returns microjoules


# Measure training energy
start_energy = read_rapl_energy()
start_time = time.time()

# Training loop
for epoch in range(num_epochs):
    train_one_epoch(model, dataloader, optimizer)

end_energy = read_rapl_energy()
end_time = time.time()

energy_joules = (end_energy - start_energy) / 1e6
avg_power_watts = energy_joules / (end_time - start_time)
print(
    f"Training energy: {energy_joules:.2f} J, Average power: {avg_power_watts:.2f} W"
)
```
:::

RAPL measurements exclude discrete GPUs, which require separate monitoring through vendor-specific interfaces.

#### GPU Power Monitoring {#sec-sustainable-ai-gpu-power-monitoring-88fe-88fe}

NVIDIA GPUs expose power measurements through the NVIDIA Management Library (NVML), accessible via the `nvidia-smi` command-line tool or programmatic bindings. GPU power monitoring reports instantaneous power draw, which can vary significantly during computation due to dynamic voltage and frequency scaling. @lst-gpu-power implements a measurement loop that samples power at regular intervals, computing average and peak power over the inference workload:

::: {#lst-gpu-power lst-cap="**GPU Power Monitoring**: Using NVIDIA's pynvml library to measure GPU power consumption during inference."}
```{.python}
import pynvml
import torch
import time

pynvml.nvmlInit()
handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # First GPU


def measure_inference_power(model, input_data, num_iterations=100):
    """Measure average GPU power during inference."""
    power_readings = []

    model.eval()
    with torch.no_grad():
        for _ in range(num_iterations):
            # Run inference
            _ = model(input_data)
            torch.cuda.synchronize()

            # Sample power (milliwatts)
            power_mw = pynvml.nvmlDeviceGetPowerUsage(handle)
            power_readings.append(power_mw / 1000)  # Convert to watts

    avg_power = sum(power_readings) / len(power_readings)
    return avg_power


avg_power = measure_inference_power(model, sample_input)
print(f"Average inference power: {avg_power:.1f} W")
```
:::

For accurate energy measurement rather than instantaneous power sampling, integrate power readings over time or use NVIDIA's energy counter when available on datacenter GPUs.

#### Edge and Mobile Device Energy Measurement {#sec-sustainable-ai-edge-mobile-device-energy-measurement-3012}

The measurement techniques described above apply to datacenter hardware with built-in power monitoring capabilities. Edge devices and microcontrollers present fundamentally different measurement challenges: they lack built-in power counters, operate at milliwatt rather than kilowatt scales, and require external instrumentation for accurate energy profiling. As TinyML deployments expand to billions of devices, understanding edge energy measurement becomes essential for comprehensive sustainability assessment.

#### Hardware Power Monitors for Embedded Systems

Microcontrollers and edge processors require external current and voltage measurement to quantify energy consumption. Several instrumentation approaches provide different trade-offs between accuracy, resolution, and cost:

The INA219 and INA226 I2C-based current sensors provide affordable measurement for development and validation, sampling at rates sufficient to capture inference-level energy consumption. For research requiring nanosecond-resolution measurements of individual operations, instruments like the Joulescope JS220 measure current from sub-microamp sleep states through ampere-level active peaks, enabling characterization of the full dynamic range of edge AI workloads.

#### Mobile Platform Energy Profiling

Mobile devices provide platform-specific APIs for energy attribution, though with less granularity than hardware monitors:

- **Android PowerStats HAL**: Provides per-component power attribution for CPU, GPU, NPU, and radio subsystems, enabling developers to identify which model operations dominate energy consumption.
- **Qualcomm Trepn Profiler**: Offers millisecond-resolution power measurement on Snapdragon platforms, correlating power traces with code execution for NPU workload optimization.
- **ARM Streamline**: Provides energy-annotated profiling for Cortex-A and Mali GPU platforms, enabling identification of inefficient kernel implementations.
- **Apple Instruments Energy Log**: Reports thermal state and energy impact scores for iOS applications, though without direct wattage measurements.

These mobile profiling tools integrate with development workflows, enabling iterative optimization of on-device inference energy consumption during model deployment. @tbl-edge-power-monitors summarizes the available instrumentation options across platforms, including resolution, accuracy, and integration requirements.

| **Instrument**       |                 **Resolution** |       **Accuracy** | **Use Case**                     |
|:---------------------|-------------------------------:|-------------------:|:---------------------------------|
| **INA219/INA226**    |       100 microsecond sampling |   plus or minus 1% | Low-cost embedded profiling      |
| **PAC1934**          |      1 millisecond, 4 channels |   plus or minus 2% | Multi-rail MCU measurement       |
| **Joulescope JS220** | Sub-microsecond, nanoamp range | plus or minus 0.1% | Professional TinyML benchmarking |
| **Otii Arc Pro**     |     10 microsecond, automation | plus or minus 0.5% | Automated battery life testing   |

: **Edge Power Measurement Instruments**: External power monitors enable energy measurement on devices without built-in counters. The Joulescope JS220 provides the gold-standard accuracy for TinyML research, while INA-series sensors offer cost-effective solutions for deployment validation. {#tbl-edge-power-monitors}

#### Edge Measurement Methodology

Edge energy measurement requires careful methodology to produce reproducible results:

1. **Baseline Characterization**: Measure idle power consumption across all sleep states, as baseline power can vary from 1 microamp in deep sleep to 1 milliamp in idle active states on typical microcontrollers.

2. **Warm-up Period**: Execute 100 or more inference iterations before measurement to reach thermal equilibrium, as initial iterations may exhibit different power characteristics due to cache warming and voltage regulator settling.

3. **Duty Cycle Accounting**: Edge devices typically operate with significant idle periods between inferences. Report both peak inference power and average power at realistic duty cycles. @eq-edge-duty-cycle expresses this relationship:

$$P_{average} = P_{active} \times D + P_{idle} \times (1 - D)$$ {#eq-edge-duty-cycle}

where $D$ is the duty cycle (fraction of time performing inference).

4. **Peripheral Isolation**: Disable or account for peripheral power consumption (sensors, radios, displays) when measuring model inference energy, as these can dominate total system power.

#### System-Level Energy Profiling {#sec-sustainable-ai-systemlevel-energy-profiling-eecf}

Comprehensive energy accounting requires combining chip-level measurements with infrastructure overhead. @eq-total-energy formalizes total energy as the sum of component contributions scaled by facility overhead:

$$E_{total} = (E_{CPU} + E_{GPU} + E_{memory} + E_{network}) \times PUE$$ {#eq-total-energy}

System-level profilers like Intel VTune, NVIDIA Nsight Systems, and open-source tools such as PowerJoular aggregate measurements across components. For production deployments, smart power distribution units (PDUs) at the rack level provide facility-verified measurements that include cooling overhead.

@eq-facility-power expresses the relationship between measured component power and total facility energy:

$$P_{facility} = P_{IT} \times PUE = (P_{servers} + P_{network} + P_{storage}) \times PUE$$ {#eq-facility-power}

For a cluster consuming 1 MW of IT power in a facility with PUE of 1.4, total facility power consumption reaches 1.4 MW, with the additional 400 kW powering cooling, power conversion, and infrastructure systems.

Understanding that a PUE of 1.4 means an automatic 40% overhead on all computational power highlights the critical role of facility efficiency. However, operational power consumption is only one piece of the equation; to capture the true environmental cost of our systems, we must formalize how we convert raw kilowatts into tons of carbon emissions.

## Carbon Footprint Calculation {#sec-sustainable-ai-carbon-footprint-calculation-c2fe}

Consider a datacenter running on 100% renewable hydroelectric power. Its operational carbon emissions are effectively zero. Does that mean the AI trained there is perfectly green? No, because mining the silicon, manufacturing the GPUs, and pouring the concrete for the datacenter released thousands of tons of CO2 before the servers were ever turned on. A true carbon footprint calculation must account for both the energy consumed during operation and the "embodied carbon" burned during construction.

#### Operational Carbon Calculation {#sec-sustainable-ai-operational-carbon-calculation-4627-calculation-4627}

Operational carbon emissions result from electricity consumption during training and inference, scaled by grid carbon intensity. @eq-operational-carbon quantifies this as the product of energy, grid carbon intensity, and facility overhead:

$$C_{operational} = E_{total} \times CI_{grid} \times PUE$$ {#eq-operational-carbon}

where $E_{total}$ is the energy consumed by IT equipment, $CI_{grid}$ is the carbon intensity of the electricity grid, and $PUE$ accounts for facility overhead. A concrete *training emissions calculation* illustrates this framework.

```{python}
#| label: training-emissions-setup
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ TRAINING EMISSIONS CALCULATION
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @sec-sustainable-ai-scale-environmental-impact-ac9a Training Emissions
# │          Calculation callout example
# │
# │ Goal: Compute step-by-step operational carbon for 64 A100 GPUs training for
# │       14 days at US average grid intensity (429 gCO₂/kWh) and compare to
# │       a low-carbon alternative (Quebec, 20 gCO₂/kWh) to quantify the geographic
# │       multiplier argument.
# │ Show: ~21,504 kWh GPU energy → ~25,805 kWh facility (PUE 1.2) → ~4,428 kg CO₂
# │       US vs ~516 kg CO₂ Quebec → ~21x reduction — inline in callout example.
# │ How: GPU energy = n_gpus × A100_TDP × hours; facility = GPU × PUE;
# │       emissions = facility_kwh × grid_intensity / 1000.
# │
# │ Imports: mlsys.constants (A100_TDP, watt — via SustainableAISetup cell)
# │ Exports: training_hours_str, gpu_energy_wh_str, gpu_energy_kwh_str,
# │          facility_energy_kwh_str, emissions_kg_str, emissions_tons_str,
# │          quebec_emissions_kg_str, emissions_ratio_str
# └─────────────────────────────────────────────────────────────────────────────

# ┌── P.I.C.O. ISOLATED SCENARIO ───────────────────────────────────────────────
class TrainingEmissions:
    """Namespace for GPT-3 training emissions worked example."""

    # ┌── 1. PARAMETERS (Inputs) ──────────────────────────────────────────────
    n_gpus = 64
    training_days = 14
    training_hours = training_days * 24
    gpu_power_w = A100_TDP.m_as(watt)  # 400
    pue = 1.2
    grid_ci_g_per_kwh = 429  # US average gCO2/kWh
    quebec_ci = 20            # gCO2/kWh

    # ┌── 2. CALCULATION (The Physics) ────────────────────────────────────────
    gpu_energy_wh = n_gpus * gpu_power_w * training_hours
    gpu_energy_kwh = gpu_energy_wh / 1000
    facility_energy_kwh = gpu_energy_kwh * pue
    emissions_kg = facility_energy_kwh * grid_ci_g_per_kwh / 1000
    emissions_tons = emissions_kg / 1000
    quebec_emissions_kg = facility_energy_kwh * quebec_ci / 1000
    emissions_ratio = emissions_kg / quebec_emissions_kg

    # ┌── 3. INVARIANTS (Guardrails) ──────────────────────────────────────────
    # No check() calls needed — values are monotone functions of inputs.

    # ┌── 4. OUTPUTS (Formatting) ─────────────────────────────────────────────
    training_hours_str = f"{training_hours:,}"
    gpu_energy_wh_str = f"{gpu_energy_wh:,.0f}"
    gpu_energy_kwh_str = f"{gpu_energy_kwh:,.0f}"
    facility_energy_kwh_str = f"{facility_energy_kwh:,.0f}"
    emissions_kg_str = f"{emissions_kg:,.0f}"
    emissions_tons_str = f"{emissions_tons:.1f}"
    quebec_emissions_kg_str = f"{quebec_emissions_kg:,.0f}"
    emissions_ratio_str = f"{emissions_ratio:.0f}"

# ┌── EXPORTS (Bridge to Text) ─────────────────────────────────────────────────
training_hours_str = TrainingEmissions.training_hours_str
gpu_energy_wh_str = TrainingEmissions.gpu_energy_wh_str
gpu_energy_kwh_str = TrainingEmissions.gpu_energy_kwh_str
facility_energy_kwh_str = TrainingEmissions.facility_energy_kwh_str
emissions_kg_str = TrainingEmissions.emissions_kg_str
emissions_tons_str = TrainingEmissions.emissions_tons_str
quebec_emissions_kg_str = TrainingEmissions.quebec_emissions_kg_str
emissions_ratio_str = TrainingEmissions.emissions_ratio_str
```

::: {.callout-example title="Training Emissions Calculation"}

Consider training a 7 billion parameter model on 64 A100 GPUs for 14 days:

#### Step 1: Compute Energy {.unnumbered}

- GPU power: `{python} a100_tdp_w`W per A100 at typical training utilization
- Training time: 14 days times 24 hours = `{python} training_hours_str` hours
- GPU energy: 64 GPUs times `{python} a100_tdp_w`W times `{python} training_hours_str`h = `{python} gpu_energy_wh_str` Wh = `{python} gpu_energy_kwh_str` kWh

#### Step 2: Apply PUE {.unnumbered}

- Facility PUE: 1.2 (efficient hyperscale datacenter)
- Total facility energy: `{python} gpu_energy_kwh_str` kWh times 1.2 = `{python} facility_energy_kwh_str` kWh

#### Step 3: Calculate Emissions {.unnumbered}

- Grid carbon intensity: 429 gCO2/kWh (US average)
- Operational emissions: `{python} facility_energy_kwh_str` kWh times 429 g/kWh = `{python} emissions_kg_str` kg CO2 = `{python} emissions_tons_str` metric tons

**Comparison: Same training in low-carbon region**

- Quebec grid intensity: 20 gCO2/kWh
- Emissions: `{python} facility_energy_kwh_str` kWh times 20 g/kWh = `{python} quebec_emissions_kg_str` kg CO2

The geographic choice alone produces a `{python} emissions_ratio_str`-fold difference in training emissions.
:::

#### Embodied Carbon Assessment {#sec-sustainable-ai-embodied-carbon-assessment-9de0}

Embodied carbon encompasses emissions from raw material extraction, semiconductor fabrication, assembly, transportation, and end-of-life disposal. For AI hardware, manufacturing emissions are substantial due to the energy-intensive nature of advanced semiconductor processes.

A single NVIDIA H100 GPU embodies approximately 150 to 200 kg CO2eq from manufacturing, including wafer fabrication at advanced process nodes, high-bandwidth memory production, and packaging. @eq-embodied-daily amortizes this embodied carbon over the hardware lifetime to compute per-use emissions:

$$C_{embodied,daily} = \frac{C_{manufacturing}}{L_{lifetime} \times 365}$$ {#eq-embodied-daily}

Understanding how embodied carbon accumulates over time reveals why hardware utilization and lifetime significantly affect total lifecycle emissions.

::: {.callout-perspective title="Embodied Carbon Amortization"}
**The Hidden Cost**: When you rent a GPU for an hour, you aren't just paying for electricity; you are "paying off" the carbon debt of its manufacturing.

**Formula**:
$$ C_{total} = C_{operational} + \left( \frac{C_{manufacturing}}{T_{lifetime}} \times T_{job} \right) $$

**Scenario**: Training a model for **10 hours** on **8 NVIDIA H100s**.

*   **Operational**: 8 GPUs$\times$ `{python} h100_tdp_kw` kW$\times$ 10h = 56 kWh. At 0.4 kg/kWh (gas grid) = **22.4 kg CO₂**.
*   **Embodied**: 8 GPUs$\times$ 150 kg/GPU = 1200 kg total.
*   **Amortization**: Lifetime = 3 years (26,280 hours).
    *   Hourly "Rent" = $1200 / 26280 \approx 0.046$ kg/hour.
    *   Job Cost = $0.046 \times 10 = \mathbf{0.46 \text{ kg } CO_2}$.

**Conclusion**: For long-lived hardware in dirty grids, **electricity dominates** (22.4 vs 0.46). However, in **clean grids** (hydro, 0.02 kg/kWh), operational drops to 1.1 kg, making embodied carbon a significant fraction (~30-40%) of the total footprint.
:::

For an H100 with 175 kg embodied carbon and 4-year datacenter lifetime:

$$C_{embodied,daily} = \frac{175 \text{ kg}}{4 \times 365} = 0.12 \text{ kg/day}$$

Over a 14-day training run using 64 GPUs:

$$C_{embodied,training} = 64 \times 14 \times 0.12 = 108 \text{ kg CO2}$$

This embodied contribution of 108 kg represents approximately 2.4% of the operational emissions (4,428 kg) calculated above for US average grid, but would represent 52% of total emissions if training occurred in Quebec's low-carbon grid.

#### Lifecycle Carbon Accounting {#sec-sustainable-ai-lifecycle-carbon-accounting-99a1}

Complete lifecycle assessment combines operational and embodied emissions across all phases. @eq-lifecycle-carbon aggregates these contributions:

$$C_{lifecycle} = C_{training} + C_{inference} + C_{embodied}$$ {#eq-lifecycle-carbon}

::: {#fig-carbon-lifecycle fig-env="figure" fig-pos="htb" fig-cap="The Carbon Lifecycle of an ML System. Operational emissions dominate, particularly during inference, but embodied carbon remains a significant factor." fig-alt="Lifecycle diagram showing carbon emissions across ML system stages from manufacturing through training, inference, and decommissioning."}
```{=latex}
\begin{tikzpicture}
    \usefont{T1}{phv}{m}{n}
    \definecolor{OpInfColor}{HTML}{006395}
    \definecolor{OpTrainColor}{HTML}{5D9BBE}
    \definecolor{EmbMfgColor}{HTML}{CB202D}
    \definecolor{EmbEoLColor}{HTML}{F5D2D5}
    \foreach \start/\end/\col in {90/-108/OpInfColor, -108/-198/OpTrainColor, 162/108/EmbMfgColor, 108/90/EmbEoLColor} {
        \fill[\col] (0,0) -- (\start:3) arc (\start:\end:3) -- cycle;
    }
    \fill[white] (0,0) circle (1.5);
    \node[font=\bfseries, align=center] at (-10:2.2) {\color{white}55\%};
    \node[anchor=west, align=left] at (3.2, 0) {\textbf{Operational}\\\small(Inference)};
    \draw[thick] (10:2.8) -- (3.1, 0);
    \node[font=\bfseries] at (-153:2.2) {\color{white}25\%};
    \node[anchor=east, align=right] at (-3.2, -1.5) {\textbf{Operational}\\\small(Training)};
    \draw[thick] (-153:2.8) -- (-3.1, -1.5);
    \node[font=\bfseries] at (135:2.2) {\color{white}15\%};
    \node[anchor=east, align=right] at (-3.2, 2.1) {\textbf{Embodied}\\\small(Manufacturing)};
    \draw[thick] (135:2.8) -- (-3.1, 2.1);
    \node[anchor=south, align=center] at (0, 3.2) {\textbf{Embodied}\\\small(End-of-Life) \textbf{5\%}};
    \draw[thick] (99:2.9) -- (0, 3.2);
    \node[align=center, font=\large\bfseries] at (0,0) {Total\\Carbon\\Footprint};
\end{tikzpicture}
```
:::

For models deployed at scale, inference emissions often dominate the lifecycle. Consider a model serving 10 million queries per day at 0.001 kWh per query:

**Annual Inference Energy and Emissions:**

- Daily energy: 10 million times 0.001 kWh = 10,000 kWh
- Annual energy: 10,000 times 365 = 3,650,000 kWh
- Annual emissions (US grid): 3,650,000 times 0.429 = 1,565,850 kg = 1,566 metric tons CO2

Compare to single training run of 4.4 metric tons. After less than 2 days of deployment at this scale, cumulative inference emissions exceed training emissions.

This lifecycle perspective reveals that optimization efforts should prioritize inference efficiency for widely-deployed models, while training efficiency matters most for models that undergo frequent retraining or experimental iteration.

#### Regional Grid Intensity Data Sources {#sec-sustainable-ai-regional-grid-intensity-data-sources-0b88}

Accurate carbon accounting requires reliable grid intensity data. Real-time carbon intensity varies with generation mix, which changes hourly based on demand, renewable availability, and plant dispatch decisions. Several data sources provide this information:

The US Energy Information Administration (EIA) publishes historical grid emissions factors by region, updated annually. For prospective analysis, these annual averages provide reasonable estimates. ElectricityMap and WattTime provide real-time carbon intensity APIs covering major grids worldwide, enabling carbon-aware scheduling systems. For retrospective analysis of completed training runs, hourly marginal emissions data from these sources enables accurate attribution. @lst-carbon-calculation implements a lifecycle carbon calculator that integrates energy measurements with grid intensity data:

::: {#lst-carbon-calculation lst-cap="**Lifecycle Carbon Calculation**: Computing total carbon footprint including operational and embodied emissions."}
```{.python}
def calculate_carbon_footprint(
    gpu_power_watts: float,
    num_gpus: int,
    training_hours: float,
    pue: float,
    grid_intensity_gco2_kwh: float,
    gpu_embodied_kg: float,
    gpu_lifetime_years: float,
) -> dict:
    """Calculate lifecycle carbon footprint for a training run."""

    # Operational emissions
    energy_kwh = (gpu_power_watts * num_gpus * training_hours) / 1000
    facility_energy_kwh = energy_kwh * pue
    operational_kg = (
        facility_energy_kwh * grid_intensity_gco2_kwh / 1000
    )

    # Embodied emissions (amortized)
    daily_embodied = gpu_embodied_kg / (gpu_lifetime_years * 365)
    training_days = training_hours / 24
    embodied_kg = num_gpus * training_days * daily_embodied

    return {
        "energy_kwh": facility_energy_kwh,
        "operational_carbon_kg": operational_kg,
        "embodied_carbon_kg": embodied_kg,
        "total_carbon_kg": operational_kg + embodied_kg,
        "embodied_fraction": embodied_kg
        / (operational_kg + embodied_kg),
    }


# Example: 7B model training
result = calculate_carbon_footprint(
    gpu_power_watts=400,
    num_gpus=64,
    training_hours=336,  # 14 days
    pue=1.2,
    grid_intensity_gco2_kwh=429,  # US average
    gpu_embodied_kg=175,
    gpu_lifetime_years=4,
)
print(
    f"Total carbon footprint: {result['total_carbon_kg']:.0f} kg CO2"
)
print(f"Embodied fraction: {result['embodied_fraction']:.1%}")
```
:::

This programmatic approach allows teams to integrate total lifecycle carbon accounting directly into their orchestration dashboards. Armed with the ability to calculate both operational and embodied emissions, we must now zoom out to examine the macro-level patterns of how modern AI data centers consume these vast resources at scale.

## Datacenter Energy and Resource Consumption {#sec-sustainable-ai-data-center-energy-consumption-patterns-09c0}

When a traditional web server handles an HTTP request, the CPU briefly spikes to 20% utilization and immediately returns to idle. When a GPU cluster trains a foundation model, thousands of processors run at 100% utilization, drawing maximum power continuously for three straight months. This unprecedented, unyielding thermal density fundamentally breaks traditional datacenter design, forcing engineers to adopt liquid cooling and redesign entire power distribution networks.

[^fn-dense-operations]: **Dense Operations**: Computational patterns where most elements participate in calculations, including matrix multiplications, convolutions, and attention. Dense matrix-matrix multiply achieves 2N³ FLOPs for N$\times$ N matrices, enabling high arithmetic intensity (>100 FLOP/byte) that maximizes GPU utilization. Transformers are particularly dense, with attention requiring O(N²) operations per token.

#### Data Center Energy and AI Workloads {#sec-sustainable-ai-data-center-energy-ai-workloads-b1a8}

Data centers serve as the primary energy consumers for AI systems, with power demands that reveal both the scale of the challenge and specific optimization opportunities.

Data center energy efficiency varies significantly across facilities. Power Usage Effectiveness ranges from 1.1 in Google's most efficient facilities to 2.5 in typical enterprise data centers, effectively doubling energy consumption through infrastructure overhead. Geographic location impacts carbon intensity. Training the same model in Quebec with hydro power versus West Virginia with coal power differs by 10$\times$ in carbon emissions per kilowatt-hour. Without access to renewable energy, these facilities rely heavily on nonrenewable sources such as coal and natural gas, contributing to global carbon emissions. Current estimates suggest that data centers produce up to 2 percent of total global CO₂ emissions, a figure that approaches the airline industry's footprint [@liu2020energy].[^fn-datacenter-emissions] The energy burden of AI is expected to grow exponentially due to three factors: increasing data center capacity, rising AI training workloads, and increasing inference demands [@patterson2022carbon]. Without intervention, these trends risk making AI's environmental footprint unsustainably large [@thompson2023compute].

[^fn-datacenter-emissions]: **Data Center Climate Impact**: Data centers consume approximately 1% of global electricity and produce 0.3% of global carbon emissions directly. However, when including embodied carbon from hardware manufacturing, the figure rises to 2%. For perspective, this equals the annual emissions of Argentina (1.8% of global total) and exceeds the aviation industry's 2.1%. The largest hyperscale data centers consume over 100 MW continuously, equivalent to powering 80,000 homes.

#### Energy Demands in Data Centers {#sec-sustainable-ai-energy-demands-data-centers-b7ba}

AI workloads are among the most compute-intensive operations in modern data centers. Companies such as Meta operate hyperscale data centers spanning multiple football fields in size, housing hundreds of thousands of AI-optimized servers.[^fn-hyperscale-size] The training of large language models such as GPT-4 required over 25,000 Nvidia A100 GPUs running continuously for 90 to 100 days [@semianalysisGPT4], consuming thousands of megawatt-hours of electricity. These facilities rely on high-performance AI accelerators like NVIDIA DGX H100 units, each of which can draw up to 10.2 kW at peak power [@nvidiadgxH100]. The energy efficiency gap becomes clear when comparing hardware generations. H100 GPUs achieve approximately 2.5 to 3$\times$ better performance per watt than A100s for AI training workloads, while mixed-precision training can reduce energy consumption by 15 to 30 percent depending on model architecture and hardware through reduced computational precision with minimal accuracy impact [@gholami2021survey].

[^fn-hyperscale-size]: **Hyperscale Data Center Scale**: Meta's Prineville data center spans 230,000 m² (57 football fields) and houses 150,000+ servers. Microsoft's largest Azure data center in Iowa covers 283 hectares with power capacity of 300 MW. Google operates 21 hyperscale facilities globally, consuming 12.2 TWh annually—more electricity than entire countries like Lithuania or Sri Lanka.

This dramatic energy consumption reflects AI's rapid adoption across industries. @fig-ai-data-center-demand projects that AI workload energy demand will increase total data center energy use significantly after 2024, with the AI segment growing from roughly 10% to over 30% of total power consumption by 2030 [@masanet2020energy]. While efficiency gains have offset rising power needs in the past, these gains are decelerating, amplifying AI's environmental impact.

::: {#fig-ai-data-center-demand fig-env="figure" fig-pos="htb" fig-cap="**Projected Demand**: By 2030, AI workloads will significantly increase power demand in data centers, outpacing efficiency gains seen previously. This emphasizes the growing environmental impact of AI systems. Source: Masanet et al. (2020), Cisco, IEA, Goldman Sachs Global Investment Research." fig-alt="Stacked bar chart showing data center power demand from 2015 to 2030. Dark blue bars show non-AI demand growing from 200 to 780 TWh. Light blue shows AI portion growing from 0 to 240 TWh. Gray line shows efficiency gains declining then stabilizing."}
```{python}
#| fig-align: center
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ AI DATA CENTER DEMAND (FIGURE)
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @fig-ai-data-center-demand — projected power demand
# │
# │ Goal: Stacked bar chart of DC ex-AI + AI demand 2015–2030; secondary axis
# │       for efficiency gains; show AI share growing to ~30%.
# │ Show: Bars; twinx for efficiency; viz.set_book_style().
# │ How: dc_demand, ai_demand, efficiency_gains; ax.bar; ax2.plot.
# │
# │ Imports: mlsys.viz (viz), matplotlib.pyplot (plt)
# │ Exports: (figure only, no prose variables)
# └─────────────────────────────────────────────────────────────────────────────
from mlsys import viz
import matplotlib.pyplot as plt

viz.set_book_style()
COLORS = viz.COLORS

fig, ax = plt.subplots(figsize=(10, 6))

# Data
years = list(range(2015, 2031))
dc_demand = [200, 200, 200, 200, 200, 210, 220, 230, 250, 290, 340, 400, 480, 570, 670, 780]
ai_demand = [0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 20, 40, 70, 110, 170, 240]
efficiency_gains = [20, 19, 18, 17, 15, 12, 9, 6, 3, 1.5, 2, 2.5, 3, 3.2, 3.5, 3.7]

# Stacked bar chart
bar_width = 0.8
ax.bar(
    years,
    dc_demand,
    bar_width,
    label='Data Center ex-AI',
    color=COLORS['BlueLine'],
    edgecolor='white',
)
ax.bar(
    years,
    ai_demand,
    bar_width,
    bottom=dc_demand,
    label='AI',
    color=COLORS['BlueL'],
    edgecolor='white',
)

ax.set_xlabel('Year')
ax.set_ylabel('Data Center Power Demand (TWh)')
ax.legend(loc='upper left', fontsize=9)

# Secondary axis for efficiency gains
ax2 = ax.twinx()
ax2.plot(years, efficiency_gains, color=COLORS['grid'], linewidth=2)
ax2.set_ylabel('Power Efficiency Gains (%)')
ax2.set_ylim(0, 25)
ax2.spines['right'].set_visible(True)
ax2.spines['top'].set_visible(False)

# Vertical dashed line at 2024
ax.axvline(x=2024, linestyle='--', color=COLORS['OrangeLine'], linewidth=1.5)

# Annotations
ax.text(
    2022,
    900,
    'Power Demand\nIncreasing',
    fontsize=9,
    fontweight='bold',
    ha='center',
    color=COLORS['primary'],
    bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=0.5),
)
ax.text(
    2018,
    850,
    'Efficiency Gains\nDecelerating',
    fontsize=9,
    fontweight='bold',
    ha='center',
    color=COLORS['primary'],
    bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=0.5),
)

ax.set_ylim(0, 1100)

plt.show()
```
:::

Beyond computational demands, cooling accounts for 30-40% of datacenter energy consumption, as discussed in @sec-sustainable-ai-infrastructure-optimization-1d41.

While @fig-ai-data-center-demand projects global trends, the United States alone illustrates just how rapidly AI is reshaping national energy infrastructure. @fig-energy-gap presents US datacenter electricity consumption data from the Lawrence Berkeley National Laboratory (LBNL), showing that consumption tripled from 58 TWh in 2014 to 176 TWh in 2023, driven primarily by AI workloads. LBNL projects a further doubling or tripling by 2028, with the high-end scenario implying that datacenters would consume approximately 12% of US electricity. This trajectory represents a physical constraint on AI scaling that no software optimization alone can overcome.

::: {#fig-energy-gap fig-env="figure" fig-pos="htb" fig-cap="**The Energy Gap**. US datacenter electricity consumption tripled from 58 TWh (2014) to 176 TWh (2023), driven primarily by AI workloads. LBNL projects a further doubling to 325 to 580 TWh by 2028. At the high end, datacenters would consume approximately 12% of US electricity, representing a physical constraint on AI scaling that no software optimization can overcome." fig-alt="Bar chart showing US datacenter electricity: 58 TWh in 2014, 176 TWh in 2023, projected 325 to 580 TWh by 2028. Bars colored blue for historical and red for projections."}
```{python}
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ ENERGY GAP (FIGURE)
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @fig-energy-gap — US datacenter electricity (LBNL)
# │
# │ Goal: Bar chart of 2014/2023/2028 low/2028 high TWh; show 3× growth,
# │       12% US electricity at high end.
# │ Show: Four bars; value labels; percentage annotations.
# │ How: LBNL data; ax.bar; viz.setup_plot().
# │
# │ Imports: numpy (np), matplotlib.pyplot (plt), mlsys.viz (viz)
# │ Exports: (figure only, no prose variables)
# └─────────────────────────────────────────────────────────────────────────────
import numpy as np
import matplotlib.pyplot as plt
from mlsys import viz

fig, ax, COLORS, plt = viz.setup_plot(figsize=(8, 5))

# LBNL 2024 US Data Center Energy Usage Report
labels = ['2014', '2023', '2028\n(Low)', '2028\n(High)']
values = [58, 176, 325, 580]
colors = [COLORS['BlueLine'], COLORS['BlueLine'],
          COLORS['RedLine'], COLORS['RedLine']]
alphas = [1.0, 1.0, 0.6, 0.6]

bars = ax.bar(labels, values, color=colors, width=0.55, edgecolor='white',
              linewidth=1.2, zorder=3)
for bar, alpha in zip(bars, alphas):
    bar.set_alpha(alpha)

# Value labels on bars
for bar, val in zip(bars, values):
    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 12,
            f'{val} TWh', ha='center', va='bottom', fontsize=10,
            fontweight='bold', color=COLORS['primary'])

# Percentage of US electricity annotations
ax.text(bars[1].get_x() + bars[1].get_width() / 2, bars[1].get_height() / 2,
        '~4.4% of\nUS electricity', ha='center', va='center', fontsize=8,
        color='white', fontweight='bold')
ax.text(bars[3].get_x() + bars[3].get_width() / 2, bars[3].get_height() / 2,
        '~12% of\nUS electricity', ha='center', va='center', fontsize=8,
        color='white', fontweight='bold')

# 2014 baseline reference line
ax.axhline(y=58, color=COLORS['BlueLine'], linestyle=':', linewidth=1,
           alpha=0.4)
ax.text(3.45, 62, '2014 baseline', fontsize=7, color='gray', ha='right')

# Growth annotations
ax.annotate('', xy=(1, 176), xytext=(0, 58),
            arrowprops=dict(arrowstyle='<->', color=COLORS['BrownLine'],
                            lw=1.5))
ax.text(-0.35, 117, '3$\\times$ growth\nin 9 years', fontsize=8,
        color=COLORS['BrownLine'], ha='center')

# Source
ax.text(0.99, 0.97, 'Source: LBNL 2024 US Data Center\nEnergy Usage Report',
        transform=ax.transAxes, fontsize=7, va='top', ha='right',
        color='gray', style='italic')

ax.set_ylabel('Electricity consumption (TWh)')
ax.set_ylim(0, 680)
ax.set_title('')
plt.show()
```
:::

### Distributed Systems Energy Optimization {#sec-sustainable-ai-distributed-systems-energy-optimization-5e83}

Large-scale AI training inherently requires distributed systems coordination, creating additional energy overhead that compounds computational demands. The parallelism strategies examined in @sec-distributed-training-systems introduce network communication costs that can account for 20-40% of total energy consumption in large clusters.[^fn-training-paradigms] This coordination across thousands of GPUs requires constant synchronization of computational updates and model parameters[^fn-distributed-training], generating data movement between nodes. This communication overhead scales poorly: doubling cluster size can increase networking energy consumption by 4$\times$ due to all-to-all communication patterns in gradient aggregation.

[^fn-training-paradigms]: The distributed training paradigms established in @sec-distributed-training-systems (data, model, and pipeline parallelism) each introduce distinct communication patterns with associated energy overhead. GPT-3 combined all three across thousands of GPUs, with parallelism strategy selection significantly impacting training efficiency and energy consumption.

[^fn-distributed-training]: **Distributed Training**: Parallelizing model training across multiple nodes through coordinated gradient synchronization and parameter updates. Ring-allreduce achieves near-linear scaling to hundreds of GPUs; hierarchical approaches scale to thousands. Communication overhead consumes 10-40% of training time, motivating gradient compression (1-2$\times$ speedup) and asynchronous methods (looser consistency for better throughput).

Addressing these communication overheads, cluster-wide energy optimization requires coordinated resource management that extends beyond individual server efficiency. Dynamic workload placement can achieve 15-25% energy savings by consolidating training jobs onto fewer nodes during low-demand periods, allowing unused hardware to enter low-power states. Similarly, intelligent scheduling that coordinates training across multiple data centers can leverage time-zone differences and regional renewable energy availability, reducing carbon intensity by 30-50% through temporal load balancing.

Infrastructure sharing presents efficiency opportunities often overlooked in sustainability analyses. Multi-tenant training environments, where multiple model training jobs share the same cluster, can improve GPU utilization from typical 40-60% to 80-90%, effectively halving energy consumption per model trained. Resource sharing also enables batch processing optimizations where multiple smaller training jobs are combined to better utilize available compute capacity, reducing the energy overhead of maintaining idle infrastructure.

#### AI Energy Consumption Compared to Other Industries {#sec-sustainable-ai-ai-energy-consumption-compared-industries-3d5d}

The environmental impact of AI workloads has emerged as a concern, with carbon emissions approaching levels comparable to established carbon-intensive sectors. Research demonstrates that training a single large AI model generates carbon emissions equivalent to multiple passenger vehicles over their complete lifecycle [@strubell2019energy]. To contextualize AI's environmental footprint, @fig-carbonfootprint compares the carbon emissions of large-scale machine learning tasks to transcontinental flights, illustrating the energy demands of training and inference workloads. It shows a comparison from lowest to highest carbon footprints, starting with a roundtrip flight between NY and SF, human life average per year, American life average per year, US car including fuel over a lifetime, and a Transformer model with neural architecture search[^fn-transformer-nas], which has the highest footprint. These comparisons underscore the need for more sustainable AI practices to mitigate the industry's carbon impact.

[^fn-transformer-nas]: **Transformer + NAS Environmental Impact**: This 284,000 kg (626,000 lbs) CO₂ figure represents training one Transformer model while searching for optimal architecture. Includes evaluating 12,800 different model configurations over multiple days. For comparison, this equals the carbon footprint of 312 economy round-trip flights from NYC to London, or the annual emissions of 140 average Americans. Modern efficient NAS techniques have reduced this cost by 1000$\times$.

::: {#fig-carbonfootprint fig-env="figure" fig-pos="htb" fig-cap="**Carbon Footprint Benchmarks**: Training large AI models generates carbon emissions, comparable to everyday activities and long-distance travel, emphasizing the environmental impact of increasingly complex machine learning workloads. The comparison to roundtrip flights, average human lifespans, and vehicle lifetimes contextualizes the energy demands of training a transformer model with neural architecture search as high. " fig-alt="Horizontal bar chart of CO2 emissions in kg. From lowest to highest: NY-SF flight at 900, human life at 5,000, American life at 16,400, US car lifetime at 57,150, Transformer with NAS at 284,000."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
  \begin{axis}[title  = {Common carbon footprint benchmarks},
    title style={font=\usefont{T1}{phv}{m}{n}\bfseries},
    xbar,
    /pgf/number format/.cd,
     use comma,
    1000 sep={,},fixed,
    y axis line style = { opacity = 0 },
    axis x line       = none,
    tickwidth         = 0pt,
    enlarge y limits  = 0.2,
    enlarge x limits  = 0.02,
    symbolic y coords = {Transformer {(213M parameters)}\\ w/ neural architecture search,
    US car including fuel\\ {(avg. 1 lifetime)},
    American life {(avg. 1 year)},
    Human life {(avg. 1 year)},
    Roundtrip flight b/w NY and SF\\ {(1 passenger)}},
    yticklabel style={font=\small\usefont{T1}{phv}{m}{n},text width=50mm,align=flush left},
      nodes near coords={\footnotesize\usefont{T1}{phv}{m}{n}\pgfmathprintnumber[assume math mode=true]{\pgfplotspointmeta}},
   every node near coord/.append style={anchor=west, align=right,text=black,
                  font=\sffamily},
   bar width=17pt
  ]
  \addplot[fill=BlueLine,draw=none]
  coordinates {
  (284000,Transformer {(213M parameters)}\\ w/ neural architecture search)
  (57150,US car including fuel\\ {(avg. 1 lifetime)})
  (16400,American life {(avg. 1 year)})
  (5000,Human life {(avg. 1 year)})
  (900,Roundtrip flight b/w NY and SF\\ {(1 passenger)})
  };
  \end{axis}
\node[below=-3mm, align=center,font=\small\bfseries\usefont{T1}{phv}{m}{n}]
            at (current axis.north) {in kg of CO2 equivalent};

\end{tikzpicture}
```
:::

The training phase of large natural language processing models produces carbon dioxide emissions comparable to hundreds of transcontinental flights. When examining the broader industry impact, AI's aggregate computational carbon footprint is approaching parity with the commercial aviation sector. As AI applications scale to serve billions of users globally, the cumulative emissions from continuous inference operations may ultimately exceed those generated during training.

@fig-meta-analysis provides a detailed analysis of carbon emissions across various large-scale machine learning tasks at Meta, illustrating the environmental impact of different AI applications and architectures. This quantitative assessment of AI's carbon footprint underscores the pressing need to develop more sustainable approaches to machine learning development and deployment. Understanding these environmental costs is important for implementing effective mitigation strategies and advancing the field responsibly.

::: {#fig-meta-analysis fig-env="figure" fig-pos="htb" fig-cap="**Inference-Training Market Growth**: The rapidly expanding market for inference workloads, projected to more than double from 2017 to 2025, outpaces growth in training, reflecting the increasing demand for deploying AI models at scale. This disparity emphasizes that the operational energy footprint of running AI applications is becoming a dominant cost factor compared to model development itself. Source: Umckinsey." fig-alt="Stacked bar chart of CO2 emissions for 13 ML models. GPT-3 shows highest at nearly 1 million kg. Facebook recommendation models show significant inference portions. OSS models show training-only footprints."}
```{.tikz}
% couleurs de Poly
\definecolor{blpoly}{RGB}{65,170,230}
\definecolor{vrpoly}{RGB}{140,200,60}
\definecolor{orgpoly}{RGB}{250,150,30}
\definecolor{rgpoly}{RGB}{185,30,50}

\def\legende{{"Offline Training","Online Training","Inference"}}

\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]

\begin{axis}[ clip mode = individual,
    title  = {Operational Carbon Footprint of Large-Scale ML Tasks},
    title style={font=\usefont{T1}{phv}{m}{n}\bfseries},
    ylabel={CO2e (kg)},
    axis y line=left,
    axis x line=bottom,
    axis line style={thick,-latex},
    /pgf/number format/.cd,fixed,
    legend style={at={(0.5,1.0),font=\small\usefont{T1}{phv}{m}{n}},
    anchor=north,
    draw=none},
    legend columns=-1,
    ybar stacked,
    ymin=0,
    ymax=1.05,
    width=130mm,
    height=6cm,
    bar width=7.5mm,
    scale only axis,
    xtick=data,
    ytick={0.00,0.50,1.00},
    area style,
    enlarge x limits=0.05,
    xticklabel style={align=right,rotate=90,font=\small\usefont{T1}{phv}{m}{n}},
    tick label style={/pgf/number format/assume math mode=true},
    yticklabel style={font=\small\usefont{T1}{phv}{m}{n},
    /pgf/number format/.cd, fixed, fixed zerofill, precision=2},
    symbolic x coords={LM, RM-1, RM-2, RM-3, RM-4, RM-5, BERT-NAS, Evolved Transformer, T5, Meena, GShard-600B, Switch Transformer, GPT-3},
]
%
  \addplot [fill=rgpoly, bar shift=0.5pt] coordinates {
                    (LM, 0.06)
                    (RM-1, 0.352)
                    (RM-2, 0.243)
                    (RM-3, 0.126)
                    (RM-4, 0.128)
                    (RM-5, 0.153)
                    (BERT-NAS, 0)
                    (Evolved Transformer, 0.006)
                    (T5, 0.041)
                    (Meena, 0.090)
                    (GShard-600B, 0.006)
                    (Switch Transformer, 0.065)
                    (GPT-3, 0.544)
                };
\addlegendentry{Offline Training~~~~}

  \addplot [fill=orgpoly, bar shift=0.5pt] coordinates {
                    (LM, 0.115)
                    (RM-1, 0.041)
                    (RM-2, 0.026)
                    (RM-3, 0.02)
                    (RM-4, 0.02)
                    (RM-5, 0.02)
                    (BERT-NAS, 0)
                    (Evolved Transformer, 0)
                    (T5, 0.)
                    (Meena, 0)
                    (GShard-600B, 0)
                    (Switch Transformer, 0.)
                    (GPT-3, 0)
                };

\addlegendentry{Online Training~~~~}
  \addplot [fill=vrpoly, bar shift=0.5pt] coordinates {
                    (LM, 0)
                    (RM-1, 0.497)
                    (RM-2, 0.310)
                    (RM-3, 0.265)
                    (RM-4, 0.231)
                    (RM-5, 0.289)
                    (BERT-NAS, 0)
                    (Evolved Transformer, 0)
                    (T5, 0.)
                    (Meena, 0)
                    (GShard-600B, 0)
                    (Switch Transformer, 0.)
                    (GPT-3, 0)
                };
\addlegendentry{Inference}
  \addplot [fill=BlueLine, bar shift=0.5pt] coordinates {
                    (LM, 0)
                    (RM-1, 0)
                    (RM-2, 0)
                    (RM-3, 0)
                    (RM-4, 0)
                    (RM-5, 0)
                    (BERT-NAS, 0.279)
                    (Evolved Transformer, 0)
                    (T5, 0)
                    (Meena, 0)
                    (GShard-600B, 0)
                    (Switch Transformer, 0)
                    (GPT-3, 0)
                };
\node[anchor=south,rotate=90] at (axis description cs:-0.07,0.9) {Millions};
\end{axis}
%
\draw[dashed, thick] ({rel axis cs:0.045,0}) --({rel axis cs:0.045,-0.65})coordinate(X1);
\draw[dashed, thick] ({rel axis cs:0.51,0}) -- ({rel axis cs:0.51,-0.65})coordinate(X2);
\draw[dashed, thick] ({rel axis cs:1.03,0}) -- ({rel axis cs:1.03,-0.65})coordinate(X3);
\path[](X1)--node[above]{Facebook}(X2);
\path[](X2)--node[above]{OSS Large-Scale ML Models}(X3);
\path[](X2)--node[below]{\textbf{*Training footprint only}}(X3);
\end{tikzpicture}
```
Carbon footprint of large-scale ML tasks.
:::

### Comprehensive Carbon Accounting Methodologies {#sec-sustainable-ai-comprehensive-carbon-accounting-methodologies-62fc}

AI's impact extends beyond operational energy consumption. Comprehensive carbon footprint assessment integrates the Three-Phase Lifecycle Analysis (training, inference, manufacturing) with the three standard emission scopes defined by the GHG Protocol. With AI projected to grow at 37.3% annually through 2030, understanding total lifecycle costs across all phases and scopes is essential for identifying the most impactful sustainability interventions.

Scope 1 emissions, which account for 5 to 15 percent of the total, originate from on-site power generation including backup diesel generators, facility cooling systems, and owned power plants. While many AI data centers primarily use grid electricity, those with fossil-fuel backup systems or owned generation contribute directly to emissions.

Scope 2 emissions, which account for 60 to 75 percent of the total, represent indirect emissions from electricity purchased to power AI infrastructure. This dominant operational emission category varies dramatically by geographic location and grid energy mix. As established in our geographic optimization discussion, training location can create up to 75$\times$ differences in carbon intensity.

Scope 3 emissions, which account for 15 to 25 percent of the total, constitute the most complex category, encompassing hardware manufacturing, transportation, and disposal. Semiconductor manufacturing is carbon-intensive.[^fn-euv-lithography] Producing a single high-performance AI accelerator generates emissions equivalent to several years of operational energy use. Often overlooked, this category represents irreducible baseline emissions independent of operational efficiency.

[^fn-euv-lithography]: **EUV Lithography**: Extreme ultraviolet light (13.5nm wavelength) used to print features smaller than 7nm on silicon chips. Each EUV machine costs $200+ million, weighs 180 tons, requires 1 MW of continuous power (enough for 800 homes), and uses 30,000 liters of ultrapure water daily. ASML is the sole global supplier. EUV enables modern AI chips but consumes 10$\times$ more energy than older deep-UV lithography systems.

Beyond manufacturing, Scope 3 emissions include the downstream impact of AI once deployed. AI services such as search engines, social media platforms, and cloud-based recommendation systems operate at enormous scale, requiring continuous inference across millions or even billions of user interactions. The cumulative electricity demand of inference workloads can ultimately surpass the energy used for training, further amplifying AI's carbon impact. End-user devices, including smartphones, IoT devices, and edge computing[^fn-edge-computing] platforms, also contribute to Scope 3 emissions, as their AI-allowed functionality depends on sustained computation. Companies such as Meta and Google report that Scope 3 emissions from AI-powered services make up the largest share of their total environmental footprint, due to the sheer scale at which AI operates.

[^fn-edge-computing]: **Edge Computing for AI**: Processing data near its source rather than in distant cloud data centers. Reduces latency from 100-200ms (cloud) to 1-10ms (edge) for applications like autonomous vehicles. However, edge AI chips consume 5-50W continuously across billions of devices versus occasional cloud bursts. Tesla's FSD computer consumes 72W while driving; if all 1.4 billion cars had AI, collective power would equal 50 large power plants.

These operational emissions capture only the production phase of AI. The *hidden carbon cost of software development* itself adds another layer of environmental impact that is rarely accounted for.

::: {.callout-note title="Hidden Carbon Cost of Software"}
Beyond direct training and inference energy use, the entire software development ecosystem for AI has a significant, though difficult to measure, carbon footprint. The millions of continuous integration and continuous deployment (CI/CD) pipeline runs, constant code recompilation during development, operation of massive version control systems like GitHub, and the computational resources consumed by code review systems, automated testing frameworks, and collaborative development platforms all contribute to environmental impact. Large AI research organizations may run thousands of experimental training runs, most of which never reach production, consuming substantial energy in the exploration process. This reinforces that the entire ecosystem of AI development is energy-intensive, not just the final model training and inference phases.
:::

The GHG Protocol[^fn-ghg-protocol] framework [@ghgprotocol2023] provides the standard categorization for these emissions. @fig-ghg-protocol illustrates the three scopes:

[^fn-ghg-protocol]: **Greenhouse Gas Protocol (GHG Protocol)**: The most widely used international accounting standard for greenhouse gas emissions, developed by WRI and WBCSD. Over 90% of Fortune 500 companies reporting to CDP use GHG Protocol standards. It has become the de facto standard for sustainability reporting requirements including the EU's CSRD.

- **Scope 1 (Direct Emissions)**: Arise from direct company operations---backup generators, company-owned power generation.
- **Scope 2 (Indirect Energy Emissions)**: Electricity purchased from the grid, the primary emission source for cloud computing workloads.
- **Scope 3 (Value Chain Emissions)**: Extend beyond direct control---semiconductor manufacturing, hardware transportation, end-of-life disposal of AI accelerators.

![**GHG Emission Scopes**: Organizations categorize carbon emissions into scope 1 (direct), scope 2 (purchased energy), and scope 3 (value chain) to comprehensively assess environmental impact. Source: Ucircularise.](images/png/ghg_protocol.png){#fig-ghg-protocol fig-alt="Diagram showing three concentric emission scopes: Scope 1 for direct emissions from owned sources, Scope 2 for purchased energy emissions, and Scope 3 for value chain emissions including manufacturing and disposal."}

Categorizing these emissions into Scope 1, 2, and 3 frameworks provides a standardized vocabulary for corporate environmental reporting. To ensure we can correctly apply this framework in practice, let us test our ability to classify the various hidden emission sources across a typical ML platform's operational lifecycle.

::: {.callout-checkpoint}
## Accounting for Invisible Carbon
You are auditing the carbon footprint of a Machine Learning platform. Classify the following emission sources into Scope 1 (Direct), Scope 2 (Indirect Energy), or Scope 3 (Value Chain):
1. Diesel burned by backup generators during a grid outage at your owned facility.
2. Electricity purchased from the grid to power your leased NVIDIA H100 cluster.
3. The embodied carbon emitted during the manufacturing of the GPUs by TSMC.
4. Emissions from the end-user's smartphone battery while running your mobile inference app.
:::

Accurately classifying these hidden emissions forces engineering teams to take responsibility for the entire value chain of their deployments. With this comprehensive accounting framework established, we must now break down the operational workload itself, analyzing the massive, fundamental shift in energy consumption that occurs when a model transitions from the training phase to global inference.

## Training vs Inference Energy Analysis {#sec-sustainable-ai-training-vs-inference-energy-analysis-4cb5}

Training a massive language model is a spectacular, highly visible energy event—akin to launching a rocket. However, deploying that same model to serve a billion daily queries is like operating an international airline fleet. While training burns an enormous amount of energy in a single, concentrated burst over several months, inference burns energy continuously, query by query, year after year. Understanding where the majority of your energy budget goes dictates where you must focus your optimization efforts.

This lifecycle perspective reveals optimization opportunities across different phases. Training optimizations focus on computational efficiency and hardware utilization, while inference optimizations emphasize latency, throughput, and edge deployment strategies. Understanding these trade-offs enables targeted sustainability interventions that address the dominant energy consumers for specific AI applications.

#### Training Energy Demands {#sec-sustainable-ai-training-energy-demands-1ff6}

Training state-of-the-art AI models demands enormous computational resources, requiring extensive computational infrastructure with hundreds of thousands of cores and specialized AI accelerators operating continuously for months. OpenAI's dedicated supercomputer infrastructure, built specifically for large-scale AI training, contains 285,000 CPU cores, 10,000 GPUs, and network bandwidth exceeding 400 gigabits per second per server, illustrating the vast scale and associated energy consumption of AI training infrastructures [@patterson2021carbon].

The intensive computational loads result in significant heat dissipation, necessitating substantial cooling infrastructure that compounds total energy requirements. Advanced computational architectures and hardware optimization strategies for training systems require specialized knowledge of AI acceleration techniques, while algorithmic approaches to training efficiency involve complex optimization methods.

These energy costs occur once per trained model. The primary sustainability challenge emerges during model deployment, where inference workloads continuously serve millions or billions of users.

#### Inference Energy Costs {#sec-sustainable-ai-inference-energy-costs-aec9}

Inference workloads execute every time an AI model responds to queries, classifies images, or makes predictions. Unlike training, inference scales dynamically and continuously across applications such as search engines, recommendation systems, and generative AI models. Although each individual inference request consumes far less energy compared to training, the cumulative energy usage from billions of daily AI interactions quickly surpasses training-related consumption [@patterson2021carbon].

For example, AI-driven search engines handle billions of queries per day, recommendation systems provide personalized content continuously, and generative AI services such as ChatGPT or DALL-E have substantial per-query computational costs. The inference energy footprint is high in transformer-based models due to high memory and computational bandwidth requirements.

Market projections for inference workloads reveal dramatic growth. @fig-mckinsey_analysis tracks datacenter inference from $4-5 billion in 2017 to a projected $9-10 billion by 2025, more than doubling in size. Similarly, edge inference workloads are expected to increase from less than $0.1 billion to $4-4.5 billion in the same period. This growth substantially outpaces the expansion of training workloads in both environments, highlighting how the economic footprint of inference is rapidly outgrowing that of training operations.

::: {#fig-mckinsey_analysis fig-env="figure" fig-pos="htb" fig-cap="**AI Hardware Market Growth**: McKinsey analysis comparing 2017 and 2025 projections for datacenter and edge markets. Inference workloads dominate growth, with edge inference emerging as a significant new segment while training markets grow more gradually." fig-alt="Two grouped bar charts comparing 2017 to 2025 market projections. Datacenter inference doubles from 4-5 to 9-10 billion dollars. Edge inference grows from near zero to 4-4.5 billion dollars. Training markets grow more slowly."}
```{.tikz}
\begin{tikzpicture}
\tikzset{
  helvetica/.style={align=flush center, font={\usefont{T1}{phv}{m}{n}\small}},
  Line/.style={line width=1.0pt, black!50},
  Box/.style={helvetica,
    anchor=south,
    inner xsep=2pt,
    node distance=3.0,
    draw=none,
    fill=BrownL,
    minimum width=30,
    minimum height=100
  },
}
\begin{scope}
\begin{scope}
\node[Box](B1){};
\node[Box,minimum height=80,fill=BrownLine](B11){};
\node[above=2pt of B1]{4-5};
\node[below=2pt of B11]{2017};
\end{scope}

\begin{scope}[shift={(2,0)}]
\node[Box,minimum height=200](B2){};
\node[Box,minimum height=175,fill=BrownLine](B22){};
\node[above=2pt of B2]{9-10};
\node[below=2pt of B22]{2025};
\end{scope}

\fill[fill=OliveLine!10](B1.north east)--(B2.north west)|-(B1.south east);
\node[below=0.5 of $(B1.south)!0.5!(B2.south)$]{\textbf{Inference}};
%%%
\begin{scope}[shift={(5,0)}]
\node[Box,minimum height=20,fill=BrownLine](B3){};
\node[above=2pt of B3]{–1};
\node[below=2pt of B3]{2017};
\end{scope}

\begin{scope}[shift={(7,0)}]
\node[Box,minimum height=100](B4){};
\node[Box,minimum height=80,fill=BrownLine](B44){};
\node[above=2pt of B4]{4-5};
\node[below=2pt of B44]{2025};
\end{scope}
\fill[fill=OliveLine!10](B3.north east)--(B4.north west)|-(B3.south east);
\node[below=0.5 of $(B3.south)!0.5!(B4.south)$]{\textbf{Training}};
%%%
\scoped[on background layer]
\node[draw=VioletLine2,inner xsep=11,inner ysep=33,yshift=1mm,
           fill=VioletL2!50,fit=(B1)(B2)(B4),line width=0.75pt](BB1){};
\node[below=3pt of  BB1.north,anchor=north]{\textbf{Data center, total market}, $\$$ billion};
\end{scope}
%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%
\begin{scope}[shift={(10,0)}]
\begin{scope}
\node[Box,minimum height=200,fill=none](B0){};
\node[Box,minimum height=2mm,fill=BrownLine](B1){};
\node[above=2pt of B1]{\textless~0.1};
\node[below=2pt of B1]{2017};
\end{scope}

\begin{scope}[shift={(2,0)}]
\node[Box,minimum height=90](B2){};
\node[Box,minimum height=80,fill=BrownLine](B22){};
\node[above=2pt of B2]{4-4.5};
\node[below=2pt of B22]{2025};
\end{scope}

\fill[fill=OliveLine!10](B1.north east)--(B2.north west)|-(B1.south east);
\node[below=0.5 of $(B1.south)!0.5!(B2.south)$]{\textbf{Inference}};
%%%
\begin{scope}[shift={(5,0)}]
\node[Box,minimum height=2mm,fill=BrownLine](B3){};
\node[above=2pt of B3]{\textless~0.1};
\node[below=2pt of B3]{2017};
\end{scope}

\begin{scope}[shift={(7,0)}]
\node[Box,minimum height=31](B4){};
\node[Box,minimum height=20,fill=BrownLine](B44){};
\node[above=2pt of B4]{1-1.5};
\node[below=2pt of B44]{2025};
\end{scope}
\fill[fill=OliveLine!10](B3.north east)--(B4.north west)|-(B3.south east);
\node[below=0.5 of $(B3.south)!0.5!(B4.south)$]{\textbf{Training}};
%%%
\scoped[on background layer]
\node[draw=cyan,inner xsep=11,inner ysep=33,yshift=1mm,
           fill=cyan!03,fit=(B0)(B2)(B4),line width=0.75pt](BB1){};
\node[below=3pt of  BB1.north,anchor=north,helvetica]{\textbf{Edge total market}, $\$$ billion};
\end{scope}
\end{tikzpicture}
```
:::

Unlike traditional software applications with fixed energy footprints, inference workloads dynamically scale with user demand. AI services like Alexa, Siri, and Google Assistant rely on continuous cloud-based inference, processing millions of voice queries per minute, necessitating uninterrupted operation of energy-intensive data center infrastructure.

#### The Energy Inefficiency of the Decode Phase {#sec-sustainable-ai-energy-inefficiency-decode-phase-24da}

The distinction between "Prefill" and "Decode" established in @sec-inference-scale is not merely a latency problem; it is a profound energy efficiency challenge. Recent analysis [@ma2024challenges] reveals that autoregressive generation is inherently energy-wasteful compared to batch processing.

- **Prefill (Compute-Bound)**: High arithmetic intensity allows the GPU to perform thousands of operations for every byte read from memory, achieving near-peak energy efficiency (pJ/FLOP).
- **Decode (Bandwidth-Bound)**: The "Decode" phase requires reading the *entire* model weight set from HBM to generate a single token. Since arithmetic intensity is low, the compute units sit idle for much of the cycle.

This creates **Static Power Waste**: the GPU draws significant leakage and clock power while waiting for memory transfers. Consequently, generating 1,000 tokens through 1,000 sequential decode steps can consume 10–50$\times$ more energy than processing the same 1,000 tokens in a single prefill batch. This inefficiency drives the demand for the specialized, memory-optimized NPUs and TPUs examined in @sec-compute-infrastructure, which prioritize bandwidth-per-watt over raw TFLOPS.

#### Edge AI Impact {#sec-sustainable-ai-edge-ai-impact-6694}

The edge intelligence architectures from @sec-edge-intelligence enable inference beyond centralized datacenters. This distributed approach offers unique sustainability advantages by reducing data transmission energy costs and lowering dependency on high-power cloud infrastructure. Instead of routing every AI request to centralized cloud servers, models can be deployed directly on user devices or at edge computing nodes.

However, running inference at the edge does not eliminate energy concerns, especially when AI is deployed at scale. Autonomous vehicles, for instance, require millisecond-latency AI inference, meaning cloud processing is impractical. Instead, vehicles are now being equipped with onboard AI accelerators that function as "data centers on wheels" [@sudhakar2023data]. These embedded computing systems process real-time sensor data equivalent to small data centers, consuming significant power even without relying on cloud inference.

Similarly, consumer devices such as smartphones, wearables, and IoT sensors individually consume relatively little power but collectively contribute significantly to global energy use due to their sheer numbers. Therefore, the efficiency benefits of edge computing must be balanced against the extensive scale of device deployment.

The key insight often missed in edge AI sustainability discussions is that edge deployment can be *more* sustainable than cloud deployment when designed correctly, not merely less impactful per device. The combination of eliminated data transmission, local processing efficiency, and duty-cycled operation can reduce total system energy consumption by orders of magnitude compared to always-connected cloud inference.

#### Edge and Mobile Power Budgets {#sec-sustainable-ai-edge-mobile-power-budgets-b3b2-b3b2}

ARM-based edge devices operate under fundamentally different power constraints than datacenter GPUs. Understanding these constraints is essential for sustainable edge AI system design:

These power budgets reflect the physical constraints of battery capacity, thermal dissipation, and deployment environment. Examine @tbl-edge-power-budgets to see how the constraints propagate: TinyML devices operating from coin cells or energy harvesting cannot exceed milliwatt average power, mobile devices must balance user experience with battery life, and automotive systems face thermal constraints within enclosed vehicle compartments despite having access to vehicle power.

| **Platform Category**  | **Idle Power** | **Active Power** | **Peak Power** | **Example Devices**                               |
|:-----------------------|---------------:|-----------------:|---------------:|:--------------------------------------------------|
| **TinyML (MCU)**       |   1-100 microW |          1-50 mW |         100 mW | Arduino Nano 33, STM32H7, Nordic nRF5340          |
| **Mobile NPU**         |      10-100 mW |          0.5-5 W |           10 W | Pixel Tensor, Apple Neural Engine, Snapdragon NPU |
| **Edge GPU/TPU**       |          1-5 W |           5-30 W |           75 W | NVIDIA Jetson Orin, Google Edge TPU, RPi AI Kit   |
| **Autonomous Vehicle** |        10-50 W |         50-200 W |          500 W | Tesla FSD Computer, Mobileye EyeQ, NVIDIA Drive   |

: **Edge AI Power Budget Categories**: Edge platforms span five orders of magnitude in power consumption, from sub-milliwatt TinyML systems to automotive compute platforms approaching datacenter power levels. Sustainable deployment requires matching workload requirements to appropriate power tiers. {#tbl-edge-power-budgets}

#### TinyML Power State Dynamics {#sec-sustainable-ai-tinyml-power-state-dynamics-ceaf}

TinyML efficiency depends heavily on duty cycling, where devices alternate between deep sleep and active inference. @eq-tinyml-duty-cycle expresses average power as a weighted sum of active and sleep power:

$$P_{average} = P_{active} \times \frac{t_{inference}}{T_{period}} + P_{sleep} \times \frac{T_{period} - t_{inference}}{T_{period}}$$ {#eq-tinyml-duty-cycle}

For a **KWS Lighthouse** (keyword spotting) model running on a Cortex-M4 microcontroller:

- Active inference power: 15 mW for 20 ms per detection cycle
- Deep sleep power: 10 microamps at 3.3V (33 microwatts)
- Detection period: 1 second (continuous listening)

$$P_{average} = 15 \text{ mW} \times \frac{20 \text{ ms}}{1000 \text{ ms}} + 0.033 \text{ mW} \times \frac{980 \text{ ms}}{1000 \text{ ms}}$$

$$P_{average} = 0.30 \text{ mW} + 0.032 \text{ mW} = 0.33 \text{ mW}$$

At this average power, a 250 mAh coin cell battery (at 3.0V nominal) provides approximately 2,270 hours of operation, nearly 95 days of continuous always-on AI inference. This calculation demonstrates how TinyML enables sustainable AI deployment scenarios impossible with higher-power platforms.

The following example applies these power-aware design principles to a practical industrial deployment scenario.

::: {.callout-example title="Battery Life for TinyML"}

Consider deploying an anomaly detection model on a factory sensor node:

**System Parameters:**

- Model: Autoencoder for vibration anomaly detection
- MCU: ARM Cortex-M4 at 80 MHz
- Inference latency: 5 ms per sample
- Sampling rate: 10 Hz (100 ms period)
- Active power: 12 mW during inference
- Sleep power: 5 microamps at 3.3V (16.5 microwatts)
- Battery: 2x AA (3000 mAh at 3.0V)

#### Step 1: Calculate Duty Cycle and Average Power {.unnumbered}

$$D = \frac{5 \text{ ms}}{100 \text{ ms}} = 0.05 \text{ (5\% duty cycle)}$$

$$P_{avg} = 12 \text{ mW} \times 0.05 + 0.0165 \text{ mW} \times 0.95 = 0.60 + 0.016 = 0.616 \text{ mW}$$

#### Step 2: Calculate Battery Life {.unnumbered}

$$E_{battery} = 3000 \text{ mAh} \times 3.0 \text{ V} = 9000 \text{ mWh}$$

$$t_{life} = \frac{9000 \text{ mWh}}{0.616 \text{ mW}} = 14,610 \text{ hours} \approx 1.7 \text{ years}$$

This deployment achieves continuous AI-powered monitoring for nearly two years on standard batteries, demonstrating the sustainability potential of TinyML systems designed with power-aware principles.
:::

#### Energy Harvesting for Autonomous Edge AI {#sec-sustainable-ai-energy-harvesting-autonomous-edge-ai-ac2b-autonomous-edge-ai-ac2b}

With sufficient optimization, TinyML enables energy-autonomous operation where devices harvest ambient energy rather than relying on batteries:

Consider @tbl-energy-harvesting: a keyword spotting model optimized to 0.5 mW average power can operate indefinitely on approximately 5 square centimeters of indoor solar harvesting, eliminating battery replacement and associated e-waste for distributed sensor deployments. This perpetual operation model represents the ultimate sustainable edge AI deployment, where operational energy comes entirely from ambient sources.

| **Harvesting Source**          |   **Typical Power** | **Viable TinyML Applications** |
|:-------------------------------|--------------------:|:-------------------------------|
| **Indoor solar (1 cm^2)**      |   10-100 microwatts | Periodic sensor classification |
| **Outdoor solar (1 cm^2)**     |     1-10 milliwatts | Continuous keyword spotting    |
| **Thermoelectric (body heat)** |   10-100 microwatts | Wearable gesture recognition   |
| **RF harvesting (WiFi)**       |     1-10 microwatts | Ultra-low-duty sensor nodes    |
| **Vibration piezoelectric**    | 100 microwatts-1 mW | Industrial monitoring          |

: **Energy Harvesting Power Budgets**: Ambient energy harvesting enables batteryless TinyML deployments when average power consumption remains within harvesting capacity. Solar harvesting provides the highest power density for most deployments. {#tbl-energy-harvesting}

#### Sustainable Edge Deployment Patterns {#sec-sustainable-ai-sustainable-edge-deployment-patterns-9415}

Beyond individual device efficiency, architectural patterns determine total system energy consumption across edge-cloud boundaries:

#### Cascade Inference Architecture

Deploy a small edge model (under 100 KB) to filter inputs before cloud inference. @eq-cascade-energy expresses total energy as the sum of local processing plus probabilistically-triggered cloud costs:

$$E_{cascade} = E_{edge} + p_{escalate} \times (E_{transmit} + E_{cloud})$$ {#eq-cascade-energy}

where $p_{escalate}$ is the probability of requiring cloud inference (typically 5-20% for well-designed cascades).

For a visual inspection system:

- Edge model (MobileNet-v3 tiny): 0.5 mJ per image classification
- Cloud model (ResNet-152): 50 mJ per classification
- Transmission energy: 10 mJ per image (cellular)
- Escalation rate: 10% (only ambiguous cases sent to cloud)

$$E_{cascade} = 0.5 + 0.10 \times (10 + 50) = 0.5 + 6.0 = 6.5 \text{ mJ/image}$$

Compared to always-cloud inference at 60 mJ per image, the cascade architecture achieves 89% energy reduction while maintaining accuracy through selective cloud escalation.

#### Wake-Word Triggered Systems

Always-on systems use hierarchical wake detection to minimize average power:

1. Ultra-low-power analog front end: 10 microwatts continuous voice activity detection
2. Tiny neural network wake detector: 100 microwatts when speech detected
3. Full model inference: 10 mW for 50 ms when wake word confirmed

With typical speech activity rates of 5% and wake word occurrence of 0.1%:

$$P_{average} = 0.01 + 0.05 \times 0.1 + 0.001 \times 10 \times 0.05 = 0.015 \text{ mW}$$

This hierarchical approach achieves 15 microwatts average power compared to 10 mW for always-active full inference, a 667$\times$ reduction enabling battery-powered voice assistants with multi-year operation.

#### Federated Learning Energy Analysis

Training at the edge eliminates data transmission but increases local compute. @eq-federated-energy contrasts the energy trade-offs between federated and centralized approaches:

$$E_{federated} = N \times E_{local\_train} + E_{aggregation}$$
$$E_{centralized} = N \times E_{transmit} + E_{cloud\_train}$$ {#eq-federated-energy}

Federated learning becomes more energy-efficient when data sizes exceed model update sizes. For privacy-sensitive applications with rich sensor data, federated approaches often achieve both privacy AND energy benefits, as transmitting model weight updates (megabytes) requires less energy than transmitting raw data (gigabytes) for applications like on-device personalization.

AI's environmental footprint extends beyond electricity consumption to include physical resources---water, hazardous chemicals, and critical materials---that require different assessment approaches.

### Resource Consumption and Ecosystem Effects {#sec-sustainable-ai-resource-consumption-ecosystem-effects-51f5}

Carbon footprint analysis provides a crucial but incomplete picture of AI's environmental impact. Comprehensive assessment requires measuring additional ecological impacts including water consumption, hazardous chemical usage, rare material extraction, and biodiversity disruption that often receive less attention despite their ecological significance. Modern semiconductor fabrication plants producing AI chips require millions of liters of water daily and use over 250 hazardous substances in their processes. In regions already facing water stress, such as Taiwan, Arizona, and Singapore, this intensive usage threatens local ecosystems and communities. AI hardware also relies heavily on scarce materials like gallium, indium, arsenic, and helium, which face both geopolitical supply risks and depletion concerns. These resource dependencies are examined in detail in the hardware lifecycle assessment that follows.

### Water, Chemicals, and Critical Materials {#sec-sustainable-ai-water-usage-caae}

Semiconductor fabrication is an exceptionally water-intensive process. TSMC's fab in Arizona is projected to consume 34 million liters of water per day [@tsmc2023water][^fn-tsmc-water], accounting for nearly 3% of the city's total water production. A single 300mm silicon wafer requires over 8,300 liters of water throughout the complete fabrication process. @fig-water_cycle illustrates the typical fab water cycle, where advanced recycling can reclaim 60-80% of water but still leaves a substantial consumption footprint.

[^fn-tsmc-water]: **Semiconductor Water Consumption Scale**: TSMC's Arizona facility will consume 12 billion liters annually, equivalent to 37,000 Olympic swimming pools. Each AI chip requires 5-10$\times$ more water than traditional processors due to advanced nodes and complex manufacturing. Intel's Ireland fab uses 5.7 billion liters annually, while Samsung's Texas facility is projected to use 23 million liters daily. Water treatment and purification add 30-50% to total consumption. During peak summer months, the cumulative daily water consumption of major fabs rivals that of cities with populations exceeding half a million people.

::: {#fig-water_cycle fig-env="figure" fig-pos="htb" fig-cap="**Semiconductor Water Cycle**. Modern fabs consume millions of liters of water daily. To mitigate this, advanced facilities implement closed-loop recycling. Raw water is purified to Ultra-Pure Water (UPW) for processing. Wastewater is treated and recycled back into the UPW system, reducing net consumption by 60-80%." fig-alt="Flowchart of fab water cycle with 5 stages: raw water source, ultra-pure water purification, fab processing, wastewater treatment, and recycling plant. Blue arrow shows 60-80 percent reclaim loop. Dashed line shows discharge."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}, node distance=1.5cm]
  \definecolor{WaterColor}{RGB}{200,240,255}
  \definecolor{WasteColor}{RGB}{220,220,220}

  \tikzset{
    stage/.style={draw=black!70, thick, rounded corners=2pt, align=center, minimum width=2.5cm, minimum height=1.2cm}
  }

  % Nodes
  \node[stage, fill=WaterColor] (Source) {Raw Water\\Source};
  \node[stage, fill=WaterColor, right=of Source] (UPW) {Ultra-Pure\\Water (UPW)};
  \node[stage, fill=white, right=of UPW] (Fab) {\textbf{Fab Process}\\Etching/Cleaning};
  \node[stage, fill=WasteColor, below=of Fab] (Waste) {Wastewater\\Treatment};
  \node[stage, fill=WaterColor, left=of Waste] (Recycle) {Recycling\\Plant};

  % Flows
  \draw[->, thick] (Source) -- (UPW);
  \draw[->, thick] (UPW) -- (Fab);
  \draw[->, thick] (Fab) -- (Waste);
  \draw[->, thick] (Waste) -- (Recycle);
  \draw[->, thick, blue] (Recycle) -- node[left] {Reclaim (60-80\%)} (UPW);
  \draw[->, thick, dashed] (Waste) -- (0, -1.5) node[below] {Discharge};

\end{tikzpicture}
```
:::

Fabrication is also heavily reliant on hazardous chemicals for etching, doping, and cleaning. Strong acids (hydrofluoric, sulfuric), volatile organic compounds like xylene, and highly toxic gases (arsine, phosphine) are used in massive quantities---a large fab may consume over 2,000 metric tons of acids annually. These substances create hazardous waste streams requiring extensive treatment to prevent ecological harm.

AI hardware depends on a suite of scarce and geopolitically sensitive **critical materials**. While silicon is abundant, high-performance chips require rare elements like gallium, indium, tantalum, and helium. The USGS has classified indium as a critical material with fewer than 15 years of supply at current consumption rates [@davies2011endangered]. China's dominance over 90% of rare earth element refining creates significant supply chain vulnerabilities. @tbl-material_depletion quantifies the scope of this material dependency challenge.

| **Material**                   | **Application in AI Semiconductor Manufacturing**             | **Supply Concerns**                                                                  |
|:-------------------------------|:--------------------------------------------------------------|:-------------------------------------------------------------------------------------|
| **Silicon (Si)**               | Primary substrate for chips, wafers, transistors              | • Processing constraints<br>• Geopolitical risks                                     |
| **Gallium (Ga)**               | GaN-based power amplifiers, high-frequency components         | • Limited availability<br>• Byproduct of aluminum and zinc production                |
| **Germanium (Ge)**             | High-speed transistors, photodetectors, optical interconnects | • Scarcity<br>• Geographically concentrated                                          |
| **Indium (In)**                | Indium Tin Oxide (ITO), optoelectronics                       | • Limited reserves<br>• Recycling dependency                                         |
| **Tantalum (Ta)**              | Capacitors, stable integrated components                      | • Conflict mineral<br>• Vulnerable supply chains                                     |
| **Rare Earth Elements (REEs)** | Magnets, sensors, high-performance electronics                | • High geopolitical risks<br>• Environmental extraction concerns                     |
| **Cobalt (Co)**                | Batteries for edge computing devices                          | • Human rights issues<br>• Geographical concentration (Congo)                        |
| **Tungsten (W)**               | Interconnects, barriers, heat sinks                           | • Limited production sites<br>• Geopolitical concerns                                |
| **Copper (Cu)**                | Interconnects, barriers, heat sinks                           | • Limited high-purity sources<br>• Geopolitical concerns                             |
| **Helium (He)**                | Semiconductor cooling, plasma etching, EUV lithography        | • Non-renewable<br>• Irretrievable atmospheric loss<br>• Limited extraction capacity |

: **Critical Materials for AI Hardware**: Semiconductor manufacturing relies on specific materials, including silicon, neodymium, and yttrium, that face increasing supply constraints and geopolitical risks, potentially impacting AI hardware production and innovation. The table details these materials, their applications in AI systems, and the associated supply vulnerabilities requiring proactive mitigation strategies. {#tbl-material_depletion}

The construction and operation of fabs and data centers also directly impacts natural ecosystems through habitat destruction, water stress from aquifer depletion, and pollution from chemical discharge. In Hsinchu, Taiwan, extensive water extraction by fabs has led to falling water tables and seawater intrusion, affecting both agriculture and aquatic biodiversity [@hsu2016accumulation]. Waste generation from fabrication---including gaseous emissions, VOC-laden air, and metal-contaminated wastewater---requires advanced treatment systems, and the end-of-life disposal of AI hardware contributes to a growing e-waste crisis, with only 17.4% of global e-waste properly recycled [@singh2022disentangling].

The environmental toll of our computational demands extends far beyond atmospheric carbon, manifesting as severe water stress and ecological disruption around manufacturing hubs. This sobering reality brings us to the ultimate physical consequence of the AI arms race: what happens to these massive, resource-intensive hardware clusters when they become obsolete just three years later?

## Hardware Lifecycle and E-Waste {#sec-sustainable-ai-hardware-lifecycle-environmental-assessment-66ee}

The environmental cost of an AI accelerator begins long before its first FLOP is calculated. The **embodied carbon** of a single NVIDIA H100 GPU is estimated at 150 to 200 kg of CO₂ equivalent from manufacturing alone.[^fn-lifecycle-assessment] The fleet of thousands of such processors required to train our 175B parameter model---consuming 1,287 MWh of electricity---represents a significant upfront carbon investment before any computation occurs. A comprehensive **Life Cycle Assessment (LCA)** quantifies the cumulative environmental impact across four key phases: design, manufacture, use, and disposal. LCA reveals that hardware manufacturing often contributes 30-50% of an AI system's total lifetime emissions, making it a critical sustainability lever that operational efficiency improvements alone cannot address.

[^fn-lifecycle-assessment]: **Life Cycle Assessment (LCA)**: Systematic methodology for evaluating environmental impacts throughout a product's entire lifespan, from raw material extraction through manufacturing, use, and disposal. Developed in the 1960s, standardized by ISO 14040/14044. For AI systems, LCA reveals that hardware manufacturing often contributes 30-50% of total emissions despite consuming no operational energy.

::: {.callout-checkpoint}
## The Training-Inference Flip
Consider a vision model where training requires 2,000 GPU-hours at an average power draw of 300W. Once deployed, the model serves 1 million requests per day, with each request taking 50ms at an average draw of 100W.
1. Calculate the total energy used for training.
2. Calculate the total energy used for inference over a 2-year product lifespan.
3. Determine the "Inference-to-Training Ratio." Based on this, where should an engineer focus optimization efforts to maximize sustainability?
:::

Life Cycle Assessments reveal that discarding functional hardware purely for modest efficiency gains often causes more environmental harm through embodied carbon than it saves in operational power. To mathematically evaluate the tipping point where new hardware becomes environmentally justified, we must calculate the exact intersection of training costs, inference scale, and hardware lifespans.

Each of the four primary lifecycle stages contributes to an AI system's total environmental footprint. @fig-ai_lca visualizes this progression from design through disposal, highlighting the interdependencies between phases and the environmental impact categories associated with each stage.

::: {#fig-ai_lca fig-env="figure" fig-pos="htb" fig-cap="**AI System Lifecycle**: Analyzing AI systems across design, manufacture, use, and disposal stages exposes the full environmental impact beyond operational energy consumption, encompassing resource depletion and electronic waste. This lifecycle assessment allows targeted interventions to improve sustainability throughout the entire AI system's existence." fig-alt="Four connected arrow boxes showing AI lifecycle phases: Design with computer icon, Manufacture with factory icon, Use with mobile device icon, and Disposal with recycling bin icon. Labeled as Life Cycle Analysis."}
```{.tikz}
\begin{tikzpicture}[line join=round,font=\usefont{T1}{phv}{m}{n}]
\definecolor{Green}{RGB}{84,180,53}
\definecolor{Red}{RGB}{249,56,39}
\definecolor{Blue}{RGB}{0,97,168}
\definecolor{Violet}{RGB}{178,108,186}
 \tikzset{
     comp/.style = {draw,
        minimum width  =20mm,
        minimum height = 12mm,
        inner sep      = 0pt,
        rounded corners,
       draw = BlueLine,
       fill=cyan!10,
       line width=2.0pt
    },
   arrowbox/.style={signal,
       node distance=1.2,
        signal from=west,
        signal to=east,
        minimum width=45mm,
        minimum height=15mm,
        text=black,
        fill=BlueLine!70,
        align=center}
}
\node[arrowbox] (A1) {~~Design Phase};
\node[arrowbox, fill=orange!80, right=of A1] (A2) {~~Manufacture Phase};
\node[arrowbox, fill=Violet, right=of A2] (A3) {~~Use Phase};
\node[arrowbox, fill=Green!80, right=of A3] (A4) {~~Disposal Phase};
%%%
%recycled
\begin{scope}[local bounding box=MOB,scale=0.7, every node/.append style={transform shape},
                        shift={($(A4.south)+(0,-2.05)$)}]
\coordinate(A)at(-0.5,-0.63);
\coordinate(B)at(0.5,-0.63);
\coordinate(C)at(0.7,1.15);
\coordinate(C1)at($(C)+(0.15,0)$);
\coordinate(D)at(-0.7,1.15);
\coordinate(D1)at($(D)+(-0.15,0)$);
\draw[line width=1.5pt,fill=brown!70](A)--(B)--(C)--(D)--cycle;
\draw[line width=2.5pt](D1)--(C1);
\draw[line width=1.5pt]($(C1)!0.38!(D1)$)--++(90:0.2)-|($(C1)!0.62!(D1)$);
\draw[line width=1.5pt]($(C1)!0.5!(D1)+(0,-0.2)$)--++(270:1.35);
\draw[line width=1.5pt]($(C1)!0.3!(D1)+(0,-0.2)$)--++(265:1.35);
\draw[line width=1.5pt]($(C1)!0.7!(D1)+(0,-0.2)$)--++(275:1.35);
\end{scope}
%%%%
%mobile
\begin{scope}[local bounding box=MOB,scale=0.4, every node/.append style={transform shape},
                        shift={($(A3.south)+(0,-2.45)$)}]
\node[rectangle,draw,minimum height=94,minimum width=47,
            rounded corners=6,thick,fill=Red](R1){};
\node[rectangle,draw,minimum height=60,minimum width=32,thick,fill=white](R2){};
\node[circle,draw,minimum size=8,below= 2pt of R2,inner sep=0pt,thick,fill=brown]{};
\node[rectangle,fill=black,minimum height=1,minimum width=20,above= 4pt of R2,inner sep=0pt,thick]{};
%
\coordinate(G)at(-1.01,-2.12);
\coordinate(D)at(-1.62,-1.59);
\coordinate(D1)at(-0.03,-1.65);
\coordinate(D2)at(-0.82,-0.25);
\coordinate(D3)at(-1.17,0.25);
\coordinate(D4)at(-0.73,-1.0);
\coordinate(D5)at(-1.14,0.6);
\coordinate(D6)at(-1.29,-0.1);
\coordinate(D7)at(-1.55,-0.71);
%\fill[blue](G)circle(1pt);
\coordinate(P1)at(0.83,0.80);
\coordinate(P11)at(0.93,0.80);
\coordinate(P2)at(0.83,0.36);
\coordinate(P22)at(0.93,0.36);
\coordinate(P3)at(0.76,-0.03);
\coordinate(P4)at(0.76,-0.56);
\coordinate(P5)at(0.76,-1.09);
%hand
\draw[thick,fill=orange!20](D)--(G)to[out=320,in=190] (D1)%--++(180:0.05)
to[out=180,in=270,distance=15] (D4)--(D2)to[out=50,in=50,distance=13] (D5)
to[out=230,in=70] (D6)to[out=250,in=70] (D7)to[out=250,in=150] (D);

\node[rectangle,draw,minimum height=12,minimum width=23,thick,
            rounded corners=2.5,rotate=35,fill=orange!20]at(P3)(PR2){};
\node[rectangle,draw,minimum height=12,minimum width=23,thick,
            rounded corners=2.5,rotate=35,fill=orange!20]at(P4)(PR3){};
\node[rectangle,draw,minimum height=12,minimum width=19,thick,
            rounded corners=2.5,rotate=35,fill=orange!20]at(P5)(PR4){};
\draw[thick,fill=orange!20](P1)--(P11)to[out=355,in=5,distance=9] (P22)--(P2)--cycle;
%\fill[blue](D4)circle(1pt);
\end{scope}
%%%
%factory
\begin{scope}[local bounding box=MOB,scale=1.4, every node/.append style={transform shape},
                          shift={($(A2.south)+(0,-1.05)$)}]
\node[rectangle,draw,fill=brown,minimum height=15,minimum width=23,line width=1.0pt](R1){};
\draw[fill=brown,line width=1.0pt]($(R1.40)+(0,-0.01)$)--++(110:0.2)--++(180:0.12)|-($(R1.40)+(0,-0.01)$);
\draw[line width=1.0pt,fill=green](-0.68,-0.27)--++(88:0.9)--++(0:0.15)--(-0.48,-0.27)--cycle;
\draw[line width=2.5pt](-0.8,-0.27)--(0.55,-0.27);

\foreach \x in{0.25,0.45,0.65}{
\node[rectangle,fill=black,minimum height=2,minimum width=5,thick,inner sep=0pt]
at ($(R1.north)!\x!(R1.south)$){};
}
\foreach \x in{0.25,0.45,0.65}{
\node[rectangle,fill=black,minimum height=2,minimum width=5,thick,inner sep=0pt]
at ($(R1.130)!\x!(R1.230)$){};
}
\foreach \x in{0.25,0.45,0.65}{
\node[rectangle,fill=black,minimum height=2,minimum width=5,thick,inner sep=0pt]
at ($(R1.50)!\x!(R1.310)$){};
}
\end{scope}
%%
%display
\colorlet{BlueLine}{BrownLine!70!black!99}
\begin{scope}[local bounding box=COMP, shift={($(A1.south)+(0,-1.05)$)}]
  \node[comp,fill=BrownLine!10](COM){};
  \draw[draw = BlueLine,line width=1.0pt]
    ($(COM.north west)!0.85!(COM.south west)$)
    -- ($(COM.north east)!0.85!(COM.south east)$);
  \draw[draw = BlueLine,line width=1.0pt]
    ($(COM.south west)!0.4!(COM.south east)$)--++(270:0.2)coordinate(DL);
  \draw[draw = BlueLine,line width=1.0pt]
    ($(COM.south west)!0.6!(COM.south east)$)--++(270:0.2)coordinate(DD);
  \draw[draw = BlueLine,line width=3.0pt,shorten <=-3mm,shorten >=-3mm](DL)--(DD);

  \node[GreenLine](CB1) at ($(COM.north west)!0.25!(COM.south west)+(0.3,0)$) {$\checkmark$};
  \node[GreenLine](CB2) at ($(COM.north west)!0.6!(COM.south west)+(0.3,0)$) {$\checkmark$};

  \draw[GreenLine,decoration={zigzag,segment length=4pt, amplitude=0.5pt},decorate]
    ($(CB1)+(0.3,0.05)$)--++(0:1.3);
  \draw[GreenLine,decoration={zigzag,segment length=4pt, amplitude=0.5pt},decorate]
    ($(CB1)+(0.3,-0.12)$)--++(0:1.0);
  \draw[GreenLine,decoration={zigzag,segment length=4pt, amplitude=0.5pt},decorate]
    ($(CB2)+(0.3,0.05)$)--++(0:1.3);
  \draw[GreenLine,decoration={zigzag,segment length=4pt, amplitude=0.5pt},decorate]
    ($(CB2)+(0.3,-0.12)$)--++(0:1.0);
\end{scope}
%%%%%%
%pencil
\begin{scope}[rotate=300,scale=0.3,shift={($(COMP)+(-0.15,1.05)$)}]
            \fill[Green] (0,4) -- (0.4,4) -- (0.4,0) --(0.3,-0.15) -- (0.2,0) -- (0.1,-0.14) -- (0,0) -- cycle;
            \draw[color=yellow,thick] (0.2,4) -- (0.2,0);
            \fill[black] (0,3.5) -- (0.2,3.47) -- (0.4,3.5) -- (0.4,4) arc(30:150:0.23cm);
            \fill[brown!60] (0,0) -- (0.2,-0.8)node[coordinate,pos=0.75](a){} -- (0.4,0)node[coordinate,pos=0.25](b){} -- (0.3,-0.15) -- (0.2,0) -- (0.1,-0.14) -- cycle;
            \fill[gray] (a) -- (0.2,-0.8) -- (b) -- cycle;
\end{scope}
%
\node[above=0.9 of $(A2)!0.5!(A3)$](LCA){\textbf{Life Cycle Analysis}};
\node[above=0 of LCA](LCA){AI System};
 \end{tikzpicture}
```
:::

### Design and Experimentation Phase {#sec-sustainable-ai-design-phase-0954}

The design phase encompasses the research, development, and optimization of ML models before deployment---iterating on architectures, tuning hyperparameters, and running training experiments. The environmental cost of this phase is often underestimated because reported training energy (such as GPT-3's 1,287 MWh) reflects only the final run, not the extensive trial-and-error that preceded it. Automated architecture search techniques evaluate hundreds or thousands of configurations, each requiring a separate training cycle. Early Neural Architecture Search (NAS) required 1,800 GPU-days; efficient variants like DARTS reduce this to 1-4 GPU-days through weight-sharing and differentiable search [@strubell2019energy]. @tbl-training-emissions reveals stark differences in emissions across model scales.

| **AI Model**    |   **Training FLOPs** | **Estimated $\textrm{CO}_2$ Emissions (kg)** | **Equivalent Car Distance** |
|:----------------|---------------------:|---------------------------------------------:|----------------------------:|
| **GPT-3**       | $3.1 \times 10^{23}$ |                                   502,000 kg |              1.9 million km |
| **T5-11B**      | $2.3 \times 10^{22}$ |                                    85,000 kg |                  338,000 km |
| **BERT (Base)** | $3.3 \times 10^{18}$ |                                       650 kg |                    2,400 km |
| **ResNet-50**   | $2.0 \times 10^{17}$ |                                        35 kg |                      129 km |

: **Model Carbon Footprint**: Training large AI models generates substantial carbon emissions directly correlating with computational demands. GPT-3's training emissions are equivalent to driving 1.9 million km. {#tbl-training-emissions}

Addressing the design phase's sustainability challenges requires innovations in training efficiency: sparse training, low-precision arithmetic, weight-sharing, and energy-aware NAS approaches. Transfer learning and fine-tuning pre-trained models can reduce computational costs by orders of magnitude compared to training from scratch [@gupta2022].

### Manufacturing Phase {#sec-sustainable-ai-manufacturing-phase-4ce1}

The manufacturing of AI hardware is enormously resource-intensive, with the embodied carbon of a single H100 GPU reaching 150-200 kg CO₂ equivalent before any computation occurs. Semiconductor fabrication requires extreme precision through processes such as EUV lithography---each tool consuming approximately 1 MW of continuous power---chemical vapor deposition, and ion implantation. The resource demands detailed in @sec-sustainable-ai-water-usage-caae reveal the scale: TSMC's Arizona fab consumes 34 million liters of water daily, fabrication relies on over 250 hazardous substances, and the supply chain depends on geopolitically concentrated critical materials.

The energy required to manufacture AI hardware is substantial, with the total energy cost per chip often exceeding its entire operational lifetime energy use in clean-grid regions. A single 5nm fabrication plant consumes millions of liters of ultrapure water daily and relies on energy-intensive processes that generate significant CO₂ emissions. Recognizing these challenges, industry leaders including Intel, TSMC, and Samsung have pledged to transition toward carbon-neutral fabrication through renewable energy integration, closed-loop water recycling systems, and eco-friendly etching techniques that minimize hazardous waste generation.

### Use Phase {#sec-sustainable-ai-use-phase-a0a1}

The operational energy consumed during training and inference is detailed in @sec-sustainable-ai-training-vs-inference-energy-analysis-4cb5. What merits attention here is the *pattern* of this consumption and its interaction with grid infrastructure. The 1,287 MWh required to train our 175B model represents a massive, inflexible power draw that runs 24/7, making it difficult to shift workloads to times of higher renewable energy availability.

This inflexibility exacerbates a critical grid management problem known as the **duck curve**---as solar power ramps down in the late afternoon, grid operators must rapidly bring other generation sources online to meet evening demand. A datacenter's constant, high power draw deepens this evening ramp, increasing reliance on fossil-fuel peaker plants. Cooling systems compound the problem, accounting for 30-40% of a datacenter's total energy consumption. Geographic optimization, as discussed in @sec-sustainable-ai-carbon-footprint-calculation-c2fe, can place datacenters in regions with cleaner energy grids, but the operational footprint remains shaped by these infrastructure-level dynamics.

### Disposal, E-Waste, and Embedded AI {#sec-sustainable-ai-disposal-phase-b4f1}

::: {.column-margin}
_DALL·E 3 Prompt: Detailed illustration of electronic waste transforming into nature. A pile of discarded GPUs and circuit boards morphs into roots and plants at the bottom, symbolizing the circular economy and the regeneration of resources through recycling._
:::

The rapid pace of innovation in AI hardware creates a relentless upgrade cycle, contributing to a growing global crisis of **electronic waste (e-waste)**. Globally, humanity generates over 50 million metric tons of e-waste annually, of which only 17.4% is formally documented as collected and properly recycled [@singh2022disentangling]. The powerful servers used for training large models have a typical service life of just three to five years before they are considered obsolete. Discarded AI hardware contains toxic materials---lead, mercury, cadmium, and beryllium---that can leach into soil and groundwater when disposed of in landfills or informal recycling facilities.

The problem is compounded by the rise of **embedded AI**, where machine learning capabilities are integrated into billions of consumer devices. @fig-iot-number projects over 30 billion IoT devices by 2030 [@Statista_2022], creating a distributed, low-value, and exceptionally difficult-to-recycle form of e-waste. Many AI-powered IoT sensors, wearables, and smart appliances are built with short lifespans and limited upgradability, making them difficult or impossible to repair or recycle [@Balde_2017]. Non-replaceable lithium-ion batteries, sealed enclosures, and proprietary components ensure that even minor failures lead to complete device replacement.

::: {#fig-iot-number fig-env="figure" fig-pos="htb" fig-cap="**IoT Device Growth**: Rapid expansion in the number of connected devices amplifies the environmental impact of embedded AI systems, as short device lifecycles contribute to escalating electronic waste. Projections exceeding 30 billion devices by 2030 necessitate sustainable design and improved recycling infrastructure to mitigate the growing e-waste crisis. " fig-alt="Bar chart showing IoT device growth from 8.6 billion in 2019 to projected 29.42 billion in 2030. Steady annual increases of approximately 2 billion devices per year. Asterisks mark projected values from 2024 onward."}
```{.tikz}
\begin{tikzpicture}
\begin{axis}[
    axis lines=left,
    axis line style={thick,-latex},
    /pgf/number format/.cd,fixed,
    ylabel = Connected devices in billions,
    ylabel style={font=\footnotesize\usefont{T1}{phv}{m}{n}},
    symbolic x coords={2019,2020,2021,2022,2023,2024*,2025*,2026*,2027*,2028*,2029*,2030*},
    ybar,
    ymin=0,
    ymax=34,
    width=136mm,
    height=65mm,
    bar width=7.5mm,
    scale only axis,
    xtick=data,
    ytick={0,5,10,15,20,25,30},
    enlarge x limits=0.07,
    xticklabel style={align=right,font=\small\usefont{T1}{phv}{m}{n}},
    tick label style={/pgf/number format/assume math mode=true},
    yticklabel style={font=\small\usefont{T1}{phv}{m}{n},
    /pgf/number format/.cd, fixed, precision=1},
    nodes near coords,
    nodes near coords style={/pgf/number format/assume math mode=true,
    font=\footnotesize\usefont{T1}{phv}{m}{n},  /pgf/number format/.cd, fixed, precision=2},
    grid= major,
    major grid style = {dashed},
    xmajorgrids = false,
]
\addplot [fill=RedLine] coordinates {
(2019, 8.6) (2020, 9.76)(2021, 11.28) (2022, 13.14)(2023, 15.14) (2024*, 17.8)(2025*, 19.08)
(2026*, 21.09)(2027*, 23.14)(2028*, 25.21)(2029*, 27.31)(2030*, 29.42)
};
\end{axis}
\end{tikzpicture}
```
:::

This cycle is often accelerated by **planned obsolescence**, where products are intentionally designed with limited lifespans through software updates that degrade performance, proprietary components that prevent repair, or sealed designs that make disassembly impossible. A disproportionate share of this e-waste burden falls on developing nations, which often receive shipments of discarded electronics from wealthier countries, leading to significant environmental and social costs for populations least equipped to manage them.

### Extending Hardware Lifespan {#sec-sustainable-ai-extending-hardware-lifespan-b028}

Countering the linear "take-make-dispose" model requires a shift toward a **circular economy** that prioritizes reuse, refurbishment, and recycling. Extending the functional lifespan of AI hardware is the single most effective way to reduce its total environmental impact, as it amortizes the high embodied carbon over a longer period. Extending server life from three to five years reduces embodied carbon per year of service by 40%---a larger gain than most algorithmic optimizations.

Several strategies can facilitate this shift. Legislative movements promoting the **right-to-repair** are gaining traction globally, pushing back against proprietary designs and mandating the availability of spare parts and service information. Modular AI hardware designs---allowing independent upgrade of accelerators, memory, or networking interfaces---prevent the need to discard entire systems when only one component is obsolete, following the principle demonstrated by companies like Framework in consumer laptops. Extended software and firmware support cycles ensure that hardware remains secure and performant for longer, delaying its entry into the e-waste stream. Companies such as Google and Microsoft have launched initiatives to repurpose decommissioned AI hardware for secondary applications, redistributing functional components to research institutions and running lower-priority workloads on older equipment.

Mandating interoperability and extending hardware lifespans through right-to-repair initiatives are crucial steps toward a circular economy. Having diagnosed the sheer scale of the hardware, energy, and carbon footprint generated by AI systems, it is time to pivot from analysis to action: what specific engineering techniques can we deploy to drastically reduce this impact?

---

## Mitigation Strategies {#sec-sustainable-ai-part-iii-implementation-solutions-232d}

When your datacenter hits its absolute power ceiling, you cannot simply buy more GPUs. You must extract more intelligence from every watt. This requires algorithmic intervention: quantizing FP32 weights down to INT4, pruning inactive neural pathways, and scheduling training runs to execute precisely when the local power grid is flooded with excess solar energy. Mitigation is the process of treating energy efficiency as a core algorithmic constraint.

The measurement frameworks we developed revealed where environmental costs concentrate: training dominates for research workloads, inference dominates for deployed services, and manufacturing contributes a baseline that operational efficiency cannot eliminate. These findings guide our implementation strategy: algorithmic optimization reduces per-operation costs, infrastructure choices determine whether those savings translate to actual emissions reduction, and policy frameworks ensure industry-wide adoption.

Implementation must account for Jevons Paradox[^fn-jevons-paradox], the counterintuitive risk that efficiency improvements may inadvertently increase overall consumption by making AI more accessible and affordable. This rebound effect occurs when efficiency gains lower computation costs, enabling entirely new applications that were previously economically infeasible. Successful strategies therefore combine technical optimization with usage governance that prevents efficiency gains from being offset by exponential growth in deployment scale.

::: {.callout-definition title="Jevons Paradox in AI"}

***Jevons Paradox in AI***\index{Jevons Paradox!definition} is the phenomenon where improvements in ML efficiency (e.g., lower energy per token) lead to an increase in **Total Resource Consumption** due to stimulated demand.

1.  **Significance (Quantitative):** It challenges the assumption that efficiency automatically reduces environmental impact. As the cost per operation ($O$) falls through quantization or distillation, the **Aggregate Deployment Volume** often grows super-linearly, potentially increasing the total **Energy and Carbon Footprint** of the system.
2.  **Distinction (Durable):** Unlike **Rebound Effects** (which assume a fixed resource pool), Jevons Paradox specifically addresses cases where efficiency unlocks **Entirely New Use Cases** that were previously economically or physically infeasible.
3.  **Common Pitfall:** A frequent misconception is that efficiency is "counter-productive." In reality, Jevons Paradox highlights that **Efficiency is a Catalyst**: it enables greater scale and utility, but must be paired with **Governance** and carbon-aware scheduling to achieve net sustainability goals.

:::

### Multi-Layer Mitigation Strategy Framework {#sec-sustainable-ai-multilayer-mitigation-strategy-framework-80f2}

Addressing AI's environmental footprint requires a multi-layered approach that integrates energy-efficient algorithmic design, optimized hardware deployment, sustainable infrastructure operations, and carbon-aware computing strategies. The selection and optimization of AI frameworks themselves play a role in efficiency, involving careful evaluation of computational efficiency and resource utilization patterns. Additionally, AI systems must be designed with lifecycle sustainability in mind, ensuring that models remain efficient throughout their deployment, from training to inference.

This section explores key strategies for mitigating AI's environmental impact, beginning with sustainable AI development principles. @fig-jevons-ai captures the core challenge: efficiency improvements that reduce per-unit energy often trigger demand increases that overwhelm the savings, a phenomenon known as the Jevons paradox.

[^fn-jevons-paradox]: **Jevon's Paradox**: Named after British economist William Stanley Jevons who observed in 1865 that improving coal efficiency actually increased total coal consumption rather than reducing it. Modern examples include LEDs—despite being 85% more efficient than incandescent bulbs, total lighting energy consumption has increased due to expanded usage. In AI, this means that making models 10$\times$ more efficient might lead to 100$\times$ more AI applications, resulting in net increase in environmental impact.

As AI systems become more efficient, the cost per unit of computation decreases, whether for language model tokens, computer vision inferences, or recommendation system predictions. Moving from point A to point B represents a drop in computation cost. However, this price reduction leads to increased usage across all AI applications, with corresponding shift from point C to point D on the horizontal axis. While there are savings from reduced costs, the total consumption of AI services increases even more rapidly, ultimately resulting in higher overall resource usage and environmental impact. This dynamic highlights the core of Jevon's Paradox in AI: efficiency alone is not sufficient to guarantee sustainability.

::: {#fig-jevons-ai fig-env="figure" fig-pos="htb" fig-cap="**Jevon's Paradox**: Decreasing computation costs drive increased AI usage, potentially offsetting efficiency gains and leading to higher overall resource consumption; the figure maps this effect, showing how a cost reduction (A to B) fuels demand growth (C to D). This counterintuitive relationship underscores the importance of considering systemic effects when evaluating the environmental impact of AI advancements." fig-alt="Supply-demand graph with downward-sloping curve. Y-axis shows AI service costs dropping 50 percent from point A to B. X-axis shows usage more than doubling from C to D. Shaded regions show efficiency savings offset by increased consumption."}
```{.tikz}
\scalebox{0.75}{%
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
% Axses
\draw[thick,-latex] (0,0)--(9.0,0)coordinate(XT) node[below=1mm] {AI Usage};
\draw[thick,-latex] (0,0)--(0,5.2)coordinate(YT)
              node[below left=0mm and 3mm,align=right] {Cost of\\ AI Services};
% curved line
\draw[line width=1.95pt,BlueLine,name path=G] (1,4.7) to[bend right=20]
               node[align=center,right=7mm,pos=0.3,text=black]{Demand Response \\
                         Curve for AI Usage}(8.5,1.9);
%
\path[name path=L1](1.75,0)coordinate(X1)--(1.75,5.5);
\path[name path=L2](6.7,0)coordinate(X2)--(6.7,5.5);
\path [name intersections={of=G and L1,by=T1}];
\path [name intersections={of=G and L2,by=T2}];
 %
\draw[dashed,thick](X1)--(T1)--(T1-|YT)coordinate(Y2);
\draw[dashed,thick](X2)--(T2)--(T2-|YT)coordinate(Y1);
\draw[](Y2)--++(180:0.5)coordinate(YY2)node[left]{A};
\draw[](Y1)--++(180:0.5)coordinate(YY1)node[left]{B};
\draw[-latex]($(Y2)!0.8!(YY2)$)--
            node[align=center,left,font=\footnotesize\usefont{T1}{phv}{m}{n}]{50\% Drop\\ in Costs}($(Y1)!0.8!(YY1)$);
%
\draw[](0,0)--++(270:0.5)coordinate(XX0);
\draw[](X1)--++(270:0.5)coordinate(XX1)node[below]{C};
\draw[](X2)--++(270:0.5)coordinate(XX2)node[below]{D};
\draw[-latex]($(0,0)!0.8!(XX0)$)--($(X1)!0.8!(XX1)$);
\draw[-latex]($(X1)!0.8!(XX1)$)--
            node[align=center,below,font=\footnotesize
            \usefont{T1}{phv}{m}{n}]{Consumption of tech. more than\\
              doubles - total costs are higher}($(X2)!0.8!(XX2)$);
%
\scoped[on background layer]
\fill[fill=GreenL!60](X1)rectangle(T2);
\scoped[on background layer]
\fill[fill=BrownL!60](Y1)rectangle(T1);
\node[align=center,font=\footnotesize\usefont{T1}{phv}{m}{n}]
at($(Y1)!0.5!(T1)$){Savings  \\ from\\ reduced\\ AI costs};
\node[align=center,font=\footnotesize\usefont{T1}{phv}{m}{n}]
at($(X1)!0.5!(T2)$){Savings are offset\\ by increased AI usage};
\end{tikzpicture}}
```
:::

The paradox has profound implications for sustainable AI strategy. Test your understanding with this quick check.

::: {.callout-checkpoint}
## The Efficiency Trap (Jevons Paradox)
Your team optimizes a translation service, reducing the computational cost per query by 50% (2x efficiency gain).
1. If demand is inelastic (price change does not affect usage), how does total energy consumption change?
2. If demand is highly elastic, such that the 50% cost reduction leads to a 300% increase in query volume (new use cases become viable), calculate the net change in total energy consumption.
3. Define how this "rebound effect" challenges the assumption that "efficient models are automatically green models."
:::

Jevons Paradox does not invalidate efficiency as a strategy; it simply means that efficiency must be paired with governance and capacity planning. At the level of individual systems, efficiency remains the single most impactful lever engineers can pull.

::: {.callout-note title="Efficiency as Sustainability"}

Every model optimization and efficiency technique is not just a performance optimization but also a primary tool for sustainability. Consider how these techniques directly reduce environmental impact: pruning reduces both computational complexity and energy consumption by eliminating unnecessary model parameters, quantization decreases memory requirements and accelerates inference while dramatically cutting power consumption, and knowledge distillation enables smaller, more efficient models to achieve competitive performance with significantly lower resource demands.

These optimization techniques represent a direct bridge between performance engineering and environmental responsibility. When we optimize a model to run faster or use less memory, we simultaneously reduce its carbon footprint. When we design efficient architectures or implement hardware-software co-design, we create systems that are both high-performing and environmentally sustainable.

This connection reveals a powerful insight: **sustainable AI is not separate from efficient AI; it is efficient AI**. The same engineering principles that enable systems to scale, perform better, and cost less to operate also make them more environmentally responsible. Understanding this relationship transforms sustainability from an additional constraint into an integral part of good systems engineering.
:::

### Lifecycle-Aware Development Methodologies {#sec-sustainable-ai-lifecycleaware-development-methodologies-bf40}

Implementing sustainable AI requires systematic integration of environmental considerations across the entire development lifecycle. This framework spans algorithmic design choices, infrastructure optimization, operational practices, and governance mechanisms that collectively reduce environmental impact while maintaining technical capabilities.

#### Energy-Efficient Algorithmic Design {#sec-sustainable-ai-energyefficient-algorithmic-design-e71c}

Many deep learning models rely on billions of parameters, requiring trillions of FLOPS during training and inference.[^fn-flops-vs-flops] While these large models achieve state-of-the-art performance, research indicates that much of their computational complexity is unnecessary. Many parameters contribute little to final predictions, leading to wasteful resource utilization. Sustainable AI development treats energy efficiency as a design constraint rather than an optimization afterthought, requiring hardware-software co-design approaches that simultaneously optimize algorithmic choices and their hardware implementation for maximum efficiency per unit of computational capability.

```{python}
#| label: energy-efficiency-range-calc
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ ENERGY EFFICIENCY RANGE CALCULATION
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @sec-sustainable-ai-energyefficient-algorithmic-design-e71c
# │
# │ Goal: Compute 1000x efficiency range from CPU (~100 pJ/FLOP) to ASIC
# │       (~0.1 pJ/FLOP) to quantify the sustainability opportunity.
# │ Show: "1000" efficiency range — inline in footnote and prose.
# │ How: Scalar ratio of CPU vs ASIC pJ/FLOP energy costs.
# │
# │ Imports: (none — pure scalars)
# │ Exports: cpu_pj_per_flop, gpu_pj_per_flop, tpu_pj_per_flop,
# │          asic_pj_per_flop, efficiency_range_str
# └─────────────────────────────────────────────────────────────────────────────

# ┌── P.I.C.O. ISOLATED SCENARIO ───────────────────────────────────────────────
class EnergyEfficiencyRange:
    """Namespace for hardware energy efficiency range across CPU to ASIC."""

    # ┌── 1. PARAMETERS (Inputs) ──────────────────────────────────────────────
    cpu_pj_per_flop = 100
    gpu_pj_per_flop = 10
    tpu_pj_per_flop = 1
    asic_pj_per_flop = 0.1

    # ┌── 2. CALCULATION (The Physics) ────────────────────────────────────────
    efficiency_range = cpu_pj_per_flop / asic_pj_per_flop

    # ┌── 3. INVARIANTS (Guardrails) ──────────────────────────────────────────
    # No check() calls needed — values are definitional constants.

    # ┌── 4. OUTPUTS (Formatting) ─────────────────────────────────────────────
    efficiency_range_str = f"{efficiency_range:.0f}"

# ┌── EXPORTS (Bridge to Text) ─────────────────────────────────────────────────
cpu_pj_per_flop = EnergyEfficiencyRange.cpu_pj_per_flop
gpu_pj_per_flop = EnergyEfficiencyRange.gpu_pj_per_flop
tpu_pj_per_flop = EnergyEfficiencyRange.tpu_pj_per_flop
asic_pj_per_flop = EnergyEfficiencyRange.asic_pj_per_flop
efficiency_range_str = EnergyEfficiencyRange.efficiency_range_str
```

[^fn-flops-vs-flops]: **FLOPS vs FLOPs**: FLOPS (all caps) = Floating-Point Operations Per Second (rate), while FLOPs (mixed case) = total Floating-Point Operations (count). GPT-3 training required $3.1 \times 10^{23}$ FLOPs total, executed on hardware capable of $1.25 \times 10^{17}$ FLOPS. Energy efficiency varies dramatically across hardware: CPUs consume ~`{python} cpu_pj_per_flop` pJ/FLOP, GPUs achieve ~`{python} gpu_pj_per_flop` pJ/FLOP, TPUs reach ~`{python} tpu_pj_per_flop` pJ/FLOP, while specialized AI accelerators approach `{python} asic_pj_per_flop` pJ/FLOP—a `{python} efficiency_range_str`$\times$ efficiency range that defines sustainability opportunities.

Model pruning provides a widely used method for improving energy efficiency by removing unnecessary connections from trained models.[^fn-pruning-technique] By systematically eliminating redundant weights, pruning reduces both the model size and the number of computations required during inference. Studies show that structured pruning can remove up to 90 percent of weights in models such as ResNet-50 while maintaining comparable accuracy. This approach allows AI models to operate efficiently on lower-power hardware, making them more suitable for deployment in resource-constrained environments.

[^fn-pruning-technique]: Pruning fundamentals are covered in model optimization references. For sustainability, the key insight is that structured pruning at 90% sparsity can reduce inference energy by 2-10$\times$ with minimal accuracy impact. LLMs like SparseGPT achieve 60% sparsity with <1% accuracy loss, reducing inference memory and compute proportionally.

Another technique for reducing energy consumption is quantization, which lowers the numerical precision of computations in AI models.[^fn-quantization-technique] Standard deep learning models typically use 32-bit floating-point precision, but many operations can be performed with 8-bit or even 4-bit integers without significant accuracy loss. The energy efficiency gains from quantization are substantial. 8-bit integer operations consume approximately 16$\times$ less energy than 32-bit floating-point operations, while 4-bit operations achieve 64$\times$ energy reductions. This hardware-software co-design optimization requires careful coordination between algorithm precision requirements and hardware capabilities. By using lower precision, quantization reduces memory requirements, speeds up inference, and lowers power consumption. NVIDIA's TensorRT framework applies post-training quantization to deep learning models, achieving a threefold increase in inference speed while maintaining nearly identical accuracy. Similarly, Intel's Q8BERT demonstrates that quantizing the BERT language model to 8-bit integers can reduce its size by a factor of four with minimal performance degradation [@zafrir2019q8bert].

[^fn-quantization-technique]: **Quantization Technique**: Reducing numerical precision (FP32→INT8/INT4) to improve efficiency, with calibration preserving accuracy. Post-training quantization requires calibration datasets; quantization-aware training achieves <0.5% accuracy loss at INT8. GPTQ enables 4-bit LLM quantization with 2% perplexity increase, reducing LLaMA-65B memory from 130GB to 32GB for consumer GPU deployment.

A third approach, knowledge distillation [@hinton2015distilling], allows large AI models to transfer their learned knowledge to smaller, more efficient models.[^fn-knowledge-distillation] In this process, a large teacher model trains a smaller student model to approximate its predictions, enabling the student model to achieve competitive performance with significantly fewer parameters. DistilBERT exemplifies this technique, retaining 97 percent of the original BERT model's accuracy while using only 40 percent of its parameters and being 60 percent faster [@sanh2019distilbert]. Knowledge distillation techniques allow AI practitioners to deploy lightweight models that require less computational power while delivering high-quality predictions.

[^fn-knowledge-distillation]: **Knowledge Distillation**: Compression technique introduced by Geoffrey Hinton in 2015 where a smaller "student" model learns to mimic the outputs of a larger "teacher" model. The student trains on "soft targets" (probability distributions) rather than hard labels, capturing richer information about class relationships. Energy savings come from deploying the compact student model: DistilBERT reduces BERT's parameters by 40% while retaining 97% accuracy, achieving 60% faster inference. For sustainability, distillation offers a compelling trade-off where the one-time cost of training both teacher and student is offset by substantial inference savings across millions of deployment queries.

These optimization techniques represent strategies for sustainable AI development. Comprehensive coverage of these methods requires understanding detailed implementation approaches and performance trade-offs in model optimization techniques and their integration into efficient AI system design.

While model compression, efficient architectures, and carbon-aware scheduling provide the technical mechanisms for efficiency, deploying them haphazardly yields diminishing returns. To achieve maximum impact, engineering teams must synthesize these isolated techniques into a coherent, prioritized strategy that attacks the largest sources of emissions first.

::: {.callout-checkpoint}
## Prioritizing Decarbonization Strategy
You are deploying a 70B LLM for a latency-sensitive application. Rank the following techniques by their potential to reduce total energy consumption, justifying your order using the principle that "memory movement costs more than arithmetic":
1. **INT4 Quantization** (reduces memory footprint and bandwidth by 4x).
2. **Unstructured Pruning** (zeros out weights, requires specialized hardware support).
3. **Carbon-Aware Scheduling** (shifts workload to times of high renewable energy availability).
4. **Knowledge Distillation** (trains a smaller student model to mimic the teacher).
:::

#### TinyML Optimization Stack

TinyML deployments face unique constraints beyond datacenter optimization: models must fit in kilobytes of SRAM, execute with microsecond latency, and consume milliwatts of power. Standard optimization techniques like INT8 quantization (4$\times$ memory reduction, 8-16$\times$ energy savings) and structured pruning (2-10$\times$ improvements at 90% sparsity) provide the foundation for microcontroller deployment. However, achieving sustainable operation on energy-harvesting devices requires pushing optimization to extremes. This section examines techniques that enable truly autonomous TinyML systems operating on harvested energy budgets of 10-100 microwatts, as summarized in @tbl-tinyml-optimization.

| **Technique**              | **Typical Accuracy** **Impact** | **Memory Reduction** |         **Energy Reduction** |
|:---------------------------|:--------------------------------|:---------------------|-----------------------------:|
| **Binary Neural Networks** | 5-15%                           | 32x                  |                      50-100x |
| **Neural Architecture**    | varies                          | task-dependent       | 2-5$\times$ versus baseline |
| **Search for MCUs**        |                                 |                      |                              |

: **Extreme TinyML Optimization Techniques**: For energy-harvesting devices operating on microwatt budgets, these techniques push beyond conventional INT8/pruning approaches, trading significant accuracy for the dramatic efficiency gains required for truly autonomous operation. {#tbl-tinyml-optimization}

*Memory-Aware Optimization:* Microcontrollers operate with 64 KB to 2 MB SRAM, requiring careful memory planning during model design:

- **Layer-wise memory analysis**: Peak activation memory must fit in SRAM, not just model weights
- **In-place operations**: Reuse activation buffers to minimize memory footprint
- **Tensor arena optimization**: Single contiguous memory allocation eliminates fragmentation overhead
- **Operator fusion**: Combine sequential operations to reduce intermediate storage requirements

*Binary Neural Networks for Energy Harvesting:* For devices powered by ambient energy harvesting (solar, vibration, RF), even INT8 inference may exceed available power budgets. Binary neural networks (BNNs) push quantization to its extreme, representing weights and activations as single bits. This directly enables the ultra-low-power operation required for the **TinyML** paradigms established in @sec-edge-intelligence.

- **XNOR-Net operations**: Replace multiply-accumulate with bit operations, achieving 50-100$\times$ energy reduction over full-precision inference
- **Sub-milliwatt inference**: Enable always-on sensing on harvested energy budgets of 10-100 microwatts
- **Accuracy trade-offs**: BNNs sacrifice 5-15% accuracy compared to full-precision models, acceptable for many classification tasks where sustainability outweighs precision requirements

*Neural Architecture Search for TinyML:* Automated architecture design finds efficient network structures for specific constraints:

- **MCUNet**: Jointly searches network architecture and inference scheduling for memory-limited MCUs, achieving ImageNet-scale accuracy on 256 KB SRAM devices
- **Once-for-All Networks**: Train a supernet once, then extract specialized subnets for different target devices without retraining
- **ProxylessNAS**: Hardware-aware architecture search that directly optimizes for latency and energy on target devices

These TinyML-specific techniques enable sustainable AI deployment at unprecedented scale: billions of always-on sensor nodes achieving useful intelligence on harvested energy, eliminating the infrastructure, network, and power demands of cloud-dependent alternatives.

While these optimization techniques improve efficiency, they also introduce trade-offs. Pruning and quantization can lead to small reductions in model accuracy, requiring fine-tuning to balance performance and sustainability. Knowledge distillation demands additional training cycles, meaning that energy savings are realized during deployment rather than in the training phase. The Jevons Paradox principle established earlier demonstrates how, efficiency gains must be carefully managed to prevent proliferation effects that increase overall consumption. Strategies that combine efficiency with conscious limitations on resource usage are necessary to ensure these techniques genuinely reduce environmental footprint.

#### Lifecycle-Aware Systems {#sec-sustainable-ai-lifecycleaware-systems-5f26}

Many AI deployments operate with a short-term mindset, where models are trained, deployed, and discarded within months. Reducing this waste requires limiting full model retraining through incremental learning and transfer learning---fine-tuning pre-trained models on new datasets reduces computational cost by orders of magnitude compared to training from scratch [@Raffel2020exploring]. Edge deployment further enhances sustainability by running inference on specialized low-power hardware at the point of use, eliminating the energy costs of constant cloud communication [@Xu2021edge].

Embedding LCA methodologies into AI workflows allows developers to identify sustainability bottlenecks early. Organizations such as MLCommons are developing sustainability benchmarks measuring energy efficiency per inference and carbon emissions per training cycle [@Henderson2020towards]. However, as Jevons Paradox warns, optimizing individual stages may not reduce overall impact if efficiency gains enable expanded usage.

#### Sustainability Benchmarks and Metrics {#sec-sustainable-ai-policy-incentives-3370}

Standardized benchmarks provide the objective data needed to compare and improve AI system efficiency. The ML.ENERGY Leaderboard [@mlenergy2023leaderboard] ranks models by energy efficiency and carbon footprint, encouraging researchers to optimize for sustainability alongside accuracy.

#### MLPerf Sustainability Benchmarks

MLCommons provides industry-standard benchmarks that enable fair comparison of AI system efficiency across platforms. The MLPerf benchmark suite includes power measurement protocols for both datacenter and edge deployments:

*MLPerf Inference Power Metrics:*

- **Samples per Joule**: Primary energy efficiency measure for batch inference workloads
- **Queries per Joule**: Efficiency metric for latency-sensitive server scenarios
- **Joules per Token**: Emerging metric for generative AI workloads where output length varies

These standardized metrics enable organizations to compare efficiency across hardware platforms and model implementations, driving competition toward more sustainable AI systems.

#### MLPerf Tiny for TinyML Systems

For sub-watt TinyML deployments, MLPerf Tiny provides benchmarks specifically designed for microcontroller-class devices:

Examine @tbl-mlperf-tiny to understand the benchmark tasks and their typical energy requirements spanning from sub-millijoule to multi-millijoule ranges. The MLPerf Tiny measurement methodology requires external power monitors (like those in @sec-sustainable-ai-edge-mobile-device-energy-measurement-3012) and specifies warm-up periods, measurement windows, and statistical reporting requirements to ensure reproducible results across submissions.

| **Benchmark**            | **Task**                                |   **Reference** **Model** | **Typical Energy** **(mJ/inference)** |
|:-------------------------|:----------------------------------------|--------------------------:|--------------------------------------:|
| **Visual Wake Words**    | Image Classification (person detection) | MobileNetV1 0.25 (250 KB) |                            0.1-1.0 mJ |
| **Keyword Spotting**     | Audio Classification (12 keywords)      |            DS-CNN (19 KB) |                           0.05-0.5 mJ |
| **Anomaly Detection**    | Time Series (machine health)            |   Deep Autoencoder (5 KB) |                           0.01-0.1 mJ |
| **Image Classification** | Visual Recognition (CIFAR-10)           |          ResNet-8 (70 KB) |                            0.5-5.0 mJ |

: **MLPerf Tiny Benchmark Suite**: Standardized benchmarks for TinyML systems measure accuracy, latency, and energy consumption on microcontroller-class hardware. Reference model sizes indicate minimum viable deployments; optimized implementations often achieve 2-10$\times$ better energy efficiency. {#tbl-mlperf-tiny}

#### Energy Delay Product

Beyond simple energy metrics, the Energy Delay Product (EDP) balances energy consumption against latency. @eq-energy-delay-product formalizes this as the product of energy and time, penalizing solutions that achieve low power through excessive delays:

$$EDP = E \times T = P \times T^2$$ {#eq-energy-delay-product}

where $E$ is energy consumed, $T$ is latency, and $P$ is average power. The quadratic latency term penalizes solutions that achieve low energy through excessive delays. Lower EDP indicates better efficiency, enabling comparison of systems with different energy-latency trade-offs.

For TinyML deployments, EDP helps identify optimal operating points. A microcontroller running at reduced clock frequency consumes less power but takes longer to complete inference. The EDP-minimizing configuration often operates at moderate frequencies where voltage can be reduced (exploiting the quadratic voltage term in CMOS power) without excessive latency penalties.

These sustainability metrics complement traditional performance benchmarks, creating comprehensive evaluation frameworks that account for both capability and environmental impact. As regulatory frameworks like the EU's Sustainable Digital Markets Act mandate transparent AI energy reporting [@EuropeanCommission2023sustainability], these metrics will transition from voluntary best practices to compliance requirements.

### Infrastructure Optimization {#sec-sustainable-ai-infrastructure-optimization-1d41}

Beyond algorithmic optimizations, infrastructure-level innovations provide complementary pathways to sustainable AI deployment. This section explores three key approaches: renewable energy integration in data centers, carbon-aware workload scheduling, and AI-driven cooling optimization. These infrastructure strategies address the operational environment where computational efficiency gains are realized.

#### Green Data Centers {#sec-sustainable-ai-green-data-centers-2580}

::: {.column-margin}
_DALL·E 3 Prompt: Futuristic green data center nestled in a Nordic landscape, powered by wind turbines and hydro dams. The building features transparent walls revealing glowing server racks, harmoniously integrated with the surrounding lush nature, symbolizing the union of technology and ecology._
:::

A single hyperscale datacenter can consume over 100 MW of power---comparable to a small city[^fn-pue-efficiency]. Reducing this footprint requires three complementary strategies: renewable energy integration, advanced cooling, and AI-driven optimization.

[^fn-pue-efficiency]: **Power Usage Effectiveness**: Datacenter efficiency is measured by PUE---total facility power divided by IT equipment power. Industry average PUE is 1.67, but leading hyperscalers achieve 1.1-1.2. Google's best datacenters reach PUE of 1.08. Each 0.1 PUE improvement saves millions annually in electricity costs.

Major cloud providers have committed to powering their datacenters with renewable energy, but intermittency remains a challenge. AI infrastructure must incorporate energy storage solutions and intelligent scheduling that shifts workloads to times of peak renewable availability. Google has set a goal to operate on **24/7 carbon-free energy** by 2030[^fn-google-carbon-free], matching every unit of electricity consumed with renewable generation in real time rather than relying on annual carbon offsets.

[^fn-google-carbon-free]: **Google's Carbon-Free Commitment**: Currently at 64% carbon-free energy globally. Denmark datacenters run on 100% wind power. Achieving 24/7 CFE requires $15 billion+ investment in clean energy projects worldwide.

Cooling systems account for 30-40% of total datacenter electricity consumption[^fn-cooling-energy]. Liquid cooling, which transfers heat directly from accelerators using specially designed coolants, is significantly more effective than traditional air cooling and is now being deployed in high-density AI clusters. DeepMind's ML-based cooling optimization achieved a 40% reduction in cooling energy by dynamically adjusting parameters based on real-time sensor data---demonstrating AI improving the sustainability of its own infrastructure.

[^fn-cooling-energy]: **Datacenter Cooling Costs**: Cooling consumes 38% of total datacenter energy on average. Liquid cooling can be 3,000$\times$ more efficient than air cooling for high-density AI workloads, reducing cooling energy from 40% to under 10% of total consumption.

#### Carbon-Aware Scheduling {#sec-sustainable-ai-carbonaware-scheduling-c2db}

Grid carbon intensity fluctuates dramatically based on the mix of power sources available at any given time---from 50 g CO₂/kWh in nuclear-heavy France to 820 g/kWh in coal-dependent Poland. **Carbon-aware scheduling** dynamically shifts AI computations to times and locations where low-carbon energy is available, representing the highest-leverage sustainability intervention available to most organizations.

This is fundamentally a **load shifting software problem**. The scheduler queries real-time grid carbon intensity APIs (e.g., ElectricityMap, WattTime) and dynamically:

1.  **Pauses** non-urgent training jobs during carbon-intensive periods (e.g., evening peak).
2.  **Migrates** workloads to geographic regions with excess renewable energy (e.g., solar peak in California vs wind peak in Iowa).

Google's carbon-intelligent computing platform[^fn-google-carbon-scheduling] demonstrated this approach at scale, achieving a 40% reduction in carbon footprint by shifting workloads between datacenters globally.

::: {.callout-note title="Carbon-Aware Scheduling Framework" collapse="true"}
```mermaid
graph TD
    A[Start: AI Job Submission] --> B{Is Job Urgent?}
    B -- Yes --> C[Execute Immediately]
    B -- No --> D[Check Grid Carbon Intensity]
    D --> E{Carbon Intensity < Threshold?}
    E -- Yes --> C
    E -- No --> F[Delay Job / Shift Region]
    F --> D
    C --> G[Monitor Renewable Availability]
    G --> H[Job Complete]

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#9f9,stroke:#333,stroke-width:2px
    style F fill:#ff9,stroke:#333,stroke-width:2px
```
**Carbon-Aware Workload Scheduling**. Conceptual diagram showing the decision logic for temporal and geographic shifting. The scheduler evaluates urgency and grid carbon intensity to decide whether to execute immediately, delay until renewable energy is abundant (temporal shifting), or route the job to a cleaner region (geographic shifting).
:::

[^fn-google-carbon-scheduling]: **Google Carbon-Aware Scheduling Results**: Achieved 15% reduction in hourly carbon footprint by shifting workloads within regions, 40% reduction globally. Non-urgent batch training can shift 70% of workload to lower-carbon time periods.

The effectiveness of carbon-aware scheduling depends on accurate real-time grid emissions data. The Electricity Maps API provides real-time CO₂ emissions data for power grids worldwide[^fn-grid-carbon-data], while WattTime provides marginal emissions data showing which power plants turn on/off next. @fig-carbon-aware-scheduling demonstrates the scheduling opportunity: shifting training jobs to low-carbon hours in hydro-powered regions reduces emissions by up to 8x without changing a single line of model code.

[^fn-grid-carbon-data]: **Real-Time Grid Carbon Intensity**: In Texas, intensity fluctuates 10$\times$ daily (150-1,500 g/kWh) based on wind generation. WattTime's marginal emissions data allows 2-5$\times$ better carbon optimization than average intensity.

::: {#fig-carbon-aware-scheduling fig-env="figure" fig-pos="htb" fig-cap="Carbon-Aware Scheduling Opportunity. Grid carbon intensity varies by region and time of day. Training during off-peak hours in hydro-powered regions (US-West) produces up to 8x less carbon than peak hours in coal-heavy regions (US-East). This geographic and temporal flexibility is the highest-leverage sustainability intervention available." fig-alt="Two curves of grid carbon intensity over 24 hours: US-East (coal-heavy, peak) high; US-West (hydro, off-peak) low. Shaded low-carbon window 6-10am; peak carbon 6-10pm."}
```{python}
#| echo: false
# ┌─────────────────────────────────────────────────────────────────────────────
# │ CARBON-AWARE SCHEDULING (FIGURE)
# ├─────────────────────────────────────────────────────────────────────────────
# │ Context: @fig-carbon-aware-scheduling — grid carbon intensity by region/time
# │
# │ Goal: Plot US-East (coal, peak) vs US-West (hydro, off-peak) carbon
# │       intensity over 24h; show 8× difference; low-carbon window.
# │ Show: fill_between; two curves; shaded regions.
# │ How: Sinusoidal + noise; matplotlib.
# │
# │ Imports: matplotlib.pyplot (plt), numpy (np)
# │ Exports: (figure only, no prose variables)
# └─────────────────────────────────────────────────────────────────────────────
import matplotlib.pyplot as plt
import numpy as np

np.random.seed(42)
plt.style.use('seaborn-v0_8-whitegrid')
fig, ax = plt.subplots(figsize=(9, 5))

hours = np.arange(24)
us_east_peak = 800 + 200 * np.sin(2 * np.pi * (hours - 18) / 24) + 50 * np.random.randn(24)
us_east_peak = np.clip(us_east_peak, 400, 1000)
us_west_offpeak = 80 + 40 * np.sin(2 * np.pi * (hours - 12) / 24) + 20 * np.random.randn(24)
us_west_offpeak = np.clip(us_west_offpeak, 30, 150)

ax.fill_between(hours, 0, us_east_peak, alpha=0.4, color='#CB202D')
ax.plot(hours, us_east_peak, color='#CB202D', linewidth=2, label='US-East (coal-heavy, peak)')

ax.fill_between(hours, 0, us_west_offpeak, alpha=0.4, color='#008F45')
ax.plot(hours, us_west_offpeak, color='#008F45', linewidth=2, label='US-West (hydro, off-peak)')

ax.axvspan(6, 10, alpha=0.1, color='#008F45')
ax.axvspan(18, 22, alpha=0.1, color='#CB202D')
ax.text(8, 50, 'Low-carbon\nwindow', fontsize=9, ha='center', color='#008F45')
ax.text(20, 900, 'Peak carbon', fontsize=9, ha='center', color='#CB202D')

ax.set_xlabel('Hour of Day', fontsize=11, fontweight='bold')
ax.set_ylabel('Grid Carbon Intensity (g CO₂/kWh)', fontsize=11, fontweight='bold')
ax.set_xlim(0, 23)
ax.set_ylim(0, 1050)
ax.legend(loc='upper right', fontsize=9)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```
:::

Renewable energy variability presents a key challenge for carbon-aware scheduling. @fig-europe_energy_grid captures European grid dynamics: solar energy peaks at midday, wind shows distinct peaks in mornings and evenings, and fossil generation fills the gaps. This temporal pattern determines when AI workloads can run on clean energy.

![**European Energy Mix**: Renewable energy sources exhibit significant temporal variability, necessitating fossil fuel supplementation to meet consistent demand. Understanding this fluctuation is important for effectively scheduling AI workloads to periods of high renewable energy availability. Source: Uenergy charts.](images/png/europe_energy_grid.png){#fig-europe_energy_grid fig-alt="Stacked area chart of European energy production showing temporal variability. Solar peaks at midday, wind varies throughout day. Nuclear provides constant baseload. Fossil fuels supplement when renewables fall short."}

Energy-aware AI frameworks complement scheduling by optimizing the workloads themselves. Zeus [@jie2023zeus] achieves 75% energy savings on BERT training by automatically finding optimal energy-performance trade-offs, while Perseus [@jaewon2023perseus] reduces GPU memory usage by 50% through dynamic batching. These tools, alongside CodeCarbon for emissions tracking, democratize energy optimization beyond hyperscale companies.

#### AI-Driven Thermal Optimization {#sec-sustainable-ai-aidriven-thermal-optimization-68ef}

AI-driven cooling optimization represents an immediate, software-deployable opportunity for reducing datacenter energy consumption. Traditional cooling systems rely on fixed control policies with predefined temperature thresholds, often consuming more energy than necessary. DeepMind's deep reinforcement learning system continuously analyzes real-time sensor data---temperature, humidity, cooling pump speeds, and fan activity---to identify the most energy-efficient configuration for each workload. In production at Google's datacenters, this system achieved a 40% reduction in cooling energy usage and a 15% reduction in total datacenter power consumption.

Complementing software optimization, advances in **liquid cooling** and **immersion cooling** are transforming datacenter thermal management. Liquid cooling transfers heat directly from accelerator chips using specially designed coolants, achieving 3,000$\times$ better heat transfer than air. Immersion cooling submerges entire server racks in non-conductive liquid coolants, eliminating traditional air-based systems entirely. These approaches enable higher compute densities with lower power consumption---critical as AI accelerators push thermal design power above 700W per chip.

### Case Study: Google's Framework {#sec-sustainable-ai-case-study-googles-framework-e4c2}

To mitigate emissions from rapidly expanding AI workloads, Google engineers identified four key optimization areas, identified as the "4 Ms," where systematic improvements collectively reduce the carbon footprint of machine learning [@patterson2022carbon]:

* **Model**: The selection of efficient AI architectures reduces computation requirements by 5-10$\times$ without compromising model quality. Google has extensively researched sparse models and neural architecture search methodologies, resulting in efficient architectures such as the Evolved Transformer and Primer.

* **Machine**: The implementation of AI-specific hardware offers 2-5$\times$ improvements in performance per watt compared to general-purpose systems. Google's TPUs demonstrate 5-13$\times$ greater carbon efficiency relative to non-optimized GPUs.

* **Mechanization**: The utilization of optimized cloud computing infrastructure with high utilization rates yields 1.4-2$\times$ energy reductions compared to conventional on-premise data centers. Google's facilities consistently exceed industry standards for PUE.

* **Map**: The strategic positioning of data centers in regions with low-carbon electricity supplies reduces gross emissions by 5-10$\times$. Google maintains real-time monitoring of renewable energy usage across its global infrastructure.

The combined effect of these practices produces multiplicative efficiency gains. For instance, implementing the optimized Transformer model on TPUs in strategically located data centers reduced energy consumption by a factor of 83 and CO₂ emissions by a factor of 747.

Despite substantial growth in AI deployment across Google's product ecosystem, systematic efficiency improvements have effectively constrained energy consumption growth. A significant indicator of this progress is the observation that AI workloads have maintained a consistent 10% to 15% proportion of Google's total energy consumption from 2019 through 2021. As AI functionality expanded across Google's services, corresponding increases in compute cycles were offset by advancements in algorithms, specialized hardware, infrastructure design, and geographical optimization.

Empirical case studies demonstrate how engineering principles focused on sustainable AI development allow simultaneous improvements in both performance and environmental impact. For example, comparative analysis between GPT-3 (considered state-of-the-art in mid-2020) and Google's GLaM model reveals improved accuracy metrics alongside reduced training computation requirements and lower-carbon energy sources—resulting in a 14-fold reduction in CO₂ emissions within an 18-month development cycle.

Google's multifaceted strategy---combining systematic measurement, carbon-aware development, transparency in reporting, and renewable energy transition---establishes a replicable framework for sustainable AI scaling. Their analysis also revealed that previous published estimates overestimated ML's energy requirements by 100 to 100,000$\times$ due to methodological limitations, underscoring the importance of empirical measurement over theoretical projections.

### Engineering Guidelines for Sustainable AI Development {#sec-sustainable-ai-engineering-guidelines-sustainable-ai-development-309d}

The strategies and frameworks presented in this section provide the foundation for sustainable AI development, but implementation requires concrete, actionable steps. This checklist consolidates the key practices that AI engineers and practitioners can implement immediately to reduce the environmental impact of their work:

1. **Measure First**: Use tools like CodeCarbon to track the emissions of your training runs. You cannot improve what you do not measure, and establishing baseline metrics is essential for validating the effectiveness of optimization efforts.

2. **Choose Your Region Wisely**: Train models in data centers powered by renewable energy. Check grid carbon intensity and schedule workloads in regions and times when clean energy is most abundant.

3. **Optimize Your Model**: Do not just train the largest model possible. Use pruning, quantization, and knowledge distillation to find the smallest model that meets your accuracy target. Remember that a 90% accurate model requiring 10% of the resources often provides better real-world value than a 95% accurate model requiring full resources.

4. **Do Not Retrain From Scratch**: Use transfer learning and fine-tuning instead of full retraining whenever possible. Standing on the shoulders of existing pre-trained models can reduce computational requirements by orders of magnitude.

5. **Think About Hardware**: Choose energy-efficient accelerators (such as TPUs or specialized inference chips) for deployment. Consider the full hardware lifecycle and select platforms optimized for your specific workload characteristics.

6. **Consider the Full Lifecycle**: Advocate for longer hardware refresh cycles and responsible e-waste policies in your organization. The environmental impact of manufacturing often exceeds operational energy consumption, making hardware longevity a critical sustainability factor.

The cumulative impact of individual technical choices depends on systemic adoption across the industry. Understanding the policy landscape helps engineers anticipate compliance requirements and advocate for governance frameworks that translate engineering possibilities into industry-wide practice.

Understanding that the cumulative impact of these technical choices requires systemic, industry-wide adoption highlights the limitations of purely engineering-driven solutions. Without external pressure, market forces often prioritize speed and scale over efficiency, necessitating the introduction of robust policy and regulatory frameworks to enforce sustainable practices globally.

## Policy, Regulation, and the Path Forward {#sec-sustainable-ai-policy-regulation-9668}

If a company can slash its cloud computing bill by relocating its training cluster to a region powered entirely by cheap, high-emission coal, the market alone will not prevent them from doing so. Engineering ingenuity can provide the tools for efficient computation, but it requires policy, regulation, and carbon pricing to ensure that utilizing those tools becomes a financial and legal imperative rather than just a corporate public relations talking point.

### Regulatory Mechanisms {#sec-sustainable-ai-regulatory-mechanisms-global-coordination-4180}

Effective AI sustainability governance operates through a combination of mandatory reporting, emission restrictions, and financial incentives, though global policy fragmentation presents a significant implementation challenge. The European Union has taken a leading role with mandatory approaches, notably the **AI Act**[^fn-ai-act] and the **Corporate Sustainability Reporting Directive (CSRD)**.[^fn-csrd] The AI Act introduces a risk-based framework that classifies certain general-purpose AI models as high-risk, requiring conformity assessments and detailed energy consumption reporting for both training and inference. The CSRD mandates that over 50,000 large companies disclose their environmental impacts, including Scope 1, 2, and 3 emissions from AI operations, according to standardized, audited reporting frameworks. This regulatory shift transforms energy monitoring from an optional optimization into a legal necessity.

[^fn-ai-act]: **EU AI Act**: World's first comprehensive AI regulation, enacted in 2024. Introduces risk-based approach classifying AI systems as minimal, limited, high, or unacceptable risk. High-risk AI systems (including foundation models >$10^{25}$ FLOPs) must undergo conformity assessments, provide transparency documentation, and report energy consumption. Fines range up to €35 million or 7% of global revenue.

[^fn-csrd]: **Corporate Sustainability Reporting Directive (CSRD)**: EU regulation requiring 50,000+ large companies to disclose environmental, social, and governance (ESG) impacts starting 2024. Mandates audited sustainability reporting covering Scope 1, 2, and 3 emissions, including AI-related energy consumption, using standardized European Sustainability Reporting Standards (ESRS).

Beyond measurement mandates, governments are exploring direct restriction mechanisms. These include setting limits on computational power available for training large AI models, mirroring **Emissions Trading Systems (ETS)**[^fn-emissions-trading] used in environmental policy. Such "cap-and-trade" systems for compute would force organizations to operate within predefined energy budgets or procure additional capacity, creating a market for computational carbon credits. The expansion of carbon pricing and **Carbon Border Adjustment Mechanisms (CBAM)** is converting the geographic location of compute into a direct financial variable---the carbon intensity of regional electricity grids can vary by over 40x, making carbon-aware scheduling a key compliance strategy.

[^fn-emissions-trading]: **Emissions Trading Systems (ETS)**: Market-based mechanisms where governments set total emission limits (cap) and distribute tradeable allowances. The EU ETS, launched in 2005, is the world's largest carbon market. A similar system for AI could cap total computational energy, creating a market to drive efficiency.

To balance these restrictions, government incentives play a proactive role. Financial support, tax benefits, and grants for Green AI research can make sustainability a competitive advantage. Spain has committed €300 million to AI projects focused on sustainability. Governments can also use their public procurement power, mandating that vendors meet sustainability benchmarks such as operating on carbon-neutral datacenters or using energy-efficient models. Broader corporate reporting frameworks---the Greenhouse Gas Protocol, TCFD, and ISSB---are increasingly scrutinizing Scope 3 emissions, encompassing the substantial embodied carbon of GPU procurement and datacenter construction alongside operational emissions of outsourced cloud compute.

### Industry Self-Regulation and Standards {#sec-sustainable-ai-selfregulation-02df}

Alongside government mandates, the AI industry is driving significant environmental improvements through self-regulation and common standards. The most visible commitment is the pledge by major cloud providers---Google, Microsoft, and Amazon---to power their datacenters with 100% renewable energy. Going further, the push for **24/7 Carbon-Free Energy (CFE)** aims to match every hour of energy consumption with real-time clean energy procurement, moving beyond annual averages and carbon offsets that can obscure actual emissions from fossil-fuel-reliant grids.

Internal carbon pricing is another powerful self-regulatory tool. By assigning a "shadow price" to carbon emissions, companies integrate environmental costs directly into financial decision-making for AI projects, naturally prioritizing investments in energy-efficient hardware and low-emission models. Voluntary checklists and open-source tools further promote accountability: the **AI Sustainability Coalition** and projects like **CodeCarbon** and **ML $\textrm{CO}_2$ Impact** provide frameworks that allow developers to estimate and track model carbon footprints directly within their workflows.

Standardized benchmarks provide the objective data needed to validate these efforts. **MLCommons**, through its MLPerf benchmark suite, has incorporated power measurement protocols for both datacenter and edge deployments. By establishing metrics like "samples per Joule" and "Joules per token," MLCommons enables fair, transparent comparison of AI system efficiency across different hardware and software platforms. These benchmarks, combined with independent sustainability audits from organizations like the Green Software Foundation, create a powerful mechanism for holding the industry accountable and driving competition toward genuinely greener AI.

### Public Engagement and Environmental Justice {#sec-sustainable-ai-public-engagement-9850}

Effective AI sustainability governance requires public support, which depends on transparency, clear communication, and equitable access. Currently, public understanding of AI's environmental impact is limited and often polarized between narratives of technological salvation and ecological disaster. Fostering informed discourse requires moving beyond **greenwashing**[^fn-greenwashing]---the practice of making misleading claims about environmental responsibility---toward genuine, verifiable transparency.

[^fn-greenwashing]: **Greenwashing**: Marketing practice where companies create a misleading impression of environmental responsibility through selective disclosure, vague claims, or symbolic actions. In AI, greenwashing manifests as claims of "carbon neutrality" through offsets while expanding datacenter capacity, highlighting efficient model architectures while ignoring total compute growth, or publishing sustainability reports that omit Scope 3 emissions. The EU's Green Claims Directive (2024) now requires companies to substantiate environmental claims with verifiable evidence.

The **Montréal Carbon Pledge** offers a model for such transparency. Originally for institutional investors, its core commitment---to measure and disclose carbon footprints annually---is directly applicable to the AI industry.

> "Measuring our carbon footprint is integral to understanding better, quantifying, and managing the carbon and climate change-related impacts, risks, and opportunities in our investments. Therefore, as a first step, we commit to measuring and disclosing the carbon footprint...annually." --- Montréal Carbon Pledge

Adopting a similar pledge would help build public trust by substantiating sustainability claims with data. Building public participation through citizen science, open data platforms, and inclusive governance forums ensures that AI development aligns with societal values and that its benefits are shared broadly.

The principles of **environmental justice** must be central to AI sustainability. The environmental burdens of AI---from resource extraction for hardware manufacturing to the siting of energy-intensive datacenters---are often borne by marginalized communities, while economic benefits concentrate elsewhere. The digital divide means that access to AI-driven sustainability tools is unevenly distributed, potentially widening global inequalities. Ensuring equitable access to AI technologies, investing in capacity-building in developing nations, and requiring social impact assessments for large-scale AI projects are critical steps to ensure that the transition to a sustainable AI ecosystem is also a just one.

### Future Research Directions {#sec-sustainable-ai-future-challenges-58e2}

While policy and public engagement shape the context for sustainable AI, its future ultimately depends on continued technical innovation. One of the most promising areas is the development of **non-von Neumann computing architectures**[^fn-von-neumann], such as **neuromorphic computing** and **in-memory computing**. By processing data where it is stored, these paradigms aim to eliminate the "von Neumann bottleneck"---the energy-intensive shuttling of data between memory and processing units that can account for 60-80% of a system's power consumption. Successful implementation could yield energy efficiency improvements of 100-1000$\times$ for certain AI workloads.

[^fn-von-neumann]: **Von Neumann Architecture**: Traditional computing model where processing unit and memory are separate, requiring constant data movement between CPU and RAM. Proposed by John von Neumann in 1945, dominates modern computers but creates the "von Neumann bottleneck"---energy-intensive data shuttling that consumes 60-80% of system power. Non-von Neumann approaches like neuromorphic chips, in-memory computing, and dataflow architectures eliminate this bottleneck by processing data where it's stored, potentially reducing AI energy consumption by 100-1000$\times$.

A critical implementation barrier is the "measurement gap": the lack of standardized, hardware-level tools for accurately measuring the environmental footprint of AI systems. Current methods often rely on coarse proxy metrics---GPU-hours multiplied by average grid intensity---which fail to capture the real-world dynamics required by emerging regulations. Developing and standardizing granular, real-time energy and carbon accounting tools is essential for both compliance and effective optimization.

Furthermore, an integrated, data-centric approach is needed to minimize redundant computation. Research shows that the predictive value of training data often decays, meaning models are frequently trained on vast datasets with diminishing returns [@wu2022sustainable]. Smarter data sampling, active learning, and data valuation techniques can optimize training processes to use only the most informative data, reducing computational waste without sacrificing accuracy. Ultimately, an integrated approach combining algorithmic efficiency, hardware innovation, renewable energy adoption, and transparent governance is necessary to ensure AI's trajectory aligns with global sustainability goals.

Minimizing redundant computation through smarter data curation directly aligns regulatory compliance with operational efficiency. As we wrap up our analysis of sustainable AI engineering, we must review the most dangerous assumptions and miscalculations that cause well-intentioned teams to inadvertently increase their environmental footprint.

## Fallacies and Pitfalls {#sec-sustainable-ai-fallacies-pitfalls-ee9a}

Sustainability involves counterintuitive physics where efficiency improvements can increase total consumption and geographic choices dominate all other optimizations. These fallacies and pitfalls capture errors that waste compute budgets and planetary resources through misallocated optimization effort.

**Fallacy:** ***Cloud computing automatically makes AI systems more environmentally sustainable.***

Engineers assume cloud providers operate efficiently and sustainably. In production, geographic region dominates all other factors through grid carbon intensity differences. Training a 7B model on 64 A100s for 14 days produces 4.4 metric tons CO₂ on the US average grid (367 g/kWh) but only 206 kg CO₂ in Quebec's hydroelectric grid (34.5 g/kWh lifecycle)—a 21-fold difference for identical workloads. Coal-powered grids emit 800-1000 g CO₂/kWh while well-managed hydroelectric sources emit 10-50 g CO₂/kWh. As demonstrated in @sec-sustainable-ai-carbon-footprint-calculation-c2fe, teams that deploy to default cloud regions without checking grid carbon intensity waste 20-50$\times$ more carbon budget than necessary, turning "cloud sustainability" into a geographic lottery rather than an inherent advantage.

**Pitfall:** ***Focusing only on operational energy consumption while ignoring embodied carbon and lifecycle impacts.***

Teams optimize training efficiency while ignoring manufacturing emissions. In low-carbon grids, embodied carbon dominates total footprint. As quantified in @sec-sustainable-ai-embodied-carbon-assessment-9de0, a single H100 GPU embodies 164 kg CO₂ from manufacturing (per NVIDIA's product carbon footprint); for the 14-day training run above, 64 H100s contribute 10.5 metric tons embodied carbon, representing 70% of total emissions on the US grid and over 98% on Quebec's clean grid where operational emissions are minimal. Extending hardware lifetime from 3 to 5 years reduces amortized embodied carbon by 40%—a larger gain than most algorithmic optimizations. Organizations focusing exclusively on operational efficiency miss this 40% improvement available through procurement and depreciation policy changes while optimizing marginal gains in PUE or compute efficiency.

**Fallacy:** ***Efficiency improvements automatically reduce total environmental impact.***

Engineers assume that halving inference cost cuts environmental impact in half. In production, Jevons Paradox establishes that efficiency improvements increase total consumption by enabling expanded usage. GPT-3's launch at $0.06 per 1,000 tokens enabled applications impossible at GPT-2's economics; reducing costs to $0.002 per 1,000 tokens (30$\times$ improvement) triggered a 100$\times$ increase in query volume, growing total emissions despite per-query efficiency gains. Quantization that reduces inference energy by 4$\times$ often leads to 10$\times$ deployment expansion as cost constraints relax. Organizations that optimize efficiency without usage governance consistently experience 3-5$\times$ consumption growth within six months of deployment, transforming sustainability wins into consumption explosions requiring carbon budgets and usage caps as discussed in @sec-sustainable-ai-carbonaware-scheduling-c2db.

**Pitfall:** ***Treating carbon offsets as a substitute for reducing actual emissions.***

Organizations purchase offsets to neutralize emissions without validating offset quality. In reality, analysis of voluntary carbon markets reveals that 60-90% of credits fail to deliver claimed reductions due to inflated baselines, non-permanent sequestration, or projects that would have occurred regardless. A company training models on coal grids (1000 g CO₂/kWh) and buying offsets spends 2-3$\times$ more than directly migrating to renewable regions (20-50 g CO₂/kWh) while achieving inferior environmental outcomes. Offset projects take 5-20 years to sequester carbon while compute emissions are immediate. Teams that prioritize offsets over actual reduction miss the 20-50$\times$ leverage available through geographic optimization shown in @sec-sustainable-ai-carbon-footprint-calculation-c2fe and delay renewable energy transitions that deliver permanent improvements.

**Pitfall:** ***Optimizing individual components without analyzing system-level lifecycle impacts.***

Teams reduce training cost to improve sustainability without analyzing deployment scale. In production, training-inference trade-offs often invert total emissions. A model pruned by 40% to save training energy but requiring 2$\times$ inference compute increases total lifecycle emissions if it serves more than 100 million queries—a crossover point reached in 3-6 months for production systems. Edge deployment that reduces datacenter energy by 60% but requires manufacturing 10,000 specialized devices adds 1,500-2,000 kg embodied carbon (10$\times$ the cloud training emissions). Extending GPU lifetime from 3 to 5 years reduces amortized embodied carbon by 40% but may sacrifice 15-25% operational efficiency; the lifecycle break-even depends on grid carbon intensity, with lifetime extension dominating on clean grids and efficiency winning on dirty grids. Effective sustainability requires holistic analysis across @sec-sustainable-ai-lifecycle-carbon-accounting-99a1 rather than local optimization.

A model aggressively pruned to save training energy, only to require massive computational overhead during inference to compensate for lost accuracy, perfectly illustrates the danger of localized optimization. Avoiding these systemic pitfalls allows us to view the ML lifecycle holistically, bringing us to a final synthesis of sustainable AI architecture.

## Summary {#sec-sustainable-ai-summary-8cec}

Sustainable AI represents the "physical limit" of the Machine Learning Fleet. Throughout Volume II, we have optimized the logic, constructed the hardware, launched global services, and hardened the perimeter. This chapter has confronted the final gating constraint: can our systems exist within the energy, water, and material boundaries of our planet?

We established that sustainability is not a "nice-to-have" but a core engineering requirement. We analyzed the lifecycle carbon footprint—from the 164 kg of CO₂ embodied in a single H100 GPU (per NVIDIA's product carbon footprint) to the thousands of megawatt-hours consumed during training. We explored the "Mobile Memory Wall" and the "Decode Energy Problem," identifying why the shift to specialized accelerators is a survival strategy for both the cloud and the edge. Finally, we addressed the "Rebound Effect," recognizing that efficiency alone cannot solve the crisis if it simply leads to exponential increases in usage.

::: {.callout-takeaways title="Efficiency Alone Is Not Enough"}

* **The Sustainability Paradox**: AI compute demands are growing 10$\times$ faster than hardware efficiency gains. Without algorithmic intervention (e.g., pruning, quantization), the Machine Learning Fleet will hit a "Power Wall" that constrains all future innovation.
* **The Inefficiency of Decode**: Autoregressive token generation is notoriously energy-wasteful. While "Prefill" is compute-bound and efficient, "Decode" is bandwidth-bound, leaving GPUs idling and drawing massive static power. Specialized, memory-optimized NPUs/TPUs are essential for sustainable serving.
* **Embodied Carbon is Real**: Up to 30% of a system's lifecycle emissions occur before it is ever powered on. The manufacturing of sub-5nm chips is water- and chemical-intensive, making hardware longevity and circular economy reuse critical MLOps concerns.
* **Jevons Paradox**: Improving the efficiency of AI tokens reduces their cost, which often triggers a massive increase in total demand. Sustainable AI requires a dual strategy: technical optimization combined with carbon-aware governance.
* **Carbon-Aware Scheduling**: Geographic placement is the highest-leverage sustainability choice. Moving a training job from a coal-powered grid to a hydro-powered one can reduce emissions by 20–50$\times$ without changing a single line of code.
:::

Sustainability is an engineering discipline, not a public relations exercise. Carbon budgets, power delivery constraints, and cooling capacity impose hard limits on fleet expansion that no amount of marketing language can circumvent. The Jevons Paradox makes this especially clear: efficiency gains that reduce per-query cost routinely trigger demand explosions that overwhelm the original savings, meaning that technical optimization without governance is self-defeating. Organizations that treat sustainability as a solved problem after adopting a few efficiency techniques are repeating the same mistake that drove industrial energy consumption upward for two centuries.

The practitioner who can quantify lifecycle carbon across training, inference, and embodied manufacturing emissions, and who can design carbon-aware scheduling policies that respect grid carbon intensity, is increasingly essential to production ML teams. These skills transform sustainability from an abstract corporate goal into a measurable engineering constraint with the same rigor applied to latency budgets or memory capacity. As regulatory frameworks mature and carbon pricing mechanisms expand, the ability to account for and minimize environmental impact will become as fundamental to ML systems engineering as fault tolerance or security.

::: {.callout-chapter-connection title="From Sustainability to Responsibility"}

We have quantified and constrained the environmental footprint of the ML fleet, ensuring that our systems remain viable as they scale. Security, robustness, and sustainability together form the engineering foundation of production AI. But a system that is technically sound can still cause social harm.

In @sec-responsible-engineering, we turn to the governance frameworks, fairness requirements, and ethical guardrails that ensure our fleet serves the values of the society that built it, completing the transition from *how to build* the machine to *whom it serves*.

:::
