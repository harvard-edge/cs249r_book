---
title: "ML Operations at Scale"
bibliography: ops_scale.bib
---

<!--
================================================================================
EDITORIAL GUIDELINES: MODEL-TYPE DIVERSITY FOR ML OPERATIONS AT SCALE
================================================================================

EXPERT FEEDBACK FROM SERVING CHAPTER REVIEW (January 2025):
The following production operations topics were identified by experts as important
but appropriately deferred from Vol I Serving chapter to this chapter:

FROM CHIP HUYEN:

- Feature store integration (online vs offline stores, point-in-time correctness)
- Shadow deployment patterns for model validation
- Progressive rollout strategies with automatic rollback triggers
- Model artifact registries and versioning schemes
- Observability beyond latency (prediction logging, distributed tracing, alerting)
- Error handling and fallback strategies (circuit breakers, fallback models)
- Cost optimization (autoscaling policies, spot instances, serverless tradeoffs)

FROM JEFF DEAN:

- Retry budgets to prevent load amplification
- Blue-green and canary deployment patterns
- Graceful shutdown and draining procedures
- Observability architecture (metrics, distributed tracing, anomaly detection)

FROM ION STOICA:

- Health checking infrastructure (liveness vs readiness probes)
- Graceful shutdown and connection draining
- Resource isolation vs sharing tradeoffs

================================================================================

CORE PRINCIPLE: MLOps practices vary by model type and deployment context.
Recommendation systems have different operational needs than LLMs.
Ensemble management differs from single-model operations.

MODEL-SPECIFIC OPERATIONS CONSIDERATIONS:

| Model Type      | Update Frequency    | Monitoring Focus    | Deployment Pattern  |
|-----------------|---------------------|---------------------|---------------------|
| LLMs            | Infrequent (months) | Quality, safety     | A/B, staged rollout |
| Recommendation  | Frequent (daily)    | Engagement metrics  | Shadow, interleaving|
| Vision          | Moderate (weeks)    | Accuracy, latency   | Canary deployment   |
| Real-time       | Continuous          | Drift detection     | Online learning     |

REQUIRED COVERAGE FOR THIS CHAPTER:

MULTI-MODEL MANAGEMENT:

- Single model: Simpler ops (vision, many NLP)
- Model ensemble: Complex dependencies (recommendation)
- Model cascade: Sequential models with fallbacks
- Include: Why RecSys ops is fundamentally about ensembles

CI/CD FOR ML:

- Training pipelines: Different for different model types
- Model validation: Metrics differ by application domain
- Deployment strategies: A/B vs interleaving vs shadow
- Include: Why recommendation systems use interleaving experiments

MONITORING:

- Model quality: Accuracy, latency, throughput
- Data quality: Drift, schema changes, freshness
- Business metrics: Engagement, conversion, retention
- Include: Different monitoring priorities for different model types

PLATFORM ENGINEERING:

- Self-service for data scientists
- Infrastructure abstraction by workload type
- Include: How platforms handle heterogeneous model types

CASE STUDIES TO INCLUDE:

- Meta ML platform (multi-model, recommendation-heavy)
- Uber Michelangelo (diverse ML workloads)
- Netflix ML infrastructure (recommendation + content analysis)
- Google Vertex AI (general-purpose platform)

ORGANIZATIONAL PATTERNS:

- Centralized ML platform teams
- Embedded ML engineers
- Include: How org structure varies by model portfolio

ANTI-PATTERNS TO AVOID:

- Assuming all MLOps is single-model operations
- Ignoring ensemble complexity in recommendation
- One-size-fits-all monitoring dashboards
- Treating all model updates as equivalent risk

================================================================================
-->

# ML Operations at Scale {#sec-ops-scale}

::: {layout-narrow}
::: {.column-margin}
_DALLÂ·E 3 Prompt: A comprehensive visualization of enterprise ML operations orchestrating hundreds of models across distributed infrastructure. The scene shows a unified platform architecture with multiple model pipelines flowing through shared infrastructure. Visual elements include a central control plane dashboard displaying health metrics for dozens of deployed models, CI/CD pipelines depicted as automated assembly lines moving models from development through staging to production, and infrastructure-as-code templates generating consistent environments. Teams of engineers interact with self-service interfaces while governance policies appear as guardrails along deployment paths. Monitoring systems display aggregate metrics, A/B test results, and model performance trends. The composition emphasizes scale with many models in simultaneous operation connected to shared data sources and compute resources. Color scheme uses professional blues and grays for infrastructure with accent colors distinguishing different model types and team ownership. Modern enterprise software visualization style suitable for an MLOps engineering textbook._
:::

\noindent
![](images/png/cover_ops_scale.png)

:::

## Purpose {.unnumbered}

_Why do the operational practices that suffice for individual ML projects fail catastrophically when organizations deploy hundreds of models across distributed infrastructure?_

Operating machine learning systems at organizational scale introduces challenges fundamentally different from managing individual models: teams must coordinate across dozens of models with interdependent data pipelines, version artifacts across complex experimental workflows, and maintain reliability for systems where gradual degradation affects millions of users. The practices that enable a single team to iterate on one model become unsustainable when multiplied across an enterprise, requiring platform abstractions that provide self-service capabilities while maintaining governance and consistency. Organizations discover that operational excellence at scale demands new organizational structures, communication patterns, and engineering cultures alongside improved tooling. Understanding how platform engineering, multi-model management, and infrastructure-as-code practices address these challenges enables engineers to build ML operations that scale with organizational growth rather than becoming bottlenecks that constrain what teams can accomplish.

## Coming 2026

This chapter will cover platform engineering, multi-model management, ML infrastructure as code, organizational patterns, and production debugging at scale.

```{=latex}
\part{key:vol2_responsible}
```
