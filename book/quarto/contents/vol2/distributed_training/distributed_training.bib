@article{brown2020language,
  title = {Language models are few-shot learners},
  author = {Brown, Tom and others},
  year = {2020},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {1877--1901},
}

@inproceedings{dean2012distbelief,
  title = {Large Scale Distributed Deep Networks.},
  author = {
    Dean, Jeffrey and Corrado, Greg and Monga, Rajat and 0010, Kai Chen and Devin, Matthieu and Le,
    Quoc V. and Mao, Mark Z. and Ranzato, Marc'Aurelio and Senior, Andrew W. and Tucker, Paul A.
    and Yang, Ke and Ng, Andrew Y.
  },
  year = {2012},
  journal = {NIPS},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {25},
  pages = {1232--1240},
  url = {https://proceedings.neurips.cc/paper/2012/hash/6aca97005c68f1206823815f66102863-Abstract.html},
  source = {DBLP},
}

@inproceedings{deepspeed_training_system_2021,
  title = {DeepSpeed},
  author = {Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = aug,
  journal = {
    Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data
    Mining
  },
  booktitle = {
    Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data
    Mining
  },
  publisher = {ACM},
  pages = {3505--3506},
  doi = {10.1145/3394486.3406703},
  url = {https://doi.org/10.1145/3394486.3406703},
  source = {Crossref},
  subtitle = {System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters},
}

@article{goyal2017accurate,
  title = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
  author = {
    Goyal, Priya and Doll\'ar, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski,
    Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming
  },
  year = {2017},
  month = jun,
  journal = {CoRR},
  booktitle = {arXiv preprint arXiv:1706.02677},
  volume = {abs/1706.02677},
  url = {http://arxiv.org/abs/1706.02677v2},
  primaryclass = {cs.CV},
  archiveprefix = {arXiv},
  source = {DBLP},
}

@inproceedings{gpipe2019,
  title = {GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism.},
  author = {
    Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen,
    Mia Xu and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V. and Wu, Yonghui and Chen, Zhifeng
  },
  year = {2019},
  journal = {NeurIPS},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {32},
  pages = {103--112},
  url = {https://proceedings.neurips.cc/paper/2019/hash/093f65e080a295f8076b1c5722a46aa2-Abstract.html},
  source = {DBLP},
}

@inproceedings{harlap2018pipedream,
  title = {PipeDream},
  author = {
    Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur,
    Nikhil R. and Ganger, Gregory R. and Gibbons, Phillip B. and Zaharia, Matei
  },
  year = {2019},
  month = oct,
  booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
  publisher = {ACM},
  pages = {1--15},
  doi = {10.1145/3341301.3359646},
  url = {https://doi.org/10.1145/3341301.3359646},
  source = {Crossref},
  subtitle = {generalized pipeline parallelism for DNN training},
}

@inproceedings{he2016resnet,
  title = {Deep Residual Learning for Image Recognition},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  month = jun,
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  pages = {770--778},
  doi = {10.1109/cvpr.2016.90},
  url = {https://doi.org/10.1109/cvpr.2016.90},
  source = {Crossref},
}

@inproceedings{jouppi2017tpu,
  title = {In-datacenter performance analysis of a Tensor Processing Unit},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and others},
  year = {2017},
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
  pages = {1--12},
}

@article{kingma2015adam,
  title = {Adam: A Method for Stochastic Optimization},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2014},
  month = dec,
  journal = {ICLR},
  booktitle = {International Conference on Learning Representations},
  url = {http://arxiv.org/abs/1412.6980v9},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  source = {DBLP},
}

@inproceedings{li2014parameter,
  title = {Scaling Distributed Machine Learning with the Parameter Server.},
  author = {
    0003, Mu Li and Andersen, David G. and Park, Jun Woo and Smola, Alexander J. and 0001, Amr
    Ahmed and Josifovski, Vanja and Long, James and Shekita, Eugene J. and Su, Bor-Yiing
  },
  year = {2014},
  journal = {OSDI},
  booktitle = {Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation},
  pages = {583--598},
  url = {https://www.usenix.org/conference/osdi14/technical-sessions/presentation/li\_mu},
  source = {DBLP},
}

@inproceedings{narayanan_pipeline_parallelism_2021,
  title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
  author = {
    Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary,
    Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer,
    Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei
  },
  year = {2021},
  month = nov,
  journal = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
  booktitle = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
  publisher = {ACM},
  pages = {1--15},
  doi = {10.1145/3458817.3476209},
  url = {https://doi.org/10.1145/3458817.3476209},
  source = {Crossref},
}

@article{patarasuk2009allreduce,
  title = {Bandwidth optimal all-reduce algorithms for clusters of workstations},
  author = {Patarasuk, Pitch and Yuan, Xin},
  year = {2009},
  month = feb,
  journal = {Journal of Parallel and Distributed Computing},
  publisher = {Elsevier BV},
  volume = {69},
  number = {2},
  pages = {117--124},
  doi = {10.1016/j.jpdc.2008.09.002},
  issn = {0743-7315},
  url = {https://doi.org/10.1016/j.jpdc.2008.09.002},
  source = {Crossref},
}

@inproceedings{rajbhandari2020zero,
  title = {ZeRO: Memory optimizations Toward Training Trillion Parameter Models},
  author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = nov,
  journal = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
  booktitle = {
    SC20: International Conference for High Performance Computing, Networking, Storage and Analysis
  },
  publisher = {IEEE},
  pages = {1--16},
  doi = {10.1109/sc41405.2020.00024},
  url = {https://doi.org/10.1109/sc41405.2020.00024},
  source = {Crossref},
}

@article{sergeev2018horovod,
  title = {Horovod: fast and easy distributed deep learning in TensorFlow},
  author = {Sergeev, Alexander and Balso, Mike Del},
  year = {2018},
  month = feb,
  journal = {CoRR},
  booktitle = {arXiv preprint arXiv:1802.05799},
  volume = {abs/1802.05799},
  url = {http://arxiv.org/abs/1802.05799v3},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
  source = {DBLP},
}

@article{shazeer_mixture_of_experts_2017,
  title = {Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author = {
    Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and
    Hinton, Geoffrey and Dean, Jeff
  },
  year = {2017},
  journal = {International Conference on Learning Representations},
}

@article{shoeybi2019megatron,
  title = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  author = {
    Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared
    and Catanzaro, Bryan
  },
  year = {2019},
  month = sep,
  journal = {arXiv preprint arXiv:1909.08053},
  url = {http://arxiv.org/abs/1909.08053v4},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
}

@article{valiant1990bsp,
  title = {A bridging model for parallel computation},
  author = {Valiant, Leslie G.},
  year = {1990},
  month = aug,
  journal = {Communications of the ACM},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {33},
  number = {8},
  pages = {103--111},
  doi = {10.1145/79173.79181},
  issn = {0001-0782,1557-7317},
  url = {https://doi.org/10.1145/79173.79181},
  source = {Crossref},
}

@article{zhao2023fsdp,
  title = {PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel},
  author = {
    Zhao, Yanli and Gu, Andrew and Varma, Rohan and Luo, Liang and Huang, Chien-Chin and Xu, Min
    and Wright, Less and Shojanazeri, Hamid and Ott, Myle and Shleifer, Sam and Desmaison, Alban
    and Balioglu, Can and Damania, Pritam and Nguyen, Bernard and Chauhan, Geeta and Hao, Yuchen
    and Mathews, Ajit and Li, Shen
  },
  year = {2023},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {16},
  number = {12},
  pages = {3848--3860},
  doi = {10.14778/3611540.3611569},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3611540.3611569},
  source = {Crossref},
}

\n@inproceedings{shazeer2017outrageously,\n  title = {Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},\n  author = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Piotr and others},\n  year = {2017},\n  booktitle = {International Conference on Learning Representations},\n}
