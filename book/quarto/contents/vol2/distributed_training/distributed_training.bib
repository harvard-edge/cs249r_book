@article{brown2020language,
  title = {Language models are few-shot learners},
  author = {Brown, Tom and others},
  year = {2020},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {1877--1901},
}

@inproceedings{dean2012distbelief,
  author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and 0010, Kai Chen and Devin, Matthieu and Le, Quoc V. and Mao, Mark Z. and Ranzato, Marc'Aurelio and Senior, Andrew W. and Tucker, Paul A. and Yang, Ke and Ng, Andrew Y.},
  title = {Large Scale Distributed Deep Networks.},
  journal = {NIPS},
  pages = {1232--1240},
  year = {2012},
  url = {https://proceedings.neurips.cc/paper/2012/hash/6aca97005c68f1206823815f66102863-Abstract.html},
  source = {DBLP},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {25},
}

@inproceedings{deepspeed_training_system_2021,
  doi = {10.1145/3394486.3406703},
  pages = {3505--3506},
  source = {Crossref},
  author = {Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  subtitle = {System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters},
  year = {2020},
  month = aug,
  url = {https://doi.org/10.1145/3394486.3406703},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining},
  publisher = {ACM},
  title = {DeepSpeed},
  journal = {
    Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data
    Mining
  },
}

@article{goyal2017accurate,
  url = {http://arxiv.org/abs/1706.02677v2},
  title = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
  year = {2017},
  month = jun,
  primaryclass = {cs.CV},
  author = {Goyal, Priya and Doll\'ar, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  archiveprefix = {arXiv},
  journal = {CoRR},
  booktitle = {arXiv preprint arXiv:1706.02677},
  volume = {abs/1706.02677},
  source = {DBLP},
}

@inproceedings{gpipe2019,
  author = {Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia Xu and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V. and Wu, Yonghui and Chen, Zhifeng},
  title = {GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism.},
  journal = {NeurIPS},
  pages = {103--112},
  year = {2019},
  url = {https://proceedings.neurips.cc/paper/2019/hash/093f65e080a295f8076b1c5722a46aa2-Abstract.html},
  source = {DBLP},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {32},
}

@inproceedings{harlap2018pipedream,
  doi = {10.1145/3341301.3359646},
  pages = {1--15},
  source = {Crossref},
  author = {Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R. and Ganger, Gregory R. and Gibbons, Phillip B. and Zaharia, Matei},
  subtitle = {generalized pipeline parallelism for DNN training},
  year = {2019},
  month = oct,
  url = {https://doi.org/10.1145/3341301.3359646},
  booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
  publisher = {ACM},
  title = {PipeDream},
}

@inproceedings{he2016resnet,
  doi = {10.1109/cvpr.2016.90},
  pages = {770--778},
  source = {Crossref},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  month = jun,
  url = {https://doi.org/10.1109/cvpr.2016.90},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  title = {Deep Residual Learning for Image Recognition},
}

@inproceedings{jouppi2017tpu,
  title = {In-datacenter performance analysis of a Tensor Processing Unit},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and others},
  year = {2017},
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
  pages = {1--12},
}

@article{kingma2015adam,
  url = {http://arxiv.org/abs/1412.6980v9},
  title = {Adam: A Method for Stochastic Optimization},
  year = {2014},
  month = dec,
  primaryclass = {cs.LG},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  archiveprefix = {arXiv},
  journal = {ICLR},
  booktitle = {International Conference on Learning Representations},
  source = {DBLP},
}

@inproceedings{li2014parameter,
  author = {0003, Mu Li and Andersen, David G. and Park, Jun Woo and Smola, Alexander J. and 0001, Amr Ahmed and Josifovski, Vanja and Long, James and Shekita, Eugene J. and Su, Bor-Yiing},
  title = {Scaling Distributed Machine Learning with the Parameter Server.},
  journal = {OSDI},
  pages = {583--598},
  year = {2014},
  url = {https://www.usenix.org/conference/osdi14/technical-sessions/presentation/li\_mu},
  source = {DBLP},
  booktitle = {Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation},
}

@inproceedings{narayanan_pipeline_parallelism_2021,
  doi = {10.1145/3458817.3476209},
  pages = {1--15},
  source = {Crossref},
  author = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei},
  year = {2021},
  month = nov,
  url = {https://doi.org/10.1145/3458817.3476209},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  publisher = {ACM},
  title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
  journal = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
}

@article{patarasuk2009allreduce,
  number = {2},
  doi = {10.1016/j.jpdc.2008.09.002},
  pages = {117--124},
  source = {Crossref},
  volume = {69},
  author = {Patarasuk, Pitch and Yuan, Xin},
  year = {2009},
  month = feb,
  url = {https://doi.org/10.1016/j.jpdc.2008.09.002},
  issn = {0743-7315},
  journal = {Journal of Parallel and Distributed Computing},
  publisher = {Elsevier BV},
  title = {Bandwidth optimal all-reduce algorithms for clusters of workstations},
}

@inproceedings{rajbhandari2020zero,
  doi = {10.1109/sc41405.2020.00024},
  pages = {1--16},
  source = {Crossref},
  author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = nov,
  url = {https://doi.org/10.1109/sc41405.2020.00024},
  booktitle = {SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  publisher = {IEEE},
  title = {ZeRO: Memory optimizations Toward Training Trillion Parameter Models},
  journal = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
}

@article{sergeev2018horovod,
  url = {http://arxiv.org/abs/1802.05799v3},
  title = {Horovod: fast and easy distributed deep learning in TensorFlow},
  year = {2018},
  month = feb,
  primaryclass = {cs.LG},
  author = {Sergeev, Alexander and Balso, Mike Del},
  archiveprefix = {arXiv},
  journal = {CoRR},
  booktitle = {arXiv preprint arXiv:1802.05799},
  volume = {abs/1802.05799},
  source = {DBLP},
}

@article{shazeer_mixture_of_experts_2017,
  title = {Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  year = {2017},
  journal = {International Conference on Learning Representations},
}

@article{shoeybi2019megatron,
  url = {http://arxiv.org/abs/1909.08053v4},
  title = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  year = {2019},
  month = sep,
  primaryclass = {cs.CL},
  author = {Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1909.08053},
}

@article{valiant1990bsp,
  number = {8},
  doi = {10.1145/79173.79181},
  pages = {103--111},
  source = {Crossref},
  volume = {33},
  author = {Valiant, Leslie G.},
  year = {1990},
  month = aug,
  url = {https://doi.org/10.1145/79173.79181},
  issn = {0001-0782,1557-7317},
  journal = {Communications of the ACM},
  publisher = {Association for Computing Machinery (ACM)},
  title = {A bridging model for parallel computation},
}

@article{zhao2023fsdp,
  number = {12},
  doi = {10.14778/3611540.3611569},
  pages = {3848--3860},
  source = {Crossref},
  volume = {16},
  author = {Zhao, Yanli and Gu, Andrew and Varma, Rohan and Luo, Liang and Huang, Chien-Chin and Xu, Min and Wright, Less and Shojanazeri, Hamid and Ott, Myle and Shleifer, Sam and Desmaison, Alban and Balioglu, Can and Damania, Pritam and Nguyen, Bernard and Chauhan, Geeta and Hao, Yuchen and Mathews, Ajit and Li, Shen},
  year = {2023},
  month = aug,
  url = {https://doi.org/10.14778/3611540.3611569},
  issn = {2150-8097},
  journal = {Proceedings of the VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  title = {PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel},
}