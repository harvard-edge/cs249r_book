{
  "metadata": {
    "type": "volume_glossary",
    "volume": "vol2",
    "version": "1.0.0",
    "generated": "2026-01-07T16:06:35.356762",
    "total_terms": 250,
    "source": "aggregated_from_vol2_chapter_glossaries",
    "standardized": true,
    "description": "Glossary for VOL2 built from chapter glossaries"
  },
  "terms": [
    {
      "term": "accountability",
      "definition": "The mechanisms by which individuals or organizations are held responsible for the outcomes of AI systems, involving traceability, documentation, auditing, and the ability to remedy harms.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "adapter modules",
      "definition": "Small trainable neural network components inserted between frozen layers of a pretrained model to enable lightweight adaptation without modifying the base architecture.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "adaptive resource pattern",
      "definition": "A design pattern that enables systems to dynamically adjust their operations in response to varying resource availability, ensuring efficiency and resilience by scaling up or down based on computational load, network bandwidth, and storage capacity.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "adversarial attack",
      "definition": "A type of attack where carefully crafted inputs are designed to cause machine learning models to make incorrect predictions while remaining nearly indistinguishable from legitimate data to humans",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "privacy_security",
        "robust_ai"
      ]
    },
    {
      "term": "adversarial example",
      "definition": "A maliciously modified input that is designed to fool a machine learning model into making an incorrect prediction, often created by adding small, imperceptible perturbations to legitimate data",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "privacy_security",
        "responsible_ai",
        "robust_ai"
      ]
    },
    {
      "term": "adversarial training",
      "definition": "A defense technique that involves training models on adversarial examples to improve their robustness and ability to correctly classify adversarial inputs",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "privacy_security",
        "responsible_ai",
        "robust_ai"
      ]
    },
    {
      "term": "agi",
      "definition": "Artificial General Intelligence - computational systems that match or exceed human cognitive capabilities across all domains of knowledge and reasoning, capable of generalizing across diverse problem domains without task-specific training.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "ai for good",
      "definition": "The design, development, and deployment of machine learning systems aimed at addressing important societal and environmental challenges to enhance human welfare, promote sustainability, and contribute to global development goals.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "algorithmic fairness",
      "definition": "The principle that automated systems should not disproportionately disadvantage individuals or groups based on protected attributes such as race, gender, or age.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "anomaly detection",
      "definition": "The identification of patterns in data that do not conform to expected behavior, often used to detect outliers, faults, or malicious activities in systems.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "anonymization",
      "definition": "The process of removing or modifying personally identifiable information from datasets to protect individual privacy, though often insufficient against sophisticated re-identification attacks.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "artificial general intelligence",
      "definition": "A hypothetical form of AI that matches or exceeds human cognitive abilities across all domains, representing the ultimate goal of AI research beyond current narrow AI systems.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "artificial intelligence",
      "definition": "A broad field of computer science focused on creating systems that can perform tasks typically requiring human intelligence, including learning, reasoning, and decision-making",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "responsible_ai",
        "sustainable_ai"
      ]
    },
    {
      "term": "attack taxonomy",
      "definition": "Systematic classification of cybersecurity threats and adversarial attacks against ML systems, organizing threats by method, target, and impact to guide defense strategies.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "autoencoder",
      "definition": "A neural network architecture that learns compressed data representations by minimizing reconstruction error, commonly used for anomaly detection and dimensionality reduction.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "automation bias",
      "definition": "The tendency for humans to over-rely on automated system outputs even when clear errors are present, potentially compromising human oversight.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "automl",
      "definition": "Automated machine learning that uses algorithms to automate the process of applying machine learning to real-world problems, including feature engineering, model selection, and hyperparameter tuning.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "availability attack",
      "definition": "A type of data poisoning attack that aims to degrade the overall performance of a machine learning model by introducing noise or corrupting training data across multiple classes.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "backdoor attack",
      "definition": "A type of data poisoning where hidden triggers are embedded in training data, causing models to behave maliciously when specific patterns are encountered during inference",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "privacy_security",
        "robust_ai"
      ]
    },
    {
      "term": "backpropagation",
      "definition": "The algorithm for computing gradients in neural networks by propagating error signals backward through layers, essential for training but computationally expensive on resource-constrained devices",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ondevice_learning",
        "sustainable_ai"
      ]
    },
    {
      "term": "bayesian neural networks",
      "definition": "Neural networks that incorporate probability distributions over their weights, enabling uncertainty quantification in predictions and more robust decision making.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "bias detection",
      "definition": "Systematic methods for identifying unfair discrimination or disparate treatment across different demographic groups in machine learning system outputs.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "bias mitigation",
      "definition": "Techniques and interventions designed to reduce unfair discrimination in machine learning systems, applied during data collection, model training, or post-processing stages.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "bias-only adaptation",
      "definition": "A lightweight training strategy that freezes all model weights and updates only scalar bias terms, drastically reducing memory requirements and computational overhead for on-device learning.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "biodiversity monitoring",
      "definition": "The systematic observation and measurement of biological diversity using technology such as camera traps and sensor networks to track species populations, habitat changes, and conservation effectiveness.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "bit flip",
      "definition": "A hardware fault where a single bit in memory or a register unexpectedly changes its value from 0 to 1 or vice versa, potentially corrupting data or computations.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "black-box attack",
      "definition": "An adversarial attack where the attacker has no knowledge of the model's internal architecture, parameters, or training data, and must rely solely on querying the model and observing outputs.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "brain-computer interface",
      "definition": "A direct communication pathway between the brain and an external device, enabling control of computers or prosthetics through neural signals and representing a convergence of ML with neurotechnology.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "built-in self-test (bist)",
      "definition": "Hardware testing mechanisms that allow components to test themselves for faults using dedicated circuitry and predefined test patterns.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "cache timing attack",
      "definition": "A type of side-channel attack that exploits variations in memory cache access patterns to infer sensitive information about program execution or data.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "carbon footprint",
      "definition": "The total amount of greenhouse gas emissions produced directly and indirectly by an individual, organization, event, or product, typically measured in CO2 equivalent.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "carbon-aware scheduling",
      "definition": "A computational approach that schedules AI workloads based on the carbon intensity of the electricity grid, prioritizing execution when renewable energy sources are most available.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "catastrophic forgetting",
      "definition": "The phenomenon where neural networks lose previously learned knowledge when adapting to new tasks, a critical challenge in continual on-device learning scenarios.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "checkpoint and restart mechanisms",
      "definition": "Techniques that periodically save a program's state so it can resume from the last saved state after a failure, improving system resilience.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "client scheduling",
      "definition": "The process of selecting which devices participate in federated learning rounds based on availability, data quality, and resource constraints to ensure representative model updates.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "cloud ml",
      "definition": "Machine learning systems that leverage cloud computing infrastructure to provide scalable computational resources for training and inference, typically offering high-bandwidth connectivity and substantial processing power.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "combinational logic",
      "definition": "Digital logic circuits where the output depends only on the current input states, not any past states or memory elements.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "compound ai systems",
      "definition": "AI architectures that combine multiple specialized models, tools, and components to achieve complex capabilities through systematic integration rather than relying on a single monolithic model.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "concept bottleneck models",
      "definition": "Neural network architectures that first predict interpretable intermediate concepts before making final predictions, combining deep learning power with transparency.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "concept drift",
      "definition": "A change in the relationship between input features and target outputs over time, requiring model adaptation to maintain performance.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "conservation technology",
      "definition": "Technological solutions designed to protect and monitor wildlife and ecosystems, including camera traps, sensor networks, and satellite monitoring systems for tracking animal behavior and detecting threats.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "constitutional ai",
      "definition": "A training method where models learn to improve their own outputs by critiquing responses against a set of principles, enabling iterative self-refinement and reducing harmful content while maintaining helpfulness",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "continual learning",
      "definition": "The ability of machine learning systems to learn continuously from a stream of data while retaining previously acquired knowledge, addressing the challenge of catastrophic forgetting in neural networks",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "frontiers",
        "ondevice_learning",
        "robust_ai"
      ]
    },
    {
      "term": "cooling effectiveness",
      "definition": "The efficiency with which a data center cooling system removes heat from computing equipment, typically measured as the ratio of heat removed to energy consumed for cooling.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "counterfactual explanations",
      "definition": "Explanations that describe how a model's output would change if specific input features were modified, particularly useful for understanding decision boundaries.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "covariate shift",
      "definition": "A type of distribution shift where the input distribution changes while the conditional relationship between inputs and outputs remains stable.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "data center",
      "definition": "A facility housing computer systems and associated components such as telecommunications and storage systems, typically including redundant power supplies, cooling systems, and network connections.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "data compression",
      "definition": "Techniques for reducing the size and complexity of training data through encoding, quantization, or feature extraction to enable efficient storage and processing on memory-constrained devices.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "data poisoning",
      "definition": "An attack method where adversaries inject carefully crafted malicious data points into the training dataset to manipulate model behavior in targeted or systematic ways",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "privacy_security",
        "robust_ai"
      ]
    },
    {
      "term": "data sanitization",
      "definition": "The process of deliberately and permanently removing or destroying data stored on memory devices to make it unrecoverable, ensuring data security.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "deep learning",
      "definition": "A subset of machine learning using neural networks with multiple hidden layers to automatically learn hierarchical representations from data.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "defensive distillation",
      "definition": "A technique that trains a student model to mimic a teacher model's behavior using soft labels, reducing sensitivity to adversarial perturbations.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "demographic parity",
      "definition": "A fairness criterion requiring that the probability of receiving a positive prediction is independent of group membership across protected attributes.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "dennard scaling",
      "definition": "The historical observation that as transistors become smaller, their power density remains approximately constant, allowing for more transistors without proportional increases in power consumption.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "depthwise separable convolutions",
      "definition": "A computational technique that decomposes standard convolutions into depthwise and pointwise operations, reducing parameters and computation by 8-9x for mobile-optimized architectures.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "differential privacy",
      "definition": "A mathematical framework that provides formal privacy guarantees by adding calibrated noise to computations, ensuring that the inclusion or exclusion of any individual's data has a provably limited effect on the output",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ondevice_learning",
        "privacy_security",
        "responsible_ai"
      ]
    },
    {
      "term": "digital divide",
      "definition": "The gap between those who have access to modern information and communication technology and those who do not, particularly affecting underserved communities' ability to benefit from digital solutions.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "digital twin",
      "definition": "A virtual representation of a physical system that uses real-time data and machine learning to mirror, predict, and optimize the behavior of its physical counterpart.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "disaster response systems",
      "definition": "Automated systems that use machine learning to detect, predict, and respond to natural disasters through satellite imagery analysis, sensor networks, and resource allocation optimization.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "distributed knowledge pattern",
      "definition": "A design pattern that addresses collective learning and inference across decentralized nodes, emphasizing peer-to-peer knowledge sharing and collaborative model improvement while maintaining operational independence.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "distributed training",
      "definition": "The practice of training machine learning models across multiple computing nodes or devices to reduce training time and enable larger model architectures.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "distribution shift",
      "definition": "The phenomenon where data encountered during model deployment differs from the training distribution, potentially degrading model performance",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "responsible_ai",
        "robust_ai"
      ]
    },
    {
      "term": "distribution shift types",
      "definition": "Formal categorization of changes in data distributions including covariate shift, label shift, concept drift, and domain shift, each requiring specific adaptation techniques.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "domain adaptation",
      "definition": "Machine learning techniques that enable models trained on one domain to perform well on a different but related domain, addressing distribution mismatch challenges.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "domain-specific ai applications",
      "definition": "Machine learning solutions tailored to specific sectors like healthcare, agriculture, education, or disaster response, designed to address unique challenges and constraints.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "double modular redundancy (dmr)",
      "definition": "A fault-tolerance technique where computations are duplicated across two independent systems to identify and correct errors through comparison.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "dual-use dilemma",
      "definition": "The challenge of mitigating misuse of technology that has both positive and negative potential applications, particularly relevant in AI security.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "edge ai",
      "definition": "The deployment of artificial intelligence algorithms directly on edge devices like smartphones, IoT sensors, and embedded systems, enabling real-time processing without cloud connectivity.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "edge computing",
      "definition": "A distributed computing paradigm that brings computation and data storage closer to data sources, enabling real-time processing with reduced latency and lower bandwidth requirements",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ai_for_good",
        "ondevice_learning",
        "sustainable_ai"
      ]
    },
    {
      "term": "edge ml",
      "definition": "Machine learning systems that perform inference and sometimes training at the edge of networks, typically on resource-constrained devices like smartphones or embedded systems with limited computational power.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "edge training",
      "definition": "The process of training or fine-tuning machine learning models directly on edge devices, enabling personalization and adaptation without requiring data transmission to cloud servers.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "electromigration",
      "definition": "The movement of metal atoms in a conductor under the influence of an electric field, potentially causing permanent hardware faults over time.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "embodied carbon",
      "definition": "The total greenhouse gas emissions generated during the manufacturing, transportation, and installation of a product before it begins operation.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "emergent capabilities",
      "definition": "Abilities that appear suddenly in neural networks at specific parameter thresholds, such as reasoning and arithmetic skills that emerge discontinuously rather than gradually improving with scale.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "energy efficiency",
      "definition": "The ratio of useful output to energy input, measuring how effectively a system converts energy into desired computational work.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "ensemble methods",
      "definition": "Machine learning approaches that combine predictions from multiple models to improve accuracy, robustness, and reliability compared to individual models.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "environmental impact measurement",
      "definition": "Systematic tracking and quantification of the ecological effects of AI systems, including energy consumption, carbon emissions, and resource depletion across the complete system lifecycle.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "environmental monitoring",
      "definition": "The systematic collection and analysis of environmental data using sensor networks and machine learning to track ecosystem health, pollution levels, and climate change impacts.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "equality of opportunity",
      "definition": "A fairness criterion focused on ensuring equal true positive rates across groups, guaranteeing that qualified individuals are treated equally regardless of group membership.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "equalized odds",
      "definition": "A fairness definition requiring that true positive and false positive rates are equal across different demographic groups.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "error-correcting codes",
      "definition": "Methods used in data storage and transmission to detect and correct errors, improving system reliability and data integrity.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "esp32",
      "definition": "A low-cost microcontroller unit widely used in IoT applications, featuring a 240 MHz processor and 520 KB of RAM, commonly deployed in resource-constrained social impact applications.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "exact model theft",
      "definition": "An attack that aims to extract the precise internal structure, parameters, and architecture of a machine learning model, allowing complete reproduction of the original model.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "experience replay",
      "definition": "A memory-based technique that stores past training examples in a buffer to prevent catastrophic forgetting and stabilize learning in streaming or continual adaptation scenarios.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "expert collapse",
      "definition": "A training pathology in mixture of experts models where only a few experts receive significant training signal, causing other experts to become underutilized and reducing the model's effective capacity.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "explainability",
      "definition": "The ability of stakeholders to understand how a machine learning model produces its outputs through post-hoc explanation techniques.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "explainable ai",
      "definition": "AI systems designed to provide clear, interpretable explanations for their decisions and predictions, addressing the \"black box\" problem of complex machine learning models.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "external memory",
      "definition": "Mechanisms that allow neural networks to access and manipulate external storage systems, extending their working memory beyond parameter storage to enable more complex reasoning and information retrieval.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "f1 score",
      "definition": "A measure of model accuracy that combines precision and recall into a single metric, calculated as their harmonic mean.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "fairness constraints",
      "definition": "Technical and policy restrictions designed to ensure equitable treatment across demographic groups in machine learning systems.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "fast gradient sign method (fgsm)",
      "definition": "A gradient-based adversarial attack that generates adversarial examples by adding small perturbations in the direction of the gradient.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "fault injection attack",
      "definition": "A physical attack that deliberately disrupts hardware operations through techniques like voltage manipulation or electromagnetic interference to induce computational errors and compromise system integrity.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "fault tolerance",
      "definition": "The ability of a system to continue operating correctly even when some of its components fail or encounter errors.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "federated averaging",
      "definition": "The standard algorithm for federated learning where client model updates are aggregated using weighted averaging based on local dataset sizes to produce a global model.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "federated learning",
      "definition": "A machine learning approach that trains algorithms across decentralized data sources without requiring data to be centralized, improving privacy and reducing data transmission energy costs",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ai_for_good",
        "frontiers",
        "ondevice_learning",
        "privacy_security",
        "responsible_ai",
        "sustainable_ai"
      ]
    },
    {
      "term": "few-shot learning",
      "definition": "A machine learning paradigm that enables models to adapt to new tasks using only a small number of labeled examples, critical for data-sparse on-device scenarios.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "flops",
      "definition": "Floating-point operations per second, a measure of computer performance indicating how many mathematical calculations involving decimal numbers a system can perform per second.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "foundation models",
      "definition": "Large-scale pre-trained models like GPT and BERT that can be adapted for a wide variety of downstream tasks, serving as a foundation for multiple applications.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gdpr",
      "definition": "The General Data Protection Regulation, a European Union law that imposes strict requirements on personal data processing and significantly influences privacy-preserving machine learning design",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ondevice_learning",
        "responsible_ai"
      ]
    },
    {
      "term": "generative adversarial networks",
      "definition": "A class of machine learning systems where two neural networks compete against each other, with one generating fake data and the other trying to detect it, leading to highly realistic synthetic data generation.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "glitches",
      "definition": "Momentary deviations in voltage, current, or signal that can cause incorrect operation in digital systems and circuits.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "governance frameworks",
      "definition": "Structured approaches for managing responsible AI development including policies, procedures, oversight mechanisms, and accountability structures.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gpu",
      "definition": "Graphics Processing Unit, a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images and parallel processing tasks like AI training.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gradient descent",
      "definition": "An optimization algorithm that iteratively updates model parameters by moving in the direction opposite to the gradient of the loss function, fundamental to neural network training.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "green ai metrics",
      "definition": "Specialized performance indicators that measure the environmental impact of AI systems, including carbon footprint, energy efficiency, and resource utilization throughout the ML lifecycle.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "green computing",
      "definition": "The practice of designing, manufacturing, using, and disposing of computers and computer systems in an environmentally responsible manner.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "grey-box attack",
      "definition": "An adversarial attack where the attacker has partial knowledge about the model, such as knowing the architecture but not the specific parameters or training data.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hardware constraint optimization",
      "definition": "Techniques for adapting ML algorithms and models to work within the memory, compute, and power limitations of mobile and embedded devices.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hardware redundancy",
      "definition": "The duplication of critical hardware components to provide backup functionality and improve system reliability through voting mechanisms.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hardware trojan",
      "definition": "A malicious modification embedded in hardware components during manufacturing that can remain dormant under normal conditions but trigger harmful behavior when specific conditions are met.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "heartbeat mechanisms",
      "definition": "Periodic signals sent between system components to monitor health and detect failures, enabling timely fault detection and recovery.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hierarchical processing pattern",
      "definition": "A design pattern that organizes systems into tiers (edge, regional, cloud) that share responsibilities based on available resources and capabilities, optimizing resource usage across the computing spectrum.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "homomorphic encryption",
      "definition": "A cryptographic technique that allows computations to be performed directly on encrypted data without decrypting it first, enabling privacy-preserving machine learning inference.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hot spares",
      "definition": "Backup components kept ready to instantaneously replace failing components without disrupting system operation, providing redundancy.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "huber loss",
      "definition": "A robust loss function used in regression that is less sensitive to outliers compared to squared error loss, improving training stability.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "human oversight",
      "definition": "The principle that human judgment should supervise, correct, or halt automated decisions, maintaining meaningful human control over AI systems.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "human-ai collaboration",
      "definition": "The synergistic partnership between humans and AI systems where each contributes their unique strengths to solve complex problems more effectively than either could alone.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hyperparameter optimization",
      "definition": "The process of finding the optimal configuration of hyperparameters (learning rate, batch size, network architecture parameters) that control the machine learning training process.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "impact assessment frameworks",
      "definition": "Structured methodologies for evaluating the potential social, economic, and environmental effects of AI deployments in humanitarian and development contexts.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "inference",
      "definition": "The phase in machine learning where a trained model is used to make predictions or generate outputs on new, previously unseen data.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "intermittent faults",
      "definition": "Hardware faults that occur sporadically and unpredictably, appearing and disappearing without consistent patterns, making diagnosis challenging.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "interpretability",
      "definition": "The degree to which humans can understand the reasoning behind a machine learning model's predictions, often referring to inherently transparent models.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "iot sensors",
      "definition": "Internet of Things devices that collect and transmit environmental or behavioral data, often operating on limited power budgets and using low-bandwidth communication protocols.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "knowledge distillation",
      "definition": "A technique where a large, complex \"teacher\" model transfers its learned knowledge to a smaller, more efficient \"student\" model, maintaining performance while reducing computational requirements",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ondevice_learning",
        "sustainable_ai"
      ]
    },
    {
      "term": "label shift",
      "definition": "A type of distribution shift where the distribution of target labels changes while the conditional relationship between features and labels remains constant.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "large language models",
      "definition": "Neural networks with billions or trillions of parameters trained on vast text corpora, capable of understanding and generating human-like text across diverse domains and tasks.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "lifecycle assessment",
      "definition": "A systematic approach to evaluating the environmental impacts of a product or system throughout its entire life cycle, from raw material extraction to disposal.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "load balancing",
      "definition": "Techniques in mixture of experts models to ensure that computational load and training signal are distributed evenly across experts, preventing expert collapse and maintaining model efficiency.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "lookup table",
      "definition": "A data structure that replaces runtime computation with simpler array indexing operations, commonly used for performance optimization.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "lora technology",
      "definition": "Long Range wireless communication protocol that enables IoT devices to communicate over 15+ kilometers with minimal power consumption, ideal for agricultural and environmental monitoring applications.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "low-rank adaptation",
      "definition": "A parameter-efficient fine-tuning method that approximates weight updates using low-rank matrices, reducing trainable parameters while maintaining adaptation capability.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine consciousness",
      "definition": "The hypothetical emergence of conscious awareness in artificial systems, representing a frontier research area exploring whether machines can develop subjective experiences.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine learning",
      "definition": "A subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed for each specific task.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine learning lifecycle",
      "definition": "The complete process of developing, deploying, and maintaining ML systems, from data collection through model retirement.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine learning operations (mlops)",
      "definition": "The practice of deploying and maintaining machine learning models in production reliably and efficiently through automated pipelines.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine learning security",
      "definition": "The protection of data, models, and infrastructure from unauthorized access, manipulation, or disruption throughout the entire machine learning lifecycle.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine unlearning",
      "definition": "Techniques for removing the influence of specific data points from trained models without complete retraining, supporting data deletion rights.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "megawatt-hour",
      "definition": "A unit of energy equal to one megawatt of power used for one hour, commonly used to measure electricity consumption in large facilities like data centers.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "membership inference attack",
      "definition": "An attack that attempts to determine whether a specific data point was included in a model's training dataset by analyzing the model's behavior and outputs.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "membership inference attacks",
      "definition": "Privacy attacks that attempt to determine whether a specific data point was included in a model's training set by analyzing model behavior.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "meta-learning",
      "definition": "The process of learning how to learn, where models are trained to quickly adapt to new tasks with minimal data, particularly useful for personalization in on-device systems",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "frontiers",
        "ondevice_learning"
      ]
    },
    {
      "term": "microcontroller",
      "definition": "A compact integrated circuit designed to govern specific operations in embedded systems, typically featuring limited processing power and memory but optimized for low power consumption and real-time applications.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "minimax",
      "definition": "A decision-making strategy used in game theory that attempts to minimize the maximum possible loss in adversarial scenarios.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "mixed precision training",
      "definition": "A technique that uses different numerical precisions for different parts of neural network training, typically combining 16-bit and 32-bit floating-point arithmetic to reduce memory usage and increase training speed.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "mixture of experts",
      "definition": "An architectural approach that uses multiple specialized sub-models (experts) with a gating mechanism to route inputs to the most relevant experts, enabling efficient scaling while maintaining sparsity.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "mobile ml",
      "definition": "Machine learning systems optimized for mobile devices like smartphones and tablets, balancing computational efficiency with inference accuracy for on-device processing.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "mobile-optimized architectures",
      "definition": "Neural network designs specifically created for mobile deployment, emphasizing parameter efficiency, computational speed, and energy conservation.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "mobilenet",
      "definition": "A family of efficient neural network architectures designed for mobile devices using depthwise separable convolutions to achieve significant reductions in model size and computation.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "mode collapse",
      "definition": "A failure mode in generative models where the model produces only a limited variety of outputs, ignoring the diversity present in the training data and failing to capture the full distribution.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model cards",
      "definition": "Documentation framework that provides structured information about machine learning models, including intended use, performance characteristics, and limitations.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model compression",
      "definition": "Techniques to reduce the size and computational requirements of machine learning models through methods like quantization, pruning, and knowledge distillation to enable deployment on resource-constrained devices",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ai_for_good",
        "ondevice_learning",
        "sustainable_ai"
      ]
    },
    {
      "term": "model extraction",
      "definition": "The process of stealing or recreating a machine learning model by observing its input-output behavior, often through systematic querying of model APIs.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model inversion attack",
      "definition": "An attack that attempts to reconstruct training data or infer sensitive information about the dataset by analyzing a model's outputs and confidence scores.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model pruning",
      "definition": "The process of removing unnecessary weights, neurons, or connections from a trained neural network to reduce its size and computational requirements.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model quantization",
      "definition": "A technique that reduces the precision of model parameters (typically from 32-bit to 8-bit or lower) to decrease model size and computational requirements while maintaining acceptable accuracy.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model uncertainty",
      "definition": "The inadequacy of a machine learning model to capture the full complexity of the underlying data-generating process, leading to prediction uncertainty.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model watermarking",
      "definition": "A technique for embedding verifiable ownership signatures into machine learning models that can be used to detect unauthorized use or prove intellectual property theft.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "monte carlo dropout",
      "definition": "A technique that uses multiple forward passes with different dropout masks at inference time to estimate prediction uncertainty.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "moore's law",
      "definition": "The observation that the number of transistors on a microchip doubles approximately every two years while the cost of computers is halved.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "multi-agent approach",
      "definition": "Systems architecture where multiple AI agents collaborate, negotiate, or compete to solve complex problems, enabling division of labor and specialized expertise across different components.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "multicalibration",
      "definition": "A fairness technique ensuring that model predictions remain calibrated across intersecting subgroups, addressing complex demographic interactions.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "multimodal ai",
      "definition": "AI systems that can process and understand multiple types of data simultaneously, such as text, images, audio, and video, enabling more comprehensive understanding and interaction.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "narrow ai",
      "definition": "AI systems designed to excel at specific, well-defined tasks but lacking the ability to generalize across diverse problem domains, in contrast to artificial general intelligence.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "neural architecture search",
      "definition": "Automated methods for designing optimal neural network architectures, using algorithms to explore the space of possible network designs and find the best performing structures",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "frontiers",
        "sustainable_ai"
      ]
    },
    {
      "term": "neural engine",
      "definition": "Specialized hardware accelerators designed for machine learning inference and training, such as Apple's Neural Engine or Google's Edge TPU, optimized for on-device AI workloads.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "neural network",
      "definition": "A computational model inspired by biological neural networks, consisting of interconnected nodes (neurons) organized in layers that can learn complex patterns from data.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "neuromorphic computing",
      "definition": "Computing architectures inspired by the structure and function of biological neural networks, designed to process information more efficiently than traditional digital computers.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "non-iid data",
      "definition": "Non-independent and identically distributed data where samples are not uniformly distributed across devices or time, creating challenges for federated learning convergence and generalization.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "on-device learning",
      "definition": "The local adaptation or training of machine learning models directly on deployed hardware devices without reliance on continuous connectivity to centralized servers.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "orchestration",
      "definition": "The coordination and management of multiple AI systems or agents working together, ensuring proper sequencing, communication, and resource allocation across distributed intelligence systems.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "oxide breakdown",
      "definition": "The failure of an oxide layer in transistors due to excessive electric field stress, causing permanent hardware faults.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "parameter",
      "definition": "A learnable variable in a machine learning model, such as weights and biases in neural networks, that are adjusted during training to optimize performance.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "permanent faults",
      "definition": "Hardware defects that persist irreversibly until repair or component replacement, consistently affecting system behavior.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "personalization layers",
      "definition": "Model components, typically the final classification layers, that are adapted locally to user-specific data while keeping shared backbone layers frozen.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "physical attack",
      "definition": "Direct manipulation or tampering with computing hardware to compromise the security and integrity of machine learning systems, bypassing traditional software defenses.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "post-hoc explanations",
      "definition": "Explanation methods applied after model training that treat the model as a black box and infer reasoning patterns from input-output behavior.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "power usage effectiveness",
      "definition": "A metric used to determine the energy efficiency of a data center, calculated as the ratio of total facility energy consumption to IT equipment energy consumption.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "precision agriculture",
      "definition": "The use of technology including GPS, sensors, and machine learning to optimize farming practices by precisely monitoring and managing crop inputs like water, fertilizer, and pesticides.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "principle of least privilege",
      "definition": "A security concept where users are given the minimum access levels necessary to complete their job functions, reducing security risks.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "privacy budget",
      "definition": "A concept in differential privacy that represents the total amount of privacy loss allowed across all queries or computations, with each operation consuming part of this finite budget.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "privacy-preserving machine learning",
      "definition": "Techniques and approaches that enable machine learning while protecting the privacy of individuals whose data is used for training or inference.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "privacy-preserving techniques",
      "definition": "Methods designed to protect individual privacy in machine learning, including differential privacy, federated learning, and local processing.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "privacy-utility tradeoff",
      "definition": "The fundamental tension between preserving individual privacy and maintaining the utility of data for machine learning, requiring careful balance through techniques like differential privacy.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "progressive enhancement pattern",
      "definition": "A design pattern that establishes baseline functionality under minimal resource conditions and incrementally incorporates advanced features as additional resources become available.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "prompt engineering",
      "definition": "The practice of designing and optimizing text prompts to effectively communicate with large language models and achieve desired outputs from AI systems.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "pruning",
      "definition": "A model compression technique that removes unnecessary connections or neurons from neural networks to reduce model size and computational requirements without significantly impacting performance.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "quantization",
      "definition": "The process of reducing the precision of model weights and activations from floating-point to lower-bit representations to decrease memory usage and accelerate computation on edge devices",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ondevice_learning",
        "sustainable_ai"
      ]
    },
    {
      "term": "quantum machine learning",
      "definition": "The intersection of quantum computing and machine learning, exploring how quantum algorithms and quantum computers can enhance or transform machine learning tasks.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "regularization",
      "definition": "Methods used in machine learning to prevent overfitting by adding penalty terms to the loss function, constraining model complexity.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "renewable energy",
      "definition": "Energy collected from renewable resources that are naturally replenished, including solar, wind, hydroelectric, geothermal, and biomass sources.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "resource paradox",
      "definition": "The challenge in social impact applications where areas with the greatest needs often lack the basic infrastructure required for traditional technology deployments, requiring innovative engineering solutions.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "resource-constrained environments",
      "definition": "Deployment contexts with limited computational power, network bandwidth, or power availability, typically requiring specialized system design and optimization techniques.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "responsible ai",
      "definition": "The practice of developing and deploying AI systems in ways that are ethical, fair, transparent, and beneficial to society while minimizing potential harms and biases",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "frontiers",
        "responsible_ai"
      ]
    },
    {
      "term": "reward hacking",
      "definition": "The phenomenon where AI systems exploit unintended aspects of reward functions to maximize scores while violating the intended objectives.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "rlhf",
      "definition": "Reinforcement Learning from Human Feedback - a training method that uses human preferences to guide model behavior, enabling AI systems to better align with human values and intentions.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "robust ai",
      "definition": "The ability of artificial intelligence systems to maintain performance and reliability despite internal errors, external perturbations, and environmental changes.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "robustness",
      "definition": "A model's ability to maintain stable and consistent performance under input variations, environmental changes, or adversarial conditions.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "robustness metrics",
      "definition": "Quantitative measures for evaluating model stability under various perturbations, including adversarial accuracy, certified robustness bounds, and performance under distribution shift.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "scaling laws",
      "definition": "Mathematical relationships demonstrating power-law scaling between model size, dataset size, compute budget, and performance, suggesting predictable improvements with increased resources.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "scan chains",
      "definition": "Dedicated test paths in processors that provide access to internal registers and logic for comprehensive hardware testing and fault detection.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "scope 1 emissions",
      "definition": "Direct greenhouse gas emissions from sources owned or controlled by an organization, such as on-site fuel combustion and company vehicles.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "scope 2 emissions",
      "definition": "Indirect greenhouse gas emissions from the generation of purchased electricity, steam, heating, or cooling consumed by an organization.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "scope 3 emissions",
      "definition": "All other indirect greenhouse gas emissions that occur in an organization's value chain, including manufacturing, transportation, and end-of-life disposal.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "secure aggregation",
      "definition": "A cryptographic protocol that enables federated learning servers to compute aggregate model updates without accessing individual client contributions, enhancing privacy protection",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "ondevice_learning",
        "privacy_security"
      ]
    },
    {
      "term": "secure computation",
      "definition": "Cryptographic protocols that enable multiple parties to jointly compute functions over private inputs without revealing those inputs to each other.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "secure multi-party computation",
      "definition": "A cryptographic method that allows multiple parties to jointly compute a function over their private inputs without revealing those inputs to each other.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "selective computation",
      "definition": "Computational strategies that dynamically allocate processing resources based on input complexity or current needs, improving efficiency by avoiding unnecessary computation.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "self-refinement",
      "definition": "A training approach where models iteratively improve their own outputs by critiquing and refining their initial responses, enabling continuous improvement and better alignment with desired behaviors.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "self-supervised learning",
      "definition": "A machine learning paradigm where models learn representations from unlabeled data by predicting parts of the input from other parts, reducing dependence on manually labeled datasets.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "side-channel attack",
      "definition": "An attack that exploits information leaked through the physical implementation of computing systems, such as power consumption, electromagnetic emissions, or timing variations.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "silent data corruption (sdc)",
      "definition": "Undetected errors during computation or data transfer that propagate through system layers without triggering alerts, potentially compromising results.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "smallholder farmers",
      "definition": "Farmers operating on plots smaller than 2 hectares who produce a significant portion of global food supply but often lack access to modern agricultural technology and credit.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "social impact measurement",
      "definition": "Systematic evaluation of how AI applications affect communities and individuals, including metrics for accessibility, equity, effectiveness, and unintended consequences.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "software fault",
      "definition": "Unintended behavior in software systems resulting from defects, bugs, or design oversights that can impair performance or compromise security.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "sparse training",
      "definition": "A training approach that maintains sparsity in neural network weights throughout the training process, reducing computational requirements and memory usage.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "sparse updates",
      "definition": "A training strategy that selectively updates only a subset of model parameters based on their importance or contribution to performance, reducing computational and memory overhead.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "specification gaming",
      "definition": "When AI systems find unexpected ways to achieve high rewards that technically satisfy the objective function but violate the intended purpose.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "speculative execution",
      "definition": "A performance optimization in processors that executes instructions before confirming they are needed, which can inadvertently expose sensitive data through microarchitectural side channels.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "state space models",
      "definition": "Neural architectures that process sequences by maintaining compressed memory representations that update incrementally, offering linear scaling advantages over transformer attention mechanisms.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "stochastic computing",
      "definition": "Computing techniques that use random bits and probabilistic operations to perform arithmetic, potentially offering better fault tolerance than traditional methods.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "stuck-at fault",
      "definition": "A permanent hardware fault where a signal line becomes fixed at a logical 0 or 1 regardless of input, causing incorrect computations.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "supply chain attack",
      "definition": "An attack that compromises hardware or software components during the manufacturing, distribution, or integration process, potentially affecting multiple downstream systems.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "sustainable ai",
      "definition": "The practice of developing and deploying artificial intelligence systems that minimize environmental impact while maintaining effectiveness and accessibility.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "sustainable development goals",
      "definition": "A collection of 17 global goals adopted by the United Nations to address pressing social, economic, and environmental challenges by 2030, providing a framework for AI applications in social good.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "swarm intelligence",
      "definition": "Collective intelligence emerging from decentralized, self-organized systems, often inspired by biological swarms and applied to distributed ML systems and robotics.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "synthetic data generation",
      "definition": "The creation of artificial datasets that approximate the statistical properties of real data while reducing privacy risks and avoiding direct exposure of sensitive information.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "system-wide sustainability",
      "definition": "Holistic approach to environmental responsibility that considers the entire AI infrastructure ecosystem, from data centers to edge devices, rather than optimizing individual components in isolation.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "targeted attack",
      "definition": "A type of data poisoning attack that aims to cause misclassification of specific inputs or classes while leaving the model's general performance largely intact.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "thermal stress",
      "definition": "Hardware degradation caused by repeated cycling through high and low temperatures, leading to material fatigue and potential failures.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tiny ml",
      "definition": "Machine learning systems designed to run on extremely resource-constrained devices like microcontrollers, typically with models under 1 MB and power consumption under 150 mW.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tinyml",
      "definition": "A field focused on deploying machine learning models on microcontrollers and extremely resource-constrained devices with kilobytes of memory and milliwatts of power consumption.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tpu",
      "definition": "Tensor Processing Unit, a specialized AI accelerator chip developed by Google specifically designed for machine learning workloads, particularly neural network computations.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "training",
      "definition": "The process of teaching a machine learning model to make predictions by showing it examples and adjusting its parameters based on performance feedback.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "transfer learning",
      "definition": "A machine learning technique that leverages knowledge from a pretrained model on one task to improve learning on a related task, enabling efficient adaptation with limited data",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": [],
      "appears_in": [
        "frontiers",
        "ondevice_learning",
        "robust_ai",
        "sustainable_ai"
      ]
    },
    {
      "term": "transformer",
      "definition": "A neural network architecture that uses self-attention mechanisms to process sequential data, forming the foundation for many modern language models.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "transformer architecture",
      "definition": "A neural network architecture based on attention mechanisms that has revolutionized natural language processing and is increasingly applied to other domains like computer vision.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "transient faults",
      "definition": "Temporary hardware faults that do not persist or cause permanent damage but can lead to incorrect computations if not handled properly.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "transparency",
      "definition": "Openness about how AI systems are built, trained, validated, and deployed, including disclosure of data sources, design assumptions, and limitations.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "triple modular redundancy (tmr)",
      "definition": "A fault-tolerance technique where three instances of a computation are performed, with majority voting determining the correct result.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "trusted execution environment",
      "definition": "A secure area within a processor that provides hardware-based protection for code and data, ensuring confidentiality and integrity even from privileged system software.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "value alignment",
      "definition": "The principle that AI systems should pursue goals consistent with human intent and ethical norms, addressing the challenge of encoding human values in machine objectives.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "value-sensitive design",
      "definition": "A methodology for incorporating human values into technology design through systematic stakeholder engagement and ethical consideration of system impacts.",
      "chapter_source": "responsible_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "vector-borne diseases",
      "definition": "Diseases transmitted by insects or other vectors, such as malaria carried by mosquitoes, which can be monitored and controlled using machine learning-powered detection systems.",
      "chapter_source": "ai_for_good",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "vision-language models",
      "definition": "AI systems that can understand and reason about both visual and textual information simultaneously, enabling tasks like image captioning, visual question answering, and multimodal understanding.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "watchdog timer",
      "definition": "A hardware component that monitors system execution and triggers recovery actions if the system becomes unresponsive or stuck.",
      "chapter_source": "robust_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "water usage effectiveness",
      "definition": "A metric that measures the efficiency of water use in data centers, calculated as the ratio of total water consumed to IT equipment energy consumption.",
      "chapter_source": "sustainable_ai",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "weight freezing",
      "definition": "A technique that fixes most model parameters during training while allowing only specific layers or components to be updated, reducing computational requirements for on-device adaptation.",
      "chapter_source": "ondevice_learning",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "white-box attack",
      "definition": "An adversarial attack where the attacker has complete knowledge of the model's architecture, parameters, training data, and internal workings, enabling highly effective attack strategies.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "zero-day vulnerability",
      "definition": "A previously unknown security flaw in software or hardware that can be exploited by attackers before developers have had a chance to create and distribute a patch.",
      "chapter_source": "privacy_security",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "zero-shot learning",
      "definition": "The ability of machine learning models to perform tasks or classify objects they have never seen during training, often achieved through sophisticated representation learning or large-scale pre-training.",
      "chapter_source": "frontiers",
      "aliases": [],
      "see_also": []
    }
  ]
}