# About This Volume {.unnumbered}

## Overview {#sec-volume-overview-52bf}

Volume II: Advanced Machine Learning Systems addresses the complexities of **building and managing the machine learning fleet**. This volume follows the Hennessy & Patterson pedagogical model, building upon single-node foundations to tackle the challenges of ML systems that span thousands of machines, traverse global networks, and serve millions of users simultaneously. It shifts the focus from the individual accelerator to the warehouse-scale computer—the Machine Learning Fleet.

## What This Volume Covers {#sec-volume-volume-covers-e07b}

**Part I: Foundations of Scale** asks: *How do we coordinate computation across thousands of devices?*

Scaling beyond a single machine requires mastering the algorithms of distributed coordination. This part covers the parallelism strategies (Data, Tensor, Pipeline) for training models too large for single GPUs, the collective communication primitives that synchronize them, and the fault tolerance mechanisms that ensure reliability at scale.

**Part II: Building the Machine Learning Fleet** asks: *How do we architect the physical computer for AI?*

The "computer" is no longer a single box but a warehouse-scale fleet. This part examines the physical infrastructure—datacenter design, specialized accelerators, high-performance networking, and storage systems—required to support distributed workloads.

**Part III: Deployment at Scale** asks: *How do we serve intelligence to the world?*

Training is only the beginning. This part navigates the shift to inference, optimization techniques for latency and throughput, the push of intelligence to the edge, and the operational lifecycle (MLOps) required to manage production fleets.

**Part IV: Production Concerns** asks: *How do we harden systems for real-world reliability?*

Production systems face adversarial threats and physical constraints. This part addresses the non-functional requirements of privacy, security, robust system design, and environmental sustainability.

**Part V: Responsible AI at Scale** asks: *How do we shape the future of these systems?*

Technical excellence must be paired with societal responsibility. This part explores AI governance, applications for social good, and the emerging frontiers of AGI systems.

## Prerequisites {#sec-volume-prerequisites-860e}

This volume assumes a background in single-machine ML systems:

**Required:**

- Understanding of ML workflows and development lifecycle
- Familiarity with neural network architectures and training
- Knowledge of optimization techniques and hardware acceleration
- Experience with deployment and ML operations concepts

**Recommended:**

- Familiarity with distributed systems concepts (networking, parallelism)
- Experience with cloud infrastructure or container orchestration
- Understanding of production software engineering practices

## Extending Foundational Concepts {#sec-volume-extending-foundational-concepts-293c}

Volume II extends major machine learning concepts to the distributed scale:

| **Foundational Concept**    | **Volume II Extension**              |
| **Single GPU training**     | Distributed training across clusters |
| **Model optimization**      | System level optimization at scale   |
| **Local serving**           | Global inference infrastructure      |
| **ML operations**           | Operations for distributed systems   |
| **Responsible engineering** | Responsible AI governance            |
+-----------------------------+--------------------------------------+

## Copyright and Licensing {#sec-volume-copyright-licensing-f9a5}

This work is open source and licensed under [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0). For more information, visit the [GitHub repository](https://github.com/harvard-edge/cs249r_book).
