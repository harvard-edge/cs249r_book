# About This Book {.unnumbered}

## Overview {#sec-volume-overview-52bf}

Volume II: Advanced Machine Learning Systems addresses the complexities of **building and managing the machine learning fleet**. This book follows the Hennessy & Patterson pedagogical model, building upon single-node foundations to tackle the challenges of ML systems that span thousands of machines, traverse global networks, and serve millions of users simultaneously. It shifts the focus from the individual accelerator to the warehouse-scale computer—the Machine Learning Fleet.

## What This Book Covers {#sec-volume-volume-covers-e07b}

**Part I: The Fleet** asks: *What is the physical substrate of the AI datacenter?*

The "computer" is no longer a single box but a warehouse-scale fleet. This part builds the physical substrate from the ground up: the landscape of distributed ML systems, the silicon and cooling of compute infrastructure, the network fabrics that connect thousands of accelerators, and the scalable data systems that feed training pipelines.

**Part II: Distributed ML** asks: *How do we partition work across thousands of devices?*

Scaling beyond a single machine requires mastering the logic of distribution. This part covers the parallelism strategies (Data, Tensor, Pipeline) for training models too large for single devices, the collective communication primitives that synchronize gradients, the fault tolerance mechanisms that ensure reliability when failure is routine, and the orchestration systems that manage the fleet.

**Part III: Deployment at Scale** asks: *How do we serve intelligence to the world?*

Training is only the beginning. This part takes the trained model from the cluster to the world—inference serving at massive scale, performance engineering for efficiency, edge intelligence for resource-constrained devices, and the operational lifecycle required to manage production fleets.

**Part IV: The Responsible Fleet** asks: *How do we ensure the fleet serves humanity well?*

Technical excellence must be paired with societal responsibility. This part confronts the forces that determine whether the fleet serves its users or harms them: security and privacy, robust system design, environmental sustainability, and responsible engineering as fundamental system constraints.

## Prerequisites {#sec-volume-prerequisites-860e}

This book assumes a background in single-machine ML systems:

**Required:**

- Understanding of ML workflows and development lifecycle
- Familiarity with neural network architectures and training
- Knowledge of optimization techniques and hardware acceleration
- Experience with deployment and ML operations concepts

**Recommended:**

- Familiarity with distributed systems concepts (networking, parallelism)
- Experience with cloud infrastructure or container orchestration
- Understanding of production software engineering practices

## Extending Foundational Concepts {#sec-volume-extending-foundational-concepts-293c}

Volume II extends major machine learning concepts to the distributed scale:

| **Foundational Concept**    | **Volume II Extension**              |
| **Single GPU training**     | Distributed training across clusters |
| **Model optimization**      | System level optimization at scale   |
| **Local serving**           | Global inference infrastructure      |
| **ML operations**           | Operations for distributed systems   |
| **Responsible engineering** | Responsible AI governance            |
+-----------------------------+--------------------------------------+

## Copyright and Licensing {#sec-volume-copyright-licensing-f9a5}

This work is open source and licensed under [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0). For more information, visit the [GitHub repository](https://github.com/harvard-edge/cs249r_book).
