---
number-sections: false
---

# Notation and Conventions {.unnumbered}

This book spans three disciplines: **Machine Learning** (computer science/statistics), **Systems** (computer architecture/hardware), and **Distributed Systems** (networking/coordination). Each field developed its notation independently, and many symbols mean different things depending on which community you are reading. This collision creates real confusion when the disciplines merge, which is exactly what fleet-scale ML requires.

Consider a simple statement: *"Increasing $N$ improves throughput."* To an ML researcher, $N$ might mean the number of model parameters. To a distributed systems engineer, $N$ means the number of nodes. Both interpretations are correct in their respective fields, but at fleet scale, we need both concepts in the same equation. This section establishes our notation to eliminate such ambiguity.

## Foundational Notation {#sec-vol2-notation-foundational}

This book adopts the notation conventions established for ML Systems, where ML conventions take precedence for single-letter symbols and systems concepts receive subscripts or multi-letter names. The foundational performance equation is the Iron Law of ML Systems:

$$T = \frac{D_{\text{vol}}}{\text{BW}} + \frac{O}{R_{\text{peak}} \cdot \eta} + L_{\text{lat}}$$

| **Symbol**            | **Definition**  | **Unit** | **Why This Symbol?**                                                                                                                                   |
|:----------------------|:----------------|:---------|:-------------------------------------------------------------------------------------------------------------------------------------------------------|
| **$T$**               | **Time**        | seconds  | Unambiguous. Wall-clock time for an operation.                                                                                                         |
| **$D_{\text{vol}}$**  | **Data Volume** | bytes    | **Avoids collision with $D$ (Dataset Size)**. In scaling laws, $D$ means training tokens. Here we need bytes moved through memory.                     |
| **$\text{BW}$**       | **Bandwidth**   | bytes/s  | **Avoids collision with $B$ (Batch Size)**. Physics uses $B$ for bandwidth, but every ML paper uses $B$ for batch size. We preserve the ML convention. |
| **$O$**               | **Operations**  | FLOPs    | Total floating-point operations.                                                                                                                       |
| **$R_{\text{peak}}$** | **Peak Rate**   | FLOP/s   | **Avoids collision with $P$ (Parameters)**. Roofline models use $P$ for peak performance, but ML universally uses $P$ for parameter count.             |
| **$\eta$**            | **Efficiency**  | ---      | Hardware utilization ($0 \le \eta \le 1$). Overloaded with learning rate, but context always disambiguates.                                            |
| **$L_{\text{lat}}$**  | **Latency**     | seconds  | **Avoids collision with $\mathcal{L}$ (Loss)**. Fixed overhead time (kernel launch, network RTT).                                                      |

The energy cost of ML workloads decomposes as:

$$E_{\text{total}} \approx D_{vol} \times E_{\text{move}} + O \times E_{\text{compute}}$$

| **Symbol**               | **Definition**            | **Unit**    | **Notes**                                                                                        |
|:-------------------------|:--------------------------|:------------|:-------------------------------------------------------------------------------------------------|
| **$E_{\text{move}}$**    | **Energy per Byte Moved** | joules/byte | Energy cost of data movement. Dominates total energy ($E_{\text{move}} \gg E_{\text{compute}}$). |
| **$E_{\text{compute}}$** | **Energy per Operation**  | joules/FLOP | Energy cost of a single arithmetic operation.                                                    |

## Distributed Systems Notation {#sec-vol2-notation-distributed}

Fleet-scale ML introduces a second layer of notation for coordination, communication, and reliability. The central equation of this book is the **Distributed Step Time Law**:

$$T_{\text{step}}(N) = \frac{T_{\text{compute}}}{N} + T_{\text{comm}}(N) - T_{\text{overlap}}$$

| **Symbol**               | **Definition**                 | **Unit** | **Notes**                                                               |
|:-------------------------|:-------------------------------|:---------|:------------------------------------------------------------------------|
| **$N$**                  | **Number of Devices**          | Integer  | Accelerator count in a distributed job. *(Not parameters --- use $P$.)* |
| **$T_{\text{step}}(N)$** | **Distributed Step Time**      | seconds  | Wall-clock time for one training step at scale $N$.                     |
| **$T_{\text{compute}}$** | **Single-Device Compute Time** | seconds  | Forward + backward pass on one device.                                  |
| **$T_{\text{comm}}(N)$** | **Communication Time**         | seconds  | Time for collective operations (AllReduce, AllGather). Grows with $N$.  |
| **$T_{\text{overlap}}$** | **Overlapped Time**            | seconds  | Communication hidden behind computation. Reduces effective overhead.    |
| **$T_{\text{sync}}$**    | **Synchronization Time**       | seconds  | Total non-overlapped synchronization cost per step.                     |

### The \texorpdfstring{$\alpha$-$\beta$}{α-β} Communication Model {#sec-vol2-notation-alpha-beta}

Network communication time decomposes into a fixed latency and a bandwidth-dependent transfer:

$$T(n) = \alpha + \frac{n}{\beta}$$

| **Symbol**   | **Definition**      | **Unit** | **Notes**                                                                             |
|:-------------|:--------------------|:---------|:--------------------------------------------------------------------------------------|
| **$\alpha$** | **Network Latency** | seconds  | Fixed per-message overhead. *(Not learning rate --- context disambiguates.)*          |
| **$\beta$**  | **Link Bandwidth**  | bytes/s  | Effective throughput per link.                                                        |
| **$n$**      | **Message Size**    | bytes    | Size of the payload (e.g., gradient tensor).                                          |
| **$n^*$**    | **Crossover Point** | bytes    | $n^* = \alpha \cdot \beta$. Below $n^*$: latency-bound. Above $n^*$: bandwidth-bound. |

### Scaling Efficiency {#sec-vol2-notation-scaling}

$$\eta_{\text{scaling}} = \frac{T_1}{N \times T_N} \leq 1$$

| **Symbol**                  | **Definition**         | **Unit**      | **Notes**                                                                  |
|:----------------------------|:-----------------------|:--------------|:---------------------------------------------------------------------------|
| **$\eta_{\text{scaling}}$** | **Scaling Efficiency** | Dimensionless | Fraction of ideal linear speedup achieved. $1.0$ is the theoretical limit. |
| **$T_1$**                   | **Single-Device Time** | seconds       | Baseline wall-clock time on one device.                                    |
| **$T_N$**                   | **N-Device Time**      | seconds       | Wall-clock time on $N$ devices.                                            |

### Fault Tolerance and Reliability {#sec-vol2-notation-reliability}

System reliability degrades with scale. Single-component reliability follows an exponential distribution:

$$R_{\text{system}}(t) = e^{-N\lambda t}$$

The optimal checkpoint interval balances I/O cost against rework cost:

$$\tau_{\text{opt}} = \sqrt{2 \cdot T_{\text{write}} \cdot \text{MTBF}}$$

| **Symbol**              | **Definition**                  | **Unit**    | **Notes**                                                                                                      |
|:------------------------|:--------------------------------|:------------|:---------------------------------------------------------------------------------------------------------------|
| **$R(t)$**              | **Reliability Function**        | Probability | Probability of no failure before time $t$.                                                                     |
| **$\lambda$**           | **Failure Rate**                | FIT         | Failures per billion device-hours. *(Not sensitivity --- context disambiguates.)*                              |
| **$\text{MTBF}$**       | **Mean Time Between Failures**  | hours       | Average time between consecutive failures. $\text{MTBF}_{\text{system}} = \text{MTBF}_{\text{component}} / N$. |
| **$\text{MTTR}$**       | **Mean Time To Repair**         | hours       | Average recovery time after a failure.                                                                         |
| **$\tau_{\text{opt}}$** | **Optimal Checkpoint Interval** | seconds     | Young-Daly formula. Minimizes total wasted time.                                                               |
| **$T_{\text{write}}$**  | **Checkpoint Write Time**       | seconds     | Time to persist model state to storage.                                                                        |

### Parallelism Dimensions {#sec-vol2-notation-parallelism}

Large-scale training partitions the workload across three orthogonal dimensions:

$$N_{\text{total}} = d \times p \times t$$

| **Symbol** | **Definition**           | **Unit** | **Notes**                                                                      |
|:-----------|:-------------------------|:---------|:-------------------------------------------------------------------------------|
| **$d$**    | **Data Parallelism**     | Integer  | Number of model replicas. *(Also hidden dimension --- context disambiguates.)* |
| **$p$**    | **Pipeline Parallelism** | Integer  | Number of pipeline stages (model depth partitioning).                          |
| **$t$**    | **Tensor Parallelism**   | Integer  | Degree of intra-layer partitioning (model width).                              |
| **$M$**    | **Gradient Size**        | bytes    | Total size of gradient or model state to communicate.                          |

## Deep Learning Notation {#sec-vol2-notation-deep-learning}

We follow standard deep learning conventions with explicit disambiguation for systems and distributed variables.

| **Symbol**        | **Definition**       | **Dimensions / Type**                                                                                 |
|:------------------|:---------------------|:------------------------------------------------------------------------------------------------------|
| **$B$**           | **Batch Size**       | Integer. The number of samples processed in parallel. *(Never bandwidth.)*                            |
| **$P$**           | **Parameters**       | Integer. The total count of trainable weights in a model. *(Never peak FLOP/s.)*                      |
| **$D$**           | **Dataset Size**     | Integer. Number of training samples or tokens. *(Never data volume in bytes --- use $D_{vol}$.)*      |
| **$S$**           | **Sequence Length**  | Integer. Number of tokens or time steps.                                                              |
| **$d$**           | **Hidden Dimension** | Integer. Size of the hidden state vector. *(Also data parallelism degree --- context disambiguates.)* |
| **$\mathcal{L}$** | **Loss Function**    | Scalar. The objective function minimized during training.                                             |
| **$\eta$**        | **Learning Rate**    | Scalar. Step size for the optimizer. *(Also efficiency --- context distinguishes.)*                   |
| **$\theta$**      | **Model Weights**    | Vector/Matrix. The set of all learnable parameters.                                                   |

## Units and Precision {#sec-vol2-notation-units}

*   **Physical Units**: This book uses SI (metric) units throughout --- meters, kilograms, seconds, watts, °C --- consistent with standard engineering and scientific practice. A space always separates the number from the unit (e.g., 100 ms, 2 TB/s).
*   **Data and memory**: We use **decimal SI prefixes only**: KB = $10^3$ bytes, MB = $10^6$, GB = $10^9$, TB = $10^{12}$. We do not use binary units (KiB, MiB, GiB) in prose; all capacities, throughputs, and model sizes are reported in decimal units (e.g., 80 GB, 2 TB/s, 102 MB).
*   **Compute**: We use decimal prefixes for operations (e.g., GFLOPs, TFLOPs).
    *   1 TFLOP = $10^{12}$ FLOPs
*   **Network throughput**: Reported in both bytes/s (GB/s, TB/s) and bits/s (Gbps) depending on convention. InfiniBand and Ethernet specifications use Gbps; application-level throughput uses GB/s. We note the convention on first use.
*   **Precision**:
    *   **FP32**: Single precision (4 bytes)
    *   **FP16**: Half precision (2 bytes, standard range)
    *   **BF16**: Brain float (2 bytes, wide dynamic range)
    *   **FP8**: Quarter precision (1 byte, E4M3 or E5M2 format)
    *   **INT8**: 8-bit integer (1 byte)

## Quick Reference: Resolving Collisions {#sec-vol2-notation-collisions}

When reading ML Systems literature (including this book), watch for these common collision points:

| **Symbol** | **ML Meaning**   | **Systems / Distributed Meaning** | **Our Convention**                                                              |
|:-----------|:-----------------|:----------------------------------|:--------------------------------------------------------------------------------|
| $B$        | Batch Size       | Bandwidth                         | **Batch Size**. Use $BW$ for bandwidth.                                         |
| $P$        | Parameters       | Peak FLOP/s                       | **Parameters**. Use $R_{peak}$ for peak rate.                                   |
| $D$        | Dataset Size     | Data Volume                       | **Dataset Size**. Use $D_{vol}$ for bytes moved.                                |
| $N$        | ---              | Number of Nodes / Devices         | **Device Count** in distributed context.                                        |
| $L$        | Loss             | Latency                           | **Loss** ($\mathcal{L}$). Use $L_{lat}$ for latency.                            |
| $\alpha$   | ---              | Network Latency / Learning rate   | **Network latency** in $\alpha$-$\beta$ model. Context disambiguates.           |
| $\lambda$  | Sensitivity      | Failure Rate                      | **Context-dependent**. Sensitivity in degradation; failure rate in reliability. |
| $\eta$     | Learning Rate    | Efficiency                        | **Context-dependent**. Never both in the same equation.                         |
| $d$        | Hidden Dimension | Data Parallelism Degree           | **Context-dependent**. Parallelism in 3D notation; hidden dim in architectures. |

The general principle: **ML conventions take precedence for single letters**; systems and distributed concepts get subscripts or multi-letter symbols. This reflects the primary audience (ML practitioners learning fleet-scale systems) and preserves compatibility with the vast ML literature.

```{=latex}
\part{key:volume_2}
```
```{=latex}
\part{key:vol2_fleet}
```
