@inproceedings{aji2017sparse,
  title = {Sparse Communication for Distributed Gradient Descent},
  author = {Aji, Alham Fikri and Heafield, Kenneth},
  year = {2017},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  pages = {440--445},
  doi = {10.18653/v1/d17-1045},
  url = {https://doi.org/10.18653/v1/d17-1045},
  source = {Crossref},
}

@inproceedings{alexandrov1995loggp,
  title = {LogGP},
  author = {Alexandrov, Albert and Ionescu, Mihai F. and Schauser, Klaus E. and Scheiman, Chris},
  year = {1995},
  journal = {ACM SIGPLAN Notices},
  booktitle = {
    Proceedings of the seventh annual ACM symposium on Parallel algorithms and architectures  -
    SPAA '95
  },
  publisher = {ACM Press},
  volume = {30},
  number = {7},
  pages = {95--105},
  doi = {10.1145/215399.215427},
  url = {https://doi.org/10.1145/215399.215427},
  source = {Crossref},
  subtitle = {
    incorporating long messages into the LogP model---one step closer towards a realistic model for
    parallel computation
  },
}

% Network Topologies
@article{alfares2008scalable,
  title = {A scalable, commodity data center network architecture},
  author = {Al-Fares, Mohammad and Loukissas, Alexander and Vahdat, Amin},
  year = {2008},
  month = aug,
  journal = {ACM SIGCOMM Computer Communication Review},
  booktitle = {ACM SIGCOMM Computer Communication Review},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {38},
  number = {4},
  pages = {63--74},
  doi = {10.1145/1402946.1402967},
  issn = {0146-4833},
  url = {https://doi.org/10.1145/1402946.1402967},
  source = {Crossref},
}

% Gradient Compression
@inproceedings{alistarh2017qsgd,
  title = {QSGD: Communication-efficient SGD via gradient quantization and encoding},
  author = {Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  year = {2017},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
}

% Large Language Models
@inproceedings{brown2020language,
  title = {Language models are few-shot learners},
  author = {
    Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and
    Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell,
    Amanda and others
  },
  year = {2020},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {1877--1901},
}

@article{chowdhery2022palm,
  title = {PaLM: Scaling Language Modeling with Pathways},
  author = {
    Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav
    and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann,
    Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and
    Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and
    Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin,
    Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya,
    Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and
    Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and
    Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and
    Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai,
    Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and
    Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and
    Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and
    Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah
  },
  year = {2022},
  month = apr,
  journal = {arXiv preprint arXiv:2204.02311},
  url = {http://arxiv.org/abs/2204.02311v5},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
}

% Bibliography for Communication and Collective Operations chapter

% Foundational Communication Models
@article{culler1993logp,
  title = {LogP: towards a realistic model of parallel computation},
  author = {
    Culler, David and Karp, Richard and Patterson, David and Sahay, Abhijit and Schauser, Klaus
    Erik and Santos, Eunice and Subramonian, Ramesh and von Eicken, Thorsten
  },
  year = {1993},
  month = jul,
  journal = {ACM SIGPLAN Notices},
  booktitle = {ACM SIGPLAN Notices},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {28},
  number = {7},
  pages = {1--12},
  doi = {10.1145/173284.155333},
  issn = {0362-1340,1558-1160},
  url = {https://doi.org/10.1145/173284.155333},
  source = {Crossref},
  organization = {ACM},
}

% Mixture of Experts
@article{fedus2022switch,
  title = {Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author = {Fedus, William and Zoph, Barret and Shazeer, Noam},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {120},
  pages = {1--39},
}

% Ring AllReduce and Distributed Deep Learning
@article{gibiansky2017baidu,
  title = {BRINGING BACK OLD PHOTOS INTO LIFE USING DEEP LEARNING TECHNIQUES},
  author = {Gibiansky, Andrew},
  year = {2022},
  month = sep,
  journal = {International Journal For Innovative Engineering and Management Research},
  publisher = {Institute for Advanced Studies},
  pages = {527--536},
  doi = {10.48047/ijiemr/v11/i06/32},
  issn = {2456-5083},
  url = {https://doi.org/10.48047/ijiemr/v11/i06/32},
  source = {Crossref},
  howpublished = {Baidu Research Blog},
}

% In-Network Computing
@inproceedings{graham2020sharp,
  title = {
    Scalable hierarchical aggregation and reduction protocol (SHARP) streaming-aggregation hardware
    design and evaluation
  },
  author = {
    Graham, Richard L and Bureddy, Devendar and Lui, Pak and Rober, Hal and Bloch, Gilad and
    Shainer, Gilad and Poole, Jeff and Tygert, Mark and Nguyen, Phil and Srivastava, Anurag and
    others
  },
  year = {2020},
  booktitle = {International Conference on High Performance Computing},
  pages = {41--59},
  organization = {Springer},
}

% Graph Neural Networks
@inproceedings{hamilton2017graphsage,
  title = {Inductive representation learning on large graphs},
  author = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
  year = {2017},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
}

% NVIDIA NCCL
@misc{jeaugey2017nccl,
  title = {NCCL 2.0},
  author = {Jeaugey, Sylvain},
  year = {2017},
  url = {https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2/},
  howpublished = {NVIDIA Developer Blog},
}

% TPU and Hardware
@inproceedings{jouppi2023tpuv4,
  title = {
    TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support
    for Embeddings
  },
  author = {
    Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai,
    Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young,
    Clifford and Zhou, Xiang and Zhou, Zongwei and Patterson, David A
  },
  year = {2023},
  month = jun,
  booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
  publisher = {ACM},
  pages = {1--14},
  doi = {10.1145/3579371.3589350},
  url = {https://doi.org/10.1145/3579371.3589350},
  source = {Crossref},
}

@article{karypis1998metis,
  title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
  author = {Karypis, George and Kumar, Vipin},
  year = {1998},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  publisher = {Society for Industrial \& Applied Mathematics (SIAM)},
  volume = {20},
  number = {1},
  pages = {359--392},
  doi = {10.1137/s1064827595287997},
  issn = {1064-8275,1095-7197},
  url = {https://doi.org/10.1137/s1064827595287997},
  source = {Crossref},
}

@inproceedings{kim2008dragonfly,
  title = {Technology-Driven, Highly-Scalable Dragonfly Topology},
  author = {Kim, John and Dally, Wiliam J. and Scott, Steve and Abts, Dennis},
  year = {2008},
  month = jun,
  booktitle = {2008 International Symposium on Computer Architecture},
  publisher = {IEEE},
  pages = {77--88},
  doi = {10.1109/isca.2008.19},
  url = {https://doi.org/10.1109/isca.2008.19},
  source = {Crossref},
}

@inproceedings{lepikhin2021gshard,
  title = {GShard: Scaling giant models with conditional computation and automatic sharding},
  author = {
    Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and
    Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng
  },
  year = {2021},
  booktitle = {International Conference on Learning Representations},
}

@article{li2020pytorch,
  title = {PyTorch distributed},
  author = {
    Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li,
    Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala,
    Soumith
  },
  year = {2020},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {13},
  number = {12},
  pages = {3005--3018},
  doi = {10.14778/3415478.3415530},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3415478.3415530},
  source = {Crossref},
  subtitle = {experiences on accelerating data parallel training},
}

@inproceedings{lin2018deep,
  title = {Deep gradient compression: Reducing the communication bandwidth for distributed training},
  author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J},
  year = {2018},
  booktitle = {International Conference on Learning Representations},
}

% MPI Standard
@inproceedings{mpi2021standard,
  title = {MPI},
  year = {1993},
  booktitle = {Proceedings of the 1993 ACM/IEEE conference on Supercomputing  - Supercomputing '93},
  publisher = {ACM Press},
  pages = {878--883},
  doi = {10.1145/169627.169855},
  url = {https://doi.org/10.1145/169627.169855},
  source = {Crossref},
  subtitle = {a message passing interface},
  institution = {Message Passing Interface Forum},
}

@inproceedings{narayanan2021megatron,
  title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
  author = {
    Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary,
    Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer,
    Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei
  },
  year = {2021},
  month = nov,
  booktitle = {
    Proceedings of the International Conference for High Performance Computing, Networking, Storage
    and Analysis
  },
  publisher = {ACM},
  pages = {1--15},
  doi = {10.1145/3458817.3476209},
  url = {https://doi.org/10.1145/3458817.3476209},
  source = {Crossref},
}

% Recommendation Systems
@article{naumov2019dlrm,
  title = {Deep Learning Recommendation Model for Personalization and Recommendation Systems},
  author = {
    Naumov, Maxim and Mudigere, Dheevatsa and Shi, Hao-Jun Michael and Huang, Jianyu and
    Sundaraman, Narayanan and Park, Jongsoo and Wang, Xiaodong and Gupta, Udit and Wu, Carole-Jean
    and Azzolini, Alisson G. and Dzhulgakov, Dmytro and Mallevich, Andrey and Cherniavskii, Ilia
    and Lu, Yinghai and Krishnamoorthi, Raghuraman and Yu, Ansha and Kondratenko, Volodymyr and
    Pereira, Stephanie and Chen, Xianjie and Chen, Wenlin and Rao, Vijay and Jia, Bill and Xiong,
    Liang and Smelyanskiy, Misha
  },
  year = {2019},
  month = may,
  journal = {arXiv preprint arXiv:1906.00091},
  url = {http://arxiv.org/abs/1906.00091v1},
  primaryclass = {cs.IR},
  archiveprefix = {arXiv},
}

@inproceedings{rajbhandari2020zero,
  title = {ZeRO: Memory optimizations Toward Training Trillion Parameter Models},
  author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = nov,
  booktitle = {
    SC20: International Conference for High Performance Computing, Networking, Storage and Analysis
  },
  publisher = {IEEE},
  pages = {1--16},
  doi = {10.1109/sc41405.2020.00024},
  url = {https://doi.org/10.1109/sc41405.2020.00024},
  source = {Crossref},
  organization = {IEEE},
}

@article{sergeev2018horovod,
  title = {Horovod: fast and easy distributed deep learning in TensorFlow},
  author = {Sergeev, Alexander and Balso, Mike Del},
  year = {2018},
  month = feb,
  journal = {arXiv preprint arXiv:1802.05799},
  url = {http://arxiv.org/abs/1802.05799v3},
  primaryclass = {cs.LG},
  archiveprefix = {arXiv},
}

% Distributed Training Frameworks
@article{shoeybi2019megatron,
  title = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  author = {
    Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared
    and Catanzaro, Bryan
  },
  year = {2019},
  month = sep,
  journal = {arXiv preprint arXiv:1909.08053},
  url = {http://arxiv.org/abs/1909.08053v4},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
}

% Gradient Compression
@inproceedings{vogels2020powersgd,
  title = {PowerSGD: Practical low-rank gradient compression for distributed optimization},
  author = {Vogels, Thijs and Karimireddy, Sai Praneeth and Jaggi, Martin},
  year = {2019},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {32},
}

@article{zhao2023fsdp,
  title = {PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel},
  author = {
    Zhao, Yanli and Gu, Andrew and Varma, Rohan and Luo, Liang and Huang, Chien-Chin and Xu, Min
    and Wright, Less and Shojanazeri, Hamid and Ott, Myle and Shleifer, Sam and Desmaison, Alban
    and Balioglu, Can and Damania, Pritam and Nguyen, Bernard and Chauhan, Geeta and Hao, Yuchen
    and Mathews, Ajit and Li, Shen
  },
  year = {2023},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  volume = {16},
  number = {12},
  pages = {3848--3860},
  doi = {10.14778/3611540.3611569},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3611540.3611569},
  source = {Crossref},
}
