@inproceedings{aji2017sparse,
  doi = {10.18653/v1/d17-1045},
  source = {Crossref},
  author = {Aji, Alham Fikri and Heafield, Kenneth},
  year = {2017},
  url = {https://doi.org/10.18653/v1/d17-1045},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural
          Language Processing},
  publisher = {Association for Computational Linguistics},
  title = {Sparse Communication for Distributed Gradient Descent},
  pages = {440--445},
}

@inproceedings{alexandrov1995loggp,
  doi = {10.1145/215399.215427},
  pages = {95--105},
  source = {Crossref},
  author = {Alexandrov, Albert and Ionescu, Mihai F. and Schauser, Klaus E. and Scheiman, Chris},
  subtitle = {incorporating long messages into the LogP model---one step closer towards a realistic model for parallel computation},
  year = {1995},
  url = {https://doi.org/10.1145/215399.215427},
  booktitle = {Proceedings of the seventh annual ACM symposium on Parallel algorithms and architectures  - SPAA '95},
  publisher = {ACM Press},
  title = {LogGP},
  journal = {ACM SIGPLAN Notices},
  volume = {30},
  number = {7},
}

% Network Topologies

@article{alfares2008scalable,
  number = {4},
  doi = {10.1145/1402946.1402967},
  pages = {63--74},
  source = {Crossref},
  volume = {38},
  author = {Al-Fares, Mohammad and Loukissas, Alexander and Vahdat, Amin},
  year = {2008},
  month = aug,
  url = {https://doi.org/10.1145/1402946.1402967},
  issn = {0146-4833},
  journal = {ACM SIGCOMM Computer Communication Review},
  publisher = {Association for Computing Machinery (ACM)},
  title = {A scalable, commodity data center network architecture},
  booktitle = {ACM SIGCOMM Computer Communication Review},
}

% Gradient Compression

@inproceedings{alistarh2017qsgd,
  author = {Alistarh, Dan and Grubic, Demjan and 0001, Jerry Li and Tomioka, Ryota and Vojnovic, Milan},
  title = {QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding.},
  journal = {NIPS},
  pages = {1709--1720},
  year = {2017},
  url = {https://proceedings.neurips.cc/paper/2017/hash/6c340f25839e6acdc73414517203f5f0-Abstract.html},
  source = {DBLP},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
}

% Large Language Models

@inproceedings{brown2020language,
  title = {Language models are few-shot learners},
  author = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  year = {2020},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {1877--1901},
}

@article{chowdhery2022palm,
  url = {http://arxiv.org/abs/2204.02311v5},
  title = {PaLM: Scaling Language Modeling with Pathways},
  year = {2022},
  month = apr,
  primaryclass = {cs.CL},
  author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2204.02311},
}

% Bibliography for Communication and Collective Operations chapter

% Foundational Communication Models

@article{culler1993logp,
  number = {7},
  doi = {10.1145/173284.155333},
  pages = {1--12},
  source = {Crossref},
  volume = {28},
  author = {Culler, David and Karp, Richard and Patterson, David and Sahay, Abhijit and Schauser, Klaus Erik and Santos, Eunice and Subramonian, Ramesh and von Eicken, Thorsten},
  year = {1993},
  month = jul,
  url = {https://doi.org/10.1145/173284.155333},
  issn = {0362-1340,1558-1160},
  journal = {ACM SIGPLAN Notices},
  publisher = {Association for Computing Machinery (ACM)},
  title = {LogP: towards a realistic model of parallel computation},
  booktitle = {ACM SIGPLAN Notices},
  organization = {ACM},
}

% Mixture of Experts

@article{fedus2022switch,
  title = {Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author = {Fedus, William and Zoph, Barret and Shazeer, Noam},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {120},
  pages = {1--39},
}

% Ring AllReduce and Distributed Deep Learning

@article{gibiansky2017baidu,
  doi = {10.48047/ijiemr/v11/i06/32},
  pages = {527--536},
  source = {Crossref},
  year = {2022},
  month = sep,
  url = {https://doi.org/10.48047/ijiemr/v11/i06/32},
  issn = {2456-5083},
  journal = {International Journal For Innovative Engineering and Management Research},
  publisher = {Institute for Advanced Studies},
  title = {BRINGING BACK OLD PHOTOS INTO LIFE USING
DEEP LEARNING TECHNIQUES},
  author = {Gibiansky, Andrew},
  howpublished = {Baidu Research Blog},
}

% In-Network Computing

@inproceedings{graham2020sharp,
  title = {
    Scalable hierarchical aggregation and reduction protocol (SHARP) streaming-aggregation hardware
    design and evaluation
  },
  author = {Graham, Richard L and Bureddy, Devendar and Lui, Pak and Rober, Hal and Bloch, Gilad and Shainer, Gilad and Poole, Jeff and Tygert, Mark and Nguyen, Phil and Srivastava, Anurag and others},
  year = {2020},
  booktitle = {International Conference on High Performance Computing},
  pages = {41--59},
  organization = {Springer},
}

% Graph Neural Networks

@inproceedings{hamilton2017graphsage,
  title = {Inductive representation learning on large graphs},
  author = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
  year = {2017},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
}

% NVIDIA NCCL

@misc{jeaugey2017nccl,
  title = {NCCL 2.0},
  author = {Jeaugey, Sylvain},
  year = {2017},
  url = {https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2/},
  howpublished = {NVIDIA Developer Blog},
}

% TPU and Hardware

@inproceedings{jouppi2023tpuv4,
  doi = {10.1145/3579371.3589350},
  pages = {1--14},
  source = {Crossref},
  author = {Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young, Clifford and Zhou, Xiang and Zhou, Zongwei and Patterson, David A},
  year = {2023},
  month = jun,
  url = {https://doi.org/10.1145/3579371.3589350},
  booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
  publisher = {ACM},
  title = {TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings},
}

@article{karypis1998metis,
  number = {1},
  doi = {10.1137/s1064827595287997},
  pages = {359--392},
  source = {Crossref},
  volume = {20},
  author = {Karypis, George and Kumar, Vipin},
  year = {1998},
  month = jan,
  url = {https://doi.org/10.1137/s1064827595287997},
  issn = {1064-8275,1095-7197},
  journal = {SIAM Journal on Scientific Computing},
  publisher = {Society for Industrial \& Applied Mathematics (SIAM)},
  title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
}

@inproceedings{kim2008dragonfly,
  doi = {10.1109/isca.2008.19},
  pages = {77--88},
  source = {Crossref},
  author = {Kim, John and Dally, Wiliam J. and Scott, Steve and Abts, Dennis},
  year = {2008},
  month = jun,
  url = {https://doi.org/10.1109/isca.2008.19},
  booktitle = {2008 International Symposium on Computer Architecture},
  publisher = {IEEE},
  title = {Technology-Driven, Highly-Scalable Dragonfly Topology},
}

@inproceedings{lepikhin2021gshard,
  title = {GShard: Scaling giant models with conditional computation and automatic sharding},
  author = {Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  year = {2021},
  booktitle = {International Conference on Learning Representations},
}

@article{li2020pytorch,
  number = {12},
  doi = {10.14778/3415478.3415530},
  pages = {3005--3018},
  source = {Crossref},
  volume = {13},
  author = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala, Soumith},
  subtitle = {experiences on accelerating data parallel training},
  year = {2020},
  month = aug,
  url = {https://doi.org/10.14778/3415478.3415530},
  issn = {2150-8097},
  journal = {Proceedings of the VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  title = {PyTorch distributed},
}

@inproceedings{lin2018deep,
  title = {Deep gradient compression: Reducing the communication bandwidth for distributed training},
  author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J},
  year = {2018},
  booktitle = {International Conference on Learning Representations},
}

% MPI Standard

@inproceedings{mpi2021standard,
  doi = {10.1145/169627.169855},
  pages = {878--883},
  source = {Crossref},
  author = {},
  subtitle = {a message passing interface},
  year = {1993},
  url = {https://doi.org/10.1145/169627.169855},
  booktitle = {Proceedings of the 1993 ACM/IEEE conference on Supercomputing  - Supercomputing '93},
  publisher = {ACM Press},
  title = {MPI},
  institution = {Message Passing Interface Forum},
}

@inproceedings{narayanan2021megatron,
  doi = {10.1145/3458817.3476209},
  pages = {1--15},
  source = {Crossref},
  author = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei},
  year = {2021},
  month = nov,
  url = {https://doi.org/10.1145/3458817.3476209},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  publisher = {ACM},
  title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
}

% Recommendation Systems

@article{naumov2019dlrm,
  url = {http://arxiv.org/abs/1906.00091v1},
  title = {Deep Learning Recommendation Model for Personalization and Recommendation Systems},
  year = {2019},
  month = may,
  primaryclass = {cs.IR},
  author = {Naumov, Maxim and Mudigere, Dheevatsa and Shi, Hao-Jun Michael and Huang, Jianyu and Sundaraman, Narayanan and Park, Jongsoo and Wang, Xiaodong and Gupta, Udit and Wu, Carole-Jean and Azzolini, Alisson G. and Dzhulgakov, Dmytro and Mallevich, Andrey and Cherniavskii, Ilia and Lu, Yinghai and Krishnamoorthi, Raghuraman and Yu, Ansha and Kondratenko, Volodymyr and Pereira, Stephanie and Chen, Xianjie and Chen, Wenlin and Rao, Vijay and Jia, Bill and Xiong, Liang and Smelyanskiy, Misha},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1906.00091},
}

@inproceedings{rajbhandari2020zero,
  doi = {10.1109/sc41405.2020.00024},
  pages = {1--16},
  source = {Crossref},
  author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = nov,
  url = {https://doi.org/10.1109/sc41405.2020.00024},
  booktitle = {SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  publisher = {IEEE},
  title = {ZeRO: Memory optimizations Toward Training Trillion Parameter Models},
  organization = {IEEE},
}

@article{sergeev2018horovod,
  url = {http://arxiv.org/abs/1802.05799v3},
  title = {Horovod: fast and easy distributed deep learning in TensorFlow},
  year = {2018},
  month = feb,
  primaryclass = {cs.LG},
  author = {Sergeev, Alexander and Balso, Mike Del},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1802.05799},
}

% Distributed Training Frameworks

@article{shoeybi2019megatron,
  url = {http://arxiv.org/abs/1909.08053v4},
  title = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  year = {2019},
  month = sep,
  primaryclass = {cs.CL},
  author = {Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1909.08053},
}

% Gradient Compression

@inproceedings{vogels2020powersgd,
  title = {PowerSGD: Practical low-rank gradient compression for distributed optimization},
  author = {Vogels, Thijs and Karimireddy, Sai Praneeth and Jaggi, Martin},
  year = {2019},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {32},
}

@article{zhao2023fsdp,
  number = {12},
  doi = {10.14778/3611540.3611569},
  pages = {3848--3860},
  source = {Crossref},
  volume = {16},
  author = {Zhao, Yanli and Gu, Andrew and Varma, Rohan and Luo, Liang and Huang, Chien-Chin and Xu, Min and Wright, Less and Shojanazeri, Hamid and Ott, Myle and Shleifer, Sam and Desmaison, Alban and Balioglu, Can and Damania, Pritam and Nguyen, Bernard and Chauhan, Geeta and Hao, Yuchen and Mathews, Ajit and Li, Shen},
  year = {2023},
  month = aug,
  url = {https://doi.org/10.14778/3611540.3611569},
  issn = {2150-8097},
  journal = {Proceedings of the VLDB Endowment},
  publisher = {Association for Computing Machinery (ACM)},
  title = {PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel},
}