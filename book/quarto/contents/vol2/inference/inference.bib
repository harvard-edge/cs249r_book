@article{agrawal2023sarathi,
  url = {http://arxiv.org/abs/2308.16369v1},
  title = {SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills},
  year = {2023},
  month = aug,
  primaryclass = {cs.LG},
  author = {Agrawal, Amey and Panwar, Ashish and Mohan, Jayashree and Kwatra, Nipun and Gulavani, Bhargav S. and Ramjee, Ramachandran},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2308.16369},
}

@inproceedings{ainslie2023gqa,
  doi = {10.18653/v1/2023.emnlp-main.298},
  pages = {4895--4901},
  source = {Crossref},
  author = {Ainslie, Joshua and Lee-Thorp, James and de Jong, Michiel and Zemlyanskiy, Yury and Lebron, Federico and Sanghai, Sumit},
  year = {2023},
  url = {https://doi.org/10.18653/v1/2023.emnlp-main.298},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  title = {GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
}

@inproceedings{ashkboos2024quarot,
  doi = {10.52202/079017-3180},
  pages = {100213--100240},
  source = {Crossref},
  author = {Alistarh, Dan and Ashkboos, Saleh and Cameron, Pashmina and Croci, Maximilian and Hensman, James and Hoefler, Torsten and Jaggi, Martin and Li, Bo and Mohtashami, Amirkeivan},
  year = {2024},
  url = {https://doi.org/10.52202/079017-3180},
  booktitle = {Advances in Neural Information Processing Systems 37},
  publisher = {Neural Information Processing Systems Foundation, Inc. (NeurIPS)},
  title = {QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs},
}

@inproceedings{brown2020gpt3,
  title = {Language Models are Few-Shot Learners},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  year = {2020},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {1877--1901},
}

@article{chen2023accelerating,
  url = {http://arxiv.org/abs/2302.01318v1},
  title = {Accelerating Large Language Model Decoding with Speculative Sampling},
  year = {2023},
  month = feb,
  primaryclass = {cs.CL},
  author = {Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2302.01318},
}

% ============================================================================
% Attention Mechanisms and Architectures
% ============================================================================

@inproceedings{dao2022flashattention,
  title = {FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  author = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R\'e, Christopher},
  year = {2022},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {16344--16359},
}

% ============================================================================
% Quantization Methods
% ============================================================================

@misc{frantar2023gptq,
  title = {GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers.},
  author = {Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  year = {2022},
  journal = {CoRR},
  booktitle = {International Conference on Learning Representations},
  volume = {abs/2210.17323},
  doi = {10.48550/ARXIV.2210.17323},
  url = {https://doi.org/10.48550/arXiv.2210.17323},
  source = {DBLP},
}

@article{jiang2024mixtral,
  url = {http://arxiv.org/abs/2401.04088v1},
  title = {Mixtral of Experts},
  year = {2024},
  month = jan,
  primaryclass = {cs.LG},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Hanna, Emma Bou and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, L\'elio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Scao, Teven Le and Gervet, Th\'eophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timoth\'ee and Sayed, William El},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2401.04088},
}

@inproceedings{karger1997consistent,
  doi = {10.1145/258533.258660},
  pages = {654--663},
  source = {Crossref},
  author = {Karger, David and Lehman, Eric and Leighton, Tom and Panigrahy, Rina and Levine, Matthew and Lewin, Daniel},
  subtitle = {distributed caching protocols for relieving hot spots on the World Wide Web},
  year = {1997},
  url = {https://doi.org/10.1145/258533.258660},
  booktitle = {Proceedings of the twenty-ninth annual ACM symposium on Theory of computing  - STOC '97},
  publisher = {ACM Press},
  title = {Consistent hashing and random trees},
  organization = {ACM},
}

@inproceedings{kwon2023vllm,
  doi = {10.1145/3600006.3613165},
  pages = {611--626},
  source = {Crossref},
  author = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  year = {2023},
  month = oct,
  url = {https://doi.org/10.1145/3600006.3613165},
  booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
  publisher = {ACM},
  title = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
}

% ============================================================================
% Speculative Decoding
% ============================================================================

@inproceedings{leviathan2023speculative,
  title = {Fast Inference from Transformers via Speculative Decoding},
  author = {Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  year = {2023},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages = {19274--19286},
  organization = {PMLR},
}

@article{lin2024awq,
  number = {4},
  doi = {10.1145/3714983.3714987},
  pages = {12--17},
  source = {Crossref},
  volume = {28},
  author = {Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Xiao, Guangxuan and Han, Song},
  year = {2025},
  month = jan,
  url = {https://doi.org/10.1145/3714983.3714987},
  issn = {2375-0529,2375-0537},
  journal = {GetMobile: Mobile Computing and Communications},
  publisher = {Association for Computing Machinery (ACM)},
  title = {AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration},
  booktitle = {Proceedings of Machine Learning and Systems},
}

% ============================================================================
% Load Balancing and Distributed Systems
% ============================================================================

@article{mitzenmacher2001power,
  number = {10},
  doi = {10.1109/71.963420},
  pages = {1094--1104},
  source = {Crossref},
  volume = {12},
  author = {Mitzenmacher, M.},
  year = {2001},
  url = {https://doi.org/10.1109/71.963420},
  issn = {1045-9219},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  title = {The power of two choices in randomized load balancing},
}

% ============================================================================
% Distributed Computing Frameworks
% ============================================================================

@inproceedings{moritz2018ray,
  author = {Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I. and Stoica, Ion},
  title = {Ray: A Distributed Framework for Emerging AI Applications.},
  journal = {OSDI},
  pages = {561--577},
  year = {2018},
  url = {https://www.usenix.org/conference/osdi18/presentation/nishihara},
  source = {DBLP},
  booktitle = {13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
  organization = {USENIX Association},
}

% ============================================================================
% Recommendation Systems
% ============================================================================

@article{naumov2019dlrm,
  url = {http://arxiv.org/abs/1906.00091v1},
  title = {Deep Learning Recommendation Model for Personalization and Recommendation Systems},
  year = {2019},
  month = may,
  primaryclass = {cs.IR},
  author = {Naumov, Maxim and Mudigere, Dheevatsa and Shi, Hao-Jun Michael and Huang, Jianyu and Sundaraman, Narayanan and Park, Jongsoo and Wang, Xiaodong and Gupta, Udit and Wu, Carole-Jean and Azzolini, Alisson G. and Dzhulgakov, Dmytro and Mallevich, Andrey and Cherniavskii, Ilia and Lu, Yinghai and Krishnamoorthi, Raghuraman and Yu, Ansha and Kondratenko, Volodymyr and Pereira, Stephanie and Chen, Xianjie and Chen, Wenlin and Rao, Vijay and Jia, Bill and Xiong, Liang and Smelyanskiy, Misha},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1906.00091},
}

% ============================================================================
% Software Engineering and Fault Tolerance
% ============================================================================

@book{nygard2007releaseit,
  title = {Release It!: Design and Deploy Production-Ready Software},
  author = {Nygard, Michael T.},
  year = {2007},
  publisher = {Pragmatic Bookshelf},
}

% ============================================================================
% Model Parallelism and Distributed Training
% ============================================================================

@article{shoeybi2019megatron,
  url = {http://arxiv.org/abs/1909.08053v4},
  title = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  year = {2019},
  month = sep,
  primaryclass = {cs.CL},
  author = {Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:1909.08053},
}

% ============================================================================
% Large Language Models
% ============================================================================

@article{touvron2023llama2,
  url = {http://arxiv.org/abs/2307.09288v2},
  title = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  year = {2023},
  month = jul,
  primaryclass = {cs.CL},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2307.09288},
}

@inproceedings{xiao2023smoothquant,
  author = {Xiao, Guangxuan and 0002, Ji Lin and Seznec, Micka\"el and Wu, Hao and Demouth, Julien and 0003, Song Han},
  title = {SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models.},
  journal = {ICML},
  pages = {38087--38099},
  year = {2023},
  url = {https://proceedings.mlr.press/v202/xiao23c.html},
  source = {DBLP},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  organization = {PMLR},
}

% Bibliography for Inference at Scale chapter

% ============================================================================
% Continuous Batching and LLM Serving Systems
% ============================================================================

@inproceedings{yu2022orca,
  author = {Yu, Gyeong-In and Jeong, Joo Seong and Kim, Geon-Woo and Kim, Soojeong and Chun, Byung-Gon},
  title = {Orca: A Distributed Serving System for Transformer-Based Generative Models.},
  journal = {OSDI},
  pages = {521--538},
  year = {2022},
  url = {https://www.usenix.org/conference/osdi22/presentation/yu},
  source = {DBLP},
  booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  organization = {USENIX Association},
}