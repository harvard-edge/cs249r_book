{
  "metadata": {
    "chapter": "frameworks",
    "version": "1.0.0",
    "generated": "2025-09-15T14:08:03.495518",
    "total_terms": 42,
    "standardized": true,
    "last_updated": "2025-09-15T15:01:37.286395"
  },
  "terms": [
    {
      "term": "activation function",
      "definition": "A mathematical function applied to the output of a neural network layer to introduce non-linearity, enabling the network to learn complex patterns. Common activation functions include ReLU, sigmoid, tanh, and softmax.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "automatic differentiation",
      "definition": "A computational technique that automatically calculates exact derivatives of functions implemented as computer programs by systematically applying the chain rule at the elementary operation level, essential for training neural networks through gradient-based optimization.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "backpropagation",
      "definition": "The algorithm used to train neural networks by computing gradients of the loss function with respect to network parameters through reverse-mode automatic differentiation, enabling efficient parameter updates during training.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "batch normalization",
      "definition": "A technique that normalizes the inputs to each layer in a neural network to have zero mean and unit variance, which helps stabilize training and allows higher learning rates.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "blas",
      "definition": "Basic Linear Algebra Subprograms, a specification for low-level routines that perform common linear algebra operations such as vector addition, scalar multiplication, dot products, and matrix operations, forming the computational foundation of modern ML frameworks.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "computational graph",
      "definition": "A directed acyclic graph representation of mathematical operations where nodes represent operations or variables and edges represent data flow, enabling automatic differentiation and optimization of neural network computations.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "convolution",
      "definition": "A mathematical operation fundamental to convolutional neural networks that applies filters (kernels) to input data to extract features such as edges, textures, or patterns, particularly effective for processing images and spatial data.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "cublas",
      "definition": "NVIDIA's CUDA Basic Linear Algebra Subprograms library that provides GPU-accelerated implementations of standard linear algebra operations, enabling high-performance matrix computations on NVIDIA graphics processing units.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "cuda",
      "definition": "NVIDIA's parallel computing platform and programming model that enables general-purpose computing on graphics processing units (GPUs), allowing machine learning frameworks to leverage massive parallelism for accelerated tensor operations.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "dynamic graph",
      "definition": "A computational graph that is built and modified during program execution, allowing for flexible model architectures and easier debugging but potentially limiting optimization opportunities compared to static graphs.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "eager execution",
      "definition": "An execution mode where operations are evaluated immediately as they are called in the code, providing intuitive debugging and development experience but potentially sacrificing some optimization opportunities available in graph-based execution.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "epoch",
      "definition": "One complete pass through the entire training dataset during the neural network training process, after which the model has seen every training example once.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "federated learning",
      "definition": "A machine learning approach that enables training models across decentralized data sources without centralizing the data, allowing multiple parties to collaboratively train a model while preserving data privacy.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gemm",
      "definition": "General Matrix Multiply operations that follow the pattern C = αAB + βC, representing the fundamental computational kernel underlying most neural network operations including fully connected layers and convolutional layers.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gemv",
      "definition": "General Matrix-Vector multiplication operations that compute the product of a matrix and a vector, commonly used in neural network computations and requiring careful optimization for memory access patterns.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gradient clipping",
      "definition": "A technique used during neural network training to prevent exploding gradients by limiting the magnitude of gradients to a specified threshold, helping maintain training stability in deep networks.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "gradient descent",
      "definition": "An optimization algorithm that iteratively adjusts model parameters in the direction of the negative gradient of the loss function to minimize prediction errors and improve model performance.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hardware abstraction",
      "definition": "The layer in ML frameworks that provides a unified interface to diverse computing hardware (CPUs, GPUs, TPUs, accelerators) while handling device-specific optimizations and memory management behind the scenes.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "hyperparameter",
      "definition": "A configuration setting for machine learning algorithms that is set before training begins and controls aspects of the learning process, such as learning rate, batch size, or network architecture, distinct from model parameters learned during training.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "imperative programming",
      "definition": "A programming paradigm where operations are executed immediately as they are encountered in the code, allowing for natural control flow and easier debugging but potentially limiting optimization opportunities.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "jax",
      "definition": "A numerical computing library developed by Google Research that combines NumPy's API with functional programming transformations including automatic differentiation, just-in-time compilation, and automatic vectorization for high-performance machine learning research.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "jit compilation",
      "definition": "Just-In-Time compilation that analyzes and optimizes code at runtime, enabling frameworks to balance the flexibility of eager execution with the performance benefits of graph optimization by compiling frequently used functions.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "lapack",
      "definition": "Linear Algebra Package that extends BLAS with higher-level linear algebra operations including matrix decompositions, eigenvalue problems, and linear system solutions, providing essential mathematical foundations for machine learning computations.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "learning rate",
      "definition": "A hyperparameter that determines the step size at which a model's parameters are updated during training, controlling how quickly or slowly the model learns from the training data.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "machine learning framework",
      "definition": "A software platform that provides tools and abstractions for designing, training, and deploying machine learning models, bridging user applications with infrastructure through computational graphs, hardware optimization, and workflow orchestration.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "model parallelism",
      "definition": "A distributed computing strategy that partitions a neural network model across multiple devices, enabling training of large models that exceed the memory capacity of individual devices by distributing layers or components across hardware.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "onnx",
      "definition": "Open Neural Network Exchange, a standardized format for representing machine learning models that enables interoperability between different frameworks, allowing models trained in one framework to be deployed using another.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "optimizer",
      "definition": "An algorithm that adjusts model parameters during training to minimize the loss function, with common examples including SGD (Stochastic Gradient Descent), Adam, and RMSprop, each with different strategies for parameter updates.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "pipeline parallelism",
      "definition": "A model parallelism technique that distributes consecutive layers of a neural network across different devices, enabling parallel processing where each device works on different stages of the computation pipeline.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "pytorch",
      "definition": "A deep learning framework developed by Facebook's AI Research lab that emphasizes dynamic computational graphs, eager execution, and intuitive Python integration, particularly popular for research and experimentation.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "quantization",
      "definition": "A model compression technique that reduces the precision of model parameters and activations from higher precision formats (like 32-bit floats) to lower precision (like 8-bit integers), significantly reducing memory usage and computational requirements.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "reverse-mode differentiation",
      "definition": "An automatic differentiation technique that computes gradients by traversing the computational graph in reverse order, highly efficient for functions with many inputs and few outputs, making it ideal for neural network training.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "static graph",
      "definition": "A computational graph that is defined completely before execution begins, enabling comprehensive optimization and efficient deployment but requiring all operations to be specified upfront, limiting runtime flexibility.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "symbolic programming",
      "definition": "A programming paradigm where computations are represented as abstract symbols and expressions that are constructed first and executed later, allowing for comprehensive optimization but requiring explicit execution phases.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tensor",
      "definition": "A multidimensional array that generalizes scalars, vectors, and matrices to higher dimensions, serving as the fundamental data structure in machine learning frameworks for representing and manipulating numerical data.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tensor parallelism",
      "definition": "A distributed computing technique that partitions individual tensors and operations across multiple devices, reducing per-device memory requirements while maintaining computational efficiency through coordinated parallel execution.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tensorflow",
      "definition": "A comprehensive machine learning framework developed by Google that provides tools for the entire ML pipeline from research to production, featuring both eager execution and graph-based computation with extensive ecosystem support.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "tpu",
      "definition": "Tensor Processing Unit, Google's custom Application-Specific Integrated Circuits (ASICs) designed specifically for accelerating tensor operations in machine learning workloads, offering significant performance and energy efficiency improvements over general-purpose processors.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "transfer learning",
      "definition": "A machine learning technique that leverages knowledge gained from pre-trained models on related tasks, allowing faster training and better performance on new tasks with limited data by reusing learned features and representations.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "xla",
      "definition": "Accelerated Linear Algebra, a domain-specific compiler for linear algebra operations that optimizes TensorFlow and JAX computations by generating efficient code for various hardware platforms including CPUs, GPUs, and TPUs.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "data parallelism",
      "definition": "A distributed computing strategy that partitions training data across multiple devices while maintaining identical model copies on each device, enabling efficient scaling of training by processing different data batches simultaneously.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "static graphs vs dynamic graphs",
      "definition": "Two fundamental approaches to representing computations in ML frameworks: static graphs are defined before execution and enable optimization but limit flexibility, while dynamic graphs are built during execution allowing for flexible control flow but with potential optimization limitations.",
      "chapter_source": "frameworks",
      "aliases": [],
      "see_also": []
    }
  ]
}
