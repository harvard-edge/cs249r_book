---
title: "Historical Foundations"
---

# Historical Foundations {#sec-system-foundations-historical-foundations}

This appendix traces the evolution of computing paradigms from rule-based systems to deep learning. Understanding this progression explains the architecture of modern ML pipelines and reveals why certain design decisions persist. The "System 1 vs System 2" distinction in modern LLMs mirrors this historical evolution from explicit logic to learned intuition.

::: {.callout-perspective title="Why This Matters"}
Understanding how we moved from Rule-Based Systems to Deep Learning helps explain the architecture of modern ML pipelines. The "System 1 vs System 2" distinction in modern LLMs mirrors this historical evolution from explicit logic to learned intuition.
:::

The transition to Deep Learning represents a shift in how we engineer systems: from programming logic to programming with data.

## Rule-Based Systems (1950s–1990s)

The earliest paradigm relied on humans to explicitly define the logic for every task. A programmer building a game like Breakout would write specific code to handle ball physics, paddle movement, and brick collisions. The "intelligence" resided entirely in the programmer's mind, translated directly into `if-then` statements (@fig-breakout).

::: {#fig-breakout fig-env="figure" fig-pos="htb" fig-cap="**Rule-Based Logic**: In traditional programming, humans explicitly code every rule. A game like Breakout relies on `if-then` logic defining physics and interactions. The system can only execute what the programmer explicitly anticipated." fig-alt="Diagram of Breakout game grid with ball and paddle. Overlay shows code snippet with if-statement for collision detection and velocity reversal."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
\definecolor{Sepia}{RGB}{94,33,41}
\definecolor{MidnightBlue}{RGB}{0,103,149}
\definecolor{RoyalBlue}{RGB}{0,113,187}
\definecolor{BlueGreen}{RGB}{0,179,184}
\definecolor{PineGreen}{RGB}{0,139,114}
\definecolor{OliveGreen}{RGB}{60,128,49}
\definecolor{LimeGreen}{RGB}{137,189,25}
\definecolor{YellowGreen}{RGB}{196,214,0}
\definecolor{Goldenrod}{RGB}{255,223,66}
\definecolor{Dandelion}{RGB}{253,188,66}
\definecolor{Apricot}{RGB}{253,172,83}
\definecolor{Melon}{RGB}{253,163,88}
\definecolor{YellowOrange}{RGB}{252,174,27}
\definecolor{Orange}{RGB}{245,130,31}
\definecolor{BurntOrange}{RGB}{222,87,39}
\definecolor{Bittersweet}{RGB}{192,79,23}
\definecolor{RedOrange}{RGB}{242,101,34}
\definecolor{Mahogany}{RGB}{202,52,53}
\definecolor{Maroon}{RGB}{179,32,52}
\definecolor{BrickRed}{RGB}{203,65,84}
\definecolor{Red}{RGB}{237,27,35}
\definecolor{OrangeRed}{RGB}{237,50,55}
\definecolor{RubineRed}{RGB}{237,0,140}
\definecolor{WildStrawberry}{RGB}{238,41,121}
\definecolor{Salmon}{RGB}{246,146,110}
\definecolor{CarnationPink}{RGB}{242,130,180}
\definecolor{Magenta}{RGB}{236,0,140}
\definecolor{VioletRed}{RGB}{239,65,116}
\definecolor{Rhodamine}{RGB}{239,85,164}
\definecolor{Mulberry}{RGB}{169,54,113}
\definecolor{RedViolet}{RGB}{150,38,124}
\definecolor{Fuchsia}{RGB}{140,54,140}
\definecolor{Lavender}{RGB}{244,158,196}
\definecolor{Thistle}{RGB}{216,191,216}
\definecolor{Orchid}{RGB}{175,92,166}
\definecolor{DarkOrchid}{RGB}{164,83,164}
\definecolor{Purple}{RGB}{154,37,142}
\definecolor{Plum}{RGB}{142,49,142}
\definecolor{Violet}{RGB}{88,66,155}
\definecolor{RoyalPurple}{RGB}{97,63,153}
\definecolor{BlueViolet}{RGB}{73,47,146}
\definecolor{Periwinkle}{RGB}{121,119,184}
\definecolor{CadetBlue}{RGB}{116,114,182}
\definecolor{CornflowerBlue}{RGB}{108,174,220}
\definecolor{Cerulean}{RGB}{0,122,188}
\definecolor{Peach}{RGB}{255,147,88}
\definecolor{Thistle}{RGB}{222,132,191}

\def\columns{5}
\def\rows{3}
\def\cellsize{25mm}
\def\cellheight{7mm}
\def\rowone{Peach,BlueGreen,OrangeRed,Thistle,Dandelion}
\def\rowtwo{brown!50,lime,teal,pink,lightgray}
\def\rowthree{Lavender,Goldenrod,Cerulean,Maroon,LimeGreen}
%
\foreach \x in {1,...,\columns}{
    \foreach \y in {1,...,\rows}{
        %
        \node[draw=black, fill=green!30, minimum width=\cellsize,
                    minimum height=\cellheight, line width=0.25pt] (cell-\x-\y) at (\x*\cellsize,-\y*\cellheight) {};
    }
}
\foreach \color [count=\x] in \rowone {
    \node[fill=\color,draw=black,line width=0.25pt, minimum width=\cellsize,
    minimum height=\cellheight] at (cell-\x-1) {};
}
%
\foreach \color [count=\x] in \rowtwo {
    \node[fill=\color,draw=black,line width=0.25pt, minimum width=\cellsize,
               minimum height=\cellheight] at (cell-\x-2) {};
}
%
\foreach \color [count=\x] in \rowthree {
    \node[fill=\color,draw=black,line width=0.25pt, minimum width=\cellsize,
               minimum height=\cellheight] at (cell-\x-3) {};
}
\begin{scope}[shift={($(cell-4-3)+(0,-1.7)$)}]
\node[align=left,font=\small\ttfamily]at(0,0){if (ball.collide(brick)) { \\
\qquad    removeBrick();\\
\qquad    ball.dx = 1.1 * (ball.dx);\\
\qquad    ball.dy = -1 * (ball.dy);\\
}};
\end{scope}
\node[draw,rectangle,minimum width=40mm,minimum height=4mm,fill=Sepia!50!black!]
at($(cell-3-3.south west)+(0,-2.8)$)(R){};

\node[draw,circle,minimum size=5mm,fill=Sepia!50!black!,anchor=north]
at($(cell-1-3.south west)!0.8!(cell-1-3.south east)$)(C){};
\draw[thick,-latex,dash pattern={on 5pt off 2pt on 1pt off 3pt}](R)--(C)--++(225:2);
\end{tikzpicture}
```
:::

Beyond individual applications, this rule-based paradigm extends to all traditional programming. @fig-traditional illustrates this fundamental pattern: the program takes both rules for processing and input data to produce outputs. Early artificial intelligence research explored whether this approach could scale to solve complex problems by encoding sufficient rules to capture intelligent behavior.

::: {#fig-traditional fig-env="figure" fig-pos="htb" fig-cap="**Traditional Programming Flow**: Rules and data serve as inputs to a traditional program, which produces answers as output. This input-output pattern formed the basis for early AI systems but lacks the adaptability needed for complex pattern recognition tasks." fig-alt="Flow diagram with three boxes: Rules and Data as inputs flowing into central Traditional Programming box, which outputs Answers. Arrows show data flow direction from inputs to output."}
```{.tikz}
\begin{tikzpicture}[font=\small\usefont{T1}{phv}{m}{n}]
\definecolor{GreenLine}{RGB}{0,128,0}
\definecolor{GreenL}{RGB}{220,245,220}
\definecolor{RedLine}{RGB}{180,50,50}
\definecolor{RedL}{RGB}{245,220,220}
\tikzset{
  Line/.style={line width=1.0pt,black!50,text=black},
  Box/.style={inner xsep=2pt,
    node distance=1,
    draw=GreenLine, line width=0.75pt,
    fill=GreenL,
    text width=22mm,align=flush center,
    minimum width=22mm, minimum height=8mm
  },
  Box1/.style={Box, draw=RedLine, fill=RedL,
    text width=36mm, minimum width=40mm
  },
}
 \node[Box1](B1){Traditional Programming};
 \node[Box,right=of B1](B2){Answers};
 \node[Box,above left=0.2 and 1 of B1](B3){Rules};
 \node[Box, below left=0.2 and 1 of B1](B4){Data};
 \draw[-latex,Line](B1)--(B2);
 \draw[-latex,Line](B3)-|(B1);
 \draw[-latex,Line](B4)-|(B1);
\end{tikzpicture}
```
:::

Despite their apparent simplicity, rule-based limitations surface quickly with complex real-world tasks. Recognizing human activities illustrates the challenge. Classifying movement below 4 mph as walking seems straightforward until real-world complexity intrudes. Speed variations, transitions between activities, and boundary cases each demand additional rules, creating unwieldy decision trees (@fig-activity-rules). Computer vision tasks compound these difficulties. Detecting cats requires rules about ears, whiskers, and body shapes while accounting for viewing angles, lighting, occlusions, and natural variations. Early systems achieved success only in controlled environments with well-defined constraints.

![**Activity Classification Decision Tree**: A rule-based decision tree classifies human activity by branching on speed thresholds, with values below 4 mph mapped to walking, 4 to 15 mph to running, and above 15 mph to biking. Real-world edge cases and transitions between activities demand increasingly complex branching logic.](images/png/activities.png){#fig-activity-rules fig-alt="Decision tree flowchart for activity classification. Branches split on conditions like speed less than 4 mph leading to walking, 4-15 mph to running, greater than 15 mph to biking. Additional branches handle edge cases and transitions."}

## Classical Machine Learning (1990s–2010)

To address the scalability barriers of rule-based systems, researchers began exploring approaches that could learn from data. Machine learning offered a promising direction: instead of writing rules for every situation, researchers wrote programs that identified patterns in examples. The success of these methods, however, still depended heavily on human insight to define relevant patterns, a process known as feature engineering.

This approach introduced feature engineering by transforming raw data into representations that expose patterns to learning algorithms. The Histogram of Oriented Gradients (HOG) method exemplifies this approach, identifying edges where brightness changes sharply, dividing images into cells, and measuring edge orientations within each cell (@fig-hog). This transforms raw pixels into shape descriptors robust to lighting variations and small positional changes.

![**HOG Method**: Identifies edges in images to create a histogram of gradients, transforming pixel values into shape descriptors that are invariant to lighting changes.](images/png/hog.png){#fig-hog fig-alt="Three-panel image showing HOG feature extraction: original grayscale photo of person on left, gradient magnitude visualization in center, and HOG descriptor grid overlay on right showing edge orientation histograms per cell."}
