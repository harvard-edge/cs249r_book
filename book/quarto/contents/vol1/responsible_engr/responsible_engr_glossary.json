{
  "metadata": {
    "chapter": "responsible_engr",
    "version": "1.0.0",
    "generated": "2026-01-07T12:00:00.000000",
    "total_terms": 15,
    "standardized": true,
    "last_updated": "2026-01-07T12:00:00.000000"
  },
  "terms": [
    {
      "term": "silent bias",
      "definition": "Model unfairness that produces valid-looking but discriminatory outputs, evading traditional error monitoring and requiring disaggregated evaluation to detect.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "demographic parity",
      "definition": "A fairness criterion requiring that the probability of receiving a positive prediction is independent of group membership across protected attributes.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["equalized odds"]
    },
    {
      "term": "equal opportunity",
      "definition": "A fairness criterion requiring equal true positive rates among qualified applicants across different demographic groups.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["equalized odds"]
    },
    {
      "term": "equalized odds",
      "definition": "A fairness criterion requiring that both true positive and false positive rates are equal across different demographic groups.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["demographic parity", "equal opportunity"]
    },
    {
      "term": "model cards",
      "definition": "A standardized format for documenting machine learning models, capturing information essential for responsible deployment, including intended use, performance factors, and ethical considerations.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["datasheets for datasets"]
    },
    {
      "term": "datasheets for datasets",
      "definition": "Documentation for training data that captures provenance, collection methodology, demographic composition, and known limitations affecting model behavior.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["model cards"]
    },
    {
      "term": "total cost of ownership (tco)",
      "definition": "A comprehensive financial metric for ML systems encompassing training, inference, and operational costs over the system's entire lifecycle.",
      "chapter_source": "responsible_engr",
      "aliases": ["tco"],
      "see_also": []
    },
    {
      "term": "green ai",
      "definition": "A movement in AI research and practice that prioritizes computational efficiency and energy consumption as primary metrics alongside traditional performance metrics like accuracy.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "disaggregated evaluation",
      "definition": "The practice of breaking down model performance metrics by demographic groups or other factors to reveal disparities that are hidden by aggregate measures.",
      "chapter_source": "responsible_engr",
      "aliases": ["stratified evaluation"],
      "see_also": []
    },
    {
      "term": "silent failure",
      "definition": "A system failure mode where an ML model continues to produce plausible-looking outputs that are gradually less accurate or contextually relevant without triggering conventional error alerts.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["silent bias"]
    },
    {
      "term": "feedback loop",
      "definition": "A phenomenon where a model's outputs influence its own future training data, potentially reinforcing and amplifying initial biases over time.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": []
    },
    {
      "term": "intersectional analysis",
      "definition": "Evaluation that considers combinations of demographic attributes (e.g., race and gender simultaneously) to detect concentrated harms not visible in single-factor analysis.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["disaggregated evaluation"]
    },
    {
      "term": "red ai",
      "definition": "AI research and development that prioritizes maximizing accuracy or performance without regard for the increasing computational and environmental costs required.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["green ai"]
    },
    {
      "term": "carbon footprint",
      "definition": "The total greenhouse gas emissions, typically measured in CO2 equivalent, produced directly and indirectly by training and operating an ML system.",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": ["green ai"]
    },
    {
      "term": "responsible engineering gap",
      "definition": "The disparity between technical optimization success (e.g., high benchmark accuracy) and responsible deployment outcomes (e.g., fairness and safety in production).",
      "chapter_source": "responsible_engr",
      "aliases": [],
      "see_also": []
    }
  ]
}
