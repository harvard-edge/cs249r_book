# About This Book {.unnumbered}

## Who This Book Is For {#sec-about-audience}

This book is for anyone who wants to understand how machine learning systems actually work---from the mathematics that define a neural network to the hardware that executes it and the engineering decisions that make it run efficiently.

A majority of readers will not become ML hardware architects or compiler engineers. But every practitioner who builds, trains, optimizes, or deploys a model makes decisions that depend on understanding the system beneath the code. This book gives you that understanding. Whether you are an undergraduate encountering ML systems for the first time, a practicing engineer looking to strengthen your foundations, or a researcher who needs to reason about performance and deployment, this volume provides the principled knowledge you need.

## Why a Systems Textbook for Machine Learning {#sec-about-why-systems}

In 1968, a NATO conference in Garmisch, Germany, coined the term *software engineering*. The motivation was a crisis: software systems had grown too complex for ad hoc programming to manage. Building reliable software required its own discipline---with its own principles, methodologies, and rigor. Nearly a decade later, in 1977, computer engineering emerged as a distinct field, recognizing that designing hardware systems demanded more than applied physics. In both cases, the practitioners already existed. The body of knowledge already existed. What was missing was the institutional recognition that these activities constituted a discipline.

Machine learning faces an analogous moment. Everyone wants to build models, but models alone are not systems. A neural network that achieves state-of-the-art accuracy in a notebook may fail to serve a single user in production if the data pipeline is brittle, the serving infrastructure cannot meet latency requirements, or the hardware is mismatched to the workload. The gap between a trained model and a working ML system is an engineering gap---and closing it requires an engineering discipline.

If AI is electricity, someone has to build more than the appliances. Who engineers the generators? Who builds the transmission lines? Who designs the transformers that step it down for homes and offices? That is AI engineering: the training infrastructure, the serving systems, the optimization for edge devices, the monitoring that catches failures before users do. Computer science asks what is computable. Computer engineering asks how to build systems that compute reliably. ML research asks what models can learn. AI engineering asks how to build systems that learn reliably, run efficiently, fail safely, and scale sustainably.

This book treats that discipline as its subject. It sits at the intersection of ML theory, ML systems, and applied ML---teaching the practice of building efficient, reliable, and robust intelligent systems that operate in the real world, not just models in isolation.

Now consider a box of LEGO bricks. The same interlocking pieces build a spaceship, a castle, or an entire city. The sets change; the bricks do not. ML systems work the same way. A convolutional network for image classification, a transformer for language generation, and a reinforcement learning agent for robotics are vastly different applications---but beneath them sit the same building blocks: computational graphs, memory hierarchies, data pipelines, optimization loops, and the tradeoffs between latency, throughput, and energy. Master the building blocks and you can construct any system.

This is why the book teaches enduring principles rather than current tools. Dominant frameworks have shifted from Theano to TensorFlow to PyTorch in under a decade. Hardware has evolved from repurposed graphics processors to purpose-built tensor accelerators, with new architectures emerging every year. Any textbook that teaches today's tools will be obsolete before its next edition. The building blocks endure.

We follow a quantitative methodology throughout. Where possible, we replace qualitative advice ("use a smaller model") with measurable reasoning ("reducing parameters by 4x decreases inference latency by 2.3x on this hardware, at a cost of 1.2% accuracy"). Engineering decisions should be grounded in measurement, not intuition.

## What This Book Covers {#sec-about-coverage}

This volume focuses on the **single compute node**: one machine, one to eight accelerators, a shared memory space. This is the fundamental unit of ML computation---where mathematical models meet physical hardware. Mastering it is the prerequisite for everything else.

The content is organized into four parts, each answering a core engineering question:

**Part I: Foundations** --- *What is ML systems engineering, and how does development work?*
Develops the vocabulary, mental models, and end-to-end workflow that guide every ML project, from the characteristics that distinguish ML systems from traditional software through data engineering pipelines that feed them.

**Part II: Build** --- *How do we go from mathematical foundations to working systems?*
Covers the mathematics of deep learning, the architectures built on those foundations, the frameworks that implement them, and the training procedures that bring them to life.

**Part III: Optimize** --- *How do we make systems efficient enough for the real world?*
Addresses data efficiency, model compression, hardware acceleration, and the benchmarking methodology needed to measure progress rigorously.

**Part IV: Deploy** --- *How do we operate ML systems reliably in production?*
Covers serving infrastructure, operational practices, and responsible engineering for building systems that are fair, transparent, and trustworthy.

Each part builds on the previous one. We recommend reading sequentially, though the reading paths below offer alternatives for readers with specific goals.

## Suggested Reading Paths {#sec-about-reading-paths}

While the book is designed to be read front-to-back, readers with different backgrounds and goals may benefit from tailored paths:

**The Complete Path** (all chapters, in order). For undergraduates and readers new to ML systems. Start with Foundations, progress through Build, Optimize, and Deploy. This path develops every concept from first principles.

**The ML Engineer's Path** (systems depth for practitioners). For engineers who already train and deploy models but want to understand the systems underneath. Skim Part I for vocabulary, then focus on Frameworks, Training, Hardware Acceleration, Benchmarking, and Serving.

**The Optimization Path** (efficiency-focused). For engineers working on model efficiency, edge deployment, or resource-constrained systems. After Foundations, move directly to Data Selection, Model Compression, Hardware Acceleration, and Benchmarking.

::: {.content-visible when-format="html"}

## A Learning Platform, Not Just a Book {#sec-about-platform}

This book is one component of a broader learning ecosystem designed to work together:

- **[mlsysbook.ai](https://mlsysbook.ai)** hosts the complete text alongside interactive Colab notebooks, lecture slides, exercises, videos, and supplementary materials for every chapter. All resources are freely available.

- **[TinyTorch](https://tinytorch.ai)** provides hands-on labs built on a purpose-built educational framework. These labs reinforce the concepts in each chapter through guided experimentation---building tensors, implementing backpropagation, profiling memory, and measuring real hardware performance.

- **[CS249r at Harvard](https://wiki.harvard.edu/)** and the [TinyML edX professional certificate](https://www.edx.org/certificates/professional-certificate/harvardx-tiny-machine-learning) offer structured course experiences built around this material.

The book teaches the principles. The labs teach the practice. We encourage readers to use both.

## An Open Source Textbook {#sec-about-open-source}

This book is open source. The full text, figures, and build system are available on [GitHub](https://github.com/harvard-edge/cs249r_book), and every reader is invited to contribute.

This is a deliberate choice. If AI engineering is to become a shared discipline rather than a collection of isolated practices, its foundational texts must be accessible to everyone. ML systems is a field shaped by practitioners across industry, academia, and the open source community worldwide. A textbook covering this field should reflect that breadth and be available to all, regardless of geography or institutional affiliation.

Contributions from readers---fixing an error, suggesting a clearer explanation, adding a worked example, or proposing new content---have materially improved every chapter. If you find something that could be better, open an issue or submit a pull request. This book improves because readers like you participate in building it.

:::

::: {.content-visible when-format="pdf"}

## Companion Resources {#sec-about-companion-resources}

This book is part of a broader learning ecosystem. Interactive Colab notebooks, lecture slides, exercises, videos, and supplementary materials for every chapter are available online at **mlsysbook.ai**. Hands-on labs built with the TinyTorch educational framework are available at **tinytorch.ai**, providing guided experimentation that reinforces the concepts in each chapter.

This book is open source. The full text, figures, and build system are publicly available, and contributions from readers worldwide have materially improved every chapter. Visit the GitHub repository at **github.com/harvard-edge/cs249r\_book** to report issues, suggest improvements, or contribute directly.

:::

## Prerequisites {#sec-about-prerequisites}

**Required:**

- **Programming**: Fluency in Python, including functions, classes, and basic data manipulation with NumPy.
- **Mathematics**: Comfort with linear algebra, basic calculus, and probability at the undergraduate level.

**Helpful but not required:**

- **Computer systems**: Familiarity with memory hierarchies and basic computer architecture will deepen your understanding of the optimization and hardware chapters.
- **Machine learning basics**: Prior exposure to supervised learning concepts provides useful context, but Part II develops the necessary foundations from first principles.

## Beyond This Volume {#sec-about-beyond}

This volume establishes the foundations of ML systems on a single machine. Advanced topics---including distributed training across clusters, fleet-scale infrastructure, and production systems spanning thousands of nodes---are available in companion materials at **mlsysbook.ai**.

## Using This Book in a Course {#sec-about-course-use}

This book grew out of CS249r at Harvard University and the TinyML edX professional certificate. It is designed to support a one-semester course covering the full ML systems stack. Instructors may also select individual parts for shorter modules:

- **Parts I--II** (Foundations and Build) suit an introductory half-semester on ML development fundamentals.
- **Parts III--IV** (Optimize and Deploy) suit an applied half-semester on production ML engineering.

::: {.content-visible when-format="html"}
Lecture slides, assignments, and instructor resources are available at [mlsysbook.ai](https://mlsysbook.ai).
:::

::: {.content-visible when-format="pdf"}
Lecture slides, assignments, and instructor resources are available at **mlsysbook.ai**.
:::

## Copyright and Licensing {#sec-about-copyright-licensing}

::: {.content-visible when-format="html"}
This work is licensed under [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0). The source is available on [GitHub](https://github.com/harvard-edge/cs249r_book).
:::

::: {.content-visible when-format="pdf"}
This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). The source is available at **github.com/harvard-edge/cs249r\_book**.
:::
