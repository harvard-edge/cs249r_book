# About This Book {.unnumbered}

## Who This Book Is For {#sec-about-audience}

This book is for anyone who wants to understand how machine learning systems actually work, from the mathematics that define a neural network to the hardware that executes it and the engineering decisions that make it run efficiently.

Most readers will not become ML hardware architects or compiler engineers. Yet every practitioner who builds, trains, optimizes, or deploys a model makes decisions that depend on understanding the system beneath the code. This book gives you that understanding. Whether you are an undergraduate encountering ML systems for the first time, a practicing engineer looking to strengthen your foundations, or a researcher who needs to reason about performance and deployment, this volume provides the principled knowledge you need.

## Why a Systems Textbook for Machine Learning {#sec-about-why-systems}

In 1968, a NATO conference in Garmisch, Germany, coined the term *software engineering* to address a crisis: software systems had grown too complex for ad hoc programming to manage. Building reliable software required its own discipline, with its own principles, methodologies, and rigor. Decades later, Hennessy and Patterson transformed computer architecture from an art into a quantitative science, giving engineers the tools to measure, predict, and optimize processor performance from first principles. In both cases, the practitioners already existed. The body of knowledge already existed. What was missing was the recognition that these activities constituted a discipline.

Machine learning faces its own Garmisch moment.

For the past decade, the field has been dominated by *model-centric* thinkingâ€”a focus on discovering new algorithms and architectures. But a model is not a system. A neural network that achieves state-of-the-art accuracy in a research notebook is useless if it cannot be served within latency constraints, if its data pipeline cannot scale to petabytes, or if its energy cost exceeds its economic value. The gap between a working model and a production system is not just a matter of "coding harder"; it is a gap in fundamental engineering principles.

This book treats ML systems engineering not as a collection of tools --- Kubernetes, PyTorch, CUDA --- but as a discipline governed by physical invariants. Just as civil engineers cannot ignore gravity, AI engineers cannot ignore the constraints that govern every system they build:

*   **The Iron Law**: The immutable relationship between data movement, arithmetic intensity, and system performance.
*   **Data Gravity**: The physical cost of moving information at scale.
*   **The Energy-Movement Invariant**: Moving data costs orders of magnitude more energy than computing on it.
*   **Amdahl's Law**: The serial fraction of your pipeline caps total system speedup.

If computer science asks "what is computable?" and ML research asks "what is learnable?", then AI engineering asks "what is buildable, given the physics of real hardware and real data?"

This book is the foundation for that discipline. We aim to do for AI systems what Hennessy and Patterson did for computer architecture: replace intuition with measurement, and art with engineering. The goal is to teach you to reason about the system *before* you build it, treating data, algorithms, and hardware not as separate silos but as a single, coupled optimization problem.

Consider a box of LEGO bricks. The same interlocking pieces build a spaceship, a castle, or an entire city. The sets change; the bricks do not. ML systems work the same way. A convolutional network for image classification, a transformer for language generation, and a reinforcement learning agent for robotics are vastly different applications, but beneath them sit the same building blocks: computational graphs, memory hierarchies, data pipelines, optimization loops, and the tradeoffs between latency, throughput, and energy. Master the building blocks and you can construct any system.

This is why the book teaches enduring principles rather than current tools. Dominant frameworks have shifted from Theano to TensorFlow to PyTorch in under a decade. Hardware has evolved from repurposed graphics processors to purpose-built tensor accelerators, with new architectures emerging every year. Any textbook that teaches today's tools will be obsolete before its next edition. The building blocks endure.

We follow a quantitative methodology throughout. Where possible, we replace qualitative advice ("use a smaller model") with measurable reasoning ("reducing parameters by 4$\times$ decreases inference latency by 2.3$\times$ on this hardware, at a cost of 1.2% accuracy"). Engineering decisions should be grounded in measurement, not intuition.

## What This Book Covers {#sec-about-coverage}

This volume focuses on the *single compute node*: one machine, one to eight accelerators, a shared memory space. This is the fundamental unit of ML computation, where mathematical models meet physical hardware. Mastering it is the prerequisite for everything else.

The content is organized into four parts, each answering a core engineering question:

**Part I: Foundations** -- *What is ML systems engineering, and how does development work?*
Develops the vocabulary, mental models, and end-to-end workflow that guide every ML project, from the characteristics that distinguish ML systems from traditional software through data engineering pipelines that feed them.

**Part II: Build** -- *How do we go from mathematical foundations to working systems?*
Covers the mathematics of deep learning, the architectures built on those foundations, the frameworks that implement them, and the training procedures that produce working models.

**Part III: Optimize** -- *How do we make systems efficient enough for the real world?*
Addresses data efficiency, model compression, hardware acceleration, and the benchmarking methodology needed to measure progress rigorously.

**Part IV: Deploy** -- *How do we operate ML systems reliably in production?*
Covers serving infrastructure, operational practices, and responsible engineering for building systems that are fair, transparent, and trustworthy.

Each part builds on the previous one. We recommend reading sequentially, though the reading paths below offer alternatives for readers with specific goals.

## Suggested Reading Paths {#sec-about-reading-paths}

While the book is designed to be read front-to-back, readers with different backgrounds and goals may benefit from tailored paths:

**The Complete Path** (all chapters, in order). For undergraduates and readers new to ML systems. Start with Foundations, progress through Build, Optimize, and Deploy. This path develops every concept from first principles.

**The ML Engineer's Path** (systems depth for practitioners). For engineers who already train and deploy models but want to understand the systems underneath. Skim Part I for vocabulary, then focus on Frameworks, Training, Hardware Acceleration, Benchmarking, and Serving.

**The Optimization Path** (efficiency-focused). For engineers working on model efficiency, edge deployment, or resource-constrained systems. After Foundations, move directly to Data Selection, Model Compression, Hardware Acceleration, and Benchmarking.

::: {.content-visible when-format="html"}

## A Learning Platform, Not Just a Book {#sec-about-platform}

This book is one component of a broader learning ecosystem designed to work together:

- **[mlsysbook.ai](https://mlsysbook.ai)** hosts the complete text alongside interactive Colab notebooks, lecture slides, exercises, videos, and supplementary materials for every chapter. All resources are freely available.

- **[TinyTorch](https://tinytorch.ai)** provides hands-on labs built on a purpose-built educational framework. These labs reinforce the concepts in each chapter through guided experimentation: building tensors, implementing backpropagation, profiling memory, and measuring real hardware performance.

- **[CS249r at Harvard](https://wiki.harvard.edu/)** and the [TinyML edX professional certificate](https://www.edx.org/certificates/professional-certificate/harvardx-tiny-machine-learning) offer structured course experiences built around this material.

The book teaches the principles. The labs teach the practice. We encourage readers to use both.

## An Open Source Textbook {#sec-about-open-source}

This book is open source. The full text, figures, and build system are available on [GitHub](https://github.com/harvard-edge/cs249r_book), and every reader is invited to contribute.

This is a deliberate choice. If AI engineering is to become a shared discipline rather than a collection of isolated practices, its foundational texts must be accessible to everyone. ML systems is a field shaped by practitioners across industry, academia, and the open source community worldwide. A textbook covering this field should reflect that breadth and be available to all, regardless of geography or institutional affiliation.

Contributions from readers, whether fixing an error, suggesting a clearer explanation, adding a worked example, or proposing new content, have materially improved every chapter. If you find something that could be better, open an issue or submit a pull request. This book improves because readers like you participate in building it.

:::

::: {.content-visible when-format="pdf"}

## Companion Resources {#sec-about-companion-resources}

This book is part of a broader learning ecosystem. Interactive Colab notebooks, lecture slides, exercises, videos, and supplementary materials for every chapter are available online at **mlsysbook.ai**. Hands-on labs built with the TinyTorch educational framework are available at **tinytorch.ai**, providing guided experimentation that reinforces the concepts in each chapter.

This book is open source. The full text, figures, and build system are publicly available, and contributions from readers worldwide have materially improved every chapter. Visit the GitHub repository at **github.com/harvard-edge/cs249r\_book** to report issues, suggest improvements, or contribute directly.

:::

## Prerequisites {#sec-about-prerequisites}

**Required:**

- **Programming**: Fluency in Python, including functions, classes, and basic data manipulation with NumPy.
- **Mathematics**: Comfort with linear algebra, basic calculus, and probability at the undergraduate level.

**Helpful but not required:**

- **Computer systems**: Familiarity with memory hierarchies and basic computer architecture will deepen your understanding of the optimization and hardware chapters.
- **Machine learning basics**: Prior exposure to supervised learning concepts provides useful context, but Part II develops the necessary foundations from first principles.

## About the Companion Volume {#sec-about-companion-volume}

This is the first of two volumes. Volume I covers the single compute node: one machine, one to eight accelerators, a shared memory space. A companion volume, *Advanced Machine Learning Systems*, extends these foundations to the distributed scale.

Where this volume asks how to build, optimize, and deploy ML systems on a single machine, Volume II asks how to coordinate computation across thousands of machines. It covers distributed training strategies, fleet-scale infrastructure, production deployment at global scale, and the governance challenges that arise when ML systems operate in the real world.

The two volumes are designed to be read in sequence. Volume II assumes familiarity with the concepts developed here, much as Hennessy and Patterson's *Computer Architecture: A Quantitative Approach* builds on the foundations established in *Computer Organization and Design*. Readers who complete this volume will have the prerequisite knowledge for the advanced material.

::: {.content-visible when-format="html"}
Volume II is forthcoming. Updates and early access materials are available at [mlsysbook.ai](https://mlsysbook.ai).
:::

::: {.content-visible when-format="pdf"}
Volume II is forthcoming. Updates and early access materials are available at **mlsysbook.ai**.
:::

## Using This Book in a Course {#sec-about-course-use}

This book grew out of CS249r at Harvard University and the TinyML edX professional certificate program. The TinyML course taught ML systems at the most constrained end of the spectrum --- microcontrollers running on milliwatts with kilobytes of memory --- and revealed a surprising lesson: the fundamental constraints that govern tiny devices (memory bandwidth, compute density, energy per operation) are the same constraints that govern data center GPUs. The physics scales; only the numbers change. That insight shaped this book. What began as a course on resource-constrained ML matured into a comprehensive treatment of ML systems engineering, grounded in the principle that mastering the fundamentals at any scale prepares you for every scale.

The book is designed to support a one-semester course covering the full ML systems stack. Instructors may also select individual parts for shorter modules:

- **Parts I--II** (Foundations and Build) suit an introductory half-semester on ML development fundamentals.
- **Parts III--IV** (Optimize and Deploy) suit an applied half-semester on production ML engineering.
- **Principles Only** (Part introductions: @sec-part-foundations, @sec-part-build, @sec-part-optimize, @sec-part-deploy) suits a condensed overview of ML systems invariants for survey courses or executive programs.

::: {.content-visible when-format="html"}
Lecture slides, assignments, and instructor resources are available at [mlsysbook.ai](https://mlsysbook.ai).
:::

::: {.content-visible when-format="pdf"}
Lecture slides, assignments, and instructor resources are available at **mlsysbook.ai**.
:::

## Copyright and Licensing {#sec-about-copyright-licensing}

::: {.content-visible when-format="html"}
This work is licensed under [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0). The source is available on [GitHub](https://github.com/harvard-edge/cs249r_book).
:::

::: {.content-visible when-format="pdf"}
This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). The source is available at **github.com/harvard-edge/cs249r\_book**.
:::
