concept_map:
  source: nn_computation.qmd
  generated_date: 2026-02-19
  primary_concepts:
    - Mathematical Primitives (MAC atoms)
    - Forward/Backpropagation
    - Activation Functions (ReLU, Sigmoid, Tanh, Softmax)
    - Training/Inference asymmetry
    - Representation Learning
  secondary_concepts:
    - Gradient Instabilities (Vanishing/Exploding)
    - Loss Functions (Cross-entropy)
    - Optimization Process
  technical_terms:
    - Neurons (artificial nodes)
    - Synapses (weights)
    - Soma (summation function)
    - FLOPS
    - Chain Rule
  methodologies:
    - Numerical stability optimization
    - Gradient computation
  formulas:
    - Backprop memory cost (O(N * L))
    - Computational Intensity (MatMul vs Element-wise)
