concept_map:
  source: nn_architectures.qmd
  generated_date: 2026-02-19
  primary_concepts:
    - Inductive Biases (Spatial, Sequential, Relational)
    - Representational Power vs. Efficiency
    - Architectural Building Blocks (Skip connections, Normalization, Gating)
  secondary_concepts:
    - Multi-Layer Perceptrons (MLPs)
    - Convolutional Neural Networks (CNNs)
    - Recurrent Neural Networks (RNNs)
    - Transformer Architecture
    - Attention Mechanisms
  technical_terms:
    - Feature extraction
    - Translation invariance
    - Receptive fields
    - Self-attention
    - Query-Key-Value mechanisms
  methodologies:
    - Architecture selection framework
    - Pareto efficiency analysis
  formulas:
    - Transformer quadratic scaling (O(n^2 * d))
    - CNN kernel parameter count
