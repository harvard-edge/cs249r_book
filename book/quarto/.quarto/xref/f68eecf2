{"entries":[{"caption":"Model Compression Fundamentals","key":"sec-efficient-ai-model-compression-fundamentals-bcc3","order":{"number":19,"section":[1,4,2,1,0,0,0]}},{"caption":"Multi-Dimensional Efficiency Synergies","key":"sec-efficient-ai-multidimensional-efficiency-synergies-ea04","order":{"number":17,"section":[1,4,1,0,0,0,0]}},{"caption":"Summary","key":"sec-efficient-ai-summary-66bb","order":{"number":52,"section":[1,11,0,0,0,0,0]}},{"caption":"Model Training Compute Trends: Model training compute is growing at faster and faster rates, especially in the recent deep learning era. Source: [@Sevilla_Heim_Ho_Besiroglu_Hobbhahn_Villalobos_2022.]","key":"fig-compute-trends","order":{"number":2,"section":[1,3,1,0,0,0,0]}},{"caption":": Moore’s Law Economics: Declining per-component manufacturing costs initially drove exponential growth in integrated circuit complexity, but diminishing returns eventually limited further cost reductions. This relationship mirrors optimization challenges in machine learning, where increasing model complexity yields diminishing gains in performance relative to computational expense. Source: [@moore2021cramming].","key":"fig-moores-law-plot","order":{"number":15,"section":[1,9,3,1,0,0,0]}},{"caption":": Efficiency Interdependencies: The three efficiency dimensions (algorithmic, compute, and data) overlap and influence one another, creating systemic trade-offs in machine learning systems. Optimizing for one efficiency dimension often requires careful consideration of its impact on the others, shaping overall system performance and resource utilization.","key":"fig-interdependece","order":{"number":1,"section":[1,2,1,0,0,0,0]}},{"caption":": Real-Time System Constraints: Autonomous vehicles demand careful balance between computational efficiency and low latency. Increasing processing power to reduce delay can conflict with energy and cost limitations, yet sacrificing latency compromises safety by increasing reaction time and braking distance.","key":"fig-efficiency-vs-latency","order":{"number":14,"section":[1,6,1,2,0,0,0]}},{"caption":"Efficiency Interdependencies","key":"sec-efficient-ai-efficiency-interdependencies-5d69","order":{"number":4,"section":[1,2,1,0,0,0,0]}},{"caption":"Architectural Innovation for Efficiency","key":"sec-efficient-ai-architectural-innovation-efficiency-7dd9","order":{"number":21,"section":[1,4,2,3,0,0,0]}},{"caption":": Algorithmic Efficiency Progress: Neural network training compute requirements decreased 44× between 2012 and 2019, outpacing hardware improvements and demonstrating the significant impact of algorithmic advancements on model efficiency. Innovations in model architecture and optimization techniques can drive substantial gains in AI system sustainability via this halving of compute every 16 months. Source: [@Hernandez_et_al_2020].","key":"fig-algo-efficiency","order":{"number":9,"section":[1,4,2,4,0,0,0]}},{"caption":"Balancing Innovation with Efficiency Demands","key":"sec-efficient-ai-balancing-innovation-efficiency-demands-7a44","order":{"number":48,"section":[1,9,2,0,0,0,0]}},{"caption":"Equity and Access","key":"sec-efficient-ai-equity-access-c38d","order":{"number":47,"section":[1,9,1,0,0,0,0]}},{"caption":"Achieving Algorithmic Efficiency","key":"sec-efficient-ai-achieving-algorithmic-efficiency-ef15","order":{"number":18,"section":[1,4,2,0,0,0,0]}},{"caption":"Fallacies and Pitfalls","key":"sec-efficient-ai-fallacies-pitfalls-f804","order":{"number":51,"section":[1,10,0,0,0,0,0]}},{"caption":"Real-World Efficiency Strategies","key":"sec-efficient-ai-realworld-efficiency-strategies-8387","order":{"number":29,"section":[1,5,0,0,0,0,0]}},{"caption":": Data Center Energy Projections: Between 2010 and 2030, data center electricity usage is projected to increase sharply, particularly under worst-case scenarios where consumption could exceed 8,000 TWh by 2030 [@jones2018much]. This projection underscores the critical need for improved energy efficiency in AI systems.","key":"fig-datacenter-energy-usage","order":{"number":11,"section":[1,4,3,2,0,0,0]}},{"caption":"Data Efficiency vs. Model Generalization","key":"sec-efficient-ai-data-efficiency-vs-model-generalization-044a","order":{"number":36,"section":[1,6,1,3,0,0,0]}},{"caption":"Scaling Breakdown Types: Unbalanced scaling across model size, data volume, and compute resources leads to specific failure modes, such as overfitting or diminishing returns, impacting system performance and efficiency. The table categorizes these breakdowns, identifies their root causes, and provides representative scenarios to guide more effective system design and resource allocation.","key":"tbl-scaling-breakdown","order":{"number":1,"section":[1,3,6,0,0,0,0]}},{"caption":"Optimal Compute Allocation: For fixed computational budgets, language model performance depends on balancing model size and training data volume; the left panel maps training loss across parameter counts, identifying an efficiency sweet spot for each FLOP level. The center and right panels quantify how optimal parameter counts and token requirements scale predictably with increasing compute, demonstrating the need for coordinated scaling of both model and data to maximize resource utilization in large language models. Source: [@hoffmann2022training].","key":"fig-compute-optimal","order":{"number":3,"section":[1,3,2,0,0,0,0]}},{"caption":"Sustainable Computing and Energy Awareness","key":"sec-efficient-ai-sustainable-computing-energy-awareness-d77a","order":{"number":25,"section":[1,4,3,2,0,0,0]}},{"caption":"Maximizing Learning from Limited Data","key":"sec-efficient-ai-maximizing-learning-limited-data-2885","order":{"number":28,"section":[1,4,4,1,0,0,0]}},{"caption":"Dataset Growth: Foundation models are increasingly trained on vast datasets, reflecting the growing stock of human-generated text. This trend underscores the challenge of data scarcity in maintaining model performance as scale increases. Source: @villalobos_ho_sevilla_besiroglu_heim_hobbhahn_2024.","key":"fig-running-out-of-human-data","order":{"number":12,"section":[1,4,4,1,0,0,0]}},{"caption":"Sustainability and Cost Implications","key":"sec-efficient-ai-sustainability-cost-implications-0473","order":{"number":13,"section":[1,3,5,0,0,0,0]}},{"caption":"Algorithmic Efficiency vs. Compute Requirements","key":"sec-efficient-ai-algorithmic-efficiency-vs-compute-requirements-83a7","order":{"number":34,"section":[1,6,1,1,0,0,0]}},{"caption":"Recurring Trade-off Patterns in Practice","key":"sec-efficient-ai-recurring-tradeoff-patterns-practice-c205","order":{"number":37,"section":[1,6,2,0,0,0,0]}},{"caption":"Scalability and Sustainability","key":"sec-efficient-ai-scalability-sustainability-4d30","order":{"number":31,"section":[1,5,2,0,0,0,0]}},{"caption":"Scaling Law Breakdown Conditions","key":"sec-efficient-ai-scaling-law-breakdown-conditions-1f8c","order":{"number":14,"section":[1,3,6,0,0,0,0]}},{"caption":"Compute-Optimal Resource Allocation","key":"sec-efficient-ai-computeoptimal-resource-allocation-541a","order":{"number":7,"section":[1,3,2,0,0,0,0]}},{"caption":"Context-Specific Efficiency Requirements","key":"sec-efficient-ai-contextspecific-efficiency-requirements-47e6","order":{"number":30,"section":[1,5,1,0,0,0,0]}},{"caption":"Practical Applications in System Design","key":"sec-efficient-ai-practical-applications-system-design-5c97","order":{"number":12,"section":[1,3,4,0,0,0,0]}},{"caption":": Data Scaling Regimes: The relationship between dataset size and generalization error follows distinct scaling regimes. Increasing dataset size initially reduces generalization error following a power-law relationship, but eventually plateaus at an irreducible error floor determined by inherent data limitations or model capacity [@hestness2017deep]. This behavior exposes diminishing returns from data scaling and informs practical decisions about data collection efforts in machine learning systems.","key":"fig-data-scaling-regimes","order":{"number":6,"section":[1,3,3,2,0,0,0]}},{"caption":"Efficiency Trade-offs and Challenges","key":"sec-efficient-ai-efficiency-tradeoffs-challenges-946d","order":{"number":32,"section":[1,6,0,0,0,0,0]}},{"caption":"Optimization Limits","key":"sec-efficient-ai-optimization-limits-20f0","order":{"number":49,"section":[1,9,3,0,0,0,0]}},{"caption":"Dynamic Resource Allocation at Inference","key":"sec-efficient-ai-dynamic-resource-allocation-inference-d6bc","order":{"number":40,"section":[1,7,2,0,0,0,0]}},{"caption":"Data Efficiency","key":"sec-efficient-ai-data-efficiency-a3ad","order":{"number":27,"section":[1,4,4,0,0,0,0]}},{"caption":"Integrating Efficiency with Scaling","key":"sec-efficient-ai-integrating-efficiency-scaling-a513","order":{"number":15,"section":[1,3,7,0,0,0,0]}},{"caption":": Loss vs Model and Dataset Size: Early-stopped test loss varies predictably with both dataset size and model size, highlighting the importance of balanced scaling for optimal performance under fixed compute budgets.","key":"fig-loss-vs-n-d","order":{"number":5,"section":[1,3,3,1,0,0,0]}},{"caption":"Mathematical Foundations and Operational Regimes","key":"sec-efficient-ai-mathematical-foundations-operational-regimes-9afe","order":{"number":8,"section":[1,3,3,0,0,0,0]}},{"caption":"Empirical Evidence for Scaling Laws","key":"sec-efficient-ai-empirical-evidence-scaling-laws-0105","order":{"number":6,"section":[1,3,1,0,0,0,0]}},{"caption":"Temporal Scaling Regimes","key":"sec-efficient-ai-temporal-scaling-regimes-e118","order":{"number":11,"section":[1,3,3,3,0,0,0]}},{"caption":": Temporal Scaling Regimes: Different temporal scaling regimes offer distinct approaches to improving model performance with varying compute investments. Pre-training establishes broad capabilities through large-scale training from scratch, post-training refines existing models through additional training phases, and test-time scaling dynamically allocates compute during inference to enhance per-sample results. Understanding these regimes clarifies the trade-offs between upfront investment and flexible, on-demand resource allocation for optimal system performance.","key":"fig-scaling-regimes","order":{"number":7,"section":[1,3,3,3,0,0,0]}},{"caption":"Hardware-Algorithm Co-Design","key":"sec-efficient-ai-hardwarealgorithm-codesign-67e8","order":{"number":20,"section":[1,4,2,2,0,0,0]}},{"caption":"Strategic Trade-off Management","key":"sec-efficient-ai-strategic-tradeoff-management-0ac8","order":{"number":38,"section":[1,7,0,0,0,0,0]}},{"caption":"Holistic Pipeline Optimization","key":"sec-efficient-ai-holistic-pipeline-optimization-5bcc","order":{"number":44,"section":[1,8,1,0,0,0,0]}},{"caption":"Moore’s Law Case Study","key":"sec-efficient-ai-moores-law-case-study-5767","order":{"number":50,"section":[1,9,3,1,0,0,0]}},{"caption":"The Efficiency Framework","key":"sec-efficient-ai-efficiency-framework-c0de","order":{"number":16,"section":[1,4,0,0,0,0,0]}},{"caption":"Measuring and Monitoring Efficiency Trade-offs","key":"sec-efficient-ai-measuring-monitoring-efficiency-tradeoffs-fd5b","order":{"number":42,"section":[1,7,4,0,0,0,0]}},{"caption":"Environment-Driven Efficiency Priorities","key":"sec-efficient-ai-environmentdriven-efficiency-priorities-4057","order":{"number":39,"section":[1,7,1,0,0,0,0]}},{"caption":"Compute Efficiency vs. Real-Time Needs","key":"sec-efficient-ai-compute-efficiency-vs-realtime-needs-a269","order":{"number":35,"section":[1,6,1,2,0,0,0]}},{"caption":"The Efficiency Imperative","key":"sec-efficient-ai-efficiency-imperative-d65c","order":{"number":2,"section":[1,1,0,0,0,0,0]}},{"caption":": Historical Efficiency Trends: Algorithmic, computational, and data efficiency have each contributed to substantial gains in AI capabilities, though at different rates and with diminishing returns. Understanding these historical trends clarifies the interplay between these efficiency dimensions and informs strategies for scaling machine learning systems in data-limited environments.","key":"fig-evolution-efficiency","order":{"number":8,"section":[1,4,1,0,0,0,0]}},{"caption":"Scaling Laws & Compute Optimality: Larger models consistently achieve better performance with increased training data and compute, but diminishing returns necessitate careful resource allocation during training. Optimal model size and training duration depend on the available compute budget, as evidenced by the convergence of loss curves at different parameter scales and training token counts. Source: [@kaplan2020scaling].","key":"fig-kaplan-scaling","order":{"number":4,"section":[1,3,2,0,0,0,0]}},{"caption":"Efficiency Optimization Priorities by Deployment Context: Each environment demands different trade-offs between algorithmic, compute, and data optimization strategies based on unique constraints. Cloud systems prioritize scalability, edge deployments focus on real-time performance, mobile applications balance performance with battery life, and TinyML demands extreme resource efficiency.","key":"tbl-deployment-efficiency-priorities","order":{"number":2,"section":[1,5,1,0,0,0,0]}},{"caption":"Defining System Efficiency","key":"sec-efficient-ai-defining-system-efficiency-a4b7","order":{"number":3,"section":[1,2,0,0,0,0,0]}},{"caption":"Efficient AI","key":"sec-efficient-ai","order":{"number":1,"section":[1,0,0,0,0,0,0]}},{"caption":"End-to-End Co-Design and Automated Optimization","key":"sec-efficient-ai-endtoend-codesign-automated-optimization-1220","order":{"number":41,"section":[1,7,3,0,0,0,0]}},{"caption":"Resource-Constrained Scaling Regimes","key":"sec-efficient-ai-resourceconstrained-scaling-regimes-062d","order":{"number":9,"section":[1,3,3,1,0,0,0]}},{"caption":"Societal and Ethical Implications","key":"sec-efficient-ai-societal-ethical-implications-d0e5","order":{"number":46,"section":[1,9,0,0,0,0,0]}},{"caption":"AI Scaling Laws","key":"sec-efficient-ai-ai-scaling-laws-a043","order":{"number":5,"section":[1,3,0,0,0,0,0]}},{"caption":": Efficiency and Sustainability Feedback Loop: Optimized machine learning systems achieve greater scalability, which in turn incentivizes sustainable design practices and further efficiency improvements, creating a reinforcing feedback loop for long-term impact.","key":"fig-virtuous-efficiency-cycle","order":{"number":13,"section":[1,5,2,0,0,0,0]}},{"caption":"From CPUs to AI Accelerators","key":"sec-efficient-ai-cpus-ai-accelerators-a8d7","order":{"number":24,"section":[1,4,3,1,0,0,0]}},{"caption":"Compute Efficiency","key":"sec-efficient-ai-compute-efficiency-745c","order":{"number":23,"section":[1,4,3,0,0,0,0]}},{"caption":": AI Training Compute Growth: AI training experienced a 300,000-fold increase in computational requirements from 2012 to 2019, exceeding the growth rate predicted by Moore’s Law and driving demand for specialized hardware [@Amodei_et_al_2018]. This exponential growth underscores the increasing complexity of AI models and the need for efficient computing infrastructure to support continued progress.","key":"fig-comp_efficiency","order":{"number":10,"section":[1,4,3,1,0,0,0]}},{"caption":"Production Deployment Patterns","key":"sec-efficient-ai-production-deployment-patterns-208a","order":{"number":26,"section":[1,4,3,3,0,0,0]}},{"caption":"Data-Limited Scaling Regimes","key":"sec-efficient-ai-datalimited-scaling-regimes-ba1d","order":{"number":10,"section":[1,3,3,2,0,0,0]}},{"caption":"Fundamental Sources of Efficiency Trade-offs","key":"sec-efficient-ai-fundamental-sources-efficiency-tradeoffs-d16f","order":{"number":33,"section":[1,6,1,0,0,0,0]}},{"caption":"Parameter-Efficient Adaptation","key":"sec-efficient-ai-parameterefficient-adaptation-1bce","order":{"number":22,"section":[1,4,2,4,0,0,0]}},{"caption":"Engineering Principles for Efficient AI","key":"sec-efficient-ai-engineering-principles-efficient-ai-1206","order":{"number":43,"section":[1,8,0,0,0,0,0]}},{"caption":"Lifecycle and Environment Considerations","key":"sec-efficient-ai-lifecycle-environment-considerations-3abc","order":{"number":45,"section":[1,8,2,0,0,0,0]}}],"headings":["sec-efficient-ai","purpose","sec-efficient-ai-efficiency-imperative-d65c","sec-efficient-ai-defining-system-efficiency-a4b7","sec-efficient-ai-efficiency-interdependencies-5d69","sec-efficient-ai-ai-scaling-laws-a043","sec-efficient-ai-empirical-evidence-scaling-laws-0105","sec-efficient-ai-computeoptimal-resource-allocation-541a","sec-efficient-ai-mathematical-foundations-operational-regimes-9afe","sec-efficient-ai-resourceconstrained-scaling-regimes-062d","sec-efficient-ai-datalimited-scaling-regimes-ba1d","sec-efficient-ai-temporal-scaling-regimes-e118","sec-efficient-ai-practical-applications-system-design-5c97","sec-efficient-ai-sustainability-cost-implications-0473","sec-efficient-ai-scaling-law-breakdown-conditions-1f8c","sec-efficient-ai-integrating-efficiency-scaling-a513","sec-efficient-ai-efficiency-framework-c0de","sec-efficient-ai-multidimensional-efficiency-synergies-ea04","sec-efficient-ai-achieving-algorithmic-efficiency-ef15","sec-efficient-ai-model-compression-fundamentals-bcc3","sec-efficient-ai-hardwarealgorithm-codesign-67e8","sec-efficient-ai-architectural-innovation-efficiency-7dd9","sec-efficient-ai-parameterefficient-adaptation-1bce","sec-efficient-ai-compute-efficiency-745c","sec-efficient-ai-cpus-ai-accelerators-a8d7","sec-efficient-ai-sustainable-computing-energy-awareness-d77a","sec-efficient-ai-production-deployment-patterns-208a","sec-efficient-ai-data-efficiency-a3ad","sec-efficient-ai-maximizing-learning-limited-data-2885","sec-efficient-ai-realworld-efficiency-strategies-8387","sec-efficient-ai-contextspecific-efficiency-requirements-47e6","sec-efficient-ai-scalability-sustainability-4d30","sec-efficient-ai-efficiency-tradeoffs-challenges-946d","sec-efficient-ai-fundamental-sources-efficiency-tradeoffs-d16f","sec-efficient-ai-algorithmic-efficiency-vs-compute-requirements-83a7","sec-efficient-ai-compute-efficiency-vs-realtime-needs-a269","sec-efficient-ai-data-efficiency-vs-model-generalization-044a","sec-efficient-ai-recurring-tradeoff-patterns-practice-c205","sec-efficient-ai-strategic-tradeoff-management-0ac8","sec-efficient-ai-environmentdriven-efficiency-priorities-4057","sec-efficient-ai-dynamic-resource-allocation-inference-d6bc","sec-efficient-ai-endtoend-codesign-automated-optimization-1220","sec-efficient-ai-measuring-monitoring-efficiency-tradeoffs-fd5b","sec-efficient-ai-engineering-principles-efficient-ai-1206","sec-efficient-ai-holistic-pipeline-optimization-5bcc","sec-efficient-ai-lifecycle-environment-considerations-3abc","sec-efficient-ai-societal-ethical-implications-d0e5","sec-efficient-ai-equity-access-c38d","sec-efficient-ai-balancing-innovation-efficiency-demands-7a44","sec-efficient-ai-optimization-limits-20f0","sec-efficient-ai-moores-law-case-study-5767","sec-efficient-ai-fallacies-pitfalls-f804","sec-efficient-ai-summary-66bb","self-check-answers"],"options":{"appendix-delim":":","appendix-title":"Appendix","custom":["vidfloatvidVideo"]}}