{"title":"About","markdown":{"headingText":"About","headingAttr":{"id":"","classes":["unnumbered"],"keyvalue":[]},"containsRefs":false,"markdown":"\n## Overview {#sec-book-overview-c27b}\n\nThis section provides essential background about the purpose of this work, its development context, and what readers can expect from their learning journey.\n\n### Purpose {#sec-book-purpose-book-5d4f}\n\nThe goal of this work is to provide a resource for educators and learners seeking to understand the principles and practices of machine learning systems. The content is continually updated to incorporate the latest insights and effective teaching strategies. We intend that it remains a valuable resource in this fast-evolving field. Please check back often!\n\n### Context and Development {#sec-book-context-development-2824}\n\nThis work originated as a collaborative effort with contributions from students, researchers, and practitioners. While maintaining its academic rigor and real-world applicability, the content continues to evolve through regular updates and careful curation to reflect the latest developments in machine learning systems.\n\n### What to Expect {#sec-book-expect-df55}\n\nThis textbook is organized into two volumes following the **Hennessy & Patterson pedagogical model**, the same approach that has guided generations of computer architecture students through progressively deeper understanding.\n\n| Volume | Theme | Focus | Analogy |\n|--------|-------|-------|---------|\n| **Volume I** | Build, Optimize, Deploy | Single-machine ML systems, foundational principles | \"Computer Organization and Design\" |\n| **Volume II** | Scale, Distribute, Govern | Distributed systems at production scale | \"Computer Architecture\" |\n\n**Volume I** teaches you to *understand* ML systems. **Volume II** teaches you to *build* ML systems at scale.\n\n**Volume I: Build, Optimize, Deploy** establishes the foundations through four progressive stages:\n\n- **Foundations** (Part I): Build your conceptual foundation, establishing the mental models that underpin all effective systems work.\n\n- **Development** (Part II): Engineer complete workflows, from data pipelines through training infrastructure.\n\n- **Optimization** (Part III): Transform theoretical understanding into systems that run efficiently in resource-constrained environments.\n\n- **Deployment** (Part IV): Navigate serving, operations, and responsible engineering practices.\n\n**Volume II: Scale, Distribute, Govern** extends these foundations into production-scale systems:\n\n- **Foundations of Scale** (Part V): Master infrastructure, storage, and communication for systems spanning multiple machines.\n\n- **Distributed Systems** (Part VI): Address distributed training, fault tolerance, and inference at scale.\n\n- **Production Challenges** (Part VII): Tackle on-device learning, security, privacy, and robust system design.\n\n- **Responsible Deployment** (Part VIII): Explore responsible AI, sustainability, and emerging frontiers.\n\n**Laboratory exercises** complement the core content, allowing you to apply concepts with hands-on experience across multiple embedded platforms. Throughout both volumes, **quizzes** provide quick self-checks to reinforce understanding at key learning milestones.\n\n### Pedagogical Philosophy: Foundations First {#sec-book-pedagogical-philosophy-foundations-first-4f88-foundations-first-4f88}\n\nMachine learning systems represent inherently complex engineering challenges. However, they are constructed from fundamental building blocks that must be thoroughly understood before advancing to sophisticated implementations. This pedagogical approach parallels established educational progressions: students master basic algorithms before tackling distributed systems, or develop proficiency in linear algebra before engaging with advanced machine learning theory. ML systems similarly possess essential foundational components that serve as the basis for all subsequent learning.\n\nOur curriculum emphasizes mastery of these core building blocks:\n\n- The interaction between models and hardware\n- Data flow patterns through systems\n- Computational pattern emergence\n- Optimization principles within individual systems\n\nThrough comprehensive understanding of these fundamentals, students develop the analytical framework necessary to reason effectively about complex scenarios including distributed training architectures, multi-device coordination protocols, and emerging technological paradigms.\n\nThis foundations-first methodology prioritizes conceptual depth over topical breadth. This approach enables students to construct robust mental models that will serve as enduring intellectual resources throughout their professional careers as machine learning systems continue to evolve.\n\n```{=latex}\n\\clearpage\n```\n\n## Learning Goals {#sec-book-learning-goals-bafe}\n\nThis section outlines the educational framework guiding the design of this work and the specific learning objectives readers will achieve.\n\n### Key Learning Outcomes {#sec-book-key-learning-outcomes-624e}\n\nBoth volumes are structured with [Bloom's Taxonomy](https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/) in mind (@fig-bloom), which defines six levels of learning, ranging from foundational knowledge to advanced creative thinking:\n\n![Bloom's Taxonomy (2021 edition).](images/png/bloom_revised_taxonomy.png){#fig-bloom}\n\n1. **Remembering**: Recalling basic facts and concepts.\n\n2. **Understanding**: Explaining ideas or processes.\n\n3. **Applying**: Using knowledge in new situations.\n\n4. **Analyzing**: Breaking down information into components.\n\n5. **Evaluating**: Making judgments based on criteria and standards.\n\n6. **Creating**: Producing original work or solutions.\n\n### Learning Objectives {#sec-book-learning-objectives-b644}\n\nThis work supports readers in developing practical expertise across the ML systems lifecycle:\n\n1. **Systems Thinking**: Understand how ML systems differ from traditional software, and reason about hardware-software interactions.\n\n2. **Workflow Engineering**: Design end-to-end ML pipelines, from data engineering through deployment and maintenance.\n\n3. **Performance Optimization**: Apply systematic approaches to make systems faster, smaller, and more resource-efficient.\n\n4. **Production Deployment**: Address real-world challenges including reliability, security, privacy, and scalability.\n\n5. **Responsible Development**: Navigate ethical implications and implement sustainable, socially beneficial AI systems.\n\n6. **Future-Ready Skills**: Develop judgment to evaluate emerging technologies and adapt to evolving paradigms.\n\n7. **Hands-On Implementation**: Gain practical experience across diverse embedded platforms and resource constraints.\n\n8. **Self-Directed Learning**: Use integrated assessments and interactive tools to track progress and deepen understanding.\n\n### AI Learning Companion {#sec-book-ai-learning-companion-8ec9}\n\nThroughout this resource, you'll find **SocratiQ**, an AI learning assistant designed to enhance your learning experience. Inspired by the Socratic method of teaching, SocratiQ combines interactive quizzes, personalized assistance, and real-time feedback to help you reinforce your understanding and create new connections. As part of our integration of Generative AI technologies, SocratiQ encourages critical thinking and active engagement with the material.\n\nSocratiQ is still a work in progress, and we welcome your feedback to make it better. For more details about how SocratiQ works and how to get the most out of it, visit the [AI Learning Companion page](../socratiq/socratiq.qmd).\n\n## How to Use This Work {#sec-book-use-book-aca7}\n\n### Structure {#sec-book-book-structure-0b7a}\n\nThis work takes you from understanding ML systems conceptually to building and deploying them in practice. The content is organized into two volumes following the Hennessy & Patterson pedagogical model, each containing four parts that develop specific capabilities.\n\n**Volume I: Build, Optimize, Deploy**\n\n1. **Part I: Foundations**\n   *Master the fundamentals.* Build intuition for how ML systems differ from traditional software, understand the hardware-software stack, and gain fluency with essential architectures and mathematical foundations.\n\n2. **Part II: Development**\n   *Engineer complete workflows.* Learn to design end-to-end ML pipelines, manage complex data engineering challenges, select appropriate frameworks, and orchestrate training.\n\n3. **Part III: Optimization**\n   *Optimize for real constraints.* Develop skills to make systems faster, smaller, and more efficient through model optimization, hardware acceleration, and systematic performance analysis.\n\n4. **Part IV: Deployment**\n   *Deploy with confidence.* Master serving fundamentals, ML operations, responsible engineering practices, and the principles that ensure systems work reliably in production.\n\n**Volume II: Scale, Distribute, Govern**\n\n5. **Part V: Foundations of Scale**\n   *Build for distributed systems.* Understand the infrastructure, storage systems, and communication patterns required when ML systems span multiple machines.\n\n6. **Part VI: Distributed Systems**\n   *Scale training and inference.* Master distributed training strategies, fault tolerance mechanisms, and inference optimization across diverse deployment targets.\n\n7. **Part VII: Production Challenges**\n   *Navigate real-world complexity.* Address on-device learning, edge intelligence, security and privacy requirements, and robust system design.\n\n8. **Part VIII: Responsible Deployment**\n   *Design for impact.* Explore responsible AI practices, sustainable computing, AI for societal benefit, and emerging frontiers in ML systems.\n\n**Hands-On Learning:**\n\n**Laboratory Exercises** complement both volumes, allowing you to implement concepts with hands-on experience across multiple embedded platforms, from microcontrollers to edge computing devices.\n\n### The Learning Journey {#sec-book-learning-journey}\n\nEach Part addresses a fundamental question that ML systems engineers face when building production systems. These questions provide a conceptual roadmap for your learning.\n\n**Volume I: Build, Optimize, Deploy**\n\n**Part I: Foundations** asks: *What is ML systems engineering and how does development work?*\nBefore building neural networks, engineers must understand the unique characteristics of ML systems, how they differ from traditional software, and why they require specialized engineering approaches. This Part develops the end-to-end workflow that guides ML projects from problem formulation to deployment, establishing why data engineering is foundational to everything that follows.\n\n**Part II: Development** asks: *How do we implement ML models from mathematical foundations to working systems?*\nWith workflow and data foundations established, students can appreciate why specific architectural choices matter. This Part covers the mathematics of deep learning, examines major neural network architectures, explains how frameworks like PyTorch implement these ideas, and addresses the complexities of training models effectively.\n\n**Part III: Optimization** asks: *How do we make ML systems efficient enough for real-world deployment?*\nProduction constraints demand models that are smaller, faster, and more efficient than research prototypes. This Part presents techniques for model compression and efficiency, surveys the hardware landscape from GPUs to specialized accelerators, and develops rigorous performance measurement methodologies.\n\n**Part IV: Deployment** asks: *How do we operate ML systems reliably in production?*\nBuilding an accurate model represents only part of the challenge. This Part addresses infrastructure for serving predictions at scale, operational practices that keep systems running reliably, and engineering approaches for building systems that are fair, transparent, and trustworthy.\n\n**Volume II: Scale, Distribute, Govern**\n\n**Part V: Foundations of Scale** asks: *What infrastructure enables ML systems to operate across multiple machines?*\nScaling beyond a single machine requires understanding physical infrastructure, storage systems, and the communication patterns that coordinate distributed computation. This Part establishes the foundational context for distributed ML systems.\n\n**Part VI: Distributed Systems** asks: *How do we train models too large for any single machine and serve them at scale?*\nModern models often exceed the memory and compute capacity of individual GPUs. This Part develops parallelism strategies, communication techniques, fault tolerance mechanisms, and inference optimization approaches that enable ML at unprecedented scale.\n\n**Part VII: Production Challenges** asks: *How do we navigate real-world complexity in production ML systems?*\nFrom edge intelligence to security threats and adversarial inputs, production systems face multifaceted challenges. This Part addresses on-device learning, robust system design, security, and privacy requirements.\n\n**Part VIII: Responsible Deployment** asks: *How do we ensure ML systems are sustainable and benefit society?*\nTechnical excellence alone is insufficient. This Part addresses responsible AI practices, environmental sustainability, beneficial applications, and the emerging frontiers that will shape the future of ML systems.\n\n### Suggested Reading Paths {#sec-book-suggested-reading-paths-10b8}\n\n- **Beginners**: Start with Volume I, Parts I and II to build conceptual understanding and workflow skills. Add laboratory exercises for hands-on experience before advancing to optimization topics.\n\n- **Practitioners**: Complete Volume I for core competencies, then focus on Volume II Parts V through VII for distributed systems and production deployment insights relevant to industry work.\n\n- **Researchers**: Work through Volume I for foundations, then explore Volume II for advanced topics including distributed training, robust systems, and emerging frontiers.\n\n- **Graduate Courses**: Volume I serves as a complete semester-length course. Volume II provides material for an advanced seminar or second course.\n\n- **Hands-On Learners**: Combine reading from either volume with the laboratory exercises across Arduino, Seeed, Grove Vision, and Raspberry Pi platforms.\n\n### Prerequisites {#sec-book-prerequisites-4a7c}\n\nThis textbook assumes the following background:\n\n**Required**:\n\n- **Programming Proficiency**: Fluency in Python is essential. You should be comfortable with functions, classes, data structures, and basic file I/O. Familiarity with NumPy and basic data manipulation is helpful.\n\n- **Mathematics Foundations**: Understanding of linear algebra (vectors, matrices, matrix multiplication), basic calculus (derivatives, gradients, chain rule), and probability/statistics (distributions, expectation, variance). These concepts are reviewed briefly where used but not taught from scratch.\n\n**Recommended but Not Required**:\n\n- **Computer Systems**: Familiarity with memory hierarchies, basic computer architecture, or operating systems concepts helps with optimization and deployment chapters. Students without this background will find explanatory footnotes and references throughout.\n\n- **Machine Learning Basics**: Prior exposure to supervised learning concepts (training, validation, overfitting) is helpful but not required. Part I provides foundations for students new to ML.\n\n**Volume II Additional Prerequisites**:\n\n- Volume II assumes completion of Volume I or equivalent background in single-machine ML systems.\n- Familiarity with distributed systems concepts (networking, parallelism) is helpful for Part V onward.\n\n### For Students with Different Backgrounds {#sec-book-students-different-backgrounds-21ef}\n\nThis textbook welcomes students from diverse academic backgrounds, whether you come from computer science, engineering, mathematics, or other fields. Understanding how ML systems connect to your existing knowledge helps bridge theoretical concepts to practical implementation:\n\n**Computer Science Students**: ML systems extend familiar concepts into new domains. If you've worked with algorithms and data structures, think of ML as learning algorithms that automatically optimize themselves based on data patterns rather than following fixed instructions.\n\nYour experience with system design, memory management, parallel processing, and distributed systems directly applies to ML deployment. The underlying computational complexity analysis still applies. We analyze time and space complexity for training and inference phases separately.\n\n**Electrical and Computer Engineering Students**: ML systems represent a natural evolution of signal processing and control systems principles. Machine learning can be viewed as advanced signal processing where we extract meaningful patterns from noisy, high-dimensional signals.\n\nNeural networks perform operations similar to filters. Convolution layers in image processing are literally convolution operations you have studied. Your background in computer systems organization and architecture becomes essential for understanding how ML algorithms map to different hardware platforms, while your understanding of memory hierarchies helps optimize data movement in large-scale training systems.\n\n**Students from Other Backgrounds**: Think of ML systems like a modern factory assembly line. Just as a factory transforms raw materials into finished products through coordinated stages, ML systems transform raw data into useful predictions through interconnected components.\n\nThe mathematics (linear algebra, probability, and calculus) are the \"tools\" of this factory, but you do not need to be a tool expert to understand how the assembly line works. Most concepts become clear through concrete examples, like understanding how a recommendation system works by thinking about how a librarian might suggest books based on your reading history.\n\nThe key skill is systems thinking: understanding how data pipelines, training processes, and deployment infrastructure work together, much like how supply chains, manufacturing, and distribution must coordinate in any complex operation.\n\n### Modular Design {#sec-book-modular-design-8b30}\n\nBoth volumes are designed for flexible learning, allowing readers to explore chapters independently or follow suggested sequences. Each chapter integrates:\n\n- **Interactive quizzes** for self-assessment and knowledge reinforcement\n- **Practical exercises** connecting theory to implementation\n- **Laboratory experiences** providing hands-on platform-specific learning\n\nWe embrace an iterative approach to content development, sharing valuable insights as they become available rather than waiting for perfection. Your feedback helps us continuously improve and refine this resource.\n\nWe also build upon the excellent work of experts in the field, fostering a collaborative learning ecosystem where knowledge is shared, extended, and collectively advanced.\n\n## Transparency and Collaboration {#sec-book-transparency-collaboration-171f}\n\nThis work began as a community-driven project shaped by the collective efforts of students in CS249r, colleagues at Harvard and beyond, and the broader ML systems community. The content has evolved through open collaboration, thoughtful feedback, and modern editing tools including both rule-based scripts and generative AI technologies. In a fitting twist, the very systems we study in these pages have helped refine them, highlighting the interplay between human expertise and machine intelligence. Fortunately, they are not quite ready to engineer the systems themselves. At least, not yet.\n\nAs the primary author, editor, and curator, I (Prof. Vijay Janapa Reddi) provide human-in-the-loop oversight to ensure the material remains accurate, relevant, and of the highest quality. Still, no one is perfect, so errors may exist. Your feedback is welcome and encouraged. This collaborative model is essential for maintaining quality and ensuring that knowledge remains open, evolving, and globally accessible.\n\n## Copyright and Licensing {#sec-book-copyright-licensing-33bd}\n\nThis work is open-source and developed collaboratively through GitHub. Unless otherwise stated, the content is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0).\n\nContributors retain copyright over their individual contributions, dedicated to the public domain or released under the same open license as the original project. For more information on authorship and contributions, visit the [GitHub repository](https://github.com/harvard-edge/cs249r_book).\n\n## Join the Community {#sec-book-join-community-dd04}\n\nThis work is more than a resource. It is an invitation to collaborate and learn together. Engage in [community discussions](https://github.com/harvard-edge/cs249r_book/discussions) to share insights, tackle challenges, and learn alongside fellow students, researchers, and practitioners.\n\nWhether you are a student starting your journey, a practitioner solving real-world challenges, or a researcher exploring advanced concepts, your contributions will enrich this learning community. Introduce yourself, share your goals, and let us collectively build a deeper understanding of machine learning systems.\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["../../../filters/sidenote.lua","../../../filters/inject_parts.lua","../../../filters/inject_quizzes.lua","pandoc-ext/diagram","mlsysbook-ext/custom-numbered-blocks"],"title-prefix":"","reference-location":"margin","highlight-style":"../../../assets/styles/custom-code.theme","toc":true,"toc-depth":4,"number-sections":false,"include-in-header":{"text":"<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\">\n<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n<link rel=\"manifest\" href=\"/site.webmanifest\">\n<link rel=\"apple-touch-icon\" href=\"/assets/images/icons/favicon.png\">\n<meta name=\"theme-color\" content=\"#A51C30\">\n\n<script type=\"module\"  src=\"/tools/scripts/socratiQ/bundle.js\" defer></script>\n<script src=\"/assets/scripts/sidebar-auto-collapse.js\" defer></script>\n<script src=\"/assets/scripts/version-link.js\" defer></script>\n<script src=\"/assets/scripts/subscribe-modal.js\" defer></script>\n"},"citeproc":true,"output-file":"about.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author, Editor & Curator","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Last Updated","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","bibliography":["../../../contents/vol1/introduction/introduction.bib","../../../contents/vol1/responsible_engr/responsible_engr.bib","../../../contents/vol1/benchmarking/benchmarking.bib","../../../contents/vol1/data_engineering/data_engineering.bib","../../../contents/vol1/dl_primer/dl_primer.bib","../../../contents/vol1/dnn_architectures/dnn_architectures.bib","../../../contents/vol1/efficient_ai/efficient_ai.bib","../../../contents/vol1/ml_systems/ml_systems.bib","../../../contents/vol1/frameworks/frameworks.bib","../../../contents/vol1/hw_acceleration/hw_acceleration.bib","../../../contents/vol1/ops/ops.bib","../../../contents/vol1/optimizations/optimizations.bib","../../../contents/vol1/training/training.bib","../../../contents/vol1/workflow/workflow.bib","../../../contents/vol1/serving/serving.bib","../../../contents/vol1/conclusion/conclusion.bib","../../../contents/vol2/ops_scale/ops_scale.bib","../../../contents/vol2/edge_intelligence/edge_intelligence.bib","../../../contents/vol2/privacy_security/privacy_security.bib","../../../contents/vol2/responsible_ai/responsible_ai.bib","../../../contents/vol2/robust_ai/robust_ai.bib","../../../contents/vol2/sustainable_ai/sustainable_ai.bib","../../../contents/vol2/ai_for_good/ai_for_good.bib","../../../contents/vol2/frontiers/frontiers.bib"],"crossref":{"appendix-title":"Appendix","appendix-delim":":","custom":[{"kind":"float","key":"vid","latex-env":"vid","reference-prefix":"Video"}]},"filter-metadata":{"quiz-config":{"file-pattern":"*_quizzes.json","scan-directory":"../../../contents/vol1","auto-discover-pdf":false},"part-summaries":{"file":"../../../contents/parts/summaries.yml","enabled":true},"mlsysbook-ext/custom-numbered-blocks":{"icon-path":"../../../assets/images/icons/callouts","icon-format":"png","groups":{"quiz-question":{"colors":["F0F0F8","5B4B8A"],"collapse":true},"quiz-answer":{"colors":["E8F2EA","4a7c59"],"collapse":true},"resource-slides":{"colors":["E0F2F1","20B2AA"],"collapse":true,"numbered":false},"resource-videos":{"colors":["E0F2F1","20B2AA"],"collapse":true,"numbered":false},"resource-exercises":{"colors":["E0F2F1","20B2AA"],"collapse":true,"numbered":false},"chapter-connection":{"colors":["FDF2F7","A51C30"],"boxstyle":"foldbox.simple","collapse":true,"numbered":false},"chapter-forward":{"colors":["FDF2F7","A51C30"],"boxstyle":"foldbox.simple","collapse":true,"numbered":false},"chapter-recall":{"colors":["FFF4E6","C06014"],"collapse":true,"numbered":false},"code-listing":{"colors":["F2F4F8","D1D7E0"],"collapse":false,"numbered":false},"definition":{"colors":["F0F4F8","1B4F72"],"collapse":false,"numbered":false},"example":{"colors":["F0F8F6","148F77"],"collapse":false,"numbered":false},"colab-interactive":{"colors":["FFF5E6","FF6B35"],"collapse":false,"numbered":false}},"classes":{"callout-quiz-question":{"label":"Self-Check: Question","group":"quiz-question"},"callout-quiz-answer":{"label":"Self-Check: Answer","group":"quiz-answer"},"callout-resource-slides":{"label":"Listing","group":"resource-slides"},"callout-resource-videos":{"label":"Videos","group":"resource-videos"},"callout-resource-exercises":{"label":"Exercises","group":"resource-exercises"},"callout-chapter-connection":{"label":"Related Topics","group":"chapter-connection"},"callout-code":{"label":"Code","group":"code-listing"},"callout-definition":{"label":"Definition","group":"definition"},"callout-example":{"label":"Example","group":"example"},"callout-colab":{"label":"Interactive Colab","group":"colab-interactive"}}}},"diagram":{"engine":{"dot":false,"mermaid":false,"asymptote":false,"tikz":{"execpath":"lualatex","output-format":"svg","header-includes":["\\usepackage{tikz}","\\usepackage{pgfplots}","\\usepackage{pgf-pie}","\\usepackage{amsmath}","\\usepackage{amssymb}","\\usepackage{xcolor}","\\pgfplotsset{compat=1.9}","\\usepgfplotslibrary{fillbetween}","\\usetikzlibrary{angles}","\\usetikzlibrary{arrows.meta}","\\usetikzlibrary{arrows}","\\usetikzlibrary{backgrounds}","\\usetikzlibrary{bending}","\\usetikzlibrary{calc}","\\usetikzlibrary{shadows.blur}","\\usetikzlibrary{fit}","\\usetikzlibrary{intersections}","\\usetikzlibrary{positioning}","\\usetikzlibrary{shapes.geometric}","\\usetikzlibrary{shapes}","\\usetikzlibrary{quotes}","\\usetikzlibrary{decorations.pathmorphing}","\\usetikzlibrary{decorations.markings}","\\usetikzlibrary{matrix}","\\usepgfplotslibrary{dateplot}","\\usepgfplotslibrary{polar}","\\definecolor{Brown}{rgb}{0.65, 0.16, 0.16}","\\definecolor{BrownL}{rgb}{0.6, 0.4, 0.2}","\\definecolor{BrownLine}{rgb}{0.5, 0.3, 0.1}","\\definecolor{BackColor}{RGB}{255,255,229}","\\definecolor{BackLine}{RGB}{181,181,72}","\\definecolor{BlueD}{RGB}{62,100,125}","\\definecolor{BlueL}{RGB}{209,243,255}","\\definecolor{BlueLine}{RGB}{34,148,189}","\\definecolor{BrownL}{RGB}{233,222,220}","\\definecolor{BrownLine}{RGB}{143,120,116}","\\definecolor{Green}{rgb}{0.0, 0.5, 0.0}","\\definecolor{GreenD}{RGB}{40,117,40}","\\definecolor{GreenL}{RGB}{219,253,166}","\\definecolor{GreenLine}{RGB}{73,89,56}","\\definecolor{OliveL}{RGB}{230,227,191}","\\definecolor{OliveLine}{RGB}{173,166,10}","\\definecolor{OrangeL}{RGB}{250,212,175}","\\definecolor{OrangeLine}{RGB}{255,127,76}","\\definecolor{RedL}{RGB}{253,226,240}","\\definecolor{RedLine}{RGB}{201,20,110}","\\definecolor{Sepia}{rgb}{0.44, 0.26, 0.08}","\\definecolor{TextColor}{RGB}{224,224,224}","\\definecolor{VioletL}{RGB}{247,180,247}","\\definecolor{VioletL2}{RGB}{243,243,255}","\\definecolor{VioletLine}{RGB}{34,125,189}","\\definecolor{VioletLine2}{RGB}{169,136,229}"]}}},"editor":{"render-on-save":true},"_quarto-vars":{"email":{"contact":"vj@eecs.harvard.edu","subject":["MLSys Book"],"info":"mailto:vj@eecs.harvard.edu?subject=\"CS249r%20MLSys%20with%20TinyML%20Book%20-%20\""},"title":{"long":"Machine Learning Systems","short":"Machine Learning Systems"}},"comments":{"hypothesis":{"theme":"clean","openSidebar":false}},"lightbox":true,"mermaid":{"theme":"default"},"theme":{"light":["default","../../../assets/styles/style.scss"],"dark":["default","../../../assets/styles/style.scss","../../../assets/styles/dark-mode.scss"]},"respect-user-color-scheme":true,"pagetitle":"ML Systems Textbook","code-block-bg":true,"code-copy":true,"citation-location":"margin","sidenote":true,"anchor-sections":true,"smooth-scroll":false,"citations-hover":false,"footnotes-hover":false,"toc-expand":true,"toc-title":"On this page","number-depth":3},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}