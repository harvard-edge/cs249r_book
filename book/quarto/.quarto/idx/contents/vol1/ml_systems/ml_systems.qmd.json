{"title":"ML Systems","markdown":{"yaml":{"bibliography":"ml_systems.bib","quiz":"footnote_context_quizzes.json","concepts":"ml_systems_concepts.yml","glossary":"ml_systems_glossary.json"},"headingText":"ML Systems","headingAttr":{"id":"sec-ml-systems","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n::: {layout-narrow}\n::: {.column-margin}\n*DALL·E 3 Prompt: Illustration in a rectangular format depicting the merger of embedded systems with Embedded AI. The left half of the image portrays traditional embedded systems, including microcontrollers and processors, detailed and precise. The right half showcases the world of artificial intelligence, with abstract representations of machine learning models, neurons, and data flow. The two halves are distinctly separated, emphasizing the individual significance of embedded tech and AI, but they come together in harmony at the center.*\n:::\n\n\\noindent\n![](images/png/cover_ml_systems.png)\n\n:::\n\n## Purpose {.unnumbered}\n\n_How do the environments where machine learning operates shape the nature of these systems, and what drives their widespread deployment across computing platforms?_\n\nMachine learning systems must adapt to radically different computational environments, each imposing distinct constraints and opportunities. Cloud deployments leverage massive computational resources but face network latency, while mobile devices offer user proximity but operate under severe power limitations. Embedded systems minimize latency through local processing but constrain model complexity, and tiny devices enable widespread sensing while restricting memory to kilobytes. These deployment contexts fundamentally determine system architecture, algorithmic choices, and performance trade-offs. Understanding environment-specific requirements establishes the foundation for engineering decisions in machine learning systems. This knowledge enables engineers to select appropriate deployment paradigms and design architectures that balance performance, efficiency, and practicality across computing platforms.\n\n::: {.callout-tip title=\"Learning Objectives\"}\n\n- Explain how physical constraints (speed of light, power wall, memory wall) create hard boundaries that necessitate the deployment spectrum from cloud to TinyML\n\n- Distinguish and compare the four deployment paradigms (Cloud ML, Edge ML, Mobile ML, TinyML) using quantitative metrics across compute power, memory, latency, power consumption, privacy, and connectivity dimensions\n\n- Apply the systematic deployment decision framework to select appropriate paradigms by evaluating privacy requirements, latency constraints, computational demands, and cost considerations\n\n- Analyze hybrid ML integration patterns (train-serve split, hierarchical processing, federated learning) to determine which combinations address specific system requirements\n\n- Critique common deployment fallacies and evaluate real-world production ML systems to assess whether architectural decisions align with stated requirements\n\n- Design hybrid ML architectures that integrate multiple deployment paradigms while applying universal design principles for data pipelines, resource management, and system architecture\n\n:::\n\n## Deployment Paradigm Framework {#sec-ml-systems-deployment-paradigm-framework-d434}\n\nThe preceding introduction established machine learning systems as comprising three fundamental components: data, algorithms, and computing infrastructure. While this triadic framework provides a theoretical foundation, practical implementation introduces a critical dimension that governs system design: the deployment environment. This chapter analyzes how computational context shapes architectural decisions in machine learning systems, establishing the basis for deployment-driven design principles.\n\nContemporary machine learning applications demonstrate remarkable architectural diversity driven by deployment constraints. Consider the domain of computer vision[^fn-computer-vision]: a convolutional neural network trained for image classification manifests as distinctly different systems when deployed across environments. In cloud-based medical imaging, the system exploits virtually unlimited computational resources to implement ensemble methods[^fn-ensemble-methods] and sophisticated preprocessing pipelines. When deployed on mobile devices for real-time object detection, the same fundamental algorithm undergoes architectural transformation to satisfy stringent latency requirements while preserving acceptable accuracy. Factory automation applications further constrain the design space, prioritizing power efficiency and deterministic response times over model complexity. These variations represent distinctly different architectural solutions to the same computational problem, shaped by environmental constraints rather than algorithmic considerations.\n\nThis chapter presents a systematic taxonomy of machine learning deployment paradigms, analyzing four primary categories that span the computational spectrum from cloud data centers to microcontroller-based embedded systems. Each paradigm emerges from distinct operational requirements: computational resource availability, power consumption constraints, latency specifications, privacy requirements, and network connectivity assumptions. The theoretical framework developed here provides the analytical foundation for making informed architectural decisions in production machine learning systems.\n\nModern deployment strategies transcend traditional dichotomies between centralized and distributed processing. Contemporary applications increasingly implement hybrid architectures that allocate computational tasks across multiple paradigms to optimize system-wide performance. Voice recognition systems exemplify this architectural sophistication: wake-word detection operates on ultra-low-power embedded processors to enable continuous monitoring, speech-to-text conversion utilizes mobile processors to maintain privacy and minimize latency, while semantic understanding leverages cloud infrastructure for complex natural language processing. This multi-paradigm approach reflects the engineering reality that optimal machine learning systems require architectural heterogeneity.\n\nThe deployment paradigm space exhibits clear dimensional structure. Cloud machine learning maximizes computational capabilities while accepting network-induced latency constraints. Edge computing positions inference computation proximate to data sources when latency requirements preclude cloud-based processing. Mobile machine learning extends computational capabilities to personal devices where user proximity and offline operation represent critical requirements. Tiny machine learning enables distributed intelligence on severely resource-constrained devices where energy efficiency supersedes computational sophistication.\n\nThrough comprehensive analysis of these deployment paradigms, this chapter develops the systems engineering perspective necessary for designing machine learning architectures that effectively balance algorithmic capabilities with operational constraints. This systems-oriented approach provides essential methodological foundations for translating theoretical machine learning advances into production systems that demonstrate reliable performance at scale. The analysis culminates with paradigm integration strategies for hybrid architectures and identification of core design principles that govern all machine learning deployment contexts.\n\n@fig-cloud-edge-TinyML-comparison illustrates how computational resources, latency requirements, and deployment constraints create this deployment spectrum. While @sec-ai-frameworks explores the software tools that enable ML across these paradigms, and @sec-ai-acceleration examines the specialized hardware that powers them, this chapter focuses on the fundamental deployment trade-offs that govern system architecture decisions. The subsequent analysis addresses each paradigm systematically, building toward an understanding of how they integrate into modern ML systems.\n\n## The Deployment Spectrum {#sec-ml-systems-deployment-spectrum-38d0}\n\nThe deployment spectrum from cloud to embedded systems exists not by choice, but by necessity imposed by physical laws governing computing systems. These immutable constraints create hard boundaries that no engineering advancement can overcome, forcing the evolution of specialized deployment paradigms optimized for different operational contexts.\n\nThe **speed of light** establishes absolute minimum latencies that constrain real-time applications. Light traveling through optical fiber covers approximately 200,000 kilometers per second, creating a theoretical minimum of approximately 40ms round-trip time for the roughly 4,000 km between California and Virginia. However, actual cloud service latency is dominated by software overhead: TCP connection setup (1-3 round trips), serialization and deserialization (1-10ms depending on payload), load balancer routing, and request queuing under load. Well-engineered services within a single region achieve 1-5ms median latency with 50-200ms tail latencies; cross-region requests typically see 50-150ms median latency. The physics-imposed floor matters primarily for real-time applications where even optimized cloud paths cannot meet sub-10ms requirements, such as autonomous vehicle emergency braking or industrial robotics precision control.\n\nThe **power wall**, resulting from the breakdown of Dennard scaling around 2005, transformed computing economics. Transistor shrinking no longer reduces power density, meaning chips cannot be made arbitrarily fast without proportional increases in power consumption and heat generation. This constraint forces trade-offs between computational performance and energy efficiency, directly driving the need for specialized low-power architectures in mobile and embedded systems. Data centers now dedicate 30-40% of their power budget to cooling, while mobile devices must implement thermal throttling to prevent component damage.\n\nThe **memory wall** represents the widening gap between processor speed and memory bandwidth. While computational capacity can scale through additional processing units, memory bandwidth faces fundamental limits from pin count, package power delivery, and signaling physics. Traditional DRAM achieves 50-100 GB/s per channel, while High Bandwidth Memory (HBM) provides 1-3 TB/s through 3D stacking and wide interfaces but at significant cost and power premium. This creates a progressively worsening bottleneck where processors become data-starved, spending more time waiting for memory transfers than performing calculations. Large machine learning models exacerbate this problem, requiring parameter datasets that exceed available memory bandwidth by orders of magnitude.\n\n**Economics of scale** create significant cost-per-unit differences that justify different deployment approaches. A cloud server costing $50,000 can support thousands of users through virtualization, achieving per-user costs under $50. However, applications requiring guaranteed response times or private data processing cannot share resources, eliminating this economic advantage. Meanwhile, embedded processors costing $5-50 enable deployment at billions of endpoints where individual cloud connections would be economically infeasible.\n\nThese physical constraints are not temporary engineering challenges but permanent limitations that shape the computational landscape. Understanding these boundaries explains why the deployment spectrum exists and provides the theoretical foundation for making informed architectural decisions in machine learning systems.\n\n::: {#fig-cloud-edge-TinyML-comparison fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[line cap=round,line join=round,font=\\usefont{T1}{phv}{m}{n}\\small]\n  % Parameters\n  \\def\\angle{10}        % angle\n  \\def\\length{18}       % Lengths (cm)\n  \\def\\npoints{5}       % number of points\n  \\def\\startfrac{0.13}  % start (e.g.. 0.2 = 20%)\n  \\def\\endfrac{0.87}    % end (e.g.. 0.8 = 80%)\n\n \\draw[line width=1pt, black!70] (0,0) -- ({\\length*cos(\\angle)}, {\\length*sin(\\angle)})coordinate(end);\n %\n  \\foreach \\i in {0,1,...,\\numexpr\\npoints-1} {\n    \\pgfmathsetmacro{\\t}{\\startfrac + (\\endfrac - \\startfrac)*\\i/(\\npoints-1)}\n\\coordinate(T\\i)at({\\t*\\length*cos(\\angle)}, {\\t*\\length*sin(\\angle)});\n  }\n\n\\tikzset {\npics/gatewey/.style = {\n        code = {\n\\colorlet{red}{white}\n\\begin{scope}[local bounding box=GAT,scale=0.9, every node/.append style={transform shape}]\n\\def\\rI{4mm}\n\\def\\rII{2.8mm}\n\\def\\rIII{1.6mm}\n\\draw[red,line width=1.25pt](0,0)--(0,0.38)--(1.2,0.38)--(1.2,0)--cycle;\n\\draw[red,line width=1.5pt](0.6,0.4)--(0.6,0.9);\n\n\\draw[red, line width=1.5pt] (0.6,0.9)+(60:\\rI) arc[start angle=60, end angle=-60, radius=\\rI];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(50:\\rII) arc[start angle=50, end angle=-50, radius=\\rII];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(30:\\rIII) arc[start angle=30, end angle=-30, radius=\\rIII];\n%\n \\draw[red, line width=1.5pt] (0.6,0.9)+(120:\\rI) arc[start angle=120, end angle=240, radius=\\rI];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(130:\\rII) arc[start angle=130, end angle=230, radius=\\rII];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(150:\\rIII) arc[start angle=150, end angle=210, radius=\\rIII];\n\\fill[red](0.6,0.9)circle (1.5pt);\n\n\\foreach\\i in{0.15,0.3,0.45,0.6}{\n\\fill[red](\\i,0.19)circle (1.5pt);\n}\n\n\\fill[red](1,0.19)circle (2pt);\n\\end{scope}\n}}}\n\n\\tikzset {\npics/cloud/.style = {\n        code = {\n\\colorlet{red}{white}\n\\begin{scope}[local bounding box=CLO,scale=0.6, every node/.append style={transform shape}]\n\\draw[red,line width=1.5pt](0,0)to[out=170,in=180,distance=11](0.1,0.61)\nto[out=90,in=105,distance=17](1.07,0.71)\nto[out=20,in=75,distance=7](1.48,0.36)\nto[out=350,in=0,distance=7](1.48,0)--(0,0);\n\\draw[red,line width=1.5pt](0.27,0.71)to[bend left=25](0.49,0.96);\n\\draw[red,line width=1.5pt](0.67,1.21)to[out=55,in=90,distance=13](1.5,0.96)\nto[out=360,in=30,distance=9](1.68,0.42);\n\\end{scope}\n}}}\n\n\\tikzset {\n  pics/server/.style = {\n    code = {\n      \\colorlet{red}{white}\n      \\begin{scope}[anchor=center, transform shape,scale=0.8, every node/.append style={transform shape}]\n        \\draw[red,line width=1.25pt,fill=white](-0.55,-0.5) rectangle (0.55,0.5);\n\\foreach \\i in {-0.25,0,0.25} {\n                \\draw[cyan,line width=1.25pt]( -0.55,\\i) -- (0.55, \\i);\n}\n        \\foreach \\i in {-0.375, -0.125, 0.125, 0.375} {\n          \\draw[cyan!50!black!90,line width=1.25pt](-0.45,\\i)--(0,\\i);\n          \\fill[cyan!50!black!90](0.35,\\i) circle (1.5pt);\n        }\n\n\\draw[red,line width=1.75pt](0,-0.53) |- (-0.55,-0.7);\n        \\draw[red,line width=1.75pt](0,-0.53) |- (0.55,-0.7);\n      \\end{scope}\n    }\n  }\n}\n\n\\tikzset {\npics/cpu/.style = {\n        code = {\n\\definecolor{CPU}{RGB}{0,120,176}\n\\colorlet{CPU}{white}\n\\begin{scope}[local bounding box = CPU,scale=0.33, every node/.append style={transform shape}]\n\\node[fill=CPU,minimum width=66, minimum height=66,\n            rounded corners=2,outer sep=2pt] (C1) {};\n\\node[fill=violet,minimum width=54, minimum height=54] (C2) {};\n%\\node[fill=CPU!40,minimum width=44, minimum height=44] (C3) {CPU};\n\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=4, minimum height=15,\n           inner sep=0pt,anchor=south](GO\\y)at($(C1.north west)!\\x!(C1.north east)$){};\n}\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=4, minimum height=15,\n           inner sep=0pt,anchor=north](DO\\y)at($(C1.south west)!\\x!(C1.south east)$){};\n}\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=15, minimum height=4,\n           inner sep=0pt,anchor=east](LE\\y)at($(C1.north west)!\\x!(C1.south west)$){};\n}\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=15, minimum height=4,\n           inner sep=0pt,anchor=west](DE\\y)at($(C1.north east)!\\x!(C1.south east)$){};\n}\n\\end{scope}\n    }  }}\n\n\\tikzset {\npics/mobile/.style = {\n        code = {\n\\colorlet{red}{white}\n\\begin{scope}[local bounding box=MOB,scale=0.4, every node/.append style={transform shape}]\n\\node[rectangle,draw=red,minimum height=94,minimum width=47,\n            rounded corners=6,thick,fill=white](R1){};\n\\node[rectangle,draw=red,minimum height=67,minimum width=38,thick,fill=green!69!black!90](R2){};\n\\node[circle,minimum size=8,below= 2pt of R2,inner sep=0pt,thick,fill=green!69!black!90]{};\n\\node[rectangle,fill=green!69!black!90,minimum height=2,minimum width=20,above= 4pt of R2,inner sep=0pt,thick]{};\n%\n \\end{scope}\n     }  }}\n\n\\node[draw=none,fill=red,circle,minimum size=20mm](GA)at(T2){};\n\\pic[shift={(-0.55,-0.5)}] at (T2) {gatewey};\n\\node[above=0 of GA]{Gateway};\n\\node[draw=none,fill=violet,circle,minimum size=20mm](CP)at(T0){};\n\\pic[shift={(0,-0)}] at (T0) {cpu};\n\\node[above=0 of CP,align=center]{Ultra Low Powered\\\\Devices and Sensors};\n\\node[draw=none,fill=green!70,,circle,minimum size=20mm](MO)at(T1){};\n \\pic[shift={(0,0)}] at (T1) {mobile};\n \\node[above=0 of MO,align=center]{Intelligent\\\\Device};\n\\node[draw=none,fill=cyan,circle,minimum size=20mm](SE)at(T3){};\n\\pic[shift={(-0.03,0.1)}] at (T3) {server};\n \\node[above=0 of SE,align=center]{On Premise\\\\Servers};\n\\node[draw=none,fill=brown,circle,minimum size=20mm](CL)at(T4){};\n\\pic[shift={(-0.48,-0.35)}] at (T4) {cloud};\n \\node[above=0 of CL,align=center]{Cloud};\n%\n\\path (T0) -- (T1) coordinate[pos=0.5] (M1);\n\\path (0,0) -- (T0) coordinate[pos=0.25] (M0);\n\\path (T3) -- (T4) coordinate[pos=0.5] (M2);\n\\path (T4) -- (end) coordinate[pos=0.75] (M3);\n\n\\foreach \\x in {0,1,2,3}{\n\\fill[OliveLine](M\\x)circle (2.5pt);\n}\n\n\\path[red](M0)--++(270:1.6)coordinate(LL1)-|coordinate(LL2)(M2);\n\\path[red](M0)--++(270:1.1)coordinate(L1)-|coordinate(L2)(M1);\n\\path[red](M0)--++(270:1.1)-|coordinate(L3)(M2);\n\\path[red](M0)--++(270:1.1)-|coordinate(L4)(M3);\n%\n\\draw[black!70,thick](M0)--(LL1);\n\\draw[black!70,thick](M1)--(L2);\n\\draw[black!70,thick](M3)--(L4);\n\\draw[black!70,thick](M2)--(LL2);\n\\draw[latex-latex,line width=1pt,draw=black!60](L1)--node[red,fill=white]{TinyML}(L2);\n\\draw[latex-latex,line width=1pt,draw=black!60](L3)--node[fill=white]{Cloud AI}(L4);\n\\draw[latex-latex,line width=1pt,draw=black!60]([yshift=4pt]LL1)--node[fill=white,text=black]{Edge AI}([yshift=4pt]LL2);\n\\foreach \\x in {0,1,2,3}{\n\\fill[OliveLine](M\\x)circle (2.5pt);\n}\n%\n\\path[](M0)--++(90:4.2)-|node[pos=0.25]{\\textbf{The Distributed Intelligence Spectrum}}(M3);\n\\end{tikzpicture}\n\n```\n**Distributed Intelligence Spectrum**: Machine learning system design involves trade-offs between computational resources, latency, and connectivity, resulting in a spectrum of deployment options ranging from centralized cloud infrastructure to resource-constrained edge and TinyML devices. This figure maps these options, highlighting how each approach balances processing location with device capability and network dependence. Source: [@abiresearch2024tinyml].\n:::\n\n### Deployment Paradigm Foundations {#sec-ml-systems-deployment-paradigm-foundations-0c17}\n\nThe deployment spectrum illustrated in @fig-cloud-edge-TinyML-comparison exists not through design preference, but from necessity driven by immutable physical and hardware constraints. Understanding these limitations reveals why ML systems cannot adopt uniform approaches and must instead span the complete deployment spectrum from cloud to embedded devices.\n\n@sec-introduction established the three foundational components of ML systems (data, algorithms, and infrastructure) as a unified framework that these deployment paradigms now optimize differently based on physical constraints. Cloud ML prioritizes algorithmic complexity through abundant infrastructure, while Mobile ML emphasizes data locality with constrained infrastructure, and TinyML maximizes algorithmic efficiency under extreme infrastructure limitations.\n\nThe most critical bottleneck in modern computing stems from memory bandwidth scaling differently than computational capacity. While compute power scales linearly through additional processing units, memory bandwidth scales approximately as the square root of chip area due to physical routing constraints. This creates a progressively worsening bottleneck where processors become data-starved. In practice, this manifests as ML models spending more time awaiting memory transfers than performing calculations, particularly problematic for large models[^fn-memory-bottleneck] that require more data than can be efficiently transferred.\n\n[^fn-memory-bottleneck]: **Memory Bottleneck**: When the rate of data transfer from memory to processor becomes the limiting factor in computation. Large models require so many parameters that memory bandwidth, rather than computational capacity, determines performance.\n\nCompounding these memory challenges, the breakdown of Dennard scaling[^fn-dennard-scaling] transformed computing constraints around 2005, when transistor shrinking stopped reducing power density. Power dissipation per unit area now remains constant or increases with each technology generation, creating hard limits on computational density. For mobile devices, this translates to thermal throttling that reduces performance when sustained computation generates excessive heat. Data centers face similar constraints at scale, requiring extensive cooling infrastructure that can consume 30-40% of total power budget. These power density limits directly drive the need for specialized low-power architectures in mobile and embedded contexts, and explain why edge deployment becomes necessary when power budgets are constrained.\n\n[^fn-dennard-scaling]: **Dennard Scaling**: Named after Robert Dennard (IBM, 1974), the observation that as transistors became smaller, they could operate at higher frequencies while consuming the same power density. This scaling enabled Moore's Law until 2005, when physics limitations (leakage current, voltage floors) forced the industry toward multi-core architectures and specialized processors. This transition enabled the GPU computing revolution: GPU architectures originally designed for graphics, with thousands of simple cores optimized for parallel workloads, proved remarkably effective for neural network computations, which similarly benefit from massive parallelism.\n\nBeyond power considerations, physical limits impose minimum latencies that no engineering optimization can overcome. The speed of light establishes an inherent 80ms round-trip time between California and Virginia, while internet routing, DNS resolution, and processing overhead typically contribute another 20-420ms. This 100-500ms total latency renders real-time applications infeasible with pure cloud deployment. Network bandwidth faces physical constraints: fiber optic cables have theoretical limits, and wireless communication remains bounded by spectrum availability and signal propagation physics. These communication constraints create hard boundaries that necessitate local processing for latency-sensitive applications and drive edge deployment decisions.\n\nHeat dissipation emerges as an additional limiting factor as computational density increases. Mobile devices must throttle performance to prevent component damage and maintain user comfort, while data centers require extensive cooling systems that limit placement options and increase operational costs. Thermal constraints create cascading effects: elevated temperatures reduce semiconductor reliability, increase error rates, and accelerate component aging. These thermal realities necessitate trade-offs between computational performance and sustainable operation, driving specialized cooling solutions in cloud environments and ultra-low-power designs in embedded systems.\n\nThese fundamental constraints drove the evolution of the four distinct deployment paradigms outlined in this overview (@sec-ml-systems-deployment-spectrum-38d0). Understanding these core constraints proves essential for selecting appropriate deployment paradigms and establishing realistic performance expectations.\n\nThese theoretical constraints manifest in concrete hardware differences across the deployment spectrum. To understand the practical implications of these physical limitations, @tbl-representative-systems provides representative hardware platforms for each category. These examples demonstrate the range of computational resources, power requirements, and cost considerations[^fn-cost-spectrum] across the ML systems spectrum, illustrating the practical implications of each deployment approach.[^fn-pue]\n\nThese quantitative thresholds reflect essential relationships between computational requirements, energy consumption, and deployment feasibility. These scaling relationships determine when distributed cloud deployment becomes advantageous relative to edge or mobile alternatives. Understanding these quantitative trade-offs enables informed deployment decisions across the spectrum of ML systems.\n\n@fig-vMLsizes illustrates the differences between Cloud ML, Edge ML, Mobile ML, and TinyML in terms of hardware specifications, latency characteristics, connectivity requirements, power consumption, and model complexity constraints. As systems transition from Cloud to Edge to TinyML, available resources decrease dramatically, presenting significant challenges for machine learning model deployment. This resource disparity becomes particularly evident when deploying ML models on microcontrollers, the primary hardware platform for TinyML. These devices possess severely constrained memory and storage capacities that prove insufficient for conventional complex ML models.\n\n[^fn-cost-spectrum]: **ML Hardware Cost Spectrum**: The cost range spans 6 orders of magnitude, from $10 ESP32-CAM modules to multi-million dollar TPU Pod systems. This 100,000x+ cost difference reflects proportional differences in computational capability, enabling deployment across vastly different economic contexts and use cases, from hobbyist projects to hyperscale cloud infrastructure.\n\n[^fn-pue]: **Power Usage Effectiveness (PUE)**: Data center efficiency metric measuring total facility power divided by IT equipment power. A PUE of 1.0 represents perfect efficiency (impossible in practice), while 1.1-1.3 indicates highly efficient facilities using advanced cooling and power management. Google's data centers achieve PUE of 1.12 compared to industry average of 1.8.\n\n[^fn-computer-vision]: **Computer Vision**: Field of AI enabling machines to interpret and understand visual information from images and videos. Requires processing 2-50 megapixels per image at 30+ fps for real-time applications, creating massive computational and memory bandwidth demands that drive specialized hardware like GPUs and vision processing units.\n\n[^fn-ensemble-methods]: **Ensemble Methods**: ML technique combining predictions from multiple models to improve accuracy and robustness. Requires training and running 5-100+ models simultaneously, increasing compute requirements by 10-50x but enabling 2-5% accuracy improvements that justify cloud deployment costs.\n\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **Category**  | **Example Device** | **Processor**                    | **Memory**  | **Storage** | **Power**   | **Price Range** | **Example Models/Tasks**       | **Quantitative Thresholds**               |\n+:==============+===================:+=================================:+============:+:============+============:+:================+:===============================+==========================================:+\n| **Cloud ML**  | Google TPU v4 Pod  | 4,096x TPU v4 chips              | 131 TB HBM2 | Cloud-scale | ~3 MW       | Cloud service   | Large language models,         | &gt;1000 TFLOPS compute, real-time video  |\n|               |                    | (1.1 exaflops peak)              |             | (PB-scale)  |             | (rental only)   | massive-scale training         | processing, &gt;100GB/s memory bandwidth, |\n|               |                    |                                  |             |             |             |                 |                                | PUE 1.1-1.3, 100-500ms latency            |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **Edge ML**   | NVIDIA DGX Spark   | GB10 Grace Blackwell Superchip   | 128 GB      | 4 TB NVMe   | ~200 W      | ~$5,000         | Model fine-tuning,             | ~1 PFLOPS AI compute,                     |\n|               |                    | (20-core Arm, 1 PFLOPS AI)       | LPDDR5x     |             |             |                 | on-premise inference,          | &gt;270 GB/s memory bandwidth,            |\n|               |                    |                                  |             |             |             |                 | prototype development          | desktop deployment, local processing      |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **Mobile ML** | iPhone 15 Pro      | A17 Pro (6-core CPU, 6-core GPU) | 8 GB RAM    | 128 GB-1 TB | 3-5 W       | $999+           | Face ID, computational         | 1-10 TOPS compute,                        |\n|               |                    |                                  |             |             |             |                 | photography, voice recognition | &lt;2W sustained power,                   |\n|               |                    |                                  |             |             |             |                 |                                | &lt;50ms UI response                      |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **TinyML**    | ESP32-CAM          | Dual-core @ 240MHz               | 520 KB RAM  | 4 MB Flash  | 0.05-0.25 W | $10             | Image classification,          | &lt;1 TOPS compute,                       |\n|               |                    |                                  |             |             |             |                 | motion detection               | &lt;1mW power,                            |\n|               |                    |                                  |             |             |             |                 |                                | microsecond response times                |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n\n: **Hardware Spectrum**: Machine learning system design necessitates trade-offs between computational resources, power consumption, and cost, as exemplified by the diverse hardware platforms suitable for cloud, edge, mobile, and TinyML deployments. This table quantifies those trade-offs, revealing how device capabilities, from specialized ML accelerators in cloud data centers to low-power microcontrollers in embedded systems, shape the types of models and tasks each platform can effectively support. The quantitative thresholds provide specific decision criteria to help practitioners determine the most appropriate deployment paradigm for their applications. {#tbl-representative-systems}\n\n::: {#fig-vMLsizes fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\nLine/.style={red,line width=1.0pt,text=black},\n  Box/.style={inner xsep=2pt,\n    node distance=1.1,\n    draw=none,%GreenLine,\n    line width=0.75pt,\n    fill=none,%GreenL,\n    text width=22mm,align=flush center,\n    minimum width=22mm, minimum height=11mm\n  },\n  Box1/.style={Box,node distance=0.2, minimum height=5mm},\n  Box2/.style={Box,node distance=0.4, minimum height=5mm}\n}\n\\node[Box](B0){};\n\\node[Box,right=0 of B0](B1){\\textbf{Cloud AI}\\\\(NVIDIA V100)};\n\\node[Box,right=of B1](B2){\\textbf{Mobile AI}\\\\(iPhone 15 Pro)};\n\\node[Box,right=of B2](B3){\\textbf{Tiny AI}\\\\(STM32F746)};\n\\node[Box, right=of B3](B4){\\textbf{ResNet-50}};\n\\node[Box, right=0 of B4](B5){\\textbf{MobileNetV2}};\n\\node[Box, right=0 of B5](B6){\\textbf{MobileNetV2}\\\\ (int8)};\n%%%%\n\\node[Box2,below=of B0](B20){\\textbf{Memory}};\n\\node[Box2,below=of B1](B21){16 GB};\n\\node[Box2,below=of B2](B22){4 GB};\n\\node[Box2,below=of B3](B23){\\textbf{320 kB}};\n\\node[Box2,below=of B4](B24){7.2 MB};\n\\node[Box2,below=of B5](B25){6.8 MB};\n\\node[Box2,below=of B6](B26){1.7 MB};\n%%%%\n\\node[Box1,below=of B20](B30){\\textbf{Storage}};\n\\node[Box1,below=of B21](B31){TB $\\sim$ PB};\n\\node[Box1,below=of B22](B32){> 64 GB};\n\\node[Box1,below=of B23](B33){\\textbf{1 MB}};\n\\node[Box1,below=of B24](B34){102 MB};\n\\node[Box1,below=of B25](B35){13.6 MB};\n\\node[Box1,below=of B26](B36){3.4 MB};\n%%\n\\coordinate(GL)at($(B0.north west)+(0,0)$);\n\\coordinate(GD)at($(B6.north east)+(0,0)$);\n\\coordinate(DL)at($(B30.south west)+(0,0)$);\n\\coordinate(DD)at($(B36.south east)+(0,0)$);\n\\coordinate(SL)at($(B0.south west)!0.0!(B20.north west)$);\n\\coordinate(SD)at($(B6.south east)!0.0!(B26.north east)$);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B21)--node[above]{4$\\times$}(B22);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B22)--node[above]{3100$\\times$}(B23);\n\\draw[Line,latex-latex,shorten >=-9pt,shorten <=-9pt](B23)--\nnode[above](GAG){gap}(B24);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B31)--node[above]{1000$\\times$}(B32);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B32)--node[above]{6400$\\times$}(B33);\n\\draw[Line,latex-latex,shorten >=-9pt,shorten <=-9pt](B33)--\nnode[above](GAD){gap}(B34);\n\\path[red](GL)-|coordinate(GS)(GAG);\n\\path[red](DL)-|coordinate(DS)(GAD);\n\\path[red](SL)-|coordinate(SS)(GAD);\n%\n\\draw[line width=1.75pt,shorten >=5pt](DL)--(DS);\n\\draw[line width=1.75pt,shorten >=5pt](GL)--(GS);\n\\draw[line width=1.0pt,shorten >=5pt](SL)--(SS);\n%%\n\\draw[line width=1.75pt,shorten >=5pt](DD)--(DS);\n\\draw[line width=1.75pt,shorten >=5pt](GD)--(GS);\n\\draw[line width=1.0pt,shorten >=5pt](SD)--(SS);\n%\n\\scoped[on background layer]\n\\node[draw=none,inner xsep=5mm,inner ysep=3mm,minimum width=170mm,\n      anchor=west,yshift=0mm,fill=cyan!10,fit=(GL)(DD)](BB){};\n%\n\\node[single arrow, draw=none, fill=red,inner sep=2pt,\n      minimum width = 14pt, single arrow head extend=3pt,\n      minimum height=8mm]at($(B1)!0.5!(B2)$) {};\n      \\node[single arrow, draw=none, fill=red,inner sep=2pt,\n      minimum width = 14pt, single arrow head extend=3pt,\n      minimum height=8mm]at($(B2)!0.5!(B3)$) {};\n\\end{tikzpicture}\n```\n**Device Memory Constraints**: AI model deployment spans a wide range of devices with drastically different memory capacities, from cloud servers with 16 GB to microcontroller-based systems with only 320 kb. This progression necessitates specialized optimization techniques and efficient architectures to enable on-device intelligence with limited resources. Source: [@lin2023tiny].\n:::\n\n## Cloud ML: Maximizing Computational Power {#sec-ml-systems-cloud-ml-maximizing-computational-power-f232}\n\nHaving established the constraints and evolutionary progression that shape ML deployment paradigms, this analysis addresses each paradigm systematically, beginning with Cloud ML, the foundation from which other paradigms emerged. This approach maximizes computational resources while accepting latency constraints, providing the optimal choice when computational power matters more than response time. Cloud deployments prove ideal for complex training tasks and inference workloads that can tolerate network delays.\n\nCloud Machine Learning leverages the scalability and power of centralized infrastructures[^fn-cloud-evolution] to handle computationally intensive tasks: large-scale data processing, collaborative model development, and advanced analytics. Cloud data centers utilize distributed architectures and specialized resources to train complex models and support diverse applications, from recommendation systems to natural language processing[^fn-nlp-compute]. The subsequent analysis addresses the deployment characteristics that make cloud ML systems effective for large-scale applications.\n\n[^fn-cloud-evolution]: **Cloud Infrastructure Evolution**: Cloud computing for ML emerged from Amazon's decision in 2002 to treat their internal infrastructure as a service. AWS launched in 2006, followed by Google Cloud (2008) and Azure (2010). By 2024, global cloud infrastructure spending reached approximately $138 billion annually, with total public cloud services exceeding $675 billion.\n\n[^fn-nlp-compute]: **NLP Computational Demands**: Modern language models like GPT-3 required 3,640 petaflop-days of compute for training, equivalent to running 10,000 NVIDIA V100 GPUs for approximately 15 days [@brown2020language]. This computational scale drove the need for massive cloud infrastructure.\n\n::: {.callout-definition title=\"Cloud ML\"}\n\n***Cloud Machine Learning (Cloud ML)*** is the deployment of machine learning models on _centralized data center infrastructure_, offering _massive computational capacity_ and _scalability_ for training and serving complex models at the cost of _network latency_ and _connectivity dependence_.\n:::\n\n@fig-cloud-ml provides an overview of Cloud ML's capabilities, which we will discuss in greater detail throughout this section.\n\n::: {#fig-cloud-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=30mm,align=flush center,\n    minimum width=30mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=27mm, minimum width=27mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=38mm, minimum width=38mm\n  },\n Box4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=32mm, minimum width=32mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){Cloud ML};\n%\n\\node[Box4,below=0.7 of B1](B11){Immense Computational Power};\n\\node[Box4,below=of B11](B12){Collaborative Environment};\n\\node[Box4,below=of B12](B13){Access to Advanced Tools};\n\\node[Box4,below=of B13](B14){Dynamic Scalability};\n\\node[Box4,below=of B14](B15){Centralized Infrastructure};\n%\n\\node[Box2,below=0.7 of B2](B21){Scalable Data Processing and Model Training};\n\\node[Box2,below=of B21](B22){Collaboration and Resource Sharing};\n\\node[Box2,below=of B22](B23){Flexible Deployment and Accessibility};\n\\node[Box2,below=of B23](B24){Cost-Effectiveness and Scalability};\n\\node[Box2,below=of B24](B25){Global Accessibility};\n%\n\\node[Box,below=0.7 of B3](B31){Vendor Lock-In};\n\\node[Box,below=of B31](B32){Latency Issues};\n\\node[Box,below=of B32](B33){Data Privacy and Security};\n\\node[Box,below=of B33](B34){Dependency on Internet};\n\\node[Box,below=of B34](B35){Cost Considerations};\n%\n\\node[Box3,below=0.7 of B4](B41){Virtual Assistants};\n\\node[Box3,below=of B41](B42){Security and Anomaly Detection};\n\\node[Box3,below=of B42](B43){Recommendation Systems};\n\\node[Box3,below=of B43](B44){Fraud Detection};\n\\node[Box3,below=of B44](B45){Personalized User Experience};\n%\n\\foreach \\i in{1,2,3,4,5}{\n  \\foreach \\x in{1,2,3,4}{\n\\draw[Line](B\\x.west)--++(180:0.5)|-(B\\x\\i);\n}\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n\n```\n**Cloud ML Capabilities**: Cloud machine learning systems address challenges related to scale, complexity, and resource management through centralized computing infrastructure and specialized hardware. This figure outlines key considerations for deploying models in the cloud, including the need for reliable infrastructure and efficient resource allocation to handle large datasets and complex computations.\n:::\n\n### Cloud Infrastructure and Scale {#sec-ml-systems-cloud-infrastructure-scale-848e}\n\nTo understand cloud ML's position in the deployment spectrum, we must first consider its defining characteristics. Cloud ML's primary distinguishing feature is its centralized infrastructure operating at unprecedented scale. @fig-cloudml-example illustrates this concept with an example from Google's Cloud TPU[^fn-mlsys-tpu] data center. As detailed in @tbl-representative-systems, cloud systems like Google's TPU v4 Pod represent a 100-1000x computational advantage over mobile devices, with >1000 TFLOPS compute power and megawatt-scale power consumption. Cloud service providers offer virtual platforms with >100GB/s memory bandwidth housed in globally distributed data centers[^fn-hyperscale]. These centralized facilities enable computational workloads impossible on resource-constrained devices. However, this centralization introduces critical trade-offs: network round-trip latency of 100-500ms eliminates real-time applications, while operational costs scale linearly with usage.\n\n[^fn-mlsys-tpu]: **Tensor Processing Unit (TPU)**: Google's custom ASIC designed specifically for tensor operations, first used internally in 2015 for neural network inference. A single TPU v4 Pod contains 4,096 chips and delivers 1.1 exaflops of peak performance, representing one of the world's largest publicly available ML clusters.\n\n[^fn-hyperscale]: **Hyperscale Data Centers**: These facilities contain 5,000+ servers and cover 10,000+ square feet. Microsoft's data centers span over 200 locations globally, with some individual facilities consuming enough electricity to power 80,000 homes.\n\n::: {.content-visible when-format=\"html\"}\n![**Cloud Data Center Scale**: Large-scale machine learning systems require centralized infrastructure with massive computational resources and storage capacity. Google's cloud TPU data center provides this need, housing specialized AI accelerator hardware to efficiently manage the demands of training and deploying complex models. Source: [@google2024gemini].](images/jpg/cloud_ml_tpu.jpeg){#fig-cloudml-example}\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n![Cloud TPU data center at Google. Source: [@google2024gemini]](images/jpg/cloud_ml_tpu.jpeg){#fig-cloudml-example fig-pos='htb'}\n:::\n\nCloud ML excels in processing massive data volumes through parallelized architectures. Through techniques detailed in @sec-model-optimizations, distributed training across hundreds of GPUs enables processing that would require months on single devices, while @sec-ai-acceleration covers the memory bandwidth analysis underlying this performance. This enables training on datasets requiring hundreds of terabytes of storage and petaflops of computation, resources impossible on constrained devices.\n\nThe centralized infrastructure creates exceptional deployment flexibility through cloud APIs[^fn-ml-apis], making trained models accessible worldwide across mobile, web, and IoT platforms. Seamless collaboration enables multiple teams to access projects simultaneously with integrated version control. Pay-as-you-go pricing models[^fn-paas-pricing] eliminate upfront capital expenditure while resources scale elastically with demand.\n\nA common misconception assumes that Cloud ML's vast computational resources make it universally superior to alternative deployment approaches. Cloud infrastructure offers exceptional computational power and storage, yet this advantage doesn't automatically translate to optimal solutions for all applications. Cloud deployment introduces significant trade-offs including network latency (often 100-500ms round trip), privacy concerns when transmitting sensitive data, ongoing operational costs that scale with usage, and complete dependence on network connectivity. Edge and embedded deployments excel in scenarios requiring real-time response (autonomous vehicles need sub-10ms decision making), strict data privacy (medical devices processing patient data), predictable costs (one-time hardware investment versus recurring cloud fees), or operation in disconnected environments (industrial equipment in remote locations). The optimal deployment paradigm depends on specific application requirements rather than raw computational capability.\n\n[^fn-ml-apis]: **ML APIs**: Application Programming Interfaces that democratized AI by providing pre-trained models as web services. Google's Vision API launched in 2016, processing over 1 billion images monthly within two years, enabling developers to add AI capabilities without ML expertise.\n\n[^fn-paas-pricing]: **Pay-as-You-Go Pricing**: Revolutionary model where users pay only for actual compute time used, measured in GPU-hours or inference requests. Training a model might cost $50-500 on demand versus $50,000-500,000 to purchase equivalent hardware.\n\n### Cloud ML Trade-offs and Constraints {#sec-ml-systems-cloud-ml-tradeoffs-constraints-1654}\n\nCloud ML's substantial advantages carry inherent trade-offs that shape deployment decisions. Latency represents the most significant physical constraint. Network round-trip delays typically range from 100-500ms, making cloud processing unsuitable for real-time applications requiring sub-10ms responses, such as autonomous vehicles and industrial control systems. Beyond basic timing constraints, unpredictable response times complicate performance monitoring and debugging across geographically distributed infrastructure.\n\nPrivacy and security present significant challenges when adopting cloud deployment. Transmitting sensitive data to remote data centers creates potential vulnerabilities and complicates regulatory compliance. Organizations handling data subject to regulations like GDPR[^fn-gdpr] or HIPAA[^fn-hipaa] must implement comprehensive security measures including encryption, strict access controls, and continuous monitoring to meet stringent data handling requirements.\n\n[^fn-gdpr]: **GDPR (General Data Protection Regulation)**: European privacy law effective 2018, imposing fines up to €20 million or 4% of global revenue for violations. Forces ML systems to implement \"right to be forgotten\" and data processing transparency.\n\n[^fn-hipaa]: **HIPAA (Health Insurance Portability and Accountability Act)**: US healthcare privacy law requiring strict data security measures. ML systems handling medical data must implement encryption, access controls, and audit trails, adding 30-50% to development costs.\n\nCost management introduces operational complexity requiring total cost of ownership (TCO) analysis rather than naive unit comparisons. Consider a production system serving 1 million daily inferences. Cloud costs at $0.001 per inference reach $365,000 annually, but include infrastructure management, automatic scaling, and updates. Edge deployment requires not just $100,000 hardware investment but also power ($15,000-30,000 annually at typical commercial rates), cooling infrastructure, network equipment, operational staff for monitoring and maintenance, and hardware refresh every 3-5 years. Industry analyses suggest on-premises TCO typically reaches 2-3x hardware acquisition cost. The break-even calculation depends heavily on utilization: cloud excels for variable workloads while edge becomes cost-effective for sustained high utilization exceeding 50-70% of capacity. Unpredictable usage spikes further complicate budgeting, requiring sophisticated monitoring and cost governance frameworks.\n\nNetwork dependency creates another critical constraint. Any connectivity disruption directly impacts system availability, proving particularly problematic where network access is limited or unreliable. Vendor lock-in further complicates the landscape, as dependencies on specific tools and APIs create portability and interoperability challenges when transitioning between providers. Organizations must carefully balance these constraints against cloud benefits based on application requirements and risk tolerance.\n\n### Large-Scale Training and Inference {#sec-ml-systems-largescale-training-inference-f7a8}\n\nCloud ML's computational advantages manifest most visibly in consumer-facing applications requiring massive scale. Virtual assistants like Siri and Alexa demonstrate the hybrid architectures that characterize modern ML systems. Wake word detection runs on dedicated low-power hardware (under 1mW) directly on the device, enabling always-on listening without draining batteries. Initial speech recognition increasingly runs on-device for privacy and responsiveness, while complex natural language understanding and generation leverage cloud infrastructure for access to larger models and broader knowledge. This hybrid approach reduces response latency from 500ms or more with pure cloud processing to under 200ms while maintaining the computational power needed for sophisticated language understanding.\n\nRecommendation engines deployed by Netflix and Amazon demonstrate another compelling application of cloud resources. These systems process massive datasets using collaborative filtering[^fn-collaborative-filtering] and other machine learning techniques to uncover patterns in user preferences and behavior. Cloud computational resources enable continuous updates and refinements as user data grows, with Netflix processing over 100 billion data points daily to deliver personalized content suggestions that directly enhance user engagement.\n\nFinancial institutions have revolutionized fraud detection through cloud ML capabilities. By analyzing vast amounts of transactional data in real-time, ML algorithms trained on historical fraud patterns can detect anomalies and suspicious behavior across millions of accounts, enabling proactive fraud prevention that minimizes financial losses.\n\nThese applications demonstrate how cloud ML's computational advantages translate into transformative capabilities for large-scale, complex processing tasks. Beyond these flagship applications, cloud ML permeates everyday online experiences through personalized advertisements on social media, predictive text in email services, product recommendations in e-commerce, enhanced search results, and security anomaly detection systems that continuously monitor for cyber threats at scale.\n\n[^fn-collaborative-filtering]: **Collaborative Filtering**: Recommendation technique analyzing user behavior patterns to predict preferences. Netflix's algorithm contributes to 80% of watched content and saves $1 billion annually in customer retention.\n\n## Edge ML: Reducing Latency and Privacy Risk {#sec-ml-systems-edge-ml-reducing-latency-privacy-risk-31f9}\n\nCloud ML's computational advantages come with inherent trade-offs that limit its applicability for many real-world scenarios. The 100-500ms latency and privacy concerns that we examined create fundamental barriers for applications requiring immediate response or local data processing. Edge ML emerged as a direct response to these specific limitations, moving computation closer to data sources and trading unlimited computational resources for sub-100ms latency and local data sovereignty.\n\nThis paradigm shift becomes essential for applications where cloud's 100-500ms round-trip delays prove unacceptable. Autonomous systems requiring split-second decisions and industrial IoT[^fn-industrial-iot] applications demanding real-time response cannot tolerate network delays. Similarly, applications subject to strict data privacy regulations must process information locally rather than transmitting it to remote data centers. Edge devices (gateways and IoT hubs[^fn-iot-hubs]) occupy a middle ground in the deployment spectrum, maintaining acceptable performance while operating under intermediate resource constraints.\n\n[^fn-industrial-iot]: **Industrial IoT**: Manufacturing generates over 1 exabyte of data annually, but less than 1% is analyzed due to connectivity constraints. Edge ML enables real-time analysis, with predictive maintenance alone saving manufacturers $630 billion globally by 2025.\n\n[^fn-iot-hubs]: **IoT Hubs**: Central connection points that aggregate data from multiple sensors before cloud transmission. A typical smart building might have 1 hub managing 100-1000 IoT sensors, reducing cloud traffic by 90% while enabling local decision-making.\n\n::: {.callout-definition title=\"Edge ML\"}\n\n***Edge Machine Learning (Edge ML)*** is the deployment of machine learning models on _localized infrastructure_ at the network edge, enabling _low-latency processing_ and _data privacy_ through local computation on stationary devices like gateways and industrial controllers.\n:::\n\n@fig-edge-ml provides an overview of Edge ML's key dimensions, which this analysis addresses in detail.\n\n::: {#fig-edge-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=37mm,align=flush center,\n    minimum width=37mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=27mm, minimum width=27mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=28mm, minimum width=28mm\n  },\n Box4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=30mm, minimum width=30mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){Edge ML};\n%\n\\node[Box4,below=0.7 of B1](B11){Decentralized Data Processing};\n\\node[Box4,below=of B11](B12){Local Data Storage and Computation};\n\\node[Box4,below=of B12](B13){Proximity to Data Sources};\n%\n\\node[Box2,below=0.7 of B2](B21){Reduced Latency};\n\\node[Box2,below=of B21](B22){Enhanced Data Privacy};\n\\node[Box2,below=of B22](B23){Lower Bandwidth Usage};\n%\n\\node[Box,below=0.7 of B3](B31){Security Concerns at the Edge Nodes};\n\\node[Box,below=of B31](B32){Complexity in Managing Edge Nodes};\n\\node[Box,below=of B32](B33){Limited Computational Resources};\n%\n\\node[Box3,below=0.7 of B4](B41){Industrial IoT};\n\\node[Box3,below=of B41](B42){Smart Homes and Cities};\n\\node[Box3,below=of B42](B43){Autonomous Vehicles};\n%\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B1.west)--++(180:0.5)|-(B1\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B2.west)--++(180:0.5)|-(B2\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B3.west)--++(180:0.5)|-(B3\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B4.west)--++(180:0.5)|-(B4\\i);\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n```\n**Edge ML Dimensions**: This figure outlines key considerations for edge machine learning, contrasting challenges with benefits and providing representative examples and characteristics. Understanding these dimensions enables designing and deploying effective AI solutions on resource-constrained devices.\n:::\n\n### Distributed Processing Architecture {#sec-ml-systems-distributed-processing-architecture-8d28}\n\nEdge ML's diversity spans wearables, industrial sensors, and smart home appliances, devices that process data locally[^fn-iot-growth] without depending on central servers (@fig-edgeml-example). Edge devices occupy the middle ground between cloud systems and mobile devices in computational resources, power consumption, and cost. Memory bandwidth at 25-100 GB/s enables models requiring 100MB-1GB parameters, using optimization techniques (@sec-model-optimizations) to achieve 2-4x speedup compared to cloud models. Local processing eliminates network round-trip latency, enabling <100ms response times while generating substantial bandwidth savings: processing 1000 camera feeds locally avoids 1Gbps uplink costs and reduces cloud expenses by $10,000-100,000 annually.\n\n[^fn-iot-growth]: **IoT Device Growth**: From 8.4 billion connected devices in 2017 to a projected 25.4 billion by 2030. Each device generates 2.5 quintillion bytes of data daily, making edge processing essential for bandwidth management.\n\n[^fn-latency-critical]: **Latency-Critical Applications**: Autonomous vehicles require <10ms response times for emergency braking decisions. Industrial robotics needs <1ms for precision control. Cloud round-trip latency typically ranges from 100-500ms, making edge processing essential for safety-critical applications.\n\n### Edge ML Benefits and Deployment Challenges {#sec-ml-systems-edge-ml-benefits-deployment-challenges-6e28}\n\nEdge ML provides quantifiable benefits that address key cloud limitations. Latency reduction from 100-500ms in cloud deployments to 1-50ms at the edge enables safety-critical applications[^fn-latency-critical] requiring real-time response. Bandwidth savings prove equally substantial: a retail store with 50 cameras streaming video can reduce bandwidth requirements from 100 Mbps (costing $1,000-2,000 monthly) to less than 1 Mbps by processing locally and transmitting only metadata, a 99% reduction. Privacy improves through local processing, eliminating transmission risks and simplifying regulatory compliance. Operational resilience ensures systems continue functioning during network outages, proving critical for manufacturing, healthcare, and building management applications.\n\nThese benefits carry corresponding limitations. Limited computational resources[^fn-endpoint-constraints] significantly constrain model complexity: edge servers typically provide 10-100x less processing power than cloud infrastructure, limiting deployable models to millions rather than billions of parameters. Managing distributed networks introduces complexity that scales nonlinearly with deployment size. Coordinating version control and updates across thousands of devices requires sophisticated orchestration systems[^fn-edge-coordination]. Security challenges intensify with physical accessibility—edge devices deployed in retail stores or public infrastructure face tampering risks requiring hardware-based protection mechanisms. Hardware heterogeneity further complicates deployment, as diverse platforms with varying capabilities demand different optimization strategies. Initial deployment costs of $500-2,000 per edge server create substantial capital requirements. Deploying 1,000 locations requires $500,000-2,000,000 upfront investment, though these costs are offset by long-term operational savings.\n\n[^fn-endpoint-constraints]: **Edge Server Constraints**: Typical edge servers have 1-8GB RAM and 2-32GB storage, versus cloud servers with 128-1024GB RAM and petabytes of storage. Processing power differs by 10-100x, necessitating specialized model compression techniques.\n\n[^fn-edge-coordination]: **Edge Network Coordination**: For n edge devices, the number of potential communication paths is n(n-1)/2. A network of 1,000 devices has 499,500 possible connections. Kubernetes K3s and similar platforms help manage this complexity.\n\n![**Edge Device Deployment**: Diverse IoT devices, from wearables to home appliances, enable decentralized machine learning by performing inference locally, reducing reliance on cloud connectivity and improving response times. Source: Edge Impulse.](images/jpg/edge_ml_iot.jpg){#fig-edgeml-example}\n\n### Real-Time Industrial and IoT Systems {#sec-ml-systems-realtime-industrial-iot-systems-f946}\n\nIndustries deploy Edge ML widely where low latency, data privacy, and operational resilience justify the additional complexity of distributed processing. Autonomous vehicles represent perhaps the most demanding application, where safety-critical decisions must occur within milliseconds based on sensor data that cannot be transmitted to remote servers. Systems like Tesla's Full Self-Driving process inputs from eight cameras at 36 frames per second through custom edge hardware, making driving decisions with latencies under 10ms, a response time physically impossible with cloud processing due to network delays.\n\nSmart retail environments demonstrate edge ML's practical advantages for privacy-sensitive, bandwidth-intensive applications. Amazon Go stores process video from hundreds of cameras through local edge servers, tracking customer movements and item selections to enable checkout-free shopping. This edge-based approach addresses both technical and privacy concerns: transmitting high-resolution video from hundreds of cameras would require over 200 Mbps sustained bandwidth, while local processing ensures customer video never leaves the premises, addressing privacy concerns and regulatory requirements.\n\nThe Industrial IoT[^fn-industry-40] leverages edge ML for applications where millisecond-level responsiveness directly impacts production efficiency and worker safety. Manufacturing facilities deploy edge ML systems for real-time quality control, with vision systems inspecting welds at speeds exceeding 60 parts per minute, and predictive maintenance[^fn-predictive-maintenance] applications that monitor over 10,000 industrial assets per facility. This approach has demonstrated 25-35% reductions in unplanned downtime across various manufacturing sectors.\n\nSmart buildings utilize edge ML to optimize energy consumption while maintaining operational continuity during network outages. Commercial buildings equipped with edge-based building management systems process data from 5,000-10,000 sensors monitoring temperature, occupancy, air quality, and energy usage, with edge processing reducing cloud transmission requirements by 95% while enabling sub-second response times. Healthcare applications similarly leverage edge ML for patient monitoring and surgical assistance, maintaining HIPAA compliance through local processing while achieving sub-100ms latency for real-time surgical guidance.\n\n[^fn-industry-40]: **Industry 4.0**: Fourth industrial revolution integrating cyber-physical systems into manufacturing. Expected to increase productivity by 20-30% and reduce costs by 15-25% globally.\n\n[^fn-predictive-maintenance]: **Predictive Maintenance**: ML-driven maintenance scheduling based on equipment condition. Reduces unplanned downtime by 35-45% and costs by 20-25%. GE saves $1.5 billion annually using predictive analytics.\n\n## Mobile ML: Personal and Offline Intelligence {#sec-ml-systems-mobile-ml-personal-offline-intelligence-7905}\n\nWhile Edge ML addressed the latency and privacy limitations of cloud deployment, it introduced new constraints: the need for dedicated edge infrastructure, ongoing network connectivity, and substantial upfront hardware investments. The proliferation of billions of personal computing devices (smartphones, tablets, and wearables) created an opportunity to extend ML capabilities even further by bringing intelligence directly to users' hands. Mobile ML represents this next step in the distribution of intelligence, prioritizing user proximity, offline capability, and personalized experiences while operating under the strict power and thermal constraints inherent to battery-powered devices.\n\nMobile ML integrates machine learning directly into portable devices like smartphones and tablets, providing users with real-time, personalized capabilities. This paradigm excels when user privacy, offline operation, and immediate responsiveness matter more than computational sophistication. Mobile ML supports applications such as voice recognition[^fn-voice-recognition], computational photography[^fn-computational-photography], and health monitoring while maintaining data privacy through on-device computation. These battery-powered devices must balance performance with power efficiency and thermal management, making them ideal for frequent, short-duration AI tasks.\n\n[^fn-voice-recognition]: **Voice Recognition Evolution**: Apple's Siri (2011) required cloud processing with 200-500ms latency. By 2017, on-device processing reduced latency to <50ms while improving privacy. Modern smartphones process 16kHz audio at 20-30ms latency using specialized neural engines.\n\n[^fn-computational-photography]: **Computational Photography**: Combines multiple exposures and ML algorithms to enhance image quality. Google's Night Sight captures 15 frames in 6 seconds, using ML to align and merge them. Portrait mode uses depth estimation ML models to create professional-looking bokeh effects in real-time.\n\n::: {.callout-definition title=\"Mobile ML\"}\n\n***Mobile Machine Learning (Mobile ML)*** is the deployment of machine learning models directly on _portable, battery-powered devices_, enabling _personalization_, _privacy_, and _offline operation_ within severe energy and resource constraints.\n:::\n\nThis section analyzes Mobile ML across four key dimensions, revealing how this paradigm balances capability with constraints. @fig-mobile-ml provides an overview of Mobile ML's capabilities.\n\n::: {#fig-mobile-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=32mm,align=flush center,\n    minimum width=32mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=30mm, minimum width=30mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=35mm, minimum width=35mm\n  },\n Box4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=32mm, minimum width=32mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){Mobile ML};\n%\n\\node[Box4,below=0.7 of B1](B11){On-Device Processing};\n\\node[Box4,below=of B11](B12){Battery-Powered Operation};\n\\node[Box4,below=of B12](B13){Sensor Integration};\n\\node[Box4,below=of B13](B14){Optimized Frameworks};\n%\n\\node[Box2,below=0.7 of B2](B21){Real-Time Processing};\n\\node[Box2,below=of B21](B22){Enhanced Privacy};\n\\node[Box2,below=of B22](B23){Offline Functionality};\n\\node[Box2,below=of B23](B24){Personalized Experience};\n%\n\\node[Box,below=0.7 of B3](B31){Limited Computational Resources};\n\\node[Box,below=of B31](B32){Battery Life Constraints};\n\\node[Box,below=of B32](B33){Storage Limitations};\n\\node[Box,below=of B33](B34){Model Optimization Requirements};\n%\n\\node[Box3,below=0.7 of B4](B41){Voice Recognition};\n\\node[Box3,below=of B41](B42){Computational Photography};\n\\node[Box3,below=of B42](B43){Health Monitoring};\n\\node[Box3,below=of B43](B44){Real-Time Translation};\n%\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B1.west)--++(180:0.5)|-(B1\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B2.west)--++(180:0.5)|-(B2\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B3.west)--++(180:0.5)|-(B3\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B4.west)--++(180:0.5)|-(B4\\i);\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n\n```\n**Mobile ML Capabilities**: Mobile machine learning systems balance performance with resource constraints through on-device processing, specialized hardware acceleration, and optimized frameworks. This figure outlines key considerations for deploying ML models on mobile devices, including the trade-offs between computational efficiency, battery life, and model performance.\n:::\n\n### Battery and Thermal Constraints {#sec-ml-systems-battery-thermal-constraints-52eb}\n\nMobile devices exemplify intermediate constraints: 8-24GB RAM (varying from mid-range to flagship), 128GB-1TB storage, 1-10 TOPS AI compute through Neural Processing Units[^fn-npu] consuming 3-5W power. System-on-Chip architectures[^fn-mobile-soc] integrate computation and memory to minimize energy costs. Memory bandwidth of 25-50 GB/s limits models to 10-100MB parameters, requiring aggressive optimization (@sec-model-optimizations). Battery constraints (18-22Wh capacity) make energy optimization critical: 1W continuous ML processing reduces device lifetime from 24 to 18 hours. Specialized frameworks (TensorFlow Lite[^fn-tflite], Core ML[^fn-coreml]) provide hardware-optimized inference enabling <50ms UI response times.\n\n[^fn-mobile-soc]: **Mobile System-on-Chip**: Modern flagship SoCs integrate CPU, GPU, NPU, and memory controllers on a single chip. Apple's A17 Pro contains 19 billion transistors in a 3nm process.\n\n[^fn-npu]: **Neural Processing Unit (NPU)**: Specialized processors optimized for neural network operations. Apple's Neural Engine performs 600 billion operations per second. Qualcomm's Hexagon NPU delivers up to 75 TOPS while consuming <1W.\n\n[^fn-tflite]: **TensorFlow Lite**: Google's mobile ML framework launched in 2017, designed to run models <100MB with <100ms inference time. Used in over 4 billion devices worldwide.\n\n[^fn-coreml]: **Core ML**: Apple's framework introduced in iOS 11 (2017), optimized for on-device inference. Supports models from 1KB to 1GB, with automatic optimization for Apple Silicon.\n\n### Mobile ML Benefits and Resource Constraints {#sec-ml-systems-mobile-ml-benefits-resource-constraints-63a1}\n\nMobile ML excels at delivering responsive, privacy-preserving user experiences. Real-time processing achieves sub-10ms latency, enabling imperceptible response: face detection operates at 60fps with under 5ms latency, while voice wake-word detection responds within 2-3ms. Privacy guarantees emerge from complete data sovereignty through on-device processing. Face ID processes biometric data entirely within a hardware-isolated Secure Enclave[^fn-face-detection], keyboard prediction trains locally on user data, and health monitoring maintains HIPAA compliance without complex infrastructure requirements. Offline functionality eliminates network dependency: Google Maps analyzes millions of road segments locally for navigation, translation[^fn-real-time-translation] supports 40+ language pairs using 35-45MB models that achieve 90% of cloud accuracy, and music identification matches against on-device databases. Personalization reaches unprecedented depth by leveraging behavioral data accumulated over months: iOS predicts which app users will open next with 70-80% accuracy, notification management optimizes delivery timing based on individual patterns, and camera systems continuously adapt to user preferences through implicit feedback.\n\n[^fn-real-time-translation]: **Real-Time Translation**: Google Translate processes 40+ languages offline using on-device neural networks. Models are 35-45MB versus 2GB+ cloud versions, achieving 90% accuracy while enabling instant translation without internet.\n\n[^fn-face-detection]: **Mobile Face Detection**: Apple's Face ID processes biometric data entirely on-device using the Secure Enclave, making extraction practically impossible even with physical device access.\n\nThese benefits require accepting significant resource constraints. Flagship phones allocate only 100MB-1GB to individual ML applications, representing just 0.5-5% of total memory, forcing models to remain under 100-500MB compared to cloud's ability to deploy 350GB+ models. Battery life[^fn-mobile-constraints] presents visible user impact: processing 100 inferences per hour at 0.1 joules each consumes 0.36% of battery daily, compounding with baseline drain; video processing at 30fps can reduce battery life from 24 hours to 6-8 hours. Thermal throttling unpredictably limits sustained performance, with the A17 Pro chip achieving 35 TOPS peak performance but sustaining only 10-15 TOPS during extended operation, requiring adaptive performance strategies. Development complexity multiplies across platforms, demanding separate implementations for Core ML and TensorFlow Lite, while device heterogeneity—particularly Android's span from $100 budget phones to $1,500 flagships—requires multiple model variants. Deployment friction adds further challenges: app store approval processes taking 1-7 days prevent rapid bug fixes that cloud deployments can deploy instantly.\n\n[^fn-mobile-constraints]: **Mobile Device Constraints**: Flagship phones typically have 12-24GB RAM and 512GB-2TB storage, versus cloud servers with 256-2048GB RAM and unlimited storage. Mobile processors operate at 15-25W peak power compared to server CPUs at 200-400W.\n\n### Personal Assistant and Media Processing {#sec-ml-systems-personal-assistant-media-processing-3419}\n\nMobile ML has achieved transformative success across diverse applications that showcase the unique advantages of on-device processing for billions of users worldwide. Computational photography represents perhaps the most visible success, transforming smartphone cameras into sophisticated imaging systems. Modern flagships process every photo through multiple ML pipelines operating in real-time: portrait mode[^fn-portrait-mode] uses depth estimation and segmentation networks to achieve DSLR-quality bokeh effects, night mode captures and aligns 9-15 frames with ML-based denoising that reduces noise by 10-20dB, and systems like Google Pixel process 10-15 distinct ML models per photo for HDR merging, super-resolution, and scene optimization.\n\nVoice-driven interactions demonstrate mobile ML's transformation of human-device communication. These systems combine ultra-low-power wake-word detection consuming less than 1mW with on-device speech recognition achieving under 10ms latency for simple commands. Keyboard prediction has evolved to context-aware neural models achieving 60-70% phrase prediction accuracy, reducing typing effort by 30-40%. Real-time camera translation processes over 100 languages at 15-30fps entirely on-device, enabling instant visual translation without internet connectivity.\n\nHealth monitoring through wearables like Apple Watch extracts sophisticated insights from sensor data while maintaining complete privacy. These systems achieve over 95% accuracy in activity detection and include FDA-cleared atrial fibrillation detection with 98%+ sensitivity, processing extraordinarily sensitive health data entirely on-device to maintain HIPAA compliance. Accessibility features demonstrate transformative social impact through continuous local processing: Live Text detects and recognizes text from camera feeds, Sound Recognition alerts deaf users to environmental cues through haptic feedback, and VoiceOver generates natural language descriptions of visual content.\n\nAugmented reality frameworks leverage mobile ML for real-time environment understanding at 60fps. ARCore and ARKit track device position with centimeter-level accuracy while simultaneously mapping 3D surroundings, enabling hand tracking that extracts 21-joint 3D poses and face analysis of 50+ landmark meshes for real-time effects. These applications demand consistent sub-16ms frame times, making only on-device processing viable for delivering the seamless experiences users expect.\n\n[^fn-portrait-mode]: **Portrait Mode Photography**: Uses dual cameras or LiDAR for depth maps, then ML segmentation to separate subjects from backgrounds, achieving DSLR-quality depth-of-field effects in real-time.\n\nDespite mobile ML's demonstrated capabilities, a common pitfall involves attempting to deploy desktop-trained models directly to mobile or edge devices without architecture modifications. Models developed on powerful workstations often fail dramatically when deployed to resource-constrained devices. A ResNet-50 model requiring 4GB memory for inference (including activations and batch processing) and 4 billion FLOPs per inference cannot run on a device with 512MB of RAM and a 1 GFLOP/s processor. Beyond simple resource violations, desktop-optimized models may use operations unsupported by mobile hardware (specialized mathematical operations), assume floating-point precision unavailable on embedded systems, or require batch processing incompatible with single-sample inference. Successful deployment demands architecture-aware design from the beginning, including specialized architectural techniques for mobile devices [@howard2017mobilenets], integer-only operations for microcontrollers, and optimization strategies that maintain accuracy while reducing computation.\n\n## TinyML: Ubiquitous Sensing at Scale {#sec-ml-systems-tiny-ml-ubiquitous-sensing-scale-51d8}\n\nThe progression from Cloud to Edge to Mobile ML demonstrates the increasing distribution of intelligence across computing platforms, yet each step still requires significant resources. Even mobile devices, with their sophisticated processors and gigabytes of memory, represent a relatively privileged position in the global computing landscape, demanding watts of power and hundreds of dollars in hardware investment. For truly ubiquitous intelligence (sensors in every surface, monitor on every machine, intelligence in every object), these resource requirements remain prohibitive. TinyML completes the deployment spectrum by pushing intelligence to its absolute limits, using devices costing less than $10 and consuming less than 1 milliwatt of power. This paradigm makes ubiquitous sensing not just technically feasible but economically practical at massive scales.\n\nWhere mobile ML still requires sophisticated hardware with gigabytes of memory and multi-core processors, Tiny Machine Learning operates on microcontrollers with kilobytes of RAM and single-digit dollar price points. This extreme constraint forces a significant shift in how we approach machine learning deployment, prioritizing ultra-low power consumption and minimal cost over computational sophistication. The result enables entirely new categories of applications impossible at any other scale.\n\nTinyML brings intelligence to the smallest devices, from microcontrollers[^fn-microcontrollers] to embedded sensors, enabling real-time computation in severely resource-constrained environments. This paradigm excels in applications requiring ubiquitous sensing, autonomous operation, and extreme energy efficiency. TinyML systems power applications such as predictive maintenance, environmental monitoring, and simple gesture recognition while optimized for energy efficiency[^fn-energy-efficiency], often running for months or years on limited power sources such as coin-cell batteries[^fn-coin-cell]. These systems deliver actionable insights in remote or disconnected environments where power, connectivity, and maintenance access are impractical.\n\n[^fn-microcontrollers]: **Microcontrollers**: Single-chip computers with integrated CPU, memory, and peripherals, typically operating at 1-100MHz with 32KB-2MB RAM. Arduino Uno uses an ATmega328P with 32KB flash and 2KB RAM, while ESP32 provides WiFi capability with 520KB RAM, still thousands of times less than a smartphone.\n\n[^fn-energy-efficiency]: **Energy Efficiency in TinyML**: Ultra-low power consumption enables deployment in remote locations. Modern ARM Cortex-M0+ microcontrollers consume <1µW in sleep mode and 100-300µW/MHz when active. Efficient ML inference can run for years on a single coin-cell battery.\n\n[^fn-coin-cell]: **Coin-Cell Batteries**: Small, round batteries (CR2032 being most common) providing 200-250mAh at 3V. When powering TinyML devices at 10-50mW average consumption, these batteries can operate devices for 1-5 years, enabling \"deploy-and-forget\" IoT applications.\n\n::: {.callout-definition title=\"TinyML\"}\n\n***Tiny Machine Learning (TinyML)*** is the deployment of machine learning models on _microcontrollers_ and _ultra-constrained devices_, enabling _autonomous decision-making_ with milliwatt-scale power consumption for applications requiring years of battery life.\n:::\n\nThis section analyzes TinyML through four critical dimensions that define its unique position in the ML deployment spectrum. @fig-tiny-ml encapsulates the key aspects of TinyML discussed in this section.\n\n::: {#fig-tiny-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=32mm,align=flush center,\n    minimum width=32mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=27mm, minimum width=27mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=28mm, minimum width=28mm\n  },\nBox4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=39mm, minimum width=39mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){TinyML};\n%\n\\node[Box4,below=0.7 of B1](B11){Low Power and Resource Constrained Environments};\n\\node[Box4,below=of B11](B12){On-Device Machine Learning};\n\\node[Box4,below=of B12](B13){Ultra-Small Form Factor};\n%\n\\node[Box2,below=0.7 of B2](B21){Extremely Low Latency};\n\\node[Box2,below=of B21](B22){High Data Security};\n\\node[Box2,below=of B22](B23){Energy Efficiency};\n\\node[Box2,below=of B23](B24){Always-On Operation};\n%\n\\node[Box,below=0.7 of B3](B31){Complex Development Cycle};\n\\node[Box,below=of B31](B32){Model Optimization and Compression};\n\\node[Box,below=of B32](B33){Resource Limitations};\n%\n\\node[Box3,below=0.7 of B4](B41){Anomaly Detection};\n\\node[Box3,below=of B41](B42){Environmental Monitoring};\n\\node[Box3,below=of B42](B43){Predictive Maintenance};\n\\node[Box3,below=of B43](B44){Wearable Devices};\n%\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B1.west)--++(180:0.5)|-(B1\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B2.west)--++(180:0.5)|-(B2\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B3.west)--++(180:0.5)|-(B3\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B4.west)--++(180:0.5)|-(B4\\i);\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n```\n**TinyML System Characteristics**: Constrained devices necessitate a focus on efficiency, driving trade-offs between model complexity, accuracy, and energy consumption, while enabling localized intelligence and real-time responsiveness in embedded applications. This figure outlines key aspects of TinyML, including the challenges of resource limitations, example applications, and the benefits of on-device machine learning.\n:::\n\n### Extreme Resource Constraints {#sec-ml-systems-extreme-resource-constraints-b788}\n\nTinyML operates at hardware extremes: Arduino Nano 33 BLE Sense (256KB RAM, 1MB Flash, 0.02-0.04W, $35) and ESP32-CAM (520KB RAM, 4MB Flash, 0.05-0.25W, $10) represent 30,000-50,000x memory reduction versus cloud systems and 160,000x power reduction (@fig-TinyML-example). These constraints enable months or years of autonomous operation[^fn-on-device-training] but demand specialized algorithms delivering acceptable performance at <1 TOPS compute with microsecond response times. Devices range from palm-sized to 5x5mm chips[^fn-device-size], enabling ubiquitous sensing in previously impossible contexts.\n\n[^fn-on-device-training]: **On-Device Training Constraints**: Microcontrollers rarely support full training due to memory limitations. Instead, they use transfer learning with minimal on-device adaptation or federated learning aggregation.\n\n[^fn-device-size]: **TinyML Device Scale**: The smallest ML-capable devices measure just 5x5mm (Syntiant NDP chips). Google's Coral Dev Board Mini (40x48mm) includes WiFi and full Linux capability.\n\n![**TinyML System Scale**: These device kits exemplify the extreme miniaturization achievable with TinyML, enabling deployment of machine learning on resource-constrained devices with limited power and memory. such compact systems broaden the applicability of ML to previously inaccessible edge applications, including wearable sensors and embedded IoT devices. Source: [@warden2018speech]](images/png/tiny_ml.png){#fig-TinyML-example}\n\n### TinyML Advantages and Operational Trade-offs {#sec-ml-systems-tinyml-advantages-operational-tradeoffs-db08}\n\nTinyML's extreme resource constraints enable unique advantages impossible at other scales. Microsecond-level latency eliminates all transmission overhead, achieving 10-100μs response times that enable applications requiring sub-millisecond decisions: industrial vibration monitoring processes 10kHz sampling at under 50μs latency, audio wake-word detection analyzes 16kHz audio streams under 100μs, and precision manufacturing systems inspect over 1000 parts per minute. Economic advantages prove transformative for massive-scale deployments: complete ESP32-CAM systems cost $8-12, enabling 1000-sensor deployments for $10,000 versus $500,000-1,000,000 for cellular alternatives. Agricultural monitoring can instrument buildings for $5,000 versus $50,000+ for camera-based systems, while city-scale networks of 100,000 sensors become economically viable at $1-2 million versus $50-100 million for edge alternatives. Energy efficiency enables 1-10 year operation on coin-cell batteries consuming just 1-10mW, supporting applications like wildlife tracking for years without recapture, structural health monitoring embedded in concrete during construction, and agricultural sensors deployed where power infrastructure doesn't exist. Energy harvesting from solar, vibration, or thermal sources can even enable perpetual operation. Privacy surpasses all other paradigms through physical data confinement—data never leaves the sensor, providing mathematical guarantees impossible in networked systems regardless of encryption strength.\n\nThese capabilities require substantial trade-offs. Computational constraints impose severe limits: microcontrollers provide 256KB-2MB RAM versus smartphones' 12-24GB (a 5,000-50,000x difference), forcing models to remain under 100-500KB with 10,000-100,000 parameters compared to mobile's 1-10 million parameters. Development complexity requires expertise spanning neural network optimization, hardware-level memory management, embedded toolchains, and specialized debugging using oscilloscopes and JTAG debuggers across diverse microcontroller architectures. Model accuracy suffers from extreme compression: TinyML models typically achieve 70-85% of cloud model accuracy versus mobile's 90-95%, limiting suitability for applications requiring high precision. Deployment inflexibility constrains adaptation, as devices typically run single fixed models requiring power-intensive firmware flashing for updates that risk bricking devices. With operational lifetimes spanning years, initial deployment decisions become critical. Ecosystem fragmentation[^fn-model-compression] across microcontroller vendors and ML frameworks creates substantial development overhead and platform lock-in challenges.\n\n[^fn-model-compression]: **TinyML Model Optimization**: Specialized techniques dramatically reduce model size. A typical 50MB smartphone model might optimize to 250KB for microcontroller deployment while retaining 95% accuracy (detailed in @sec-model-optimizations).\n\n### Environmental and Health Monitoring {#sec-ml-systems-environmental-health-monitoring-c9b0}\n\nTinyML succeeds remarkably across domains where its unique advantages—ultra-low power, minimal cost, and complete data privacy—enable applications impossible with other paradigms. Industrial predictive maintenance demonstrates TinyML's ability to transform traditional infrastructure through distributed intelligence. Manufacturing facilities deploy thousands of vibration sensors operating continuously for 5-10 years on coin-cell batteries while consuming less than 2mW average power. These sensors cost $15-50 compared to traditional wired sensors at $500-2,000 per point, reducing deployment costs from $5-20 million to $150,000-500,000 for 10,000 monitoring points. Local anomaly detection provides 7-14 day advance warning of equipment failures, enabling companies to achieve 25-45% reductions in unplanned downtime.\n\nWake-word detection represents TinyML's most visible consumer application, with billions of devices employing always-listening capabilities at under 1mW continuous power consumption. These systems process 16kHz audio through neural networks containing 5,000-20,000 parameters compressed to 10-50KB, detecting wake phrases with over 95% accuracy. Amazon Echo devices use dedicated TinyML chips like the AML05 that consume less than 10mW for detection, only activating the main processor when wake words trigger—reducing average power consumption by 10-20x[^fn-fitness-trackers].\n\nPrecision agriculture leverages TinyML's economic advantages where traditional solutions prove cost-prohibitive. Monitoring 100 hectares requires approximately 1,000 monitoring points, which TinyML enables for $15,000-30,000 compared to $100,000-200,000+ for cellular-connected alternatives. These sensors operate 3-5 years on batteries while analyzing temporal patterns locally, transmitting only actionable insights rather than raw data streams.\n\nWildlife conservation demonstrates TinyML's transformative potential for remote environmental monitoring. Researchers deploy solar-powered audio sensors consuming 100-500mW that process continuous audio streams for species identification. By performing local analysis, these systems reduce satellite transmission requirements from 4.3GB per day to 400KB of detection summaries, a 10,000x reduction that makes large-scale deployments of 100-1,000 sensors economically feasible. Medical wearables achieve FDA-cleared cardiac monitoring with 95-98% sensitivity while processing 250-500 ECG samples per second at under 5mW power consumption. This efficiency enables week-long continuous monitoring versus hours for smartphone-based alternatives, while reducing diagnostic costs from $2,000-5,000 for traditional in-lab studies to under $100 for at-home testing.\n\n[^fn-fitness-trackers]: **TinyML in Fitness Trackers**: Apple Watch detects falls using accelerometer data and on-device ML, automatically calling emergency services. The algorithm analyzes motion patterns in real-time using <1mW power.\n\n## Hybrid Architectures: Combining Paradigms {#sec-ml-systems-hybrid-architectures-combining-paradigms-c1f2}\n\nOur examination of individual deployment paradigms—from cloud's massive computational power to tiny ML's ultra-efficient sensing—reveals a spectrum of engineering trade-offs, each with distinct advantages and limitations. Cloud ML maximizes algorithmic sophistication but introduces latency and privacy constraints. Edge ML reduces latency but requires dedicated infrastructure and constrains computational resources. Mobile ML prioritizes user experience but operates within strict battery and thermal limitations. TinyML achieves ubiquity through extreme efficiency but severely constrains model complexity. Each paradigm occupies a distinct niche, optimized for specific constraints and use cases.\n\nYet in practice, production systems rarely confine themselves to a single paradigm, as the limitations of each approach create opportunities for complementary integration. A voice assistant that uses tiny ML for wake-word detection, mobile ML for local speech recognition, edge ML for contextual processing, and cloud ML for complex natural language understanding demonstrates a more powerful approach. Hybrid Machine Learning formalizes this integration strategy, creating unified systems that leverage each paradigm's complementary strengths while mitigating individual limitations.\n\n::: {.callout-definition title=\"Hybrid ML\"}\n\n***Hybrid Machine Learning (Hybrid ML)*** is the integration of _multiple deployment paradigms_ into unified systems, strategically distributing workloads across _computational tiers_ to achieve _scalability_, _privacy_, and _performance_ impossible with single-paradigm approaches.\n:::\n\n### Multi-Tier Integration Patterns {#sec-ml-systems-multitier-integration-patterns-c96b}\n\nHybrid ML design patterns provide reusable architectural solutions for integrating paradigms effectively. Each pattern represents a strategic approach to distributing ML workloads across computational tiers, optimized for specific trade-offs in latency, privacy, resource efficiency, and scalability.\n\nThis analysis identifies five essential patterns that address common integration challenges in hybrid ML systems.\n\n#### Train-Serve Split {#sec-ml-systems-trainserve-split-b9a1}\n\nOne of the most common hybrid patterns is the train-serve split, where model training occurs in the cloud but inference happens on edge, mobile, or tiny devices. This pattern takes advantage of the cloud's vast computational resources for the training phase while benefiting from the low latency and privacy advantages of on-device inference[^fn-train-serve-split]. For example, smart home devices often use models trained on large datasets in the cloud but run inference locally to ensure quick response times and protect user privacy. In practice, this might involve training models on powerful cloud systems like TPU Pods with exaflop-scale compute and hundreds of terabytes of memory, before deploying optimized versions to edge servers or embedded edge devices for efficient inference. Similarly, mobile vision models for computational photography are typically trained on powerful cloud infrastructure but deployed to run efficiently on phone hardware.\n\n[^fn-train-serve-split]: **Train-Serve Split Economics**: Training large models can cost $1-10M (GPT-3: $4.6M in compute costs) but inference costs <$0.01 per query when deployed efficiently [@brown2020language]. This 1,000,000x cost difference drives the pattern of expensive cloud training with cost-effective edge inference.\n\n#### Hierarchical Processing {#sec-ml-systems-hierarchical-processing-17a5}\n\nHierarchical processing creates a multi-tier system where data and intelligence flow between different levels of the ML stack. This pattern effectively combines the capabilities of Cloud ML systems (like the large-scale training infrastructure discussed in previous sections) with multiple Edge ML systems (like edge servers and embedded devices from our edge deployment examples) to balance central processing power with local responsiveness. In industrial IoT applications, tiny sensors might perform basic anomaly detection, edge devices aggregate and analyze data from multiple sensors, and cloud systems handle complex analytics and model updates. For instance, we might see ESP32-CAM devices (from our TinyML examples) performing basic image classification at the sensor level with their minimal 520 KB RAM, feeding data up to edge servers or embedded systems for more sophisticated analysis, and ultimately connecting to cloud infrastructure for complex analytics and model updates.\n\nThis hierarchy allows each tier to handle tasks appropriate to its capabilities. TinyML devices handle immediate, simple decisions; edge devices manage local coordination; and cloud systems tackle complex analytics and learning tasks. Smart city installations often use this pattern, with street-level sensors feeding data to neighborhood-level edge processors, which in turn connect to city-wide cloud analytics.\n\n#### Progressive Deployment {#sec-ml-systems-progressive-deployment-c8b7}\n\nProgressive deployment creates tiered intelligence architectures by adapting models across computational tiers through systematic compression. A model might start as a large cloud version, then be progressively optimized for edge servers, mobile devices, and finally tiny sensors using techniques detailed in @sec-model-optimizations.\n\nAmazon Alexa exemplifies this pattern: wake-word detection uses <1KB models on TinyML devices consuming <1mW, edge processing handles simple commands with 1-10MB models at 1-10W, while complex natural language understanding requires GB+ models in cloud infrastructure. This tiered approach reduces cloud inference costs by 95% while maintaining user experience.\n\nHowever, progressive deployment introduces operational complexity: model versioning across tiers, ensuring consistency between generations, managing failure cascades during connectivity loss, and coordinating updates across millions of devices. Production teams must maintain specialized expertise spanning TinyML optimization, edge orchestration, and cloud scaling.\n\n#### Federated Learning {#sec-ml-systems-federated-learning-9850}\n\nFederated learning[^fn-federated-architecture] enables learning from distributed data while maintaining privacy. Google's production system processes 6 billion mobile keyboards, training improved models while keeping typed text local. Each training round involves 100-10,000 devices contributing model updates, requiring orchestration to manage device availability, network conditions, and computational heterogeneity.\n\nProduction deployments face significant operational challenges: device dropout rates of 50-90% during training rounds, network bandwidth constraints limiting update frequency, and differential privacy mechanisms preventing information leakage. Aggregation servers must handle intermittent connectivity, varying device capabilities, and ensure convergence despite non-IID data distributions. This requires specialized monitoring infrastructure to track distributed training progress and debug issues without accessing raw data.\n\n[^fn-federated-architecture]: **Federated Learning Architecture**: Coordinates learning across millions of devices without centralizing data [@mcmahan2017federated]. Google's federated learning processes 6 billion mobile keyboards, training improved models while keeping all typed text local. Each round involves 100-10,000 devices contributing model updates.\n\n#### Collaborative Learning {#sec-ml-systems-collaborative-learning-6f7b}\n\nCollaborative learning enables peer-to-peer learning between devices at the same tier, often complementing hierarchical structures.[^fn-tiered-voice] Autonomous vehicle fleets, for example, might share learning about road conditions or traffic patterns directly between vehicles while also communicating with cloud infrastructure. This horizontal collaboration allows systems to share time-sensitive information and learn from each other's experiences without always routing through central servers.\n\n[^fn-tiered-voice]: **Tiered Voice Processing**: Amazon Alexa uses a 3-tier system: tiny wake-word detection on-device (<1KB model), edge processing for simple commands (1-10MB models), and cloud processing for complex queries (GB+ models). This reduces cloud costs by 95% while maintaining functionality.\n\n### Production System Case Studies {#sec-ml-systems-production-system-case-studies-17a6}\n\nReal-world implementations integrate multiple design patterns into cohesive solutions rather than applying them in isolation. Production ML systems form interconnected networks where each paradigm plays a specific role while communicating with others, following integration patterns that leverage the strengths and address the limitations established in our four-paradigm framework (@sec-ml-systems-deployment-spectrum-38d0).\n\n@fig-hybrid illustrates these key interactions through specific connection types: \"Deploy\" paths show how models flow from cloud training to various devices, \"Data\" and \"Results\" show information flow from sensors through processing stages, \"Analyze\" shows how processed information reaches cloud analytics, and \"Sync\" demonstrates device coordination. Notice how data generally flows upward from sensors through processing layers to cloud analytics, while model deployments flow downward from cloud training to various inference points. The interactions aren't strictly hierarchical. Mobile devices might communicate directly with both cloud services and tiny sensors, while edge systems can assist mobile devices with complex processing tasks.\n\n::: {#fig-hybrid fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\nLine/.style={line width=1.0pt,black!50,text=black},\n  Box/.style={inner xsep=2pt,\n    node distance=0.6,\n    draw=GreenLine, line width=0.75pt,\n    fill=GreenL,\n    text width=20mm,align=flush center,\n    minimum width=20mm, minimum height=9mm\n  },\n   Text/.style={inner xsep=2pt,\n    draw=none, line width=0.75pt,\n    fill=TextColor,\n    font=\\footnotesize\\usefont{T1}{phv}{m}{n},\n    align=flush center,\n    minimum width=7mm, minimum height=5mm\n  },\n  }\n\n\\node[Box,fill=RedL,draw=RedLine](G2){Training};\n\\node[Box,fill=none,draw=none,below =1.2 of G2](A){};\n\\node[Box,node distance=2.25, left=of A](B2){Inference};\n\\node[Box,node distance=2.25,left=of B2,fill=cyan!20,draw=BlueLine](B1){Inference};\n\\node[Box,node distance=2.25, right=of A,fill=orange!20,draw=OrangeLine](B3){Inference};\n%\n\\node[Box,node distance=1.15, below=of B1,fill=cyan!20,draw=BlueLine](1DB1){Processing};\n\\node[Box,node distance=1.15, below=of B3,fill=orange!20,draw=OrangeLine](1DB3){Processing};\n\\path[](1DB3)-|coordinate(S)(G2);\n\\node[Box,node distance=1.5,fill=RedL,draw=RedLine]at(S)(1DB2){Analytics};\n\\path[](G2)-|coordinate(SS)(B2);\n\\node[Box](G1)at(SS){Sensors};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=6mm,anchor= west,\n       yshift=1mm,fill=BackColor,fit=(G1)(B2),line width=0.75pt](BB2){};\n\\node[below=3pt of  BB2.north,anchor=north]{TinyML};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=7mm,anchor= west,\n       yshift=0mm,fill=BackColor,fit=(G2)(1DB2),line width=0.75pt](BB2){};\n\\node[below=3pt of  BB2.north,anchor=north]{Cloud ML};\n%\n\\draw[Line,-latex](G1.west)--++(180:0.9)|-node[Text,pos=0.1]{Data}(B2);\n\\draw[Line,-latex](G2)--++(270:1.20)-|(B2);\n\\draw[Line,-latex](G2)--++(270:1.20)-|(B3);\n\\draw[Line,-latex](G2)--node[Text,pos=0.46]{Deploy}++(270:1.20)-|(B1);\n%\n\\draw[Line,-latex](B1)--node[Text,pos=0.5]{Results}(1DB1);\n\\draw[Line,-latex](B2)|-node[Text,pos=0.75]{Results}(1DB1.10);\n%\n\\draw[Line,-latex](B1.330)--++(270:0.9)-|node[Text,pos=0.2]{Assist}(B3.220);\n\\draw[Line,-latex](B2.east)--node[Text,pos=0.5]{Sync}++(0:5.4)|-(1DB3.170);\n%\n\\draw[Line,-latex](1DB1.350)--node[Text,pos=0.75]{Results}(1DB2.190);\n\\draw[Line,-latex](1DB3.190)--node[Text,pos=0.50]{Data}(1DB2.350);\n\\draw[Line,-latex](B3.290)--node[Text,pos=0.5]{Results}(1DB3.70);\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=5mm,anchor= west,\n      yshift=-2mm,fill=BackColor,fit=(B1)(1DB1),line width=0.75pt](BB2){};\n\\node[above=3pt of  BB2.south,anchor=south]{Edge ML};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=5mm,anchor= west,\n      yshift=-2mm,fill=BackColor,fit=(B3)(1DB3),line width=0.75pt](BB2){};\n\\node[above=3pt of  BB2.south,anchor=south]{Mobile ML};\n\\end{tikzpicture}\n```\n**Hybrid System Interactions**: Data flows upward from sensors through processing layers to cloud analytics for insights, while trained models deploy downward from the cloud to enable inference at the edge, mobile, and TinyML devices. These connection types (deploy, data/results, analyze, and sync) establish a distributed architecture where each paradigm contributes unique capabilities to the overall machine learning system.\n:::\n\nProduction systems demonstrate these integration patterns across diverse applications where no single paradigm could deliver the required functionality. Industrial defect detection exemplifies model deployment patterns: cloud infrastructure trains vision models on datasets from multiple facilities, then distributes optimized versions to edge servers managing factory operations, tablets for quality inspectors, and embedded cameras on manufacturing equipment. This demonstrates how a single ML solution flows from centralized training to inference points at multiple computational scales.\n\nAgricultural monitoring illustrates hierarchical data flow: soil sensors perform local anomaly detection, transmit results to edge processors that aggregate data from dozens of sensors, which then route insights to cloud infrastructure for farm-wide analytics while simultaneously updating farmers' mobile applications. Information traverses upward through processing layers, with each tier adding analytical sophistication appropriate to its computational resources.\n\nFitness trackers exemplify gateway patterns between TinyML and mobile devices: wearables continuously monitor activity using algorithms optimized for microcontroller execution, sync processed data to smartphones that combine metrics from multiple sources, then transmit periodic updates to cloud infrastructure for long-term analysis. This enables tiny devices to participate in large-scale systems despite lacking direct network connectivity.\n\nThese integration patterns reveal how deployment paradigms complement each other through orchestrated data flows, model deployments, and cross-tier assistance. Industrial systems compose capabilities from Cloud, Edge, Mobile, and TinyML into distributed architectures that optimize for latency, privacy, cost, and operational requirements simultaneously. The interactions between paradigms often determine system success more than individual component capabilities.\n\n## Shared Principles Across Deployment Paradigms {#sec-ml-systems-shared-principles-across-deployment-paradigms-915d}\n\nDespite their diversity, all ML deployment paradigms share core principles that enable systematic understanding and effective hybrid combinations. @fig-ml-systems-convergence illustrates how implementations spanning cloud to tiny devices converge on core system challenges: managing data pipelines, balancing resource constraints, and implementing reliable architectures. This convergence explains why techniques transfer effectively between paradigms and hybrid approaches work successfully in practice.\n\n::: {#fig-ml-systems-convergence fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\nLine/.style={line width=1.0pt,black!50,text=black},\n  Box/.style={inner xsep=2pt,\n    node distance=0.6,\n    draw=GreenLine, line width=0.75pt,\n    fill=GreenL,\n    text width=30mm,align=flush center,\n    minimum width=30mm, minimum height=13mm\n  },\n  Box1/.style={inner xsep=2pt,\n    node distance=0.8,\n    draw=BlueLine, line width=0.75pt,\n    fill=BlueL,\n    text width=36mm,align=flush center,\n    minimum width=40mm, minimum height=13mm\n  },\n}\n\n\\begin{scope}[anchor=west]\n\\node[Box](B1){Cloud ML Data Centers Training at Scale};\n\\node[Box,right=of B1](B2){Edge ML Local Processing Inference Focus};\n\\node[Box,right=of B2](B3){Mobile ML Personal DevicesUser Applications};\n\\node[Box, right=of B3](B4){TinyML Embedded Systems Resource Constrained};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,\n      anchor=west,yshift=2mm,fill=BackColor,\n      fit=(B1)(B2)(B3)(B4),line width=0.75pt](BB){};\n\\node[below=11pt of  BB.north east,anchor=east]{ML System Implementations};\n\\end{scope}\n%\n\\begin{scope}[shift={(0.4,-2.8)}, anchor=west]\n\\node[Box1](2B1){Data Pipeline Collection -- Processing -- Deployment};\n\\node[Box1,right=of 2B1](2B2){Resource Management Compute -- Memory -- Energy -- Network};\n\\node[Box1,right=of 2B2](2B3){System Architecture Models -- Hardware -- Software};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,\n      anchor= west,yshift=-1mm,fill=BackColor,fit=(2B1)(2B2)(2B3),line width=0.75pt](BB2){};\n\\node[above=8pt of  BB2.south east,anchor=east]{Core System Principles};\n\\end{scope}\n%\n\\begin{scope}[shift={(0.4,-6.0)}, anchor=west]\n\\node[Box1, fill=VioletL,draw=VioletLine](3B1){Optimization \\& Efficiency Model -- Hardware -- Energy};\n\\node[Box1,right=of 3B1, fill=VioletL,draw=VioletLine](3B2){Operational Aspects Deployment -- Monitoring -- Updates};\n\\node[Box1,right=of 3B2, fill=VioletL,draw=VioletLine](3B3){Trustworthy AI Security -- Privacy -- Reliability};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,\n       anchor= west,yshift=-1mm,fill=BackColor,fit=(3B1)(3B2)(3B3),line width=0.75pt](BB3){};\n\\node[above=8pt of  BB3.south east,anchor=east]{System Considerations};\n\\end{scope}\n%\n\\draw[-latex,Line](B1.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B2.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B3.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B4.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B2.south)--++(270:0.75)-|(2B2);\n\\draw[-latex,Line](B3.south)--++(270:0.75)-|(2B3);\n%\n\\draw[-latex,Line](2B1.south)--++(270:0.95)-|(3B1);\n\\draw[-latex,Line](2B2.south)--++(270:0.95)-|(3B1);\n\\draw[-latex,Line](2B3.south)--++(270:0.95)-|(3B1);\n\\draw[-latex,Line](2B2.south)--++(270:0.95)-|(3B2);\n\\draw[-latex,Line](2B3.south)--++(270:0.95)-|(3B3);\n\\end{tikzpicture}\n```\n**Convergence of ML Systems**: Diverse machine learning deployments (cloud, edge, mobile, and tiny) share foundational principles in data pipelines, resource management, and system architecture, enabling hybrid solutions and systematic design approaches. Understanding these shared principles allows practitioners to adapt techniques across different paradigms and build cohesive, efficient ML workflows despite varying constraints and optimization goals.\n:::\n\n@fig-ml-systems-convergence reveals three distinct layers of abstraction that unify ML system design across deployment contexts.\n\nThe top layer represents ML system implementations, the four deployment paradigms examined throughout this chapter. Cloud ML operates in data centers with training at scale, Edge ML performs local processing focused on inference, Mobile ML runs on personal devices for user applications, and TinyML executes on embedded systems under severe resource constraints. Despite their apparent differences, these implementations share deeper commonalities that emerge in the underlying layers.\n\nThe middle layer identifies core system principles that unite all paradigms. Data pipeline management (@sec-data-engineering) governs information flow from collection through deployment, maintaining consistent patterns whether processing petabytes in cloud data centers or kilobytes on microcontrollers. Resource management creates universal challenges in balancing competing demands for computation, memory, energy, and network capacity across all scales. System architecture principles guide the integration of models, hardware, and software components regardless of deployment context. These foundational principles remain remarkably consistent even as implementations vary by orders of magnitude in available resources.\n\nThe bottom layer shows how system considerations manifest these principles across practical dimensions. Optimization and efficiency strategies (@sec-model-optimizations) take different forms at each scale: cloud GPU cluster training, edge model compression, mobile thermal management, and TinyML numerical precision, yet all pursue maximizing performance within available resources. Operational aspects (@sec-ml-operations) address deployment, monitoring, and updates with paradigm-specific approaches that tackle fundamentally similar challenges. Trustworthy AI requirements for security, privacy, and reliability apply universally, though implementation techniques necessarily adapt to each deployment context.\n\nThis three-layer structure explains why techniques transfer effectively between scales. Cloud-trained models deploy successfully to edge devices because training and inference optimize similar objectives under different constraints. Mobile optimization insights inform cloud efficiency strategies because both manage the same fundamental resource trade-offs. TinyML innovations drive cross-paradigm advances precisely because extreme constraints force solutions to core problems that exist at all scales. Hybrid approaches work effectively (train-serve splits, hierarchical processing, federated learning) because underlying principles align across paradigms, enabling seamless integration despite vast differences in available resources.\n\n## Comparative Analysis and Selection Framework {#sec-ml-systems-comparative-analysis-selection-framework-832e}\n\nBuilding from this understanding of shared principles, systematic comparison across deployment paradigms reveals the precise trade-offs that should drive deployment decisions and highlights scenarios where each paradigm excels, providing practitioners with analytical frameworks for making informed architectural choices.\n\nThe relationship between computational resources and deployment location forms one of the most important comparisons across ML systems. As we move from cloud deployments to tiny devices, we observe a dramatic reduction in available computing power, storage, and energy consumption. Cloud ML systems, with their data center infrastructure, can leverage virtually unlimited resources, processing data at the scale of petabytes and training models with billions of parameters. Edge ML systems, while more constrained, still offer significant computational capability through specialized hardware like edge GPUs and neural processing units. Mobile ML represents a middle ground, balancing computational power with energy efficiency on devices like smartphones and tablets. At the far end of the spectrum, TinyML operates under severe resource constraints, often limited to kilobytes of memory and milliwatts of power consumption.\n\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Aspect**                 | **Cloud ML**                             | **Edge ML**                            | **Mobile ML**                 | **TinyML**                                            |\n+:===========================+:=========================================+:=======================================+:==============================+:======================================================+\n| **Performance**            |                                          |                                        |                               |                                                       |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Processing Location**    | Centralized cloud servers (Data Centers) | Local edge devices (gateways, servers) | Smartphones and tablets       | Ultra-low-power microcontrollers and embedded systems |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Latency**                | High (100 ms-1000 ms+)                   | Moderate (10-100 ms)                   | Low-Moderate (5-50 ms)        | Very Low (1-10 ms)                                    |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Compute Power**          | Very High (Multiple GPUs/TPUs)           | High (Edge GPUs)                       | Moderate (Mobile NPUs/GPUs)   | Very Low (MCU/tiny processors)                        |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Storage Capacity**       | Unlimited (petabytes+)                   | Large (terabytes)                      | Moderate (gigabytes)          | Very Limited (kilobytes-megabytes)                    |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Energy Consumption**     | Very High (kW-MW range)                  | High (100 s W)                         | Moderate (1-10 W)             | Very Low (mW range)                                   |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Scalability**            | Excellent (virtually unlimited)          | Good (limited by edge hardware)        | Moderate (per-device scaling) | Limited (fixed hardware)                              |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Operational**            |                                          |                                        |                               |                                                       |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Data Privacy**           | Basic-Moderate (Data leaves device)      | High (Data stays in local network)     | High (Data stays on phone)    | Very High (Data never leaves sensor)                  |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Connectivity Required**  | Constant high-bandwidth                  | Intermittent                           | Optional                      | None                                                  |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Offline Capability**     | None                                     | Good                                   | Excellent                     | Complete                                              |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Real-time Processing**   | Dependent on network                     | Good                                   | Very Good                     | Excellent                                             |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Deployment**             |                                          |                                        |                               |                                                       |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Cost**                   | High ($1000s+/month)                     | Moderate ($100s-1000s)                 | Low ($0-10s)                  | Very Low ($1-10s)                                     |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Hardware Requirements**  | Cloud infrastructure                     | Edge servers/gateways                  | Modern smartphones            | MCUs/embedded systems                                 |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Development Complexity** | High (cloud expertise needed)            | Moderate-High (edge+networking)        | Moderate (mobile SDKs)        | High (embedded expertise)                             |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Deployment Speed**       | Fast                                     | Moderate                               | Fast                          | Slow                                                  |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n\n: **Deployment Locations**: Machine learning systems vary in where computation occurs, from centralized cloud servers to local edge devices and ultra-low-power TinyML chips, each impacting latency, bandwidth, and energy consumption. This table categorizes these deployments by their processing location and associated characteristics, enabling informed decisions about system architecture and resource allocation. {#tbl-big_vs_tiny}\n\n@tbl-big_vs_tiny quantifies these paradigm differences across performance, operational, and deployment dimensions, revealing clear gradients in latency (cloud: 100-1000ms → edge: 10-100ms → mobile: 5-50ms → tiny: 1-10ms) and privacy guarantees (strongest with TinyML's complete local processing).\n\n@fig-op_char visualizes performance and operational characteristics through radar plots. Plot a) contrasts compute power and scalability (Cloud ML's strengths) against latency and energy efficiency (TinyML's advantages), with Edge and Mobile ML occupying intermediate positions.\n\n::: {#fig-op_char fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\usefont{T1}{phv}{m}{n}]\n%\\node[anchor=center]at(13.13,3.22){\\includegraphics[scale=0.31]{1}};\n\\definecolor{myblue}{RGB}{31,119,180}\n\\definecolor{myorange}{RGB}{255,127,14}\n\\definecolor{mygreen}{RGB}{44,160,44}\n\\definecolor{myred}{RGB}{214,39,40}\n\\pgfplotsset{myaxis/.style={\n   y axis line style={draw=none},\n   x axis line style={draw=black,line width=1 pt},\n    width=8cm,\n    height=8cm,\n    grid=both,\n    grid style={black!30,dashed},\n    tick align=inside,\n    tick style={draw=none},\n    ymin=0, ymax=10,\n    ytick={1,3,5,7,9},\n    yticklabels={},\n    xtick={0,90,180,270},\n    xticklabel style={align=left,font=\\fontsize{8pt}{9}\\selectfont\\usefont{T1}{phv}{m}{n}},\n % yticklabel style={font=\\fontsize{7pt}{7}\\selectfont\\usefont{T1}{phv}{m}{n}},\n     yticklabel style={\n     rotate around={50:(axis cs:0,0)},\n     anchor=center\n    },\n   xlabel style={font=\\fontsize{7pt}{7}\\selectfont\\usefont{T1}{phv}{m}{n},rotate=30},\n   label distance=5pt,\n   legend style={at={(1.25,1)}, anchor=north},\n   legend cell align=left,\n   legend style={fill=BrownL!30,draw=BrownLine,row sep=2.1pt,\n   font=\\fontsize{7pt}{7}\\selectfont\\usefont{T1}{phv}{m}{n}},\n      cycle list={\n     {myblue,line width=1.5pt,fill=myblue!70,fill opacity=0.9},\n     {mygreen,line width=1.5pt,fill=mygreen!70,fill opacity=0.4},\n     {myorange,line width=1.5pt,fill=myorange!20,fill opacity=0.4},\n     {myred,line width=1.5pt,fill=myred!70,fill opacity=0.4},\n  },\n    after end axis/.code={\n      % manua y-tick labele on 50°\n      \\foreach \\R in {1,3,5,7,9}{\n      \\pgfmathtruncatemacro{\\newR}{\\R + 0.5} %\n        \\node[\n          font=\\footnotesize\\usefont{T1}{phv}{m}{n},\n          anchor=base\n        ]\n        at (axis cs:50,\\newR) {\\R};\n      }\n    },\n    legend image code/.code={\n      % rectangle in Legend\n      \\draw[fill=#1,draw=none,fill opacity=1]\n        (0pt,-2pt) rectangle (4mm,3pt);\n    }\n    }}\n %left graph\n\\begin{scope}[local bounding box=GR1,shift={(0,0)}]\n\\begin{polaraxis}[myaxis,\n    xticklabels={Compute\\\\ Power, Latency, Scalability,Energy Consumption},\n]\n% Cloud ML\n\\addplot+[]  coordinates {(0,10) (90,2) (180,10) (270,3) (360,10)};\n% Edge ML\n\\addplot+[] coordinates {(0,8) (90,7) (180,8) (270,5) (360,8)};\n% Mobile ML\n\\addplot+[] coordinates {(0,6) (90,8) (180,7) (270,7) (360,6)};\n% TinyML\n\\addplot+[]  coordinates {(0,3) (90,9) (180,5) (270,10) (360,3)};\n\\legend{Cloud ML, Edge ML, Mobile ML, TinyML}\n\\addplot[draw=myblue,line width=1.5pt]   coordinates {(0,10) (90,2) (180,10) (270,3) (360,10)};\n\\addplot[draw=mygreen,line width=1.5pt]  coordinates {(0,8) (90,7) (180,8) (270,5) (360,8)};\n\n\\end{polaraxis}\n\\end{scope}\n\\node[below=2mm of GR1,xshift=-5mm]{\\large a)};\n %right graph\n\\begin{scope}[local bounding box=GR2,shift={(10,0)}]\n\\begin{polaraxis}[myaxis,\nxticklabels={Connectivity\\\\ Dependency, Data Privacy, Real-time\\\\ Processing,Offline Capability},\n]\n% Cloud ML\n\\addplot+[]  coordinates {(0,2) (90,3) (180,2) (270,2) (360,2)};\n% Edge ML\n\\addplot+[] coordinates {(0,7) (90,7) (180,8) (270,6) (360,7)};\n% Mobile ML\n\\addplot+[] coordinates {(0,8) (90,9) (180,7) (270,8) (360,8)};\n% TinyML\n\\addplot+[]  coordinates {(0,10) (90,10) (180,10) (270,10) (360,10)};\n%\\legend{Cloud ML, Edge ML, Mobile ML, TinyML}\n\\addplot[draw=myblue,line width=1.5pt]  coordinates {(0,2) (90,3) (180,2) (270,2) (360,2)};\n\\addplot[draw=mygreen,line width=1.5pt] coordinates {(0,7) (90,7) (180,8) (270,6) (360,7)};\n\\end{polaraxis}\n\\end{scope}\n\\node[below=2mm of GR2]{\\large b)};\n\\end{tikzpicture}\n```\n**ML System Trade-Offs**: Radar plots quantify performance and operational characteristics across cloud, edge, mobile, and TinyML paradigms, revealing inherent trade-offs between compute power, latency, energy consumption, and scalability. These visualizations enable informed selection of the most suitable deployment approach based on application-specific constraints and priorities.\n:::\n\nPlot b) emphasizes operational dimensions where TinyML excels (privacy, connectivity independence, offline capability) versus Cloud ML's dependency on centralized infrastructure and constant connectivity.\n\nDevelopment complexity varies inversely with hardware capability: Cloud and TinyML require deep expertise (cloud infrastructure and embedded systems respectively), while Mobile and Edge leverage more accessible SDKs and tooling. Cost structures show similar inversion: Cloud incurs ongoing operational expenses ($1000s+/month), Edge requires moderate upfront investment ($100s-1000s), Mobile leverages existing devices ($0-10s), and TinyML minimizes hardware costs ($1-10s) while demanding higher development investment.\n\nUnderstanding these trade-offs proves crucial for selecting appropriate deployment strategies that align application requirements with paradigm capabilities.\n\nA critical pitfall in deployment selection involves choosing paradigms based solely on model accuracy metrics without considering system-level constraints. Teams often select deployment strategies by comparing model accuracy in isolation, overlooking critical system requirements that determine real-world viability. A cloud-deployed model achieving 99% accuracy becomes useless for autonomous emergency braking if network latency exceeds reaction time requirements. Similarly, a sophisticated edge model that drains a mobile device's battery in minutes fails despite superior accuracy. Successful deployment requires evaluating multiple dimensions simultaneously: latency requirements, power budgets, network reliability, data privacy regulations, and total cost of ownership. Establish these constraints before model development to avoid expensive architectural pivots late in the project.\n\n## Decision Framework for Deployment Selection {#sec-ml-systems-decision-framework-deployment-selection-f748}\n\nSelecting the appropriate deployment paradigm requires systematic evaluation of application constraints rather than organizational biases or technology trends. @fig-mlsys-playbook-flowchart provides a hierarchical decision framework that filters options through critical requirements: privacy (can data leave the device?), latency (sub-10ms response needed?), computational demands (heavy processing required?), and cost constraints (budget limitations?). This structured approach ensures deployment decisions emerge from application requirements, grounded in the physical constraints (@sec-ml-systems-deployment-paradigm-foundations-0c17) and quantitative comparisons (@sec-ml-systems-comparative-analysis-selection-framework-832e) established earlier.\n\n::: {#fig-mlsys-playbook-flowchart fig-env=\"figure\" fig-pos=\"!t\"}\n```{.tikz}\n\\resizebox{.7\\textwidth}{!}{%\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n},line width=0.75pt]\n\\tikzset{\n  Line/.style={line width=1.0pt,black!50,text=black},\n  Box/.style={inner xsep=2pt,\n    draw=GreenLine, line width=0.65pt,\n    fill=GreenL,\n    text width=25mm,align=flush center,\n    minimum width=25mm, minimum height=9mm\n  },\n  Box1/.style={inner xsep=2pt,\n    node distance=0.5,\n    draw=BlueLine, line width=0.65pt,\n    fill=BlueL,\n    text width=33mm,align=flush center,\n    minimum width=33mm, minimum height=9mm\n  },\n  Text/.style={inner xsep=2pt,\n    draw=none, line width=0.75pt,\n    fill=TextColor,\n    font=\\footnotesize\\usefont{T1}{phv}{m}{n},\n    align=flush center,\n    minimum width=7mm, minimum height=5mm\n  },\n}\n%\n\\begin{scope}\n\\node[Box, rounded corners=12pt,fill=magenta!20](B1){Start};\n\\node[Box1,below=of B1](B2){Is privacy critical?};\n\\node[Box,below left=0.1 and 1 of B2](B3){Cloud Processing Allowed};\n\\node[Box,below right=0.1 and 1 of B2](B4){Local Processing Preferred};\n\\draw[Line,-latex](B1)--(B2);\n\\draw[Line,-latex](B2)-|node[Text,pos=0.2]{No}(B3);\n\\draw[Line,-latex](B2)-|node[Text,pos=0.2]{Yes}(B4);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=3mm,yshift=-1mm,\n       fill=BackColor,fit=(B1)(B3)(B4),line width=0.75pt](BB){};\n\\node[below=11pt of BB.north east,anchor=east]{Layer: Privacy};\n\\end{scope}\n%\n\\begin{scope}[shift={(0,-4.6)}]\n\\node[Box1](2B1){Is low latency required ($<$10 ms)?};\n\\node[Box,below left=0.1 and 1 of 2B1](2B2){Latency Tolerant};\n\\node[Box,below right=0.1 and 1 of 2B1](2B3){Tiny or Edge ML};\n\\draw[Line,-latex](2B1)-|node[Text,pos=0.2]{No}(2B2);\n\\draw[Line,-latex](2B1)-|node[Text,pos=0.2]{Yes}(2B3);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=4mm,yshift=0mm,\n       fill=BackColor,fit=(2B1)(2B2)(2B3),line width=0.75pt](BB1){};\n\\node[below=11pt of BB1.north east,anchor=east]{Layer: Performance};\n\\end{scope}\n\\draw[Line,-latex](B3)--++(270:1.1)-|(2B1.110);\n\\draw[Line,-latex](B4)--++(270:1.1)-|(2B1.70);\n%\n\\begin{scope}[shift={(0,-8.0)}]\n\\node[Box1](3B1){Does the model require significant compute?};\n\\node[Box,below left=0.1 and 1 of 3B1](3B2){Heavy Compute};\n\\node[Box,below right=0.1 and 1 of 3B1](3B3){Lightweight Processing};\n\\draw[Line,-latex](3B1)-|node[Text,pos=0.2]{Yes}(3B2);\n\\draw[Line,-latex](3B1)-|node[Text,pos=0.2]{No}(3B3);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=1mm,\n       fill=BackColor,fit=(3B1)(3B2)(3B3),line width=0.75pt](BB2){};\n\\node[below=11pt of BB2.north east,anchor=east]{Layer: Compute Needs};\n\\end{scope}\n\\draw[Line,-latex](2B2)--++(270:1.1)-|(3B1.110);\n\\draw[Line,-latex](2B3)--++(270:1.1)-|(3B1.70);\n%4\n\\begin{scope}[shift={(0,-11.4)}]\n\\node[Box1](4B1){Are there strict cost constraints?};\n\\node[Box,below left=0.1 and 1 of 4B1](4B2){Flexible Budget};\n\\node[Box,below right=0.1 and 1 of 4B1](4B3){Low-Cost Options};\n\\draw[Line,-latex](4B1)-|node[Text,pos=0.2]{No}(4B2);\n\\draw[Line,-latex](4B1)-|node[Text,pos=0.2]{Yes}(4B3);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=4mm,yshift=2mm,\n       fill=BackColor,fit=(4B1)(4B2)(4B3),line width=0.75pt](BB3){};\n\\node[below=11pt of  BB3.north east,anchor=east]{Layer: Cost};\n\\end{scope}\n\\draw[Line,-latex](3B2)--++(270:1.1)-|(4B1.110);\n\\draw[Line,-latex](3B3)--++(270:1.1)-|(4B1.70);\n%5\n\\begin{scope}[shift={(-0.45,-14.0)},anchor=north east]\n\\node[Box,fill=magenta!20,rounded corners=12pt,text width=18mm,\n       minimum width=17mm](5B1){Cloud ML};\n\\node[Box,node distance=1.0,fill=magenta!20,rounded corners=12pt,left=of 5B1,text width=18mm,\n       minimum width=17mm](5B2){Edge ML};\n\\node[Box,node distance=1.0,fill=magenta!20, rounded corners=12pt,right=of 5B1,text width=18mm,\n       minimum width=17mm](5B3){Mobile ML};\n\\node[Box,node distance=1.0,fill=magenta!20, rounded corners=12pt,right=of 5B3,text width=18mm,\n       minimum width=17mm](5B4){TinyML};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=-1mm,\n       fill=BackColor,fit=(5B1)(5B2)(5B4),line width=0.75pt](BB4){};\n\\node[above=8pt of BB4.south east,anchor=east]{Layer: Deployment Options};\n\\end{scope}\n\\draw[Line,-latex](4B3)-|(5B3);\n\\draw[Line,-latex](4B3)--++(270:0.92)-|(5B4);\n\\draw[Line,-latex](4B2)--++(270:0.92)-|(5B1);\n\\draw[Line,-latex](3B2.west)--++(180:0.5)|-(5B2);\n\\end{tikzpicture}}\n```\n**Deployment Decision Logic**: This flowchart guides selection of an appropriate machine learning deployment paradigm by systematically evaluating privacy requirements and processing constraints, ultimately balancing performance, cost, and data security. Navigating the decision tree helps practitioners determine whether cloud, edge, mobile, or tiny machine learning best suits a given application.\n:::\n\nThe framework evaluates four critical decision layers sequentially. Privacy constraints form the first filter, determining whether data can be transmitted externally. Applications handling sensitive data under GDPR, HIPAA, or proprietary restrictions mandate local processing, immediately eliminating cloud-only deployments. Latency requirements establish the second constraint through response time budgets: applications requiring sub-10ms response times cannot use cloud processing, as physics-imposed network delays alone exceed this threshold. Computational demands form the third evaluation layer, assessing whether applications require high-performance infrastructure that only cloud or edge systems provide, or whether they can operate within the resource constraints of mobile or tiny devices. Cost considerations complete the framework by balancing capital expenditure, operational expenses, and energy efficiency across expected deployment lifetimes.\n\nTechnical constraints alone prove insufficient for deployment decisions. Organizational factors critically shape success by determining whether teams possess the capabilities to implement and maintain chosen paradigms. Team expertise must align with paradigm requirements: Cloud ML demands distributed systems knowledge, Edge ML requires device management capabilities, Mobile ML needs platform-specific optimization skills, and TinyML requires embedded systems expertise. Organizations lacking appropriate skills face extended development timelines and ongoing maintenance challenges that undermine technical advantages. Monitoring and maintenance capabilities similarly determine viability at scale: edge deployments require distributed device orchestration, while TinyML demands specialized firmware management that many organizations lack. Cost structures further complicate decisions through their temporal patterns: Cloud incurs recurring operational expenses favorable for unpredictable workloads, Edge requires substantial upfront investment offset by lower ongoing costs, Mobile leverages user-provided devices to minimize infrastructure expenses, and TinyML minimizes hardware and connectivity costs while demanding significant development investment.\n\nSuccessful deployment emerges from balancing technical optimization against organizational capability. Paradigm selection represents systems engineering challenges that extend well beyond pure technical requirements, encompassing team skills, operational capacity, and economic constraints. These decisions remain constrained by fundamental scaling laws explored in @sec-efficient-ai-ai-scaling-laws-a043, with operational aspects detailed in @sec-ml-operations and benchmarking approaches covered in @sec-benchmarking-ai.\n\n## Fallacies and Pitfalls {#sec-ml-systems-fallacies-pitfalls-8074}\n\nUnderstanding deployment paradigms requires recognizing common misconceptions that can lead to poor architectural decisions. These fallacies often stem from oversimplified thinking about the core trade-offs governing ML systems design.\n\n**Fallacy: \"One Paradigm Fits All\"** - The most pervasive misconception assumes that one deployment approach can solve all ML problems. Teams often standardize on cloud, edge, or mobile solutions without considering application-specific constraints. This fallacy ignores the physics-imposed boundaries discussed in @sec-ml-systems-deployment-paradigm-foundations-0c17. Real-time robotics cannot tolerate cloud latency, while complex language models exceed tiny device capabilities. Effective systems often require hybrid architectures that leverage multiple paradigms strategically.\n\n**Fallacy: \"Edge Computing Always Reduces Latency\"** - Many practitioners assume edge deployment automatically improves response times. However, edge systems introduce processing delays, load balancing overhead, and potential network hops that can exceed direct cloud connections. A poorly designed edge deployment with insufficient local compute power may exhibit worse latency than optimized cloud services. Edge benefits emerge only when local processing time plus reduced network distance outweighs the infrastructure complexity costs.\n\n**Fallacy: \"Mobile Devices Can Handle Any Workload with Optimization\"** - This misconception underestimates the fundamental constraints imposed by battery life and thermal management. Teams often assume that model compression techniques can arbitrarily reduce resource requirements while maintaining performance. However, mobile devices face hard physical limits: battery capacity scales with volume while computational demand scales with model complexity. Some applications require computational resources that no amount of optimization can fit within mobile power budgets.\n\n**Fallacy: \"TinyML is Just Smaller Mobile ML\"** - This fallacy misunderstands the qualitative differences between resource-constrained paradigms. TinyML operates under constraints so severe that different algorithmic approaches become necessary. The microcontroller environments impose memory limitations measured in kilobytes, not megabytes, requiring specialized techniques like quantization beyond what mobile optimization employs. Applications suitable for tiny ML represent a fundamentally different problem class, not simply scaled-down versions of mobile applications.\n\n**Fallacy: \"Cost Optimization Equals Resource Minimization\"** - Teams frequently assume that minimizing computational resources automatically reduces costs. This perspective ignores operational complexity, development time, and infrastructure overhead. Cloud deployments may consume more compute resources while providing lower total cost of ownership through reduced maintenance, automatic scaling, and shared infrastructure. The optimal cost solution often involves accepting higher per-unit resource consumption in exchange for simplified operations and faster development cycles.\n\n## Summary {#sec-ml-systems-summary-473b}\n\nThis chapter analyzed the diverse landscape of machine learning systems, revealing how deployment context directly shapes every aspect of system design. From cloud environments with vast computational resources to tiny devices operating under extreme constraints, each paradigm presents unique opportunities and challenges that directly influence architectural decisions, algorithmic choices, and performance trade-offs. The spectrum from cloud to edge to mobile to tiny ML represents more than just different scales of computation; it reflects a significant evolution in how we distribute intelligence across computing infrastructure.\n\nThe evolution from centralized cloud systems to distributed edge and mobile deployments shows how resource constraints drive innovation rather than simply limiting capabilities. Each paradigm emerged to address specific limitations of its predecessors: Cloud ML leverages centralized power for complex processing but must navigate latency and privacy concerns. Edge ML brings computation closer to data sources, reducing latency while introducing intermediate resource constraints. Mobile ML extends these capabilities to personal devices, balancing user experience with battery life and thermal management. TinyML pushes the boundaries of what's possible with minimal resources, enabling ubiquitous sensing and intelligence in previously impossible deployment contexts. This evolution showcases how thoughtful system design can transform limitations into opportunities for specialized optimization.\n\n::: {.callout-important title=\"Key Takeaways\"}\n* Deployment context drives architectural decisions more than algorithmic preferences\n* Resource constraints create opportunities for innovation, not just limitations\n* Hybrid approaches are emerging as the future of ML system design\n* Privacy and latency considerations increasingly favor distributed intelligence\n:::\n\nThese paradigms reflect an ongoing shift toward systems that are finely tuned to specific operational requirements, moving beyond one-size-fits-all approaches toward context-aware system design. As these deployment models mature, hybrid architectures emerge that combine their strengths: cloud-based training paired with edge inference, federated learning across mobile devices, and hierarchical processing that optimizes across the entire spectrum. This evolution demonstrates how deployment contexts will continue driving innovation in system architecture, training methodologies, and optimization techniques, creating more sophisticated and context-aware ML systems.\n\nYet deployment context represents only one dimension of system design. The algorithms executing within these environments equally influence resource requirements, computational patterns, and optimization strategies. A neural network requiring gigabytes of memory and billions of floating-point operations demands fundamentally different deployment approaches than a decision tree requiring kilobytes and integer comparisons. The next chapter (@sec-dl-primer) examines the mathematical foundations of neural networks, revealing why certain deployment paradigms suit specific algorithms and how algorithmic choices propagate through the entire system stack.\n","srcMarkdownNoYaml":"\n\n# ML Systems {#sec-ml-systems}\n\n::: {layout-narrow}\n::: {.column-margin}\n*DALL·E 3 Prompt: Illustration in a rectangular format depicting the merger of embedded systems with Embedded AI. The left half of the image portrays traditional embedded systems, including microcontrollers and processors, detailed and precise. The right half showcases the world of artificial intelligence, with abstract representations of machine learning models, neurons, and data flow. The two halves are distinctly separated, emphasizing the individual significance of embedded tech and AI, but they come together in harmony at the center.*\n:::\n\n\\noindent\n![](images/png/cover_ml_systems.png)\n\n:::\n\n## Purpose {.unnumbered}\n\n_How do the environments where machine learning operates shape the nature of these systems, and what drives their widespread deployment across computing platforms?_\n\nMachine learning systems must adapt to radically different computational environments, each imposing distinct constraints and opportunities. Cloud deployments leverage massive computational resources but face network latency, while mobile devices offer user proximity but operate under severe power limitations. Embedded systems minimize latency through local processing but constrain model complexity, and tiny devices enable widespread sensing while restricting memory to kilobytes. These deployment contexts fundamentally determine system architecture, algorithmic choices, and performance trade-offs. Understanding environment-specific requirements establishes the foundation for engineering decisions in machine learning systems. This knowledge enables engineers to select appropriate deployment paradigms and design architectures that balance performance, efficiency, and practicality across computing platforms.\n\n::: {.callout-tip title=\"Learning Objectives\"}\n\n- Explain how physical constraints (speed of light, power wall, memory wall) create hard boundaries that necessitate the deployment spectrum from cloud to TinyML\n\n- Distinguish and compare the four deployment paradigms (Cloud ML, Edge ML, Mobile ML, TinyML) using quantitative metrics across compute power, memory, latency, power consumption, privacy, and connectivity dimensions\n\n- Apply the systematic deployment decision framework to select appropriate paradigms by evaluating privacy requirements, latency constraints, computational demands, and cost considerations\n\n- Analyze hybrid ML integration patterns (train-serve split, hierarchical processing, federated learning) to determine which combinations address specific system requirements\n\n- Critique common deployment fallacies and evaluate real-world production ML systems to assess whether architectural decisions align with stated requirements\n\n- Design hybrid ML architectures that integrate multiple deployment paradigms while applying universal design principles for data pipelines, resource management, and system architecture\n\n:::\n\n## Deployment Paradigm Framework {#sec-ml-systems-deployment-paradigm-framework-d434}\n\nThe preceding introduction established machine learning systems as comprising three fundamental components: data, algorithms, and computing infrastructure. While this triadic framework provides a theoretical foundation, practical implementation introduces a critical dimension that governs system design: the deployment environment. This chapter analyzes how computational context shapes architectural decisions in machine learning systems, establishing the basis for deployment-driven design principles.\n\nContemporary machine learning applications demonstrate remarkable architectural diversity driven by deployment constraints. Consider the domain of computer vision[^fn-computer-vision]: a convolutional neural network trained for image classification manifests as distinctly different systems when deployed across environments. In cloud-based medical imaging, the system exploits virtually unlimited computational resources to implement ensemble methods[^fn-ensemble-methods] and sophisticated preprocessing pipelines. When deployed on mobile devices for real-time object detection, the same fundamental algorithm undergoes architectural transformation to satisfy stringent latency requirements while preserving acceptable accuracy. Factory automation applications further constrain the design space, prioritizing power efficiency and deterministic response times over model complexity. These variations represent distinctly different architectural solutions to the same computational problem, shaped by environmental constraints rather than algorithmic considerations.\n\nThis chapter presents a systematic taxonomy of machine learning deployment paradigms, analyzing four primary categories that span the computational spectrum from cloud data centers to microcontroller-based embedded systems. Each paradigm emerges from distinct operational requirements: computational resource availability, power consumption constraints, latency specifications, privacy requirements, and network connectivity assumptions. The theoretical framework developed here provides the analytical foundation for making informed architectural decisions in production machine learning systems.\n\nModern deployment strategies transcend traditional dichotomies between centralized and distributed processing. Contemporary applications increasingly implement hybrid architectures that allocate computational tasks across multiple paradigms to optimize system-wide performance. Voice recognition systems exemplify this architectural sophistication: wake-word detection operates on ultra-low-power embedded processors to enable continuous monitoring, speech-to-text conversion utilizes mobile processors to maintain privacy and minimize latency, while semantic understanding leverages cloud infrastructure for complex natural language processing. This multi-paradigm approach reflects the engineering reality that optimal machine learning systems require architectural heterogeneity.\n\nThe deployment paradigm space exhibits clear dimensional structure. Cloud machine learning maximizes computational capabilities while accepting network-induced latency constraints. Edge computing positions inference computation proximate to data sources when latency requirements preclude cloud-based processing. Mobile machine learning extends computational capabilities to personal devices where user proximity and offline operation represent critical requirements. Tiny machine learning enables distributed intelligence on severely resource-constrained devices where energy efficiency supersedes computational sophistication.\n\nThrough comprehensive analysis of these deployment paradigms, this chapter develops the systems engineering perspective necessary for designing machine learning architectures that effectively balance algorithmic capabilities with operational constraints. This systems-oriented approach provides essential methodological foundations for translating theoretical machine learning advances into production systems that demonstrate reliable performance at scale. The analysis culminates with paradigm integration strategies for hybrid architectures and identification of core design principles that govern all machine learning deployment contexts.\n\n@fig-cloud-edge-TinyML-comparison illustrates how computational resources, latency requirements, and deployment constraints create this deployment spectrum. While @sec-ai-frameworks explores the software tools that enable ML across these paradigms, and @sec-ai-acceleration examines the specialized hardware that powers them, this chapter focuses on the fundamental deployment trade-offs that govern system architecture decisions. The subsequent analysis addresses each paradigm systematically, building toward an understanding of how they integrate into modern ML systems.\n\n## The Deployment Spectrum {#sec-ml-systems-deployment-spectrum-38d0}\n\nThe deployment spectrum from cloud to embedded systems exists not by choice, but by necessity imposed by physical laws governing computing systems. These immutable constraints create hard boundaries that no engineering advancement can overcome, forcing the evolution of specialized deployment paradigms optimized for different operational contexts.\n\nThe **speed of light** establishes absolute minimum latencies that constrain real-time applications. Light traveling through optical fiber covers approximately 200,000 kilometers per second, creating a theoretical minimum of approximately 40ms round-trip time for the roughly 4,000 km between California and Virginia. However, actual cloud service latency is dominated by software overhead: TCP connection setup (1-3 round trips), serialization and deserialization (1-10ms depending on payload), load balancer routing, and request queuing under load. Well-engineered services within a single region achieve 1-5ms median latency with 50-200ms tail latencies; cross-region requests typically see 50-150ms median latency. The physics-imposed floor matters primarily for real-time applications where even optimized cloud paths cannot meet sub-10ms requirements, such as autonomous vehicle emergency braking or industrial robotics precision control.\n\nThe **power wall**, resulting from the breakdown of Dennard scaling around 2005, transformed computing economics. Transistor shrinking no longer reduces power density, meaning chips cannot be made arbitrarily fast without proportional increases in power consumption and heat generation. This constraint forces trade-offs between computational performance and energy efficiency, directly driving the need for specialized low-power architectures in mobile and embedded systems. Data centers now dedicate 30-40% of their power budget to cooling, while mobile devices must implement thermal throttling to prevent component damage.\n\nThe **memory wall** represents the widening gap between processor speed and memory bandwidth. While computational capacity can scale through additional processing units, memory bandwidth faces fundamental limits from pin count, package power delivery, and signaling physics. Traditional DRAM achieves 50-100 GB/s per channel, while High Bandwidth Memory (HBM) provides 1-3 TB/s through 3D stacking and wide interfaces but at significant cost and power premium. This creates a progressively worsening bottleneck where processors become data-starved, spending more time waiting for memory transfers than performing calculations. Large machine learning models exacerbate this problem, requiring parameter datasets that exceed available memory bandwidth by orders of magnitude.\n\n**Economics of scale** create significant cost-per-unit differences that justify different deployment approaches. A cloud server costing $50,000 can support thousands of users through virtualization, achieving per-user costs under $50. However, applications requiring guaranteed response times or private data processing cannot share resources, eliminating this economic advantage. Meanwhile, embedded processors costing $5-50 enable deployment at billions of endpoints where individual cloud connections would be economically infeasible.\n\nThese physical constraints are not temporary engineering challenges but permanent limitations that shape the computational landscape. Understanding these boundaries explains why the deployment spectrum exists and provides the theoretical foundation for making informed architectural decisions in machine learning systems.\n\n::: {#fig-cloud-edge-TinyML-comparison fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[line cap=round,line join=round,font=\\usefont{T1}{phv}{m}{n}\\small]\n  % Parameters\n  \\def\\angle{10}        % angle\n  \\def\\length{18}       % Lengths (cm)\n  \\def\\npoints{5}       % number of points\n  \\def\\startfrac{0.13}  % start (e.g.. 0.2 = 20%)\n  \\def\\endfrac{0.87}    % end (e.g.. 0.8 = 80%)\n\n \\draw[line width=1pt, black!70] (0,0) -- ({\\length*cos(\\angle)}, {\\length*sin(\\angle)})coordinate(end);\n %\n  \\foreach \\i in {0,1,...,\\numexpr\\npoints-1} {\n    \\pgfmathsetmacro{\\t}{\\startfrac + (\\endfrac - \\startfrac)*\\i/(\\npoints-1)}\n\\coordinate(T\\i)at({\\t*\\length*cos(\\angle)}, {\\t*\\length*sin(\\angle)});\n  }\n\n\\tikzset {\npics/gatewey/.style = {\n        code = {\n\\colorlet{red}{white}\n\\begin{scope}[local bounding box=GAT,scale=0.9, every node/.append style={transform shape}]\n\\def\\rI{4mm}\n\\def\\rII{2.8mm}\n\\def\\rIII{1.6mm}\n\\draw[red,line width=1.25pt](0,0)--(0,0.38)--(1.2,0.38)--(1.2,0)--cycle;\n\\draw[red,line width=1.5pt](0.6,0.4)--(0.6,0.9);\n\n\\draw[red, line width=1.5pt] (0.6,0.9)+(60:\\rI) arc[start angle=60, end angle=-60, radius=\\rI];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(50:\\rII) arc[start angle=50, end angle=-50, radius=\\rII];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(30:\\rIII) arc[start angle=30, end angle=-30, radius=\\rIII];\n%\n \\draw[red, line width=1.5pt] (0.6,0.9)+(120:\\rI) arc[start angle=120, end angle=240, radius=\\rI];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(130:\\rII) arc[start angle=130, end angle=230, radius=\\rII];\n\\draw[red, line width=1.5pt] (0.6,0.9)+(150:\\rIII) arc[start angle=150, end angle=210, radius=\\rIII];\n\\fill[red](0.6,0.9)circle (1.5pt);\n\n\\foreach\\i in{0.15,0.3,0.45,0.6}{\n\\fill[red](\\i,0.19)circle (1.5pt);\n}\n\n\\fill[red](1,0.19)circle (2pt);\n\\end{scope}\n}}}\n\n\\tikzset {\npics/cloud/.style = {\n        code = {\n\\colorlet{red}{white}\n\\begin{scope}[local bounding box=CLO,scale=0.6, every node/.append style={transform shape}]\n\\draw[red,line width=1.5pt](0,0)to[out=170,in=180,distance=11](0.1,0.61)\nto[out=90,in=105,distance=17](1.07,0.71)\nto[out=20,in=75,distance=7](1.48,0.36)\nto[out=350,in=0,distance=7](1.48,0)--(0,0);\n\\draw[red,line width=1.5pt](0.27,0.71)to[bend left=25](0.49,0.96);\n\\draw[red,line width=1.5pt](0.67,1.21)to[out=55,in=90,distance=13](1.5,0.96)\nto[out=360,in=30,distance=9](1.68,0.42);\n\\end{scope}\n}}}\n\n\\tikzset {\n  pics/server/.style = {\n    code = {\n      \\colorlet{red}{white}\n      \\begin{scope}[anchor=center, transform shape,scale=0.8, every node/.append style={transform shape}]\n        \\draw[red,line width=1.25pt,fill=white](-0.55,-0.5) rectangle (0.55,0.5);\n\\foreach \\i in {-0.25,0,0.25} {\n                \\draw[cyan,line width=1.25pt]( -0.55,\\i) -- (0.55, \\i);\n}\n        \\foreach \\i in {-0.375, -0.125, 0.125, 0.375} {\n          \\draw[cyan!50!black!90,line width=1.25pt](-0.45,\\i)--(0,\\i);\n          \\fill[cyan!50!black!90](0.35,\\i) circle (1.5pt);\n        }\n\n\\draw[red,line width=1.75pt](0,-0.53) |- (-0.55,-0.7);\n        \\draw[red,line width=1.75pt](0,-0.53) |- (0.55,-0.7);\n      \\end{scope}\n    }\n  }\n}\n\n\\tikzset {\npics/cpu/.style = {\n        code = {\n\\definecolor{CPU}{RGB}{0,120,176}\n\\colorlet{CPU}{white}\n\\begin{scope}[local bounding box = CPU,scale=0.33, every node/.append style={transform shape}]\n\\node[fill=CPU,minimum width=66, minimum height=66,\n            rounded corners=2,outer sep=2pt] (C1) {};\n\\node[fill=violet,minimum width=54, minimum height=54] (C2) {};\n%\\node[fill=CPU!40,minimum width=44, minimum height=44] (C3) {CPU};\n\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=4, minimum height=15,\n           inner sep=0pt,anchor=south](GO\\y)at($(C1.north west)!\\x!(C1.north east)$){};\n}\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=4, minimum height=15,\n           inner sep=0pt,anchor=north](DO\\y)at($(C1.south west)!\\x!(C1.south east)$){};\n}\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=15, minimum height=4,\n           inner sep=0pt,anchor=east](LE\\y)at($(C1.north west)!\\x!(C1.south west)$){};\n}\n\\foreach \\x/\\y in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{\n\\node[fill=CPU,minimum width=15, minimum height=4,\n           inner sep=0pt,anchor=west](DE\\y)at($(C1.north east)!\\x!(C1.south east)$){};\n}\n\\end{scope}\n    }  }}\n\n\\tikzset {\npics/mobile/.style = {\n        code = {\n\\colorlet{red}{white}\n\\begin{scope}[local bounding box=MOB,scale=0.4, every node/.append style={transform shape}]\n\\node[rectangle,draw=red,minimum height=94,minimum width=47,\n            rounded corners=6,thick,fill=white](R1){};\n\\node[rectangle,draw=red,minimum height=67,minimum width=38,thick,fill=green!69!black!90](R2){};\n\\node[circle,minimum size=8,below= 2pt of R2,inner sep=0pt,thick,fill=green!69!black!90]{};\n\\node[rectangle,fill=green!69!black!90,minimum height=2,minimum width=20,above= 4pt of R2,inner sep=0pt,thick]{};\n%\n \\end{scope}\n     }  }}\n\n\\node[draw=none,fill=red,circle,minimum size=20mm](GA)at(T2){};\n\\pic[shift={(-0.55,-0.5)}] at (T2) {gatewey};\n\\node[above=0 of GA]{Gateway};\n\\node[draw=none,fill=violet,circle,minimum size=20mm](CP)at(T0){};\n\\pic[shift={(0,-0)}] at (T0) {cpu};\n\\node[above=0 of CP,align=center]{Ultra Low Powered\\\\Devices and Sensors};\n\\node[draw=none,fill=green!70,,circle,minimum size=20mm](MO)at(T1){};\n \\pic[shift={(0,0)}] at (T1) {mobile};\n \\node[above=0 of MO,align=center]{Intelligent\\\\Device};\n\\node[draw=none,fill=cyan,circle,minimum size=20mm](SE)at(T3){};\n\\pic[shift={(-0.03,0.1)}] at (T3) {server};\n \\node[above=0 of SE,align=center]{On Premise\\\\Servers};\n\\node[draw=none,fill=brown,circle,minimum size=20mm](CL)at(T4){};\n\\pic[shift={(-0.48,-0.35)}] at (T4) {cloud};\n \\node[above=0 of CL,align=center]{Cloud};\n%\n\\path (T0) -- (T1) coordinate[pos=0.5] (M1);\n\\path (0,0) -- (T0) coordinate[pos=0.25] (M0);\n\\path (T3) -- (T4) coordinate[pos=0.5] (M2);\n\\path (T4) -- (end) coordinate[pos=0.75] (M3);\n\n\\foreach \\x in {0,1,2,3}{\n\\fill[OliveLine](M\\x)circle (2.5pt);\n}\n\n\\path[red](M0)--++(270:1.6)coordinate(LL1)-|coordinate(LL2)(M2);\n\\path[red](M0)--++(270:1.1)coordinate(L1)-|coordinate(L2)(M1);\n\\path[red](M0)--++(270:1.1)-|coordinate(L3)(M2);\n\\path[red](M0)--++(270:1.1)-|coordinate(L4)(M3);\n%\n\\draw[black!70,thick](M0)--(LL1);\n\\draw[black!70,thick](M1)--(L2);\n\\draw[black!70,thick](M3)--(L4);\n\\draw[black!70,thick](M2)--(LL2);\n\\draw[latex-latex,line width=1pt,draw=black!60](L1)--node[red,fill=white]{TinyML}(L2);\n\\draw[latex-latex,line width=1pt,draw=black!60](L3)--node[fill=white]{Cloud AI}(L4);\n\\draw[latex-latex,line width=1pt,draw=black!60]([yshift=4pt]LL1)--node[fill=white,text=black]{Edge AI}([yshift=4pt]LL2);\n\\foreach \\x in {0,1,2,3}{\n\\fill[OliveLine](M\\x)circle (2.5pt);\n}\n%\n\\path[](M0)--++(90:4.2)-|node[pos=0.25]{\\textbf{The Distributed Intelligence Spectrum}}(M3);\n\\end{tikzpicture}\n\n```\n**Distributed Intelligence Spectrum**: Machine learning system design involves trade-offs between computational resources, latency, and connectivity, resulting in a spectrum of deployment options ranging from centralized cloud infrastructure to resource-constrained edge and TinyML devices. This figure maps these options, highlighting how each approach balances processing location with device capability and network dependence. Source: [@abiresearch2024tinyml].\n:::\n\n### Deployment Paradigm Foundations {#sec-ml-systems-deployment-paradigm-foundations-0c17}\n\nThe deployment spectrum illustrated in @fig-cloud-edge-TinyML-comparison exists not through design preference, but from necessity driven by immutable physical and hardware constraints. Understanding these limitations reveals why ML systems cannot adopt uniform approaches and must instead span the complete deployment spectrum from cloud to embedded devices.\n\n@sec-introduction established the three foundational components of ML systems (data, algorithms, and infrastructure) as a unified framework that these deployment paradigms now optimize differently based on physical constraints. Cloud ML prioritizes algorithmic complexity through abundant infrastructure, while Mobile ML emphasizes data locality with constrained infrastructure, and TinyML maximizes algorithmic efficiency under extreme infrastructure limitations.\n\nThe most critical bottleneck in modern computing stems from memory bandwidth scaling differently than computational capacity. While compute power scales linearly through additional processing units, memory bandwidth scales approximately as the square root of chip area due to physical routing constraints. This creates a progressively worsening bottleneck where processors become data-starved. In practice, this manifests as ML models spending more time awaiting memory transfers than performing calculations, particularly problematic for large models[^fn-memory-bottleneck] that require more data than can be efficiently transferred.\n\n[^fn-memory-bottleneck]: **Memory Bottleneck**: When the rate of data transfer from memory to processor becomes the limiting factor in computation. Large models require so many parameters that memory bandwidth, rather than computational capacity, determines performance.\n\nCompounding these memory challenges, the breakdown of Dennard scaling[^fn-dennard-scaling] transformed computing constraints around 2005, when transistor shrinking stopped reducing power density. Power dissipation per unit area now remains constant or increases with each technology generation, creating hard limits on computational density. For mobile devices, this translates to thermal throttling that reduces performance when sustained computation generates excessive heat. Data centers face similar constraints at scale, requiring extensive cooling infrastructure that can consume 30-40% of total power budget. These power density limits directly drive the need for specialized low-power architectures in mobile and embedded contexts, and explain why edge deployment becomes necessary when power budgets are constrained.\n\n[^fn-dennard-scaling]: **Dennard Scaling**: Named after Robert Dennard (IBM, 1974), the observation that as transistors became smaller, they could operate at higher frequencies while consuming the same power density. This scaling enabled Moore's Law until 2005, when physics limitations (leakage current, voltage floors) forced the industry toward multi-core architectures and specialized processors. This transition enabled the GPU computing revolution: GPU architectures originally designed for graphics, with thousands of simple cores optimized for parallel workloads, proved remarkably effective for neural network computations, which similarly benefit from massive parallelism.\n\nBeyond power considerations, physical limits impose minimum latencies that no engineering optimization can overcome. The speed of light establishes an inherent 80ms round-trip time between California and Virginia, while internet routing, DNS resolution, and processing overhead typically contribute another 20-420ms. This 100-500ms total latency renders real-time applications infeasible with pure cloud deployment. Network bandwidth faces physical constraints: fiber optic cables have theoretical limits, and wireless communication remains bounded by spectrum availability and signal propagation physics. These communication constraints create hard boundaries that necessitate local processing for latency-sensitive applications and drive edge deployment decisions.\n\nHeat dissipation emerges as an additional limiting factor as computational density increases. Mobile devices must throttle performance to prevent component damage and maintain user comfort, while data centers require extensive cooling systems that limit placement options and increase operational costs. Thermal constraints create cascading effects: elevated temperatures reduce semiconductor reliability, increase error rates, and accelerate component aging. These thermal realities necessitate trade-offs between computational performance and sustainable operation, driving specialized cooling solutions in cloud environments and ultra-low-power designs in embedded systems.\n\nThese fundamental constraints drove the evolution of the four distinct deployment paradigms outlined in this overview (@sec-ml-systems-deployment-spectrum-38d0). Understanding these core constraints proves essential for selecting appropriate deployment paradigms and establishing realistic performance expectations.\n\nThese theoretical constraints manifest in concrete hardware differences across the deployment spectrum. To understand the practical implications of these physical limitations, @tbl-representative-systems provides representative hardware platforms for each category. These examples demonstrate the range of computational resources, power requirements, and cost considerations[^fn-cost-spectrum] across the ML systems spectrum, illustrating the practical implications of each deployment approach.[^fn-pue]\n\nThese quantitative thresholds reflect essential relationships between computational requirements, energy consumption, and deployment feasibility. These scaling relationships determine when distributed cloud deployment becomes advantageous relative to edge or mobile alternatives. Understanding these quantitative trade-offs enables informed deployment decisions across the spectrum of ML systems.\n\n@fig-vMLsizes illustrates the differences between Cloud ML, Edge ML, Mobile ML, and TinyML in terms of hardware specifications, latency characteristics, connectivity requirements, power consumption, and model complexity constraints. As systems transition from Cloud to Edge to TinyML, available resources decrease dramatically, presenting significant challenges for machine learning model deployment. This resource disparity becomes particularly evident when deploying ML models on microcontrollers, the primary hardware platform for TinyML. These devices possess severely constrained memory and storage capacities that prove insufficient for conventional complex ML models.\n\n[^fn-cost-spectrum]: **ML Hardware Cost Spectrum**: The cost range spans 6 orders of magnitude, from $10 ESP32-CAM modules to multi-million dollar TPU Pod systems. This 100,000x+ cost difference reflects proportional differences in computational capability, enabling deployment across vastly different economic contexts and use cases, from hobbyist projects to hyperscale cloud infrastructure.\n\n[^fn-pue]: **Power Usage Effectiveness (PUE)**: Data center efficiency metric measuring total facility power divided by IT equipment power. A PUE of 1.0 represents perfect efficiency (impossible in practice), while 1.1-1.3 indicates highly efficient facilities using advanced cooling and power management. Google's data centers achieve PUE of 1.12 compared to industry average of 1.8.\n\n[^fn-computer-vision]: **Computer Vision**: Field of AI enabling machines to interpret and understand visual information from images and videos. Requires processing 2-50 megapixels per image at 30+ fps for real-time applications, creating massive computational and memory bandwidth demands that drive specialized hardware like GPUs and vision processing units.\n\n[^fn-ensemble-methods]: **Ensemble Methods**: ML technique combining predictions from multiple models to improve accuracy and robustness. Requires training and running 5-100+ models simultaneously, increasing compute requirements by 10-50x but enabling 2-5% accuracy improvements that justify cloud deployment costs.\n\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **Category**  | **Example Device** | **Processor**                    | **Memory**  | **Storage** | **Power**   | **Price Range** | **Example Models/Tasks**       | **Quantitative Thresholds**               |\n+:==============+===================:+=================================:+============:+:============+============:+:================+:===============================+==========================================:+\n| **Cloud ML**  | Google TPU v4 Pod  | 4,096x TPU v4 chips              | 131 TB HBM2 | Cloud-scale | ~3 MW       | Cloud service   | Large language models,         | &gt;1000 TFLOPS compute, real-time video  |\n|               |                    | (1.1 exaflops peak)              |             | (PB-scale)  |             | (rental only)   | massive-scale training         | processing, &gt;100GB/s memory bandwidth, |\n|               |                    |                                  |             |             |             |                 |                                | PUE 1.1-1.3, 100-500ms latency            |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **Edge ML**   | NVIDIA DGX Spark   | GB10 Grace Blackwell Superchip   | 128 GB      | 4 TB NVMe   | ~200 W      | ~$5,000         | Model fine-tuning,             | ~1 PFLOPS AI compute,                     |\n|               |                    | (20-core Arm, 1 PFLOPS AI)       | LPDDR5x     |             |             |                 | on-premise inference,          | &gt;270 GB/s memory bandwidth,            |\n|               |                    |                                  |             |             |             |                 | prototype development          | desktop deployment, local processing      |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **Mobile ML** | iPhone 15 Pro      | A17 Pro (6-core CPU, 6-core GPU) | 8 GB RAM    | 128 GB-1 TB | 3-5 W       | $999+           | Face ID, computational         | 1-10 TOPS compute,                        |\n|               |                    |                                  |             |             |             |                 | photography, voice recognition | &lt;2W sustained power,                   |\n|               |                    |                                  |             |             |             |                 |                                | &lt;50ms UI response                      |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n| **TinyML**    | ESP32-CAM          | Dual-core @ 240MHz               | 520 KB RAM  | 4 MB Flash  | 0.05-0.25 W | $10             | Image classification,          | &lt;1 TOPS compute,                       |\n|               |                    |                                  |             |             |             |                 | motion detection               | &lt;1mW power,                            |\n|               |                    |                                  |             |             |             |                 |                                | microsecond response times                |\n+---------------+--------------------+----------------------------------+-------------+-------------+-------------+-----------------+--------------------------------+-------------------------------------------+\n\n: **Hardware Spectrum**: Machine learning system design necessitates trade-offs between computational resources, power consumption, and cost, as exemplified by the diverse hardware platforms suitable for cloud, edge, mobile, and TinyML deployments. This table quantifies those trade-offs, revealing how device capabilities, from specialized ML accelerators in cloud data centers to low-power microcontrollers in embedded systems, shape the types of models and tasks each platform can effectively support. The quantitative thresholds provide specific decision criteria to help practitioners determine the most appropriate deployment paradigm for their applications. {#tbl-representative-systems}\n\n::: {#fig-vMLsizes fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\nLine/.style={red,line width=1.0pt,text=black},\n  Box/.style={inner xsep=2pt,\n    node distance=1.1,\n    draw=none,%GreenLine,\n    line width=0.75pt,\n    fill=none,%GreenL,\n    text width=22mm,align=flush center,\n    minimum width=22mm, minimum height=11mm\n  },\n  Box1/.style={Box,node distance=0.2, minimum height=5mm},\n  Box2/.style={Box,node distance=0.4, minimum height=5mm}\n}\n\\node[Box](B0){};\n\\node[Box,right=0 of B0](B1){\\textbf{Cloud AI}\\\\(NVIDIA V100)};\n\\node[Box,right=of B1](B2){\\textbf{Mobile AI}\\\\(iPhone 15 Pro)};\n\\node[Box,right=of B2](B3){\\textbf{Tiny AI}\\\\(STM32F746)};\n\\node[Box, right=of B3](B4){\\textbf{ResNet-50}};\n\\node[Box, right=0 of B4](B5){\\textbf{MobileNetV2}};\n\\node[Box, right=0 of B5](B6){\\textbf{MobileNetV2}\\\\ (int8)};\n%%%%\n\\node[Box2,below=of B0](B20){\\textbf{Memory}};\n\\node[Box2,below=of B1](B21){16 GB};\n\\node[Box2,below=of B2](B22){4 GB};\n\\node[Box2,below=of B3](B23){\\textbf{320 kB}};\n\\node[Box2,below=of B4](B24){7.2 MB};\n\\node[Box2,below=of B5](B25){6.8 MB};\n\\node[Box2,below=of B6](B26){1.7 MB};\n%%%%\n\\node[Box1,below=of B20](B30){\\textbf{Storage}};\n\\node[Box1,below=of B21](B31){TB $\\sim$ PB};\n\\node[Box1,below=of B22](B32){> 64 GB};\n\\node[Box1,below=of B23](B33){\\textbf{1 MB}};\n\\node[Box1,below=of B24](B34){102 MB};\n\\node[Box1,below=of B25](B35){13.6 MB};\n\\node[Box1,below=of B26](B36){3.4 MB};\n%%\n\\coordinate(GL)at($(B0.north west)+(0,0)$);\n\\coordinate(GD)at($(B6.north east)+(0,0)$);\n\\coordinate(DL)at($(B30.south west)+(0,0)$);\n\\coordinate(DD)at($(B36.south east)+(0,0)$);\n\\coordinate(SL)at($(B0.south west)!0.0!(B20.north west)$);\n\\coordinate(SD)at($(B6.south east)!0.0!(B26.north east)$);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B21)--node[above]{4$\\times$}(B22);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B22)--node[above]{3100$\\times$}(B23);\n\\draw[Line,latex-latex,shorten >=-9pt,shorten <=-9pt](B23)--\nnode[above](GAG){gap}(B24);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B31)--node[above]{1000$\\times$}(B32);\n\\draw[Line,-latex,shorten >=-6pt,shorten <=-6pt](B32)--node[above]{6400$\\times$}(B33);\n\\draw[Line,latex-latex,shorten >=-9pt,shorten <=-9pt](B33)--\nnode[above](GAD){gap}(B34);\n\\path[red](GL)-|coordinate(GS)(GAG);\n\\path[red](DL)-|coordinate(DS)(GAD);\n\\path[red](SL)-|coordinate(SS)(GAD);\n%\n\\draw[line width=1.75pt,shorten >=5pt](DL)--(DS);\n\\draw[line width=1.75pt,shorten >=5pt](GL)--(GS);\n\\draw[line width=1.0pt,shorten >=5pt](SL)--(SS);\n%%\n\\draw[line width=1.75pt,shorten >=5pt](DD)--(DS);\n\\draw[line width=1.75pt,shorten >=5pt](GD)--(GS);\n\\draw[line width=1.0pt,shorten >=5pt](SD)--(SS);\n%\n\\scoped[on background layer]\n\\node[draw=none,inner xsep=5mm,inner ysep=3mm,minimum width=170mm,\n      anchor=west,yshift=0mm,fill=cyan!10,fit=(GL)(DD)](BB){};\n%\n\\node[single arrow, draw=none, fill=red,inner sep=2pt,\n      minimum width = 14pt, single arrow head extend=3pt,\n      minimum height=8mm]at($(B1)!0.5!(B2)$) {};\n      \\node[single arrow, draw=none, fill=red,inner sep=2pt,\n      minimum width = 14pt, single arrow head extend=3pt,\n      minimum height=8mm]at($(B2)!0.5!(B3)$) {};\n\\end{tikzpicture}\n```\n**Device Memory Constraints**: AI model deployment spans a wide range of devices with drastically different memory capacities, from cloud servers with 16 GB to microcontroller-based systems with only 320 kb. This progression necessitates specialized optimization techniques and efficient architectures to enable on-device intelligence with limited resources. Source: [@lin2023tiny].\n:::\n\n## Cloud ML: Maximizing Computational Power {#sec-ml-systems-cloud-ml-maximizing-computational-power-f232}\n\nHaving established the constraints and evolutionary progression that shape ML deployment paradigms, this analysis addresses each paradigm systematically, beginning with Cloud ML, the foundation from which other paradigms emerged. This approach maximizes computational resources while accepting latency constraints, providing the optimal choice when computational power matters more than response time. Cloud deployments prove ideal for complex training tasks and inference workloads that can tolerate network delays.\n\nCloud Machine Learning leverages the scalability and power of centralized infrastructures[^fn-cloud-evolution] to handle computationally intensive tasks: large-scale data processing, collaborative model development, and advanced analytics. Cloud data centers utilize distributed architectures and specialized resources to train complex models and support diverse applications, from recommendation systems to natural language processing[^fn-nlp-compute]. The subsequent analysis addresses the deployment characteristics that make cloud ML systems effective for large-scale applications.\n\n[^fn-cloud-evolution]: **Cloud Infrastructure Evolution**: Cloud computing for ML emerged from Amazon's decision in 2002 to treat their internal infrastructure as a service. AWS launched in 2006, followed by Google Cloud (2008) and Azure (2010). By 2024, global cloud infrastructure spending reached approximately $138 billion annually, with total public cloud services exceeding $675 billion.\n\n[^fn-nlp-compute]: **NLP Computational Demands**: Modern language models like GPT-3 required 3,640 petaflop-days of compute for training, equivalent to running 10,000 NVIDIA V100 GPUs for approximately 15 days [@brown2020language]. This computational scale drove the need for massive cloud infrastructure.\n\n::: {.callout-definition title=\"Cloud ML\"}\n\n***Cloud Machine Learning (Cloud ML)*** is the deployment of machine learning models on _centralized data center infrastructure_, offering _massive computational capacity_ and _scalability_ for training and serving complex models at the cost of _network latency_ and _connectivity dependence_.\n:::\n\n@fig-cloud-ml provides an overview of Cloud ML's capabilities, which we will discuss in greater detail throughout this section.\n\n::: {#fig-cloud-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=30mm,align=flush center,\n    minimum width=30mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=27mm, minimum width=27mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=38mm, minimum width=38mm\n  },\n Box4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=32mm, minimum width=32mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){Cloud ML};\n%\n\\node[Box4,below=0.7 of B1](B11){Immense Computational Power};\n\\node[Box4,below=of B11](B12){Collaborative Environment};\n\\node[Box4,below=of B12](B13){Access to Advanced Tools};\n\\node[Box4,below=of B13](B14){Dynamic Scalability};\n\\node[Box4,below=of B14](B15){Centralized Infrastructure};\n%\n\\node[Box2,below=0.7 of B2](B21){Scalable Data Processing and Model Training};\n\\node[Box2,below=of B21](B22){Collaboration and Resource Sharing};\n\\node[Box2,below=of B22](B23){Flexible Deployment and Accessibility};\n\\node[Box2,below=of B23](B24){Cost-Effectiveness and Scalability};\n\\node[Box2,below=of B24](B25){Global Accessibility};\n%\n\\node[Box,below=0.7 of B3](B31){Vendor Lock-In};\n\\node[Box,below=of B31](B32){Latency Issues};\n\\node[Box,below=of B32](B33){Data Privacy and Security};\n\\node[Box,below=of B33](B34){Dependency on Internet};\n\\node[Box,below=of B34](B35){Cost Considerations};\n%\n\\node[Box3,below=0.7 of B4](B41){Virtual Assistants};\n\\node[Box3,below=of B41](B42){Security and Anomaly Detection};\n\\node[Box3,below=of B42](B43){Recommendation Systems};\n\\node[Box3,below=of B43](B44){Fraud Detection};\n\\node[Box3,below=of B44](B45){Personalized User Experience};\n%\n\\foreach \\i in{1,2,3,4,5}{\n  \\foreach \\x in{1,2,3,4}{\n\\draw[Line](B\\x.west)--++(180:0.5)|-(B\\x\\i);\n}\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n\n```\n**Cloud ML Capabilities**: Cloud machine learning systems address challenges related to scale, complexity, and resource management through centralized computing infrastructure and specialized hardware. This figure outlines key considerations for deploying models in the cloud, including the need for reliable infrastructure and efficient resource allocation to handle large datasets and complex computations.\n:::\n\n### Cloud Infrastructure and Scale {#sec-ml-systems-cloud-infrastructure-scale-848e}\n\nTo understand cloud ML's position in the deployment spectrum, we must first consider its defining characteristics. Cloud ML's primary distinguishing feature is its centralized infrastructure operating at unprecedented scale. @fig-cloudml-example illustrates this concept with an example from Google's Cloud TPU[^fn-mlsys-tpu] data center. As detailed in @tbl-representative-systems, cloud systems like Google's TPU v4 Pod represent a 100-1000x computational advantage over mobile devices, with >1000 TFLOPS compute power and megawatt-scale power consumption. Cloud service providers offer virtual platforms with >100GB/s memory bandwidth housed in globally distributed data centers[^fn-hyperscale]. These centralized facilities enable computational workloads impossible on resource-constrained devices. However, this centralization introduces critical trade-offs: network round-trip latency of 100-500ms eliminates real-time applications, while operational costs scale linearly with usage.\n\n[^fn-mlsys-tpu]: **Tensor Processing Unit (TPU)**: Google's custom ASIC designed specifically for tensor operations, first used internally in 2015 for neural network inference. A single TPU v4 Pod contains 4,096 chips and delivers 1.1 exaflops of peak performance, representing one of the world's largest publicly available ML clusters.\n\n[^fn-hyperscale]: **Hyperscale Data Centers**: These facilities contain 5,000+ servers and cover 10,000+ square feet. Microsoft's data centers span over 200 locations globally, with some individual facilities consuming enough electricity to power 80,000 homes.\n\n::: {.content-visible when-format=\"html\"}\n![**Cloud Data Center Scale**: Large-scale machine learning systems require centralized infrastructure with massive computational resources and storage capacity. Google's cloud TPU data center provides this need, housing specialized AI accelerator hardware to efficiently manage the demands of training and deploying complex models. Source: [@google2024gemini].](images/jpg/cloud_ml_tpu.jpeg){#fig-cloudml-example}\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n![Cloud TPU data center at Google. Source: [@google2024gemini]](images/jpg/cloud_ml_tpu.jpeg){#fig-cloudml-example fig-pos='htb'}\n:::\n\nCloud ML excels in processing massive data volumes through parallelized architectures. Through techniques detailed in @sec-model-optimizations, distributed training across hundreds of GPUs enables processing that would require months on single devices, while @sec-ai-acceleration covers the memory bandwidth analysis underlying this performance. This enables training on datasets requiring hundreds of terabytes of storage and petaflops of computation, resources impossible on constrained devices.\n\nThe centralized infrastructure creates exceptional deployment flexibility through cloud APIs[^fn-ml-apis], making trained models accessible worldwide across mobile, web, and IoT platforms. Seamless collaboration enables multiple teams to access projects simultaneously with integrated version control. Pay-as-you-go pricing models[^fn-paas-pricing] eliminate upfront capital expenditure while resources scale elastically with demand.\n\nA common misconception assumes that Cloud ML's vast computational resources make it universally superior to alternative deployment approaches. Cloud infrastructure offers exceptional computational power and storage, yet this advantage doesn't automatically translate to optimal solutions for all applications. Cloud deployment introduces significant trade-offs including network latency (often 100-500ms round trip), privacy concerns when transmitting sensitive data, ongoing operational costs that scale with usage, and complete dependence on network connectivity. Edge and embedded deployments excel in scenarios requiring real-time response (autonomous vehicles need sub-10ms decision making), strict data privacy (medical devices processing patient data), predictable costs (one-time hardware investment versus recurring cloud fees), or operation in disconnected environments (industrial equipment in remote locations). The optimal deployment paradigm depends on specific application requirements rather than raw computational capability.\n\n[^fn-ml-apis]: **ML APIs**: Application Programming Interfaces that democratized AI by providing pre-trained models as web services. Google's Vision API launched in 2016, processing over 1 billion images monthly within two years, enabling developers to add AI capabilities without ML expertise.\n\n[^fn-paas-pricing]: **Pay-as-You-Go Pricing**: Revolutionary model where users pay only for actual compute time used, measured in GPU-hours or inference requests. Training a model might cost $50-500 on demand versus $50,000-500,000 to purchase equivalent hardware.\n\n### Cloud ML Trade-offs and Constraints {#sec-ml-systems-cloud-ml-tradeoffs-constraints-1654}\n\nCloud ML's substantial advantages carry inherent trade-offs that shape deployment decisions. Latency represents the most significant physical constraint. Network round-trip delays typically range from 100-500ms, making cloud processing unsuitable for real-time applications requiring sub-10ms responses, such as autonomous vehicles and industrial control systems. Beyond basic timing constraints, unpredictable response times complicate performance monitoring and debugging across geographically distributed infrastructure.\n\nPrivacy and security present significant challenges when adopting cloud deployment. Transmitting sensitive data to remote data centers creates potential vulnerabilities and complicates regulatory compliance. Organizations handling data subject to regulations like GDPR[^fn-gdpr] or HIPAA[^fn-hipaa] must implement comprehensive security measures including encryption, strict access controls, and continuous monitoring to meet stringent data handling requirements.\n\n[^fn-gdpr]: **GDPR (General Data Protection Regulation)**: European privacy law effective 2018, imposing fines up to €20 million or 4% of global revenue for violations. Forces ML systems to implement \"right to be forgotten\" and data processing transparency.\n\n[^fn-hipaa]: **HIPAA (Health Insurance Portability and Accountability Act)**: US healthcare privacy law requiring strict data security measures. ML systems handling medical data must implement encryption, access controls, and audit trails, adding 30-50% to development costs.\n\nCost management introduces operational complexity requiring total cost of ownership (TCO) analysis rather than naive unit comparisons. Consider a production system serving 1 million daily inferences. Cloud costs at $0.001 per inference reach $365,000 annually, but include infrastructure management, automatic scaling, and updates. Edge deployment requires not just $100,000 hardware investment but also power ($15,000-30,000 annually at typical commercial rates), cooling infrastructure, network equipment, operational staff for monitoring and maintenance, and hardware refresh every 3-5 years. Industry analyses suggest on-premises TCO typically reaches 2-3x hardware acquisition cost. The break-even calculation depends heavily on utilization: cloud excels for variable workloads while edge becomes cost-effective for sustained high utilization exceeding 50-70% of capacity. Unpredictable usage spikes further complicate budgeting, requiring sophisticated monitoring and cost governance frameworks.\n\nNetwork dependency creates another critical constraint. Any connectivity disruption directly impacts system availability, proving particularly problematic where network access is limited or unreliable. Vendor lock-in further complicates the landscape, as dependencies on specific tools and APIs create portability and interoperability challenges when transitioning between providers. Organizations must carefully balance these constraints against cloud benefits based on application requirements and risk tolerance.\n\n### Large-Scale Training and Inference {#sec-ml-systems-largescale-training-inference-f7a8}\n\nCloud ML's computational advantages manifest most visibly in consumer-facing applications requiring massive scale. Virtual assistants like Siri and Alexa demonstrate the hybrid architectures that characterize modern ML systems. Wake word detection runs on dedicated low-power hardware (under 1mW) directly on the device, enabling always-on listening without draining batteries. Initial speech recognition increasingly runs on-device for privacy and responsiveness, while complex natural language understanding and generation leverage cloud infrastructure for access to larger models and broader knowledge. This hybrid approach reduces response latency from 500ms or more with pure cloud processing to under 200ms while maintaining the computational power needed for sophisticated language understanding.\n\nRecommendation engines deployed by Netflix and Amazon demonstrate another compelling application of cloud resources. These systems process massive datasets using collaborative filtering[^fn-collaborative-filtering] and other machine learning techniques to uncover patterns in user preferences and behavior. Cloud computational resources enable continuous updates and refinements as user data grows, with Netflix processing over 100 billion data points daily to deliver personalized content suggestions that directly enhance user engagement.\n\nFinancial institutions have revolutionized fraud detection through cloud ML capabilities. By analyzing vast amounts of transactional data in real-time, ML algorithms trained on historical fraud patterns can detect anomalies and suspicious behavior across millions of accounts, enabling proactive fraud prevention that minimizes financial losses.\n\nThese applications demonstrate how cloud ML's computational advantages translate into transformative capabilities for large-scale, complex processing tasks. Beyond these flagship applications, cloud ML permeates everyday online experiences through personalized advertisements on social media, predictive text in email services, product recommendations in e-commerce, enhanced search results, and security anomaly detection systems that continuously monitor for cyber threats at scale.\n\n[^fn-collaborative-filtering]: **Collaborative Filtering**: Recommendation technique analyzing user behavior patterns to predict preferences. Netflix's algorithm contributes to 80% of watched content and saves $1 billion annually in customer retention.\n\n## Edge ML: Reducing Latency and Privacy Risk {#sec-ml-systems-edge-ml-reducing-latency-privacy-risk-31f9}\n\nCloud ML's computational advantages come with inherent trade-offs that limit its applicability for many real-world scenarios. The 100-500ms latency and privacy concerns that we examined create fundamental barriers for applications requiring immediate response or local data processing. Edge ML emerged as a direct response to these specific limitations, moving computation closer to data sources and trading unlimited computational resources for sub-100ms latency and local data sovereignty.\n\nThis paradigm shift becomes essential for applications where cloud's 100-500ms round-trip delays prove unacceptable. Autonomous systems requiring split-second decisions and industrial IoT[^fn-industrial-iot] applications demanding real-time response cannot tolerate network delays. Similarly, applications subject to strict data privacy regulations must process information locally rather than transmitting it to remote data centers. Edge devices (gateways and IoT hubs[^fn-iot-hubs]) occupy a middle ground in the deployment spectrum, maintaining acceptable performance while operating under intermediate resource constraints.\n\n[^fn-industrial-iot]: **Industrial IoT**: Manufacturing generates over 1 exabyte of data annually, but less than 1% is analyzed due to connectivity constraints. Edge ML enables real-time analysis, with predictive maintenance alone saving manufacturers $630 billion globally by 2025.\n\n[^fn-iot-hubs]: **IoT Hubs**: Central connection points that aggregate data from multiple sensors before cloud transmission. A typical smart building might have 1 hub managing 100-1000 IoT sensors, reducing cloud traffic by 90% while enabling local decision-making.\n\n::: {.callout-definition title=\"Edge ML\"}\n\n***Edge Machine Learning (Edge ML)*** is the deployment of machine learning models on _localized infrastructure_ at the network edge, enabling _low-latency processing_ and _data privacy_ through local computation on stationary devices like gateways and industrial controllers.\n:::\n\n@fig-edge-ml provides an overview of Edge ML's key dimensions, which this analysis addresses in detail.\n\n::: {#fig-edge-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=37mm,align=flush center,\n    minimum width=37mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=27mm, minimum width=27mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=28mm, minimum width=28mm\n  },\n Box4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=30mm, minimum width=30mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){Edge ML};\n%\n\\node[Box4,below=0.7 of B1](B11){Decentralized Data Processing};\n\\node[Box4,below=of B11](B12){Local Data Storage and Computation};\n\\node[Box4,below=of B12](B13){Proximity to Data Sources};\n%\n\\node[Box2,below=0.7 of B2](B21){Reduced Latency};\n\\node[Box2,below=of B21](B22){Enhanced Data Privacy};\n\\node[Box2,below=of B22](B23){Lower Bandwidth Usage};\n%\n\\node[Box,below=0.7 of B3](B31){Security Concerns at the Edge Nodes};\n\\node[Box,below=of B31](B32){Complexity in Managing Edge Nodes};\n\\node[Box,below=of B32](B33){Limited Computational Resources};\n%\n\\node[Box3,below=0.7 of B4](B41){Industrial IoT};\n\\node[Box3,below=of B41](B42){Smart Homes and Cities};\n\\node[Box3,below=of B42](B43){Autonomous Vehicles};\n%\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B1.west)--++(180:0.5)|-(B1\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B2.west)--++(180:0.5)|-(B2\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B3.west)--++(180:0.5)|-(B3\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B4.west)--++(180:0.5)|-(B4\\i);\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n```\n**Edge ML Dimensions**: This figure outlines key considerations for edge machine learning, contrasting challenges with benefits and providing representative examples and characteristics. Understanding these dimensions enables designing and deploying effective AI solutions on resource-constrained devices.\n:::\n\n### Distributed Processing Architecture {#sec-ml-systems-distributed-processing-architecture-8d28}\n\nEdge ML's diversity spans wearables, industrial sensors, and smart home appliances, devices that process data locally[^fn-iot-growth] without depending on central servers (@fig-edgeml-example). Edge devices occupy the middle ground between cloud systems and mobile devices in computational resources, power consumption, and cost. Memory bandwidth at 25-100 GB/s enables models requiring 100MB-1GB parameters, using optimization techniques (@sec-model-optimizations) to achieve 2-4x speedup compared to cloud models. Local processing eliminates network round-trip latency, enabling <100ms response times while generating substantial bandwidth savings: processing 1000 camera feeds locally avoids 1Gbps uplink costs and reduces cloud expenses by $10,000-100,000 annually.\n\n[^fn-iot-growth]: **IoT Device Growth**: From 8.4 billion connected devices in 2017 to a projected 25.4 billion by 2030. Each device generates 2.5 quintillion bytes of data daily, making edge processing essential for bandwidth management.\n\n[^fn-latency-critical]: **Latency-Critical Applications**: Autonomous vehicles require <10ms response times for emergency braking decisions. Industrial robotics needs <1ms for precision control. Cloud round-trip latency typically ranges from 100-500ms, making edge processing essential for safety-critical applications.\n\n### Edge ML Benefits and Deployment Challenges {#sec-ml-systems-edge-ml-benefits-deployment-challenges-6e28}\n\nEdge ML provides quantifiable benefits that address key cloud limitations. Latency reduction from 100-500ms in cloud deployments to 1-50ms at the edge enables safety-critical applications[^fn-latency-critical] requiring real-time response. Bandwidth savings prove equally substantial: a retail store with 50 cameras streaming video can reduce bandwidth requirements from 100 Mbps (costing $1,000-2,000 monthly) to less than 1 Mbps by processing locally and transmitting only metadata, a 99% reduction. Privacy improves through local processing, eliminating transmission risks and simplifying regulatory compliance. Operational resilience ensures systems continue functioning during network outages, proving critical for manufacturing, healthcare, and building management applications.\n\nThese benefits carry corresponding limitations. Limited computational resources[^fn-endpoint-constraints] significantly constrain model complexity: edge servers typically provide 10-100x less processing power than cloud infrastructure, limiting deployable models to millions rather than billions of parameters. Managing distributed networks introduces complexity that scales nonlinearly with deployment size. Coordinating version control and updates across thousands of devices requires sophisticated orchestration systems[^fn-edge-coordination]. Security challenges intensify with physical accessibility—edge devices deployed in retail stores or public infrastructure face tampering risks requiring hardware-based protection mechanisms. Hardware heterogeneity further complicates deployment, as diverse platforms with varying capabilities demand different optimization strategies. Initial deployment costs of $500-2,000 per edge server create substantial capital requirements. Deploying 1,000 locations requires $500,000-2,000,000 upfront investment, though these costs are offset by long-term operational savings.\n\n[^fn-endpoint-constraints]: **Edge Server Constraints**: Typical edge servers have 1-8GB RAM and 2-32GB storage, versus cloud servers with 128-1024GB RAM and petabytes of storage. Processing power differs by 10-100x, necessitating specialized model compression techniques.\n\n[^fn-edge-coordination]: **Edge Network Coordination**: For n edge devices, the number of potential communication paths is n(n-1)/2. A network of 1,000 devices has 499,500 possible connections. Kubernetes K3s and similar platforms help manage this complexity.\n\n![**Edge Device Deployment**: Diverse IoT devices, from wearables to home appliances, enable decentralized machine learning by performing inference locally, reducing reliance on cloud connectivity and improving response times. Source: Edge Impulse.](images/jpg/edge_ml_iot.jpg){#fig-edgeml-example}\n\n### Real-Time Industrial and IoT Systems {#sec-ml-systems-realtime-industrial-iot-systems-f946}\n\nIndustries deploy Edge ML widely where low latency, data privacy, and operational resilience justify the additional complexity of distributed processing. Autonomous vehicles represent perhaps the most demanding application, where safety-critical decisions must occur within milliseconds based on sensor data that cannot be transmitted to remote servers. Systems like Tesla's Full Self-Driving process inputs from eight cameras at 36 frames per second through custom edge hardware, making driving decisions with latencies under 10ms, a response time physically impossible with cloud processing due to network delays.\n\nSmart retail environments demonstrate edge ML's practical advantages for privacy-sensitive, bandwidth-intensive applications. Amazon Go stores process video from hundreds of cameras through local edge servers, tracking customer movements and item selections to enable checkout-free shopping. This edge-based approach addresses both technical and privacy concerns: transmitting high-resolution video from hundreds of cameras would require over 200 Mbps sustained bandwidth, while local processing ensures customer video never leaves the premises, addressing privacy concerns and regulatory requirements.\n\nThe Industrial IoT[^fn-industry-40] leverages edge ML for applications where millisecond-level responsiveness directly impacts production efficiency and worker safety. Manufacturing facilities deploy edge ML systems for real-time quality control, with vision systems inspecting welds at speeds exceeding 60 parts per minute, and predictive maintenance[^fn-predictive-maintenance] applications that monitor over 10,000 industrial assets per facility. This approach has demonstrated 25-35% reductions in unplanned downtime across various manufacturing sectors.\n\nSmart buildings utilize edge ML to optimize energy consumption while maintaining operational continuity during network outages. Commercial buildings equipped with edge-based building management systems process data from 5,000-10,000 sensors monitoring temperature, occupancy, air quality, and energy usage, with edge processing reducing cloud transmission requirements by 95% while enabling sub-second response times. Healthcare applications similarly leverage edge ML for patient monitoring and surgical assistance, maintaining HIPAA compliance through local processing while achieving sub-100ms latency for real-time surgical guidance.\n\n[^fn-industry-40]: **Industry 4.0**: Fourth industrial revolution integrating cyber-physical systems into manufacturing. Expected to increase productivity by 20-30% and reduce costs by 15-25% globally.\n\n[^fn-predictive-maintenance]: **Predictive Maintenance**: ML-driven maintenance scheduling based on equipment condition. Reduces unplanned downtime by 35-45% and costs by 20-25%. GE saves $1.5 billion annually using predictive analytics.\n\n## Mobile ML: Personal and Offline Intelligence {#sec-ml-systems-mobile-ml-personal-offline-intelligence-7905}\n\nWhile Edge ML addressed the latency and privacy limitations of cloud deployment, it introduced new constraints: the need for dedicated edge infrastructure, ongoing network connectivity, and substantial upfront hardware investments. The proliferation of billions of personal computing devices (smartphones, tablets, and wearables) created an opportunity to extend ML capabilities even further by bringing intelligence directly to users' hands. Mobile ML represents this next step in the distribution of intelligence, prioritizing user proximity, offline capability, and personalized experiences while operating under the strict power and thermal constraints inherent to battery-powered devices.\n\nMobile ML integrates machine learning directly into portable devices like smartphones and tablets, providing users with real-time, personalized capabilities. This paradigm excels when user privacy, offline operation, and immediate responsiveness matter more than computational sophistication. Mobile ML supports applications such as voice recognition[^fn-voice-recognition], computational photography[^fn-computational-photography], and health monitoring while maintaining data privacy through on-device computation. These battery-powered devices must balance performance with power efficiency and thermal management, making them ideal for frequent, short-duration AI tasks.\n\n[^fn-voice-recognition]: **Voice Recognition Evolution**: Apple's Siri (2011) required cloud processing with 200-500ms latency. By 2017, on-device processing reduced latency to <50ms while improving privacy. Modern smartphones process 16kHz audio at 20-30ms latency using specialized neural engines.\n\n[^fn-computational-photography]: **Computational Photography**: Combines multiple exposures and ML algorithms to enhance image quality. Google's Night Sight captures 15 frames in 6 seconds, using ML to align and merge them. Portrait mode uses depth estimation ML models to create professional-looking bokeh effects in real-time.\n\n::: {.callout-definition title=\"Mobile ML\"}\n\n***Mobile Machine Learning (Mobile ML)*** is the deployment of machine learning models directly on _portable, battery-powered devices_, enabling _personalization_, _privacy_, and _offline operation_ within severe energy and resource constraints.\n:::\n\nThis section analyzes Mobile ML across four key dimensions, revealing how this paradigm balances capability with constraints. @fig-mobile-ml provides an overview of Mobile ML's capabilities.\n\n::: {#fig-mobile-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=32mm,align=flush center,\n    minimum width=32mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=30mm, minimum width=30mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=35mm, minimum width=35mm\n  },\n Box4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=32mm, minimum width=32mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){Mobile ML};\n%\n\\node[Box4,below=0.7 of B1](B11){On-Device Processing};\n\\node[Box4,below=of B11](B12){Battery-Powered Operation};\n\\node[Box4,below=of B12](B13){Sensor Integration};\n\\node[Box4,below=of B13](B14){Optimized Frameworks};\n%\n\\node[Box2,below=0.7 of B2](B21){Real-Time Processing};\n\\node[Box2,below=of B21](B22){Enhanced Privacy};\n\\node[Box2,below=of B22](B23){Offline Functionality};\n\\node[Box2,below=of B23](B24){Personalized Experience};\n%\n\\node[Box,below=0.7 of B3](B31){Limited Computational Resources};\n\\node[Box,below=of B31](B32){Battery Life Constraints};\n\\node[Box,below=of B32](B33){Storage Limitations};\n\\node[Box,below=of B33](B34){Model Optimization Requirements};\n%\n\\node[Box3,below=0.7 of B4](B41){Voice Recognition};\n\\node[Box3,below=of B41](B42){Computational Photography};\n\\node[Box3,below=of B42](B43){Health Monitoring};\n\\node[Box3,below=of B43](B44){Real-Time Translation};\n%\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B1.west)--++(180:0.5)|-(B1\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B2.west)--++(180:0.5)|-(B2\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B3.west)--++(180:0.5)|-(B3\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B4.west)--++(180:0.5)|-(B4\\i);\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n\n```\n**Mobile ML Capabilities**: Mobile machine learning systems balance performance with resource constraints through on-device processing, specialized hardware acceleration, and optimized frameworks. This figure outlines key considerations for deploying ML models on mobile devices, including the trade-offs between computational efficiency, battery life, and model performance.\n:::\n\n### Battery and Thermal Constraints {#sec-ml-systems-battery-thermal-constraints-52eb}\n\nMobile devices exemplify intermediate constraints: 8-24GB RAM (varying from mid-range to flagship), 128GB-1TB storage, 1-10 TOPS AI compute through Neural Processing Units[^fn-npu] consuming 3-5W power. System-on-Chip architectures[^fn-mobile-soc] integrate computation and memory to minimize energy costs. Memory bandwidth of 25-50 GB/s limits models to 10-100MB parameters, requiring aggressive optimization (@sec-model-optimizations). Battery constraints (18-22Wh capacity) make energy optimization critical: 1W continuous ML processing reduces device lifetime from 24 to 18 hours. Specialized frameworks (TensorFlow Lite[^fn-tflite], Core ML[^fn-coreml]) provide hardware-optimized inference enabling <50ms UI response times.\n\n[^fn-mobile-soc]: **Mobile System-on-Chip**: Modern flagship SoCs integrate CPU, GPU, NPU, and memory controllers on a single chip. Apple's A17 Pro contains 19 billion transistors in a 3nm process.\n\n[^fn-npu]: **Neural Processing Unit (NPU)**: Specialized processors optimized for neural network operations. Apple's Neural Engine performs 600 billion operations per second. Qualcomm's Hexagon NPU delivers up to 75 TOPS while consuming <1W.\n\n[^fn-tflite]: **TensorFlow Lite**: Google's mobile ML framework launched in 2017, designed to run models <100MB with <100ms inference time. Used in over 4 billion devices worldwide.\n\n[^fn-coreml]: **Core ML**: Apple's framework introduced in iOS 11 (2017), optimized for on-device inference. Supports models from 1KB to 1GB, with automatic optimization for Apple Silicon.\n\n### Mobile ML Benefits and Resource Constraints {#sec-ml-systems-mobile-ml-benefits-resource-constraints-63a1}\n\nMobile ML excels at delivering responsive, privacy-preserving user experiences. Real-time processing achieves sub-10ms latency, enabling imperceptible response: face detection operates at 60fps with under 5ms latency, while voice wake-word detection responds within 2-3ms. Privacy guarantees emerge from complete data sovereignty through on-device processing. Face ID processes biometric data entirely within a hardware-isolated Secure Enclave[^fn-face-detection], keyboard prediction trains locally on user data, and health monitoring maintains HIPAA compliance without complex infrastructure requirements. Offline functionality eliminates network dependency: Google Maps analyzes millions of road segments locally for navigation, translation[^fn-real-time-translation] supports 40+ language pairs using 35-45MB models that achieve 90% of cloud accuracy, and music identification matches against on-device databases. Personalization reaches unprecedented depth by leveraging behavioral data accumulated over months: iOS predicts which app users will open next with 70-80% accuracy, notification management optimizes delivery timing based on individual patterns, and camera systems continuously adapt to user preferences through implicit feedback.\n\n[^fn-real-time-translation]: **Real-Time Translation**: Google Translate processes 40+ languages offline using on-device neural networks. Models are 35-45MB versus 2GB+ cloud versions, achieving 90% accuracy while enabling instant translation without internet.\n\n[^fn-face-detection]: **Mobile Face Detection**: Apple's Face ID processes biometric data entirely on-device using the Secure Enclave, making extraction practically impossible even with physical device access.\n\nThese benefits require accepting significant resource constraints. Flagship phones allocate only 100MB-1GB to individual ML applications, representing just 0.5-5% of total memory, forcing models to remain under 100-500MB compared to cloud's ability to deploy 350GB+ models. Battery life[^fn-mobile-constraints] presents visible user impact: processing 100 inferences per hour at 0.1 joules each consumes 0.36% of battery daily, compounding with baseline drain; video processing at 30fps can reduce battery life from 24 hours to 6-8 hours. Thermal throttling unpredictably limits sustained performance, with the A17 Pro chip achieving 35 TOPS peak performance but sustaining only 10-15 TOPS during extended operation, requiring adaptive performance strategies. Development complexity multiplies across platforms, demanding separate implementations for Core ML and TensorFlow Lite, while device heterogeneity—particularly Android's span from $100 budget phones to $1,500 flagships—requires multiple model variants. Deployment friction adds further challenges: app store approval processes taking 1-7 days prevent rapid bug fixes that cloud deployments can deploy instantly.\n\n[^fn-mobile-constraints]: **Mobile Device Constraints**: Flagship phones typically have 12-24GB RAM and 512GB-2TB storage, versus cloud servers with 256-2048GB RAM and unlimited storage. Mobile processors operate at 15-25W peak power compared to server CPUs at 200-400W.\n\n### Personal Assistant and Media Processing {#sec-ml-systems-personal-assistant-media-processing-3419}\n\nMobile ML has achieved transformative success across diverse applications that showcase the unique advantages of on-device processing for billions of users worldwide. Computational photography represents perhaps the most visible success, transforming smartphone cameras into sophisticated imaging systems. Modern flagships process every photo through multiple ML pipelines operating in real-time: portrait mode[^fn-portrait-mode] uses depth estimation and segmentation networks to achieve DSLR-quality bokeh effects, night mode captures and aligns 9-15 frames with ML-based denoising that reduces noise by 10-20dB, and systems like Google Pixel process 10-15 distinct ML models per photo for HDR merging, super-resolution, and scene optimization.\n\nVoice-driven interactions demonstrate mobile ML's transformation of human-device communication. These systems combine ultra-low-power wake-word detection consuming less than 1mW with on-device speech recognition achieving under 10ms latency for simple commands. Keyboard prediction has evolved to context-aware neural models achieving 60-70% phrase prediction accuracy, reducing typing effort by 30-40%. Real-time camera translation processes over 100 languages at 15-30fps entirely on-device, enabling instant visual translation without internet connectivity.\n\nHealth monitoring through wearables like Apple Watch extracts sophisticated insights from sensor data while maintaining complete privacy. These systems achieve over 95% accuracy in activity detection and include FDA-cleared atrial fibrillation detection with 98%+ sensitivity, processing extraordinarily sensitive health data entirely on-device to maintain HIPAA compliance. Accessibility features demonstrate transformative social impact through continuous local processing: Live Text detects and recognizes text from camera feeds, Sound Recognition alerts deaf users to environmental cues through haptic feedback, and VoiceOver generates natural language descriptions of visual content.\n\nAugmented reality frameworks leverage mobile ML for real-time environment understanding at 60fps. ARCore and ARKit track device position with centimeter-level accuracy while simultaneously mapping 3D surroundings, enabling hand tracking that extracts 21-joint 3D poses and face analysis of 50+ landmark meshes for real-time effects. These applications demand consistent sub-16ms frame times, making only on-device processing viable for delivering the seamless experiences users expect.\n\n[^fn-portrait-mode]: **Portrait Mode Photography**: Uses dual cameras or LiDAR for depth maps, then ML segmentation to separate subjects from backgrounds, achieving DSLR-quality depth-of-field effects in real-time.\n\nDespite mobile ML's demonstrated capabilities, a common pitfall involves attempting to deploy desktop-trained models directly to mobile or edge devices without architecture modifications. Models developed on powerful workstations often fail dramatically when deployed to resource-constrained devices. A ResNet-50 model requiring 4GB memory for inference (including activations and batch processing) and 4 billion FLOPs per inference cannot run on a device with 512MB of RAM and a 1 GFLOP/s processor. Beyond simple resource violations, desktop-optimized models may use operations unsupported by mobile hardware (specialized mathematical operations), assume floating-point precision unavailable on embedded systems, or require batch processing incompatible with single-sample inference. Successful deployment demands architecture-aware design from the beginning, including specialized architectural techniques for mobile devices [@howard2017mobilenets], integer-only operations for microcontrollers, and optimization strategies that maintain accuracy while reducing computation.\n\n## TinyML: Ubiquitous Sensing at Scale {#sec-ml-systems-tiny-ml-ubiquitous-sensing-scale-51d8}\n\nThe progression from Cloud to Edge to Mobile ML demonstrates the increasing distribution of intelligence across computing platforms, yet each step still requires significant resources. Even mobile devices, with their sophisticated processors and gigabytes of memory, represent a relatively privileged position in the global computing landscape, demanding watts of power and hundreds of dollars in hardware investment. For truly ubiquitous intelligence (sensors in every surface, monitor on every machine, intelligence in every object), these resource requirements remain prohibitive. TinyML completes the deployment spectrum by pushing intelligence to its absolute limits, using devices costing less than $10 and consuming less than 1 milliwatt of power. This paradigm makes ubiquitous sensing not just technically feasible but economically practical at massive scales.\n\nWhere mobile ML still requires sophisticated hardware with gigabytes of memory and multi-core processors, Tiny Machine Learning operates on microcontrollers with kilobytes of RAM and single-digit dollar price points. This extreme constraint forces a significant shift in how we approach machine learning deployment, prioritizing ultra-low power consumption and minimal cost over computational sophistication. The result enables entirely new categories of applications impossible at any other scale.\n\nTinyML brings intelligence to the smallest devices, from microcontrollers[^fn-microcontrollers] to embedded sensors, enabling real-time computation in severely resource-constrained environments. This paradigm excels in applications requiring ubiquitous sensing, autonomous operation, and extreme energy efficiency. TinyML systems power applications such as predictive maintenance, environmental monitoring, and simple gesture recognition while optimized for energy efficiency[^fn-energy-efficiency], often running for months or years on limited power sources such as coin-cell batteries[^fn-coin-cell]. These systems deliver actionable insights in remote or disconnected environments where power, connectivity, and maintenance access are impractical.\n\n[^fn-microcontrollers]: **Microcontrollers**: Single-chip computers with integrated CPU, memory, and peripherals, typically operating at 1-100MHz with 32KB-2MB RAM. Arduino Uno uses an ATmega328P with 32KB flash and 2KB RAM, while ESP32 provides WiFi capability with 520KB RAM, still thousands of times less than a smartphone.\n\n[^fn-energy-efficiency]: **Energy Efficiency in TinyML**: Ultra-low power consumption enables deployment in remote locations. Modern ARM Cortex-M0+ microcontrollers consume <1µW in sleep mode and 100-300µW/MHz when active. Efficient ML inference can run for years on a single coin-cell battery.\n\n[^fn-coin-cell]: **Coin-Cell Batteries**: Small, round batteries (CR2032 being most common) providing 200-250mAh at 3V. When powering TinyML devices at 10-50mW average consumption, these batteries can operate devices for 1-5 years, enabling \"deploy-and-forget\" IoT applications.\n\n::: {.callout-definition title=\"TinyML\"}\n\n***Tiny Machine Learning (TinyML)*** is the deployment of machine learning models on _microcontrollers_ and _ultra-constrained devices_, enabling _autonomous decision-making_ with milliwatt-scale power consumption for applications requiring years of battery life.\n:::\n\nThis section analyzes TinyML through four critical dimensions that define its unique position in the ML deployment spectrum. @fig-tiny-ml encapsulates the key aspects of TinyML discussed in this section.\n\n::: {#fig-tiny-ml fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\n  Box/.style={inner xsep=2pt,\n  draw=GreenLine,\n  fill=GreenL!50,\n  node distance=0.4,\n    line width=0.75pt,\n    anchor=west,\n    text width=32mm,align=flush center,\n    minimum width=32mm, minimum height=9.5mm\n  },\n  Box2/.style={Box,draw=BlueLine,fill=BlueL!50, text width=27mm, minimum width=27mm\n  },\n  Box3/.style={Box,draw=OrangeLine,fill=OrangeL!40, text width=28mm, minimum width=28mm\n  },\nBox4/.style={Box,draw=VioletLine,fill=VioletL2!40, text width=39mm, minimum width=39mm\n  },\n Line/.style={line width=1.0pt,black!50,text=black,-{Triangle[width=0.8*6pt,length=0.98*6pt]}},\n}\n\\node[Box4, fill=VioletL2!90!violet!50,](B1){Characteristics};\n\\node[Box2,right=2 of B1,fill=BlueL](B2){Benefits};\n\\node[Box,right=2 of B2,fill=GreenL](B3){Challenges};\n\\node[Box3,right=2 of B3,fill=OrangeL](B4){Examples};\n\\node[Box,draw=OliveLine,fill=OliveL!30, minimum height=11.5mm,\nabove=1of $(B2.north east)!0.5!(B3.north west)$](B0){TinyML};\n%\n\\node[Box4,below=0.7 of B1](B11){Low Power and Resource Constrained Environments};\n\\node[Box4,below=of B11](B12){On-Device Machine Learning};\n\\node[Box4,below=of B12](B13){Ultra-Small Form Factor};\n%\n\\node[Box2,below=0.7 of B2](B21){Extremely Low Latency};\n\\node[Box2,below=of B21](B22){High Data Security};\n\\node[Box2,below=of B22](B23){Energy Efficiency};\n\\node[Box2,below=of B23](B24){Always-On Operation};\n%\n\\node[Box,below=0.7 of B3](B31){Complex Development Cycle};\n\\node[Box,below=of B31](B32){Model Optimization and Compression};\n\\node[Box,below=of B32](B33){Resource Limitations};\n%\n\\node[Box3,below=0.7 of B4](B41){Anomaly Detection};\n\\node[Box3,below=of B41](B42){Environmental Monitoring};\n\\node[Box3,below=of B42](B43){Predictive Maintenance};\n\\node[Box3,below=of B43](B44){Wearable Devices};\n%\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B1.west)--++(180:0.5)|-(B1\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B2.west)--++(180:0.5)|-(B2\\i);\n}\n\\foreach \\i in{1,2,3}{\n\\draw[Line](B3.west)--++(180:0.5)|-(B3\\i);\n}\n\\foreach \\i in{1,2,3,4}{\n\\draw[Line](B4.west)--++(180:0.5)|-(B4\\i);\n}\n\\foreach \\x in{1,2,3,4}{\n\\draw[Line](B0)-|(B\\x);\n}\n\\end{tikzpicture}\n```\n**TinyML System Characteristics**: Constrained devices necessitate a focus on efficiency, driving trade-offs between model complexity, accuracy, and energy consumption, while enabling localized intelligence and real-time responsiveness in embedded applications. This figure outlines key aspects of TinyML, including the challenges of resource limitations, example applications, and the benefits of on-device machine learning.\n:::\n\n### Extreme Resource Constraints {#sec-ml-systems-extreme-resource-constraints-b788}\n\nTinyML operates at hardware extremes: Arduino Nano 33 BLE Sense (256KB RAM, 1MB Flash, 0.02-0.04W, $35) and ESP32-CAM (520KB RAM, 4MB Flash, 0.05-0.25W, $10) represent 30,000-50,000x memory reduction versus cloud systems and 160,000x power reduction (@fig-TinyML-example). These constraints enable months or years of autonomous operation[^fn-on-device-training] but demand specialized algorithms delivering acceptable performance at <1 TOPS compute with microsecond response times. Devices range from palm-sized to 5x5mm chips[^fn-device-size], enabling ubiquitous sensing in previously impossible contexts.\n\n[^fn-on-device-training]: **On-Device Training Constraints**: Microcontrollers rarely support full training due to memory limitations. Instead, they use transfer learning with minimal on-device adaptation or federated learning aggregation.\n\n[^fn-device-size]: **TinyML Device Scale**: The smallest ML-capable devices measure just 5x5mm (Syntiant NDP chips). Google's Coral Dev Board Mini (40x48mm) includes WiFi and full Linux capability.\n\n![**TinyML System Scale**: These device kits exemplify the extreme miniaturization achievable with TinyML, enabling deployment of machine learning on resource-constrained devices with limited power and memory. such compact systems broaden the applicability of ML to previously inaccessible edge applications, including wearable sensors and embedded IoT devices. Source: [@warden2018speech]](images/png/tiny_ml.png){#fig-TinyML-example}\n\n### TinyML Advantages and Operational Trade-offs {#sec-ml-systems-tinyml-advantages-operational-tradeoffs-db08}\n\nTinyML's extreme resource constraints enable unique advantages impossible at other scales. Microsecond-level latency eliminates all transmission overhead, achieving 10-100μs response times that enable applications requiring sub-millisecond decisions: industrial vibration monitoring processes 10kHz sampling at under 50μs latency, audio wake-word detection analyzes 16kHz audio streams under 100μs, and precision manufacturing systems inspect over 1000 parts per minute. Economic advantages prove transformative for massive-scale deployments: complete ESP32-CAM systems cost $8-12, enabling 1000-sensor deployments for $10,000 versus $500,000-1,000,000 for cellular alternatives. Agricultural monitoring can instrument buildings for $5,000 versus $50,000+ for camera-based systems, while city-scale networks of 100,000 sensors become economically viable at $1-2 million versus $50-100 million for edge alternatives. Energy efficiency enables 1-10 year operation on coin-cell batteries consuming just 1-10mW, supporting applications like wildlife tracking for years without recapture, structural health monitoring embedded in concrete during construction, and agricultural sensors deployed where power infrastructure doesn't exist. Energy harvesting from solar, vibration, or thermal sources can even enable perpetual operation. Privacy surpasses all other paradigms through physical data confinement—data never leaves the sensor, providing mathematical guarantees impossible in networked systems regardless of encryption strength.\n\nThese capabilities require substantial trade-offs. Computational constraints impose severe limits: microcontrollers provide 256KB-2MB RAM versus smartphones' 12-24GB (a 5,000-50,000x difference), forcing models to remain under 100-500KB with 10,000-100,000 parameters compared to mobile's 1-10 million parameters. Development complexity requires expertise spanning neural network optimization, hardware-level memory management, embedded toolchains, and specialized debugging using oscilloscopes and JTAG debuggers across diverse microcontroller architectures. Model accuracy suffers from extreme compression: TinyML models typically achieve 70-85% of cloud model accuracy versus mobile's 90-95%, limiting suitability for applications requiring high precision. Deployment inflexibility constrains adaptation, as devices typically run single fixed models requiring power-intensive firmware flashing for updates that risk bricking devices. With operational lifetimes spanning years, initial deployment decisions become critical. Ecosystem fragmentation[^fn-model-compression] across microcontroller vendors and ML frameworks creates substantial development overhead and platform lock-in challenges.\n\n[^fn-model-compression]: **TinyML Model Optimization**: Specialized techniques dramatically reduce model size. A typical 50MB smartphone model might optimize to 250KB for microcontroller deployment while retaining 95% accuracy (detailed in @sec-model-optimizations).\n\n### Environmental and Health Monitoring {#sec-ml-systems-environmental-health-monitoring-c9b0}\n\nTinyML succeeds remarkably across domains where its unique advantages—ultra-low power, minimal cost, and complete data privacy—enable applications impossible with other paradigms. Industrial predictive maintenance demonstrates TinyML's ability to transform traditional infrastructure through distributed intelligence. Manufacturing facilities deploy thousands of vibration sensors operating continuously for 5-10 years on coin-cell batteries while consuming less than 2mW average power. These sensors cost $15-50 compared to traditional wired sensors at $500-2,000 per point, reducing deployment costs from $5-20 million to $150,000-500,000 for 10,000 monitoring points. Local anomaly detection provides 7-14 day advance warning of equipment failures, enabling companies to achieve 25-45% reductions in unplanned downtime.\n\nWake-word detection represents TinyML's most visible consumer application, with billions of devices employing always-listening capabilities at under 1mW continuous power consumption. These systems process 16kHz audio through neural networks containing 5,000-20,000 parameters compressed to 10-50KB, detecting wake phrases with over 95% accuracy. Amazon Echo devices use dedicated TinyML chips like the AML05 that consume less than 10mW for detection, only activating the main processor when wake words trigger—reducing average power consumption by 10-20x[^fn-fitness-trackers].\n\nPrecision agriculture leverages TinyML's economic advantages where traditional solutions prove cost-prohibitive. Monitoring 100 hectares requires approximately 1,000 monitoring points, which TinyML enables for $15,000-30,000 compared to $100,000-200,000+ for cellular-connected alternatives. These sensors operate 3-5 years on batteries while analyzing temporal patterns locally, transmitting only actionable insights rather than raw data streams.\n\nWildlife conservation demonstrates TinyML's transformative potential for remote environmental monitoring. Researchers deploy solar-powered audio sensors consuming 100-500mW that process continuous audio streams for species identification. By performing local analysis, these systems reduce satellite transmission requirements from 4.3GB per day to 400KB of detection summaries, a 10,000x reduction that makes large-scale deployments of 100-1,000 sensors economically feasible. Medical wearables achieve FDA-cleared cardiac monitoring with 95-98% sensitivity while processing 250-500 ECG samples per second at under 5mW power consumption. This efficiency enables week-long continuous monitoring versus hours for smartphone-based alternatives, while reducing diagnostic costs from $2,000-5,000 for traditional in-lab studies to under $100 for at-home testing.\n\n[^fn-fitness-trackers]: **TinyML in Fitness Trackers**: Apple Watch detects falls using accelerometer data and on-device ML, automatically calling emergency services. The algorithm analyzes motion patterns in real-time using <1mW power.\n\n## Hybrid Architectures: Combining Paradigms {#sec-ml-systems-hybrid-architectures-combining-paradigms-c1f2}\n\nOur examination of individual deployment paradigms—from cloud's massive computational power to tiny ML's ultra-efficient sensing—reveals a spectrum of engineering trade-offs, each with distinct advantages and limitations. Cloud ML maximizes algorithmic sophistication but introduces latency and privacy constraints. Edge ML reduces latency but requires dedicated infrastructure and constrains computational resources. Mobile ML prioritizes user experience but operates within strict battery and thermal limitations. TinyML achieves ubiquity through extreme efficiency but severely constrains model complexity. Each paradigm occupies a distinct niche, optimized for specific constraints and use cases.\n\nYet in practice, production systems rarely confine themselves to a single paradigm, as the limitations of each approach create opportunities for complementary integration. A voice assistant that uses tiny ML for wake-word detection, mobile ML for local speech recognition, edge ML for contextual processing, and cloud ML for complex natural language understanding demonstrates a more powerful approach. Hybrid Machine Learning formalizes this integration strategy, creating unified systems that leverage each paradigm's complementary strengths while mitigating individual limitations.\n\n::: {.callout-definition title=\"Hybrid ML\"}\n\n***Hybrid Machine Learning (Hybrid ML)*** is the integration of _multiple deployment paradigms_ into unified systems, strategically distributing workloads across _computational tiers_ to achieve _scalability_, _privacy_, and _performance_ impossible with single-paradigm approaches.\n:::\n\n### Multi-Tier Integration Patterns {#sec-ml-systems-multitier-integration-patterns-c96b}\n\nHybrid ML design patterns provide reusable architectural solutions for integrating paradigms effectively. Each pattern represents a strategic approach to distributing ML workloads across computational tiers, optimized for specific trade-offs in latency, privacy, resource efficiency, and scalability.\n\nThis analysis identifies five essential patterns that address common integration challenges in hybrid ML systems.\n\n#### Train-Serve Split {#sec-ml-systems-trainserve-split-b9a1}\n\nOne of the most common hybrid patterns is the train-serve split, where model training occurs in the cloud but inference happens on edge, mobile, or tiny devices. This pattern takes advantage of the cloud's vast computational resources for the training phase while benefiting from the low latency and privacy advantages of on-device inference[^fn-train-serve-split]. For example, smart home devices often use models trained on large datasets in the cloud but run inference locally to ensure quick response times and protect user privacy. In practice, this might involve training models on powerful cloud systems like TPU Pods with exaflop-scale compute and hundreds of terabytes of memory, before deploying optimized versions to edge servers or embedded edge devices for efficient inference. Similarly, mobile vision models for computational photography are typically trained on powerful cloud infrastructure but deployed to run efficiently on phone hardware.\n\n[^fn-train-serve-split]: **Train-Serve Split Economics**: Training large models can cost $1-10M (GPT-3: $4.6M in compute costs) but inference costs <$0.01 per query when deployed efficiently [@brown2020language]. This 1,000,000x cost difference drives the pattern of expensive cloud training with cost-effective edge inference.\n\n#### Hierarchical Processing {#sec-ml-systems-hierarchical-processing-17a5}\n\nHierarchical processing creates a multi-tier system where data and intelligence flow between different levels of the ML stack. This pattern effectively combines the capabilities of Cloud ML systems (like the large-scale training infrastructure discussed in previous sections) with multiple Edge ML systems (like edge servers and embedded devices from our edge deployment examples) to balance central processing power with local responsiveness. In industrial IoT applications, tiny sensors might perform basic anomaly detection, edge devices aggregate and analyze data from multiple sensors, and cloud systems handle complex analytics and model updates. For instance, we might see ESP32-CAM devices (from our TinyML examples) performing basic image classification at the sensor level with their minimal 520 KB RAM, feeding data up to edge servers or embedded systems for more sophisticated analysis, and ultimately connecting to cloud infrastructure for complex analytics and model updates.\n\nThis hierarchy allows each tier to handle tasks appropriate to its capabilities. TinyML devices handle immediate, simple decisions; edge devices manage local coordination; and cloud systems tackle complex analytics and learning tasks. Smart city installations often use this pattern, with street-level sensors feeding data to neighborhood-level edge processors, which in turn connect to city-wide cloud analytics.\n\n#### Progressive Deployment {#sec-ml-systems-progressive-deployment-c8b7}\n\nProgressive deployment creates tiered intelligence architectures by adapting models across computational tiers through systematic compression. A model might start as a large cloud version, then be progressively optimized for edge servers, mobile devices, and finally tiny sensors using techniques detailed in @sec-model-optimizations.\n\nAmazon Alexa exemplifies this pattern: wake-word detection uses <1KB models on TinyML devices consuming <1mW, edge processing handles simple commands with 1-10MB models at 1-10W, while complex natural language understanding requires GB+ models in cloud infrastructure. This tiered approach reduces cloud inference costs by 95% while maintaining user experience.\n\nHowever, progressive deployment introduces operational complexity: model versioning across tiers, ensuring consistency between generations, managing failure cascades during connectivity loss, and coordinating updates across millions of devices. Production teams must maintain specialized expertise spanning TinyML optimization, edge orchestration, and cloud scaling.\n\n#### Federated Learning {#sec-ml-systems-federated-learning-9850}\n\nFederated learning[^fn-federated-architecture] enables learning from distributed data while maintaining privacy. Google's production system processes 6 billion mobile keyboards, training improved models while keeping typed text local. Each training round involves 100-10,000 devices contributing model updates, requiring orchestration to manage device availability, network conditions, and computational heterogeneity.\n\nProduction deployments face significant operational challenges: device dropout rates of 50-90% during training rounds, network bandwidth constraints limiting update frequency, and differential privacy mechanisms preventing information leakage. Aggregation servers must handle intermittent connectivity, varying device capabilities, and ensure convergence despite non-IID data distributions. This requires specialized monitoring infrastructure to track distributed training progress and debug issues without accessing raw data.\n\n[^fn-federated-architecture]: **Federated Learning Architecture**: Coordinates learning across millions of devices without centralizing data [@mcmahan2017federated]. Google's federated learning processes 6 billion mobile keyboards, training improved models while keeping all typed text local. Each round involves 100-10,000 devices contributing model updates.\n\n#### Collaborative Learning {#sec-ml-systems-collaborative-learning-6f7b}\n\nCollaborative learning enables peer-to-peer learning between devices at the same tier, often complementing hierarchical structures.[^fn-tiered-voice] Autonomous vehicle fleets, for example, might share learning about road conditions or traffic patterns directly between vehicles while also communicating with cloud infrastructure. This horizontal collaboration allows systems to share time-sensitive information and learn from each other's experiences without always routing through central servers.\n\n[^fn-tiered-voice]: **Tiered Voice Processing**: Amazon Alexa uses a 3-tier system: tiny wake-word detection on-device (<1KB model), edge processing for simple commands (1-10MB models), and cloud processing for complex queries (GB+ models). This reduces cloud costs by 95% while maintaining functionality.\n\n### Production System Case Studies {#sec-ml-systems-production-system-case-studies-17a6}\n\nReal-world implementations integrate multiple design patterns into cohesive solutions rather than applying them in isolation. Production ML systems form interconnected networks where each paradigm plays a specific role while communicating with others, following integration patterns that leverage the strengths and address the limitations established in our four-paradigm framework (@sec-ml-systems-deployment-spectrum-38d0).\n\n@fig-hybrid illustrates these key interactions through specific connection types: \"Deploy\" paths show how models flow from cloud training to various devices, \"Data\" and \"Results\" show information flow from sensors through processing stages, \"Analyze\" shows how processed information reaches cloud analytics, and \"Sync\" demonstrates device coordination. Notice how data generally flows upward from sensors through processing layers to cloud analytics, while model deployments flow downward from cloud training to various inference points. The interactions aren't strictly hierarchical. Mobile devices might communicate directly with both cloud services and tiny sensors, while edge systems can assist mobile devices with complex processing tasks.\n\n::: {#fig-hybrid fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\nLine/.style={line width=1.0pt,black!50,text=black},\n  Box/.style={inner xsep=2pt,\n    node distance=0.6,\n    draw=GreenLine, line width=0.75pt,\n    fill=GreenL,\n    text width=20mm,align=flush center,\n    minimum width=20mm, minimum height=9mm\n  },\n   Text/.style={inner xsep=2pt,\n    draw=none, line width=0.75pt,\n    fill=TextColor,\n    font=\\footnotesize\\usefont{T1}{phv}{m}{n},\n    align=flush center,\n    minimum width=7mm, minimum height=5mm\n  },\n  }\n\n\\node[Box,fill=RedL,draw=RedLine](G2){Training};\n\\node[Box,fill=none,draw=none,below =1.2 of G2](A){};\n\\node[Box,node distance=2.25, left=of A](B2){Inference};\n\\node[Box,node distance=2.25,left=of B2,fill=cyan!20,draw=BlueLine](B1){Inference};\n\\node[Box,node distance=2.25, right=of A,fill=orange!20,draw=OrangeLine](B3){Inference};\n%\n\\node[Box,node distance=1.15, below=of B1,fill=cyan!20,draw=BlueLine](1DB1){Processing};\n\\node[Box,node distance=1.15, below=of B3,fill=orange!20,draw=OrangeLine](1DB3){Processing};\n\\path[](1DB3)-|coordinate(S)(G2);\n\\node[Box,node distance=1.5,fill=RedL,draw=RedLine]at(S)(1DB2){Analytics};\n\\path[](G2)-|coordinate(SS)(B2);\n\\node[Box](G1)at(SS){Sensors};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=6mm,anchor= west,\n       yshift=1mm,fill=BackColor,fit=(G1)(B2),line width=0.75pt](BB2){};\n\\node[below=3pt of  BB2.north,anchor=north]{TinyML};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=7mm,anchor= west,\n       yshift=0mm,fill=BackColor,fit=(G2)(1DB2),line width=0.75pt](BB2){};\n\\node[below=3pt of  BB2.north,anchor=north]{Cloud ML};\n%\n\\draw[Line,-latex](G1.west)--++(180:0.9)|-node[Text,pos=0.1]{Data}(B2);\n\\draw[Line,-latex](G2)--++(270:1.20)-|(B2);\n\\draw[Line,-latex](G2)--++(270:1.20)-|(B3);\n\\draw[Line,-latex](G2)--node[Text,pos=0.46]{Deploy}++(270:1.20)-|(B1);\n%\n\\draw[Line,-latex](B1)--node[Text,pos=0.5]{Results}(1DB1);\n\\draw[Line,-latex](B2)|-node[Text,pos=0.75]{Results}(1DB1.10);\n%\n\\draw[Line,-latex](B1.330)--++(270:0.9)-|node[Text,pos=0.2]{Assist}(B3.220);\n\\draw[Line,-latex](B2.east)--node[Text,pos=0.5]{Sync}++(0:5.4)|-(1DB3.170);\n%\n\\draw[Line,-latex](1DB1.350)--node[Text,pos=0.75]{Results}(1DB2.190);\n\\draw[Line,-latex](1DB3.190)--node[Text,pos=0.50]{Data}(1DB2.350);\n\\draw[Line,-latex](B3.290)--node[Text,pos=0.5]{Results}(1DB3.70);\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=5mm,anchor= west,\n      yshift=-2mm,fill=BackColor,fit=(B1)(1DB1),line width=0.75pt](BB2){};\n\\node[above=3pt of  BB2.south,anchor=south]{Edge ML};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=4mm,inner ysep=5mm,anchor= west,\n      yshift=-2mm,fill=BackColor,fit=(B3)(1DB3),line width=0.75pt](BB2){};\n\\node[above=3pt of  BB2.south,anchor=south]{Mobile ML};\n\\end{tikzpicture}\n```\n**Hybrid System Interactions**: Data flows upward from sensors through processing layers to cloud analytics for insights, while trained models deploy downward from the cloud to enable inference at the edge, mobile, and TinyML devices. These connection types (deploy, data/results, analyze, and sync) establish a distributed architecture where each paradigm contributes unique capabilities to the overall machine learning system.\n:::\n\nProduction systems demonstrate these integration patterns across diverse applications where no single paradigm could deliver the required functionality. Industrial defect detection exemplifies model deployment patterns: cloud infrastructure trains vision models on datasets from multiple facilities, then distributes optimized versions to edge servers managing factory operations, tablets for quality inspectors, and embedded cameras on manufacturing equipment. This demonstrates how a single ML solution flows from centralized training to inference points at multiple computational scales.\n\nAgricultural monitoring illustrates hierarchical data flow: soil sensors perform local anomaly detection, transmit results to edge processors that aggregate data from dozens of sensors, which then route insights to cloud infrastructure for farm-wide analytics while simultaneously updating farmers' mobile applications. Information traverses upward through processing layers, with each tier adding analytical sophistication appropriate to its computational resources.\n\nFitness trackers exemplify gateway patterns between TinyML and mobile devices: wearables continuously monitor activity using algorithms optimized for microcontroller execution, sync processed data to smartphones that combine metrics from multiple sources, then transmit periodic updates to cloud infrastructure for long-term analysis. This enables tiny devices to participate in large-scale systems despite lacking direct network connectivity.\n\nThese integration patterns reveal how deployment paradigms complement each other through orchestrated data flows, model deployments, and cross-tier assistance. Industrial systems compose capabilities from Cloud, Edge, Mobile, and TinyML into distributed architectures that optimize for latency, privacy, cost, and operational requirements simultaneously. The interactions between paradigms often determine system success more than individual component capabilities.\n\n## Shared Principles Across Deployment Paradigms {#sec-ml-systems-shared-principles-across-deployment-paradigms-915d}\n\nDespite their diversity, all ML deployment paradigms share core principles that enable systematic understanding and effective hybrid combinations. @fig-ml-systems-convergence illustrates how implementations spanning cloud to tiny devices converge on core system challenges: managing data pipelines, balancing resource constraints, and implementing reliable architectures. This convergence explains why techniques transfer effectively between paradigms and hybrid approaches work successfully in practice.\n\n::: {#fig-ml-systems-convergence fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n}]\n\\tikzset{\nLine/.style={line width=1.0pt,black!50,text=black},\n  Box/.style={inner xsep=2pt,\n    node distance=0.6,\n    draw=GreenLine, line width=0.75pt,\n    fill=GreenL,\n    text width=30mm,align=flush center,\n    minimum width=30mm, minimum height=13mm\n  },\n  Box1/.style={inner xsep=2pt,\n    node distance=0.8,\n    draw=BlueLine, line width=0.75pt,\n    fill=BlueL,\n    text width=36mm,align=flush center,\n    minimum width=40mm, minimum height=13mm\n  },\n}\n\n\\begin{scope}[anchor=west]\n\\node[Box](B1){Cloud ML Data Centers Training at Scale};\n\\node[Box,right=of B1](B2){Edge ML Local Processing Inference Focus};\n\\node[Box,right=of B2](B3){Mobile ML Personal DevicesUser Applications};\n\\node[Box, right=of B3](B4){TinyML Embedded Systems Resource Constrained};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,\n      anchor=west,yshift=2mm,fill=BackColor,\n      fit=(B1)(B2)(B3)(B4),line width=0.75pt](BB){};\n\\node[below=11pt of  BB.north east,anchor=east]{ML System Implementations};\n\\end{scope}\n%\n\\begin{scope}[shift={(0.4,-2.8)}, anchor=west]\n\\node[Box1](2B1){Data Pipeline Collection -- Processing -- Deployment};\n\\node[Box1,right=of 2B1](2B2){Resource Management Compute -- Memory -- Energy -- Network};\n\\node[Box1,right=of 2B2](2B3){System Architecture Models -- Hardware -- Software};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,\n      anchor= west,yshift=-1mm,fill=BackColor,fit=(2B1)(2B2)(2B3),line width=0.75pt](BB2){};\n\\node[above=8pt of  BB2.south east,anchor=east]{Core System Principles};\n\\end{scope}\n%\n\\begin{scope}[shift={(0.4,-6.0)}, anchor=west]\n\\node[Box1, fill=VioletL,draw=VioletLine](3B1){Optimization \\& Efficiency Model -- Hardware -- Energy};\n\\node[Box1,right=of 3B1, fill=VioletL,draw=VioletLine](3B2){Operational Aspects Deployment -- Monitoring -- Updates};\n\\node[Box1,right=of 3B2, fill=VioletL,draw=VioletLine](3B3){Trustworthy AI Security -- Privacy -- Reliability};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,\n       anchor= west,yshift=-1mm,fill=BackColor,fit=(3B1)(3B2)(3B3),line width=0.75pt](BB3){};\n\\node[above=8pt of  BB3.south east,anchor=east]{System Considerations};\n\\end{scope}\n%\n\\draw[-latex,Line](B1.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B2.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B3.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B4.south)--++(270:0.75)-|(2B1);\n\\draw[-latex,Line](B2.south)--++(270:0.75)-|(2B2);\n\\draw[-latex,Line](B3.south)--++(270:0.75)-|(2B3);\n%\n\\draw[-latex,Line](2B1.south)--++(270:0.95)-|(3B1);\n\\draw[-latex,Line](2B2.south)--++(270:0.95)-|(3B1);\n\\draw[-latex,Line](2B3.south)--++(270:0.95)-|(3B1);\n\\draw[-latex,Line](2B2.south)--++(270:0.95)-|(3B2);\n\\draw[-latex,Line](2B3.south)--++(270:0.95)-|(3B3);\n\\end{tikzpicture}\n```\n**Convergence of ML Systems**: Diverse machine learning deployments (cloud, edge, mobile, and tiny) share foundational principles in data pipelines, resource management, and system architecture, enabling hybrid solutions and systematic design approaches. Understanding these shared principles allows practitioners to adapt techniques across different paradigms and build cohesive, efficient ML workflows despite varying constraints and optimization goals.\n:::\n\n@fig-ml-systems-convergence reveals three distinct layers of abstraction that unify ML system design across deployment contexts.\n\nThe top layer represents ML system implementations, the four deployment paradigms examined throughout this chapter. Cloud ML operates in data centers with training at scale, Edge ML performs local processing focused on inference, Mobile ML runs on personal devices for user applications, and TinyML executes on embedded systems under severe resource constraints. Despite their apparent differences, these implementations share deeper commonalities that emerge in the underlying layers.\n\nThe middle layer identifies core system principles that unite all paradigms. Data pipeline management (@sec-data-engineering) governs information flow from collection through deployment, maintaining consistent patterns whether processing petabytes in cloud data centers or kilobytes on microcontrollers. Resource management creates universal challenges in balancing competing demands for computation, memory, energy, and network capacity across all scales. System architecture principles guide the integration of models, hardware, and software components regardless of deployment context. These foundational principles remain remarkably consistent even as implementations vary by orders of magnitude in available resources.\n\nThe bottom layer shows how system considerations manifest these principles across practical dimensions. Optimization and efficiency strategies (@sec-model-optimizations) take different forms at each scale: cloud GPU cluster training, edge model compression, mobile thermal management, and TinyML numerical precision, yet all pursue maximizing performance within available resources. Operational aspects (@sec-ml-operations) address deployment, monitoring, and updates with paradigm-specific approaches that tackle fundamentally similar challenges. Trustworthy AI requirements for security, privacy, and reliability apply universally, though implementation techniques necessarily adapt to each deployment context.\n\nThis three-layer structure explains why techniques transfer effectively between scales. Cloud-trained models deploy successfully to edge devices because training and inference optimize similar objectives under different constraints. Mobile optimization insights inform cloud efficiency strategies because both manage the same fundamental resource trade-offs. TinyML innovations drive cross-paradigm advances precisely because extreme constraints force solutions to core problems that exist at all scales. Hybrid approaches work effectively (train-serve splits, hierarchical processing, federated learning) because underlying principles align across paradigms, enabling seamless integration despite vast differences in available resources.\n\n## Comparative Analysis and Selection Framework {#sec-ml-systems-comparative-analysis-selection-framework-832e}\n\nBuilding from this understanding of shared principles, systematic comparison across deployment paradigms reveals the precise trade-offs that should drive deployment decisions and highlights scenarios where each paradigm excels, providing practitioners with analytical frameworks for making informed architectural choices.\n\nThe relationship between computational resources and deployment location forms one of the most important comparisons across ML systems. As we move from cloud deployments to tiny devices, we observe a dramatic reduction in available computing power, storage, and energy consumption. Cloud ML systems, with their data center infrastructure, can leverage virtually unlimited resources, processing data at the scale of petabytes and training models with billions of parameters. Edge ML systems, while more constrained, still offer significant computational capability through specialized hardware like edge GPUs and neural processing units. Mobile ML represents a middle ground, balancing computational power with energy efficiency on devices like smartphones and tablets. At the far end of the spectrum, TinyML operates under severe resource constraints, often limited to kilobytes of memory and milliwatts of power consumption.\n\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Aspect**                 | **Cloud ML**                             | **Edge ML**                            | **Mobile ML**                 | **TinyML**                                            |\n+:===========================+:=========================================+:=======================================+:==============================+:======================================================+\n| **Performance**            |                                          |                                        |                               |                                                       |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Processing Location**    | Centralized cloud servers (Data Centers) | Local edge devices (gateways, servers) | Smartphones and tablets       | Ultra-low-power microcontrollers and embedded systems |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Latency**                | High (100 ms-1000 ms+)                   | Moderate (10-100 ms)                   | Low-Moderate (5-50 ms)        | Very Low (1-10 ms)                                    |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Compute Power**          | Very High (Multiple GPUs/TPUs)           | High (Edge GPUs)                       | Moderate (Mobile NPUs/GPUs)   | Very Low (MCU/tiny processors)                        |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Storage Capacity**       | Unlimited (petabytes+)                   | Large (terabytes)                      | Moderate (gigabytes)          | Very Limited (kilobytes-megabytes)                    |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Energy Consumption**     | Very High (kW-MW range)                  | High (100 s W)                         | Moderate (1-10 W)             | Very Low (mW range)                                   |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Scalability**            | Excellent (virtually unlimited)          | Good (limited by edge hardware)        | Moderate (per-device scaling) | Limited (fixed hardware)                              |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Operational**            |                                          |                                        |                               |                                                       |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Data Privacy**           | Basic-Moderate (Data leaves device)      | High (Data stays in local network)     | High (Data stays on phone)    | Very High (Data never leaves sensor)                  |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Connectivity Required**  | Constant high-bandwidth                  | Intermittent                           | Optional                      | None                                                  |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Offline Capability**     | None                                     | Good                                   | Excellent                     | Complete                                              |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Real-time Processing**   | Dependent on network                     | Good                                   | Very Good                     | Excellent                                             |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Deployment**             |                                          |                                        |                               |                                                       |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Cost**                   | High ($1000s+/month)                     | Moderate ($100s-1000s)                 | Low ($0-10s)                  | Very Low ($1-10s)                                     |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Hardware Requirements**  | Cloud infrastructure                     | Edge servers/gateways                  | Modern smartphones            | MCUs/embedded systems                                 |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Development Complexity** | High (cloud expertise needed)            | Moderate-High (edge+networking)        | Moderate (mobile SDKs)        | High (embedded expertise)                             |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n| **Deployment Speed**       | Fast                                     | Moderate                               | Fast                          | Slow                                                  |\n+----------------------------+------------------------------------------+----------------------------------------+-------------------------------+-------------------------------------------------------+\n\n: **Deployment Locations**: Machine learning systems vary in where computation occurs, from centralized cloud servers to local edge devices and ultra-low-power TinyML chips, each impacting latency, bandwidth, and energy consumption. This table categorizes these deployments by their processing location and associated characteristics, enabling informed decisions about system architecture and resource allocation. {#tbl-big_vs_tiny}\n\n@tbl-big_vs_tiny quantifies these paradigm differences across performance, operational, and deployment dimensions, revealing clear gradients in latency (cloud: 100-1000ms → edge: 10-100ms → mobile: 5-50ms → tiny: 1-10ms) and privacy guarantees (strongest with TinyML's complete local processing).\n\n@fig-op_char visualizes performance and operational characteristics through radar plots. Plot a) contrasts compute power and scalability (Cloud ML's strengths) against latency and energy efficiency (TinyML's advantages), with Edge and Mobile ML occupying intermediate positions.\n\n::: {#fig-op_char fig-env=\"figure\" fig-pos=\"htb\"}\n```{.tikz}\n\\begin{tikzpicture}[font=\\usefont{T1}{phv}{m}{n}]\n%\\node[anchor=center]at(13.13,3.22){\\includegraphics[scale=0.31]{1}};\n\\definecolor{myblue}{RGB}{31,119,180}\n\\definecolor{myorange}{RGB}{255,127,14}\n\\definecolor{mygreen}{RGB}{44,160,44}\n\\definecolor{myred}{RGB}{214,39,40}\n\\pgfplotsset{myaxis/.style={\n   y axis line style={draw=none},\n   x axis line style={draw=black,line width=1 pt},\n    width=8cm,\n    height=8cm,\n    grid=both,\n    grid style={black!30,dashed},\n    tick align=inside,\n    tick style={draw=none},\n    ymin=0, ymax=10,\n    ytick={1,3,5,7,9},\n    yticklabels={},\n    xtick={0,90,180,270},\n    xticklabel style={align=left,font=\\fontsize{8pt}{9}\\selectfont\\usefont{T1}{phv}{m}{n}},\n % yticklabel style={font=\\fontsize{7pt}{7}\\selectfont\\usefont{T1}{phv}{m}{n}},\n     yticklabel style={\n     rotate around={50:(axis cs:0,0)},\n     anchor=center\n    },\n   xlabel style={font=\\fontsize{7pt}{7}\\selectfont\\usefont{T1}{phv}{m}{n},rotate=30},\n   label distance=5pt,\n   legend style={at={(1.25,1)}, anchor=north},\n   legend cell align=left,\n   legend style={fill=BrownL!30,draw=BrownLine,row sep=2.1pt,\n   font=\\fontsize{7pt}{7}\\selectfont\\usefont{T1}{phv}{m}{n}},\n      cycle list={\n     {myblue,line width=1.5pt,fill=myblue!70,fill opacity=0.9},\n     {mygreen,line width=1.5pt,fill=mygreen!70,fill opacity=0.4},\n     {myorange,line width=1.5pt,fill=myorange!20,fill opacity=0.4},\n     {myred,line width=1.5pt,fill=myred!70,fill opacity=0.4},\n  },\n    after end axis/.code={\n      % manua y-tick labele on 50°\n      \\foreach \\R in {1,3,5,7,9}{\n      \\pgfmathtruncatemacro{\\newR}{\\R + 0.5} %\n        \\node[\n          font=\\footnotesize\\usefont{T1}{phv}{m}{n},\n          anchor=base\n        ]\n        at (axis cs:50,\\newR) {\\R};\n      }\n    },\n    legend image code/.code={\n      % rectangle in Legend\n      \\draw[fill=#1,draw=none,fill opacity=1]\n        (0pt,-2pt) rectangle (4mm,3pt);\n    }\n    }}\n %left graph\n\\begin{scope}[local bounding box=GR1,shift={(0,0)}]\n\\begin{polaraxis}[myaxis,\n    xticklabels={Compute\\\\ Power, Latency, Scalability,Energy Consumption},\n]\n% Cloud ML\n\\addplot+[]  coordinates {(0,10) (90,2) (180,10) (270,3) (360,10)};\n% Edge ML\n\\addplot+[] coordinates {(0,8) (90,7) (180,8) (270,5) (360,8)};\n% Mobile ML\n\\addplot+[] coordinates {(0,6) (90,8) (180,7) (270,7) (360,6)};\n% TinyML\n\\addplot+[]  coordinates {(0,3) (90,9) (180,5) (270,10) (360,3)};\n\\legend{Cloud ML, Edge ML, Mobile ML, TinyML}\n\\addplot[draw=myblue,line width=1.5pt]   coordinates {(0,10) (90,2) (180,10) (270,3) (360,10)};\n\\addplot[draw=mygreen,line width=1.5pt]  coordinates {(0,8) (90,7) (180,8) (270,5) (360,8)};\n\n\\end{polaraxis}\n\\end{scope}\n\\node[below=2mm of GR1,xshift=-5mm]{\\large a)};\n %right graph\n\\begin{scope}[local bounding box=GR2,shift={(10,0)}]\n\\begin{polaraxis}[myaxis,\nxticklabels={Connectivity\\\\ Dependency, Data Privacy, Real-time\\\\ Processing,Offline Capability},\n]\n% Cloud ML\n\\addplot+[]  coordinates {(0,2) (90,3) (180,2) (270,2) (360,2)};\n% Edge ML\n\\addplot+[] coordinates {(0,7) (90,7) (180,8) (270,6) (360,7)};\n% Mobile ML\n\\addplot+[] coordinates {(0,8) (90,9) (180,7) (270,8) (360,8)};\n% TinyML\n\\addplot+[]  coordinates {(0,10) (90,10) (180,10) (270,10) (360,10)};\n%\\legend{Cloud ML, Edge ML, Mobile ML, TinyML}\n\\addplot[draw=myblue,line width=1.5pt]  coordinates {(0,2) (90,3) (180,2) (270,2) (360,2)};\n\\addplot[draw=mygreen,line width=1.5pt] coordinates {(0,7) (90,7) (180,8) (270,6) (360,7)};\n\\end{polaraxis}\n\\end{scope}\n\\node[below=2mm of GR2]{\\large b)};\n\\end{tikzpicture}\n```\n**ML System Trade-Offs**: Radar plots quantify performance and operational characteristics across cloud, edge, mobile, and TinyML paradigms, revealing inherent trade-offs between compute power, latency, energy consumption, and scalability. These visualizations enable informed selection of the most suitable deployment approach based on application-specific constraints and priorities.\n:::\n\nPlot b) emphasizes operational dimensions where TinyML excels (privacy, connectivity independence, offline capability) versus Cloud ML's dependency on centralized infrastructure and constant connectivity.\n\nDevelopment complexity varies inversely with hardware capability: Cloud and TinyML require deep expertise (cloud infrastructure and embedded systems respectively), while Mobile and Edge leverage more accessible SDKs and tooling. Cost structures show similar inversion: Cloud incurs ongoing operational expenses ($1000s+/month), Edge requires moderate upfront investment ($100s-1000s), Mobile leverages existing devices ($0-10s), and TinyML minimizes hardware costs ($1-10s) while demanding higher development investment.\n\nUnderstanding these trade-offs proves crucial for selecting appropriate deployment strategies that align application requirements with paradigm capabilities.\n\nA critical pitfall in deployment selection involves choosing paradigms based solely on model accuracy metrics without considering system-level constraints. Teams often select deployment strategies by comparing model accuracy in isolation, overlooking critical system requirements that determine real-world viability. A cloud-deployed model achieving 99% accuracy becomes useless for autonomous emergency braking if network latency exceeds reaction time requirements. Similarly, a sophisticated edge model that drains a mobile device's battery in minutes fails despite superior accuracy. Successful deployment requires evaluating multiple dimensions simultaneously: latency requirements, power budgets, network reliability, data privacy regulations, and total cost of ownership. Establish these constraints before model development to avoid expensive architectural pivots late in the project.\n\n## Decision Framework for Deployment Selection {#sec-ml-systems-decision-framework-deployment-selection-f748}\n\nSelecting the appropriate deployment paradigm requires systematic evaluation of application constraints rather than organizational biases or technology trends. @fig-mlsys-playbook-flowchart provides a hierarchical decision framework that filters options through critical requirements: privacy (can data leave the device?), latency (sub-10ms response needed?), computational demands (heavy processing required?), and cost constraints (budget limitations?). This structured approach ensures deployment decisions emerge from application requirements, grounded in the physical constraints (@sec-ml-systems-deployment-paradigm-foundations-0c17) and quantitative comparisons (@sec-ml-systems-comparative-analysis-selection-framework-832e) established earlier.\n\n::: {#fig-mlsys-playbook-flowchart fig-env=\"figure\" fig-pos=\"!t\"}\n```{.tikz}\n\\resizebox{.7\\textwidth}{!}{%\n\\begin{tikzpicture}[font=\\small\\usefont{T1}{phv}{m}{n},line width=0.75pt]\n\\tikzset{\n  Line/.style={line width=1.0pt,black!50,text=black},\n  Box/.style={inner xsep=2pt,\n    draw=GreenLine, line width=0.65pt,\n    fill=GreenL,\n    text width=25mm,align=flush center,\n    minimum width=25mm, minimum height=9mm\n  },\n  Box1/.style={inner xsep=2pt,\n    node distance=0.5,\n    draw=BlueLine, line width=0.65pt,\n    fill=BlueL,\n    text width=33mm,align=flush center,\n    minimum width=33mm, minimum height=9mm\n  },\n  Text/.style={inner xsep=2pt,\n    draw=none, line width=0.75pt,\n    fill=TextColor,\n    font=\\footnotesize\\usefont{T1}{phv}{m}{n},\n    align=flush center,\n    minimum width=7mm, minimum height=5mm\n  },\n}\n%\n\\begin{scope}\n\\node[Box, rounded corners=12pt,fill=magenta!20](B1){Start};\n\\node[Box1,below=of B1](B2){Is privacy critical?};\n\\node[Box,below left=0.1 and 1 of B2](B3){Cloud Processing Allowed};\n\\node[Box,below right=0.1 and 1 of B2](B4){Local Processing Preferred};\n\\draw[Line,-latex](B1)--(B2);\n\\draw[Line,-latex](B2)-|node[Text,pos=0.2]{No}(B3);\n\\draw[Line,-latex](B2)-|node[Text,pos=0.2]{Yes}(B4);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=3mm,yshift=-1mm,\n       fill=BackColor,fit=(B1)(B3)(B4),line width=0.75pt](BB){};\n\\node[below=11pt of BB.north east,anchor=east]{Layer: Privacy};\n\\end{scope}\n%\n\\begin{scope}[shift={(0,-4.6)}]\n\\node[Box1](2B1){Is low latency required ($<$10 ms)?};\n\\node[Box,below left=0.1 and 1 of 2B1](2B2){Latency Tolerant};\n\\node[Box,below right=0.1 and 1 of 2B1](2B3){Tiny or Edge ML};\n\\draw[Line,-latex](2B1)-|node[Text,pos=0.2]{No}(2B2);\n\\draw[Line,-latex](2B1)-|node[Text,pos=0.2]{Yes}(2B3);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=4mm,yshift=0mm,\n       fill=BackColor,fit=(2B1)(2B2)(2B3),line width=0.75pt](BB1){};\n\\node[below=11pt of BB1.north east,anchor=east]{Layer: Performance};\n\\end{scope}\n\\draw[Line,-latex](B3)--++(270:1.1)-|(2B1.110);\n\\draw[Line,-latex](B4)--++(270:1.1)-|(2B1.70);\n%\n\\begin{scope}[shift={(0,-8.0)}]\n\\node[Box1](3B1){Does the model require significant compute?};\n\\node[Box,below left=0.1 and 1 of 3B1](3B2){Heavy Compute};\n\\node[Box,below right=0.1 and 1 of 3B1](3B3){Lightweight Processing};\n\\draw[Line,-latex](3B1)-|node[Text,pos=0.2]{Yes}(3B2);\n\\draw[Line,-latex](3B1)-|node[Text,pos=0.2]{No}(3B3);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=1mm,\n       fill=BackColor,fit=(3B1)(3B2)(3B3),line width=0.75pt](BB2){};\n\\node[below=11pt of BB2.north east,anchor=east]{Layer: Compute Needs};\n\\end{scope}\n\\draw[Line,-latex](2B2)--++(270:1.1)-|(3B1.110);\n\\draw[Line,-latex](2B3)--++(270:1.1)-|(3B1.70);\n%4\n\\begin{scope}[shift={(0,-11.4)}]\n\\node[Box1](4B1){Are there strict cost constraints?};\n\\node[Box,below left=0.1 and 1 of 4B1](4B2){Flexible Budget};\n\\node[Box,below right=0.1 and 1 of 4B1](4B3){Low-Cost Options};\n\\draw[Line,-latex](4B1)-|node[Text,pos=0.2]{No}(4B2);\n\\draw[Line,-latex](4B1)-|node[Text,pos=0.2]{Yes}(4B3);\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=4mm,yshift=2mm,\n       fill=BackColor,fit=(4B1)(4B2)(4B3),line width=0.75pt](BB3){};\n\\node[below=11pt of  BB3.north east,anchor=east]{Layer: Cost};\n\\end{scope}\n\\draw[Line,-latex](3B2)--++(270:1.1)-|(4B1.110);\n\\draw[Line,-latex](3B3)--++(270:1.1)-|(4B1.70);\n%5\n\\begin{scope}[shift={(-0.45,-14.0)},anchor=north east]\n\\node[Box,fill=magenta!20,rounded corners=12pt,text width=18mm,\n       minimum width=17mm](5B1){Cloud ML};\n\\node[Box,node distance=1.0,fill=magenta!20,rounded corners=12pt,left=of 5B1,text width=18mm,\n       minimum width=17mm](5B2){Edge ML};\n\\node[Box,node distance=1.0,fill=magenta!20, rounded corners=12pt,right=of 5B1,text width=18mm,\n       minimum width=17mm](5B3){Mobile ML};\n\\node[Box,node distance=1.0,fill=magenta!20, rounded corners=12pt,right=of 5B3,text width=18mm,\n       minimum width=17mm](5B4){TinyML};\n%\n\\scoped[on background layer]\n\\node[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=-1mm,\n       fill=BackColor,fit=(5B1)(5B2)(5B4),line width=0.75pt](BB4){};\n\\node[above=8pt of BB4.south east,anchor=east]{Layer: Deployment Options};\n\\end{scope}\n\\draw[Line,-latex](4B3)-|(5B3);\n\\draw[Line,-latex](4B3)--++(270:0.92)-|(5B4);\n\\draw[Line,-latex](4B2)--++(270:0.92)-|(5B1);\n\\draw[Line,-latex](3B2.west)--++(180:0.5)|-(5B2);\n\\end{tikzpicture}}\n```\n**Deployment Decision Logic**: This flowchart guides selection of an appropriate machine learning deployment paradigm by systematically evaluating privacy requirements and processing constraints, ultimately balancing performance, cost, and data security. Navigating the decision tree helps practitioners determine whether cloud, edge, mobile, or tiny machine learning best suits a given application.\n:::\n\nThe framework evaluates four critical decision layers sequentially. Privacy constraints form the first filter, determining whether data can be transmitted externally. Applications handling sensitive data under GDPR, HIPAA, or proprietary restrictions mandate local processing, immediately eliminating cloud-only deployments. Latency requirements establish the second constraint through response time budgets: applications requiring sub-10ms response times cannot use cloud processing, as physics-imposed network delays alone exceed this threshold. Computational demands form the third evaluation layer, assessing whether applications require high-performance infrastructure that only cloud or edge systems provide, or whether they can operate within the resource constraints of mobile or tiny devices. Cost considerations complete the framework by balancing capital expenditure, operational expenses, and energy efficiency across expected deployment lifetimes.\n\nTechnical constraints alone prove insufficient for deployment decisions. Organizational factors critically shape success by determining whether teams possess the capabilities to implement and maintain chosen paradigms. Team expertise must align with paradigm requirements: Cloud ML demands distributed systems knowledge, Edge ML requires device management capabilities, Mobile ML needs platform-specific optimization skills, and TinyML requires embedded systems expertise. Organizations lacking appropriate skills face extended development timelines and ongoing maintenance challenges that undermine technical advantages. Monitoring and maintenance capabilities similarly determine viability at scale: edge deployments require distributed device orchestration, while TinyML demands specialized firmware management that many organizations lack. Cost structures further complicate decisions through their temporal patterns: Cloud incurs recurring operational expenses favorable for unpredictable workloads, Edge requires substantial upfront investment offset by lower ongoing costs, Mobile leverages user-provided devices to minimize infrastructure expenses, and TinyML minimizes hardware and connectivity costs while demanding significant development investment.\n\nSuccessful deployment emerges from balancing technical optimization against organizational capability. Paradigm selection represents systems engineering challenges that extend well beyond pure technical requirements, encompassing team skills, operational capacity, and economic constraints. These decisions remain constrained by fundamental scaling laws explored in @sec-efficient-ai-ai-scaling-laws-a043, with operational aspects detailed in @sec-ml-operations and benchmarking approaches covered in @sec-benchmarking-ai.\n\n## Fallacies and Pitfalls {#sec-ml-systems-fallacies-pitfalls-8074}\n\nUnderstanding deployment paradigms requires recognizing common misconceptions that can lead to poor architectural decisions. These fallacies often stem from oversimplified thinking about the core trade-offs governing ML systems design.\n\n**Fallacy: \"One Paradigm Fits All\"** - The most pervasive misconception assumes that one deployment approach can solve all ML problems. Teams often standardize on cloud, edge, or mobile solutions without considering application-specific constraints. This fallacy ignores the physics-imposed boundaries discussed in @sec-ml-systems-deployment-paradigm-foundations-0c17. Real-time robotics cannot tolerate cloud latency, while complex language models exceed tiny device capabilities. Effective systems often require hybrid architectures that leverage multiple paradigms strategically.\n\n**Fallacy: \"Edge Computing Always Reduces Latency\"** - Many practitioners assume edge deployment automatically improves response times. However, edge systems introduce processing delays, load balancing overhead, and potential network hops that can exceed direct cloud connections. A poorly designed edge deployment with insufficient local compute power may exhibit worse latency than optimized cloud services. Edge benefits emerge only when local processing time plus reduced network distance outweighs the infrastructure complexity costs.\n\n**Fallacy: \"Mobile Devices Can Handle Any Workload with Optimization\"** - This misconception underestimates the fundamental constraints imposed by battery life and thermal management. Teams often assume that model compression techniques can arbitrarily reduce resource requirements while maintaining performance. However, mobile devices face hard physical limits: battery capacity scales with volume while computational demand scales with model complexity. Some applications require computational resources that no amount of optimization can fit within mobile power budgets.\n\n**Fallacy: \"TinyML is Just Smaller Mobile ML\"** - This fallacy misunderstands the qualitative differences between resource-constrained paradigms. TinyML operates under constraints so severe that different algorithmic approaches become necessary. The microcontroller environments impose memory limitations measured in kilobytes, not megabytes, requiring specialized techniques like quantization beyond what mobile optimization employs. Applications suitable for tiny ML represent a fundamentally different problem class, not simply scaled-down versions of mobile applications.\n\n**Fallacy: \"Cost Optimization Equals Resource Minimization\"** - Teams frequently assume that minimizing computational resources automatically reduces costs. This perspective ignores operational complexity, development time, and infrastructure overhead. Cloud deployments may consume more compute resources while providing lower total cost of ownership through reduced maintenance, automatic scaling, and shared infrastructure. The optimal cost solution often involves accepting higher per-unit resource consumption in exchange for simplified operations and faster development cycles.\n\n## Summary {#sec-ml-systems-summary-473b}\n\nThis chapter analyzed the diverse landscape of machine learning systems, revealing how deployment context directly shapes every aspect of system design. From cloud environments with vast computational resources to tiny devices operating under extreme constraints, each paradigm presents unique opportunities and challenges that directly influence architectural decisions, algorithmic choices, and performance trade-offs. The spectrum from cloud to edge to mobile to tiny ML represents more than just different scales of computation; it reflects a significant evolution in how we distribute intelligence across computing infrastructure.\n\nThe evolution from centralized cloud systems to distributed edge and mobile deployments shows how resource constraints drive innovation rather than simply limiting capabilities. Each paradigm emerged to address specific limitations of its predecessors: Cloud ML leverages centralized power for complex processing but must navigate latency and privacy concerns. Edge ML brings computation closer to data sources, reducing latency while introducing intermediate resource constraints. Mobile ML extends these capabilities to personal devices, balancing user experience with battery life and thermal management. TinyML pushes the boundaries of what's possible with minimal resources, enabling ubiquitous sensing and intelligence in previously impossible deployment contexts. This evolution showcases how thoughtful system design can transform limitations into opportunities for specialized optimization.\n\n::: {.callout-important title=\"Key Takeaways\"}\n* Deployment context drives architectural decisions more than algorithmic preferences\n* Resource constraints create opportunities for innovation, not just limitations\n* Hybrid approaches are emerging as the future of ML system design\n* Privacy and latency considerations increasingly favor distributed intelligence\n:::\n\nThese paradigms reflect an ongoing shift toward systems that are finely tuned to specific operational requirements, moving beyond one-size-fits-all approaches toward context-aware system design. As these deployment models mature, hybrid architectures emerge that combine their strengths: cloud-based training paired with edge inference, federated learning across mobile devices, and hierarchical processing that optimizes across the entire spectrum. This evolution demonstrates how deployment contexts will continue driving innovation in system architecture, training methodologies, and optimization techniques, creating more sophisticated and context-aware ML systems.\n\nYet deployment context represents only one dimension of system design. The algorithms executing within these environments equally influence resource requirements, computational patterns, and optimization strategies. A neural network requiring gigabytes of memory and billions of floating-point operations demands fundamentally different deployment approaches than a decision tree requiring kilobytes and integer comparisons. The next chapter (@sec-dl-primer) examines the mathematical foundations of neural networks, revealing why certain deployment paradigms suit specific algorithms and how algorithmic choices propagate through the entire system stack.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["../../../filters/sidenote.lua","../../../filters/inject_parts.lua","../../../filters/inject_quizzes.lua","pandoc-ext/diagram","mlsysbook-ext/custom-numbered-blocks"],"title-prefix":"","reference-location":"margin","highlight-style":"../../../assets/styles/custom-code.theme","toc":true,"toc-depth":4,"number-sections":false,"include-in-header":{"text":"<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\">\n<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n<link rel=\"manifest\" href=\"/site.webmanifest\">\n<link rel=\"apple-touch-icon\" href=\"/assets/images/icons/favicon.png\">\n<meta name=\"theme-color\" content=\"#A51C30\">\n\n<script type=\"module\"  src=\"/tools/scripts/socratiQ/bundle.js\" defer></script>\n<script src=\"/assets/scripts/sidebar-auto-collapse.js\" defer></script>\n<script src=\"/assets/scripts/version-link.js\" defer></script>\n<script src=\"/assets/scripts/subscribe-modal.js\" defer></script>\n"},"citeproc":true,"output-file":"ml_systems.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author, Editor & Curator","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Last Updated","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","bibliography":["../../../contents/vol1/introduction/introduction.bib","../../../contents/vol1/responsible_engr/responsible_engr.bib","../../../contents/vol1/benchmarking/benchmarking.bib","../../../contents/vol1/data_engineering/data_engineering.bib","../../../contents/vol1/dl_primer/dl_primer.bib","../../../contents/vol1/dnn_architectures/dnn_architectures.bib","../../../contents/vol1/efficient_ai/efficient_ai.bib","../../../contents/vol1/ml_systems/ml_systems.bib","../../../contents/vol1/frameworks/frameworks.bib","../../../contents/vol1/hw_acceleration/hw_acceleration.bib","../../../contents/vol1/ops/ops.bib","../../../contents/vol1/optimizations/optimizations.bib","../../../contents/vol1/training/training.bib","../../../contents/vol1/workflow/workflow.bib","../../../contents/vol1/serving/serving.bib","../../../contents/vol1/conclusion/conclusion.bib","../../../contents/vol2/ops_scale/ops_scale.bib","../../../contents/vol2/edge_intelligence/edge_intelligence.bib","../../../contents/vol2/privacy_security/privacy_security.bib","../../../contents/vol2/responsible_ai/responsible_ai.bib","../../../contents/vol2/robust_ai/robust_ai.bib","../../../contents/vol2/sustainable_ai/sustainable_ai.bib","../../../contents/vol2/ai_for_good/ai_for_good.bib","../../../contents/vol2/frontiers/frontiers.bib","ml_systems.bib"],"crossref":{"appendix-title":"Appendix","appendix-delim":":","custom":[{"kind":"float","key":"vid","latex-env":"vid","reference-prefix":"Video"}]},"filter-metadata":{"quiz-config":{"file-pattern":"*_quizzes.json","scan-directory":"../../../contents/vol1","auto-discover-pdf":false},"part-summaries":{"file":"../../../contents/parts/summaries.yml","enabled":true},"mlsysbook-ext/custom-numbered-blocks":{"icon-path":"../../../assets/images/icons/callouts","icon-format":"png","groups":{"quiz-question":{"colors":["F0F0F8","5B4B8A"],"collapse":true},"quiz-answer":{"colors":["E8F2EA","4a7c59"],"collapse":true},"resource-slides":{"colors":["E0F2F1","20B2AA"],"collapse":true,"numbered":false},"resource-videos":{"colors":["E0F2F1","20B2AA"],"collapse":true,"numbered":false},"resource-exercises":{"colors":["E0F2F1","20B2AA"],"collapse":true,"numbered":false},"chapter-connection":{"colors":["FDF2F7","A51C30"],"boxstyle":"foldbox.simple","collapse":true,"numbered":false},"chapter-forward":{"colors":["FDF2F7","A51C30"],"boxstyle":"foldbox.simple","collapse":true,"numbered":false},"chapter-recall":{"colors":["FFF4E6","C06014"],"collapse":true,"numbered":false},"code-listing":{"colors":["F2F4F8","D1D7E0"],"collapse":false,"numbered":false},"definition":{"colors":["F0F4F8","1B4F72"],"collapse":false,"numbered":false},"example":{"colors":["F0F8F6","148F77"],"collapse":false,"numbered":false},"colab-interactive":{"colors":["FFF5E6","FF6B35"],"collapse":false,"numbered":false}},"classes":{"callout-quiz-question":{"label":"Self-Check: Question","group":"quiz-question"},"callout-quiz-answer":{"label":"Self-Check: Answer","group":"quiz-answer"},"callout-resource-slides":{"label":"Listing","group":"resource-slides"},"callout-resource-videos":{"label":"Videos","group":"resource-videos"},"callout-resource-exercises":{"label":"Exercises","group":"resource-exercises"},"callout-chapter-connection":{"label":"Related Topics","group":"chapter-connection"},"callout-code":{"label":"Code","group":"code-listing"},"callout-definition":{"label":"Definition","group":"definition"},"callout-example":{"label":"Example","group":"example"},"callout-colab":{"label":"Interactive Colab","group":"colab-interactive"}}}},"diagram":{"engine":{"dot":false,"mermaid":false,"asymptote":false,"tikz":{"execpath":"lualatex","output-format":"svg","header-includes":["\\usepackage{tikz}","\\usepackage{pgfplots}","\\usepackage{pgf-pie}","\\usepackage{amsmath}","\\usepackage{amssymb}","\\usepackage{xcolor}","\\pgfplotsset{compat=1.9}","\\usepgfplotslibrary{fillbetween}","\\usetikzlibrary{angles}","\\usetikzlibrary{arrows.meta}","\\usetikzlibrary{arrows}","\\usetikzlibrary{backgrounds}","\\usetikzlibrary{bending}","\\usetikzlibrary{calc}","\\usetikzlibrary{shadows.blur}","\\usetikzlibrary{fit}","\\usetikzlibrary{intersections}","\\usetikzlibrary{positioning}","\\usetikzlibrary{shapes.geometric}","\\usetikzlibrary{shapes}","\\usetikzlibrary{quotes}","\\usetikzlibrary{decorations.pathmorphing}","\\usetikzlibrary{decorations.markings}","\\usetikzlibrary{matrix}","\\usepgfplotslibrary{dateplot}","\\usepgfplotslibrary{polar}","\\definecolor{Brown}{rgb}{0.65, 0.16, 0.16}","\\definecolor{BrownL}{rgb}{0.6, 0.4, 0.2}","\\definecolor{BrownLine}{rgb}{0.5, 0.3, 0.1}","\\definecolor{BackColor}{RGB}{255,255,229}","\\definecolor{BackLine}{RGB}{181,181,72}","\\definecolor{BlueD}{RGB}{62,100,125}","\\definecolor{BlueL}{RGB}{209,243,255}","\\definecolor{BlueLine}{RGB}{34,148,189}","\\definecolor{BrownL}{RGB}{233,222,220}","\\definecolor{BrownLine}{RGB}{143,120,116}","\\definecolor{Green}{rgb}{0.0, 0.5, 0.0}","\\definecolor{GreenD}{RGB}{40,117,40}","\\definecolor{GreenL}{RGB}{219,253,166}","\\definecolor{GreenLine}{RGB}{73,89,56}","\\definecolor{OliveL}{RGB}{230,227,191}","\\definecolor{OliveLine}{RGB}{173,166,10}","\\definecolor{OrangeL}{RGB}{250,212,175}","\\definecolor{OrangeLine}{RGB}{255,127,76}","\\definecolor{RedL}{RGB}{253,226,240}","\\definecolor{RedLine}{RGB}{201,20,110}","\\definecolor{Sepia}{rgb}{0.44, 0.26, 0.08}","\\definecolor{TextColor}{RGB}{224,224,224}","\\definecolor{VioletL}{RGB}{247,180,247}","\\definecolor{VioletL2}{RGB}{243,243,255}","\\definecolor{VioletLine}{RGB}{34,125,189}","\\definecolor{VioletLine2}{RGB}{169,136,229}"]}}},"editor":{"render-on-save":true},"_quarto-vars":{"email":{"contact":"vj@eecs.harvard.edu","subject":["MLSys Book"],"info":"mailto:vj@eecs.harvard.edu?subject=\"CS249r%20MLSys%20with%20TinyML%20Book%20-%20\""},"title":{"long":"Machine Learning Systems","short":"Machine Learning Systems"}},"comments":{"hypothesis":{"theme":"clean","openSidebar":false}},"lightbox":true,"mermaid":{"theme":"default"},"theme":{"light":["default","../../../assets/styles/style.scss"],"dark":["default","../../../assets/styles/style.scss","../../../assets/styles/dark-mode.scss"]},"respect-user-color-scheme":true,"pagetitle":"ML Systems Textbook","code-block-bg":true,"code-copy":true,"citation-location":"margin","sidenote":true,"anchor-sections":true,"smooth-scroll":false,"citations-hover":false,"footnotes-hover":false,"toc-expand":true,"toc-title":"On this page","number-depth":3,"quiz":"footnote_context_quizzes.json","concepts":"ml_systems_concepts.yml","glossary":"ml_systems_glossary.json"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}