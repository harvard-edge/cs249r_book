# Overview {.unnumbered}

Welcome to the hands-on laboratory component of our Machine Learning Systems curriculum. These labs bridge theory and practice, giving you direct experience with deploying AI on resource-constrained devices.

## What You'll Build {#sec-overview-what-youll-build}

Our labs cover the essential applications of embedded machine learning across different hardware platforms:

**Computer Vision Applications:**
- **Image Classification** - Categorize objects in real-time camera feeds
- **Object Detection** - Locate and identify multiple objects within images  
- **Advanced Vision** - Explore cutting-edge vision language models and real-time analytics

**Audio Processing Applications:**
- **Keyword Spotting** - Detect specific spoken commands for voice interfaces
- **Motion Classification** - Analyze accelerometer data for activity recognition
- **Audio Classification** - Distinguish between different sounds and acoustic events

**Specialized Applications:**
- **No-Code Deployment** - Use visual programming environments for rapid prototyping
- **Language Models** - Deploy small language models for edge AI applications
- **DSP and Feature Engineering** - Master signal processing fundamentals

## Why These Labs Matter {#sec-overview-why-labs-matter}

**Real-World Constraints:** You'll work within the actual limitations faced by deployed systems—limited memory, processing power, and energy budgets. This teaches you to make informed trade-offs between accuracy, speed, and efficiency.

**Industry-Relevant Skills:** Every lab uses tools, frameworks, and workflows employed in professional embedded ML development. The hardware platforms are the same ones powering commercial IoT devices, smart sensors, and edge AI products.

**Progressive Complexity:** Labs are designed to build on each other, starting with fundamental deployment concepts and advancing to sophisticated multi-modal systems that represent the cutting edge of embedded AI.

**End-to-End Systems:** Rather than isolated algorithms, you'll build complete systems that integrate sensors, processing, and output—the full stack of embedded ML deployment.







## Lab Compatibility Matrix {#sec-overview-lab-compatibility}

Understanding which labs work with each platform helps you plan your learning journey and curriculum design.

+---------------------------+---------------+--------------+--------------------+--------------+
| Lab Type                  | Arduino Nicla | XIAOML Kit   | Grove Vision AI V2 | Raspberry Pi |
+===========================+===============+==============+====================+==============+
| **Getting Started**       | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Image Classification**  | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Object Detection**      | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Keyword Spotting**      | ✓             | ✓            |                    |              |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Motion Classification** | ✓             | ✓            |                    |              |
+---------------------------+---------------+--------------+--------------------+--------------+
| **No-Code Applications**  |               |              | ✓                  |              |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Large Language Models** |               |              |                    | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Vision Language Models**|               |              |                    | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **DSP/Feature Engr.**     | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+

### Lab Selection Guide {#sec-overview-lab-selection-guide}

**For Beginners**: Start with Image Classification on any platform to understand basic ML deployment concepts. The Arduino Nicla and XIAOML Kit offer the most comprehensive lab coverage for foundational learning.

**For Audio/Sensor Applications**: Arduino Nicla and XIAOML Kit provide complete keyword spotting and motion classification labs that demonstrate sensor fusion and audio processing.

**For Advanced Vision**: Grove Vision AI V2 and Raspberry Pi excel at sophisticated computer vision tasks, with the Grove offering no-code options and the Pi supporting complex multi-modal models.

**For Language Models**: Only Raspberry Pi supports LLM and VLM applications, making it essential for exploring the latest AI capabilities at the edge.



## Getting Started {#sec-overview-getting-started}

### Prerequisites {#sec-overview-prerequisites}

**Math Background:** Basic linear algebra, probability, and calculus  
**Programming:** Python experience required; C/C++ helpful but not required  
**Hardware:** No prior embedded systems experience needed—we'll teach you!

### Recommended Sequence {#sec-overview-recommended-sequence}

1. **Start with Setup** - Choose your platform and configure your development environment
2. **Master the Basics** - Image Classification or Keyword Spotting on Arduino Nicla or XIAOML Kit
3. **Explore Applications** - Try Object Detection, Motion Classification, or Audio Processing
4. **Advanced Features** - Language Models on Raspberry Pi or Hardware Acceleration on Grove AI V2
5. **Build Your Project** - Combine techniques to create something uniquely yours

---

**Ready to begin your hands-on journey?** First, explore our [Hardware Kits](../../kits.qmd) to select your platform, then return here to proceed to [Getting Started](getting_started.qmd) for your first deployment experience.
