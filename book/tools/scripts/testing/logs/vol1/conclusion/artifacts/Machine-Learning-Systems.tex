% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode,linktoc=all,pdfwindowui,pdfpagemode=FullScreen,pdfpagelayout=TwoPageRight}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  9pt,
  letterpaper,
  abstract,
  titlepage]{scrbook}
\usepackage{xcolor}
\usepackage[left=1in,marginparwidth=2.0666666666667in,textwidth=4.1333333333333in,marginparsep=0.3in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{3}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

% =============================================================================
% LATEX HEADER CONFIGURATION FOR MLSYSBOOK PDF
% =============================================================================
% This file contains all LaTeX package imports, custom commands, and styling
% definitions for the PDF output of the Machine Learning Systems textbook.
%
% Key Features:
% - Harvard crimson branding throughout
% - Custom part/chapter/section styling
% - Professional table formatting with colored headers
% - Margin notes with custom styling
% - TikZ-based part dividers
% - Page numbering (Roman for frontmatter, Arabic for mainmatter)
%
% Note: This file is included via _quarto-pdf.yml and affects PDF output only.
% HTML/EPUB styling is handled separately via CSS files.
% =============================================================================

% =============================================================================
% PACKAGE IMPORTS
% =============================================================================

% Layout and positioning
% \usepackage[outercaption, ragged]{sidecap}  % Commented out to make figure captions inline instead of in margin
\usepackage{adjustbox}      % Adjusting box dimensions
\usepackage{afterpage}      % Execute commands after page break
\usepackage{morefloats}     % Increase number of floats
\usepackage{array}          % Enhanced table column formatting
\usepackage{atbegshi}       % Insert content at page beginning
%\usepackage{changepage}     % Change page dimensions mid-document
\usepackage{emptypage}      % Clear headers/footers on empty pages

% Language and text
\usepackage[english]{babel} % English language support
\usepackage{microtype}      % Improved typography and hyphenation

% Captions and floats
\usepackage{caption}
% Caption styling configuration
%\captionsetup[table]{belowskip=5pt}
\captionsetup{format=plain}
\DeclareCaptionLabelFormat{mylabel}{#1
#2:\hspace{1.0ex}}
\DeclareCaptionFont{ninept}{\fontsize{7pt}{8}\selectfont #1}

% Figure captions: Small font, bold label, ragged right
\captionsetup[figure]{labelfont={bf,ninept},labelsep=space,
belowskip=2pt,aboveskip=6pt,labelformat=mylabel,
justification=raggedright,singlelinecheck=false,font={ninept}}

% Table captions: Small font, bold label, ragged right
\captionsetup[table]{belowskip=6pt,labelfont={bf,ninept},labelsep=none,
labelformat=mylabel,justification=raggedright,singlelinecheck=false,font={ninept}}

% Typography fine-tuning
\emergencystretch=5pt       % Allow extra stretch to avoid overfull boxes

% Utility packages
\usepackage{etoolbox}       % For patching commands and environments

% Page layout and headers
\usepackage{fancyhdr}       % Custom headers and footers
\usepackage{geometry}       % Page dimensions and margins

% Graphics and figures
\usepackage{graphicx}       % Include graphics
\usepackage{float}          % Improved float placement
\usepackage[skins,breakable]{tcolorbox} % Coloured and framed text boxes
\tcbset{before upper=\setlength{\parskip}{3pt}}

% Tables
\usepackage{longtable}      % Multi-page tables

% Fonts and typography
\usepackage{fontspec}       % Font selection for LuaLaTeX
\usepackage{mathptmx}       % Times-like math fonts
\usepackage{newpxtext}      % Palatino-like font for body text

% Colors and visual elements
\usepackage[dvipsnames]{xcolor}  % Extended color support
\usepackage{tikz}           % Programmatic graphics
\usetikzlibrary{positioning}
\usetikzlibrary{calc}
\usepackage{tikzpagenodes}  % TikZ positioning relative to page

% Code listings
\usepackage{listings}       % Code highlighting

% Hyperlinks
\usepackage{hyperref}       % Clickable links in PDF

% Conditional logic
\usepackage{ifthen}         % If-then-else commands

% Math symbols
\usepackage{amsmath}        % AMS math extensions
\usepackage{amssymb}        % AMS math symbols
\usepackage{latexsym}       % Additional LaTeX symbols
\usepackage{pifont}         % Zapf Dingbats symbols
\providecommand{\blacklozenge}{\ding{117}}  % Black diamond symbol

% Lists
\usepackage{enumitem}       % Customizable lists

% Margin notes and sidenotes
\usepackage{marginfix}      % Fixes margin note overflow
\usepackage{marginnote}     % Margin notes
\usepackage{sidenotes}      % Academic-style sidenotes
\renewcommand\raggedrightmarginnote{\sloppy}
\renewcommand\raggedleftmarginnote{\sloppy}

% Typography improvements
\usepackage{ragged2e}       % Better ragged text
\usepackage[all]{nowidow}   % Prevent widows and orphans
\usepackage{needspace}      % Ensure minimum space on page

% Section formatting
\usepackage[explicit]{titlesec}  % Custom section titles
\usepackage{tocloft}        % Table of contents formatting

% QR codes and icons
\usepackage{fontawesome5}   % Font Awesome icons
\usepackage{qrcode}         % QR code generation
\qrset{link, height=15mm}

% =============================================================================
% FLOAT CONFIGURATION
% =============================================================================
% Allow more floats per page to handle figure-heavy chapters
\extrafloats{200}
\setcounter{topnumber}{12}       % Max floats at top of page
\setcounter{bottomnumber}{12}    % Max floats at bottom of page
\setcounter{totalnumber}{24}     % Max floats per page
\setcounter{dbltopnumber}{8}     % Max floats at top of two-column page
\renewcommand{\topfraction}{.95}  % Max fraction of page for top floats
\renewcommand{\bottomfraction}{.95}
\renewcommand{\textfraction}{.05}  % Min fraction of page for text
\renewcommand{\floatpagefraction}{.7}  % Min fraction of float page
\renewcommand{\dbltopfraction}{.95}

% Prevent "Float(s) lost" errors by flushing floats more aggressively
\usepackage{placeins}  % Provides \FloatBarrier

% =============================================================================
% COLOR DEFINITIONS
% =============================================================================
% Harvard crimson - primary brand color used throughout
\definecolor{crimson}{HTML}{A51C30}

% Quiz element colors
\definecolor{quiz-question-color1}{RGB}{225,243,248}  % Light blue background
\definecolor{quiz-question-color2}{RGB}{17,158,199}   % Blue border
\definecolor{quiz-answer-color1}{RGB}{250,234,241}    % Light pink background
\definecolor{quiz-answer-color2}{RGB}{152,14,90}      % Magenta border

% =============================================================================
% LIST FORMATTING
% =============================================================================
% Tighter list spacing for academic style
\def\tightlist{}
\setlist{itemsep=1pt, parsep=1pt, topsep=0pt,after={\vspace{0.3\baselineskip}}}
\let\tightlist\relax

\makeatletter
\@ifpackageloaded{framed}{}{\usepackage{framed}}
\@ifpackageloaded{fancyvrb}{}{\usepackage{fancyvrb}}
\makeatother

\makeatletter
%New float "codelisting" has been updated
\AtBeginDocument{%
\floatstyle{ruled}
\newfloat{codelisting}{!htb}{lop}
\floatname{codelisting}{Listing}
\floatplacement{codelisting}{!htb}
\captionsetup[codelisting]{labelfont={bf,ninept},labelformat=mylabel,
  singlelinecheck=false,width=\linewidth,labelsep=none,font={ninept}}%
\renewenvironment{snugshade}{%
   \def\OuterFrameSep{3pt}%
   \def\FrameCommand{\fboxsep=5pt\colorbox{shadecolor}}%
   \MakeFramed{\advance\hsize-\width\FrameRestore}%
   \leftskip 0.5em \rightskip 0.5em%
   \small% decrease font size
   }{\endMakeFramed}%
}
\makeatother

%The space before and after the verbatim environment "Highlighting" has been reduced
\fvset{listparameters=\setlength{\topsep}{0pt}\setlength{\partopsep}{0pt}}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{framesep=0mm,commandchars=\\\{\}}

\makeatletter
\renewcommand\fs@ruled{\def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@ruled
\def\@fs@pre{\hrule height.8pt depth0pt \kern2pt}%
\def\@fs@post{\kern2pt\hrule\relax}%
\def\@fs@mid{\kern2pt\hrule\kern1pt}%space between float and caption
\let\@fs@iftopcapt\iftrue}
\makeatother


% =============================================================================
% HYPHENATION RULES
% =============================================================================
% Explicit hyphenation points for technical terms to avoid bad breaks
\hyphenation{
  light-weight
  light-weight-ed
  de-vel-op-ment
  un-der-stand-ing
  mod-els
  prin-ci-ples
  ex-per-tise
  com-pli-cat-ed
  blue-print
  per‧for‧mance
  com-mu-ni-ca-tion
  par-a-digms
  hy-per-ten-sion
  a-chieved
}

% =============================================================================
% CODE LISTING CONFIGURATION
% =============================================================================
% Settings for code blocks using listings package
\lstset{
breaklines=true,              % Automatic line wrapping
breakatwhitespace=true,       % Break at whitespace only
basicstyle=\ttfamily,         % Monospace font
frame=none,                   % No frame around code
keepspaces=true,              % Preserve spaces
showspaces=false,             % Don't show space characters
showtabs=false,               % Don't show tab characters
columns=flexible,             % Flexible column width
belowskip=0pt,               % Minimal spacing
aboveskip=0pt
}

% =============================================================================
% PAGE GEOMETRY
% =============================================================================
% MIT Press trim size: 7" x 10" (per publisher specifications)
% This is a standard academic textbook format providing good readability
% for technical content with figures and code blocks.
% Wide outer margin accommodates sidenotes/margin notes.
\geometry{
  paperwidth=7in,
  paperheight=10in,
  top=0.875in,
  bottom=0.875in,
  inner=0.875in,              % Inner margin (binding side)
  outer=1.75in,               % Outer margin (includes space for sidenotes)
  footskip=30pt,
  marginparwidth=1.25in,      % Width for margin notes
  twoside                     % Different left/right pages
}

% =============================================================================
% SIDENOTE STYLING
% =============================================================================
% Custom sidenote design with crimson vertical bar
\renewcommand{\thefootnote}{\textcolor{crimson}{\arabic{footnote}}}

% Save original sidenote command
\makeatletter
\@ifundefined{oldsidenote}{
  \let\oldsidenote\sidenote%
}{}
\makeatother

% Redefine sidenote with vertical crimson bar
\renewcommand{\sidenote}[1]{%
  \oldsidenote{%
    \noindent
    \color{crimson!100}                        % Crimson vertical line
    \raisebox{0em}{%
      \rule{0.5pt}{1.5em}                      % Thin vertical line
    }
    \hspace{0.3em}                             % Space after line
    \color{black}                              % Reset text color
    \footnotesize #1                           % Sidenote content
  }%
}

% =============================================================================
% FLOAT HANDLING
% =============================================================================
% Patch LaTeX's output routine to handle float overflow gracefully
% The "Float(s) lost" error occurs in \@doclearpage when \@currlist is not empty
% This patch silently clears pending floats that can't be placed
\makeatletter
\let\orig@doclearpage\@doclearpage
\def\@doclearpage{%
  \ifx\@currlist\@empty\else
    \global\let\@currlist\@empty
    \typeout{Warning: Floats cleared to prevent overflow}%
  \fi
  \orig@doclearpage
}
\makeatother

% Additional safety for structural commands
\let\originalbackmatter\backmatter
\renewcommand{\backmatter}{%
  \clearpage%
  \originalbackmatter%
}

\let\originalfrontmatter\frontmatter
\renewcommand{\frontmatter}{%
  \clearpage%
  \originalfrontmatter%
}

\let\originalmainmatter\mainmatter
\renewcommand{\mainmatter}{%
  \clearpage%
  \originalmainmatter%
}

% =============================================================================
% PAGE HEADERS AND FOOTERS
% =============================================================================
% Ensure chapters use fancy page style (not plain)
\patchcmd{\chapter}{\thispagestyle{plain}}{\thispagestyle{fancy}}{}{}

% Main page style with crimson headers
\pagestyle{fancy}
\fancyhf{}                                              % Clear all
\fancyhead[LE]{\small\color{crimson}\nouppercase{\rightmark}}  % Left even: section
\fancyhead[RO]{\color{crimson}\thepage}                 % Right odd: page number
\fancyhead[LO]{\small\color{crimson}\nouppercase{\leftmark}}   % Left odd: chapter
\fancyhead[RE]{\color{crimson}\thepage}                 % Right even: page number
\renewcommand{\headrulewidth}{0.4pt}                    % Thin header line
\renewcommand{\footrulewidth}{0pt}                      % No footer line

% Plain page style (for chapter openings)
\fancypagestyle{plain}{
  \fancyhf{}
  \fancyfoot[C]{\color{crimson}\thepage}                % Centered page number
  \renewcommand{\headrulewidth}{0pt}
  \renewcommand{\footrulewidth}{0pt}
}

% =============================================================================
% KOMA-SCRIPT FONT ADJUSTMENTS
% =============================================================================
% Apply crimson color to all heading levels
\addtokomafont{disposition}{\rmfamily\color{crimson}}
\addtokomafont{chapter}{\color{crimson}}
\addtokomafont{section}{\color{crimson}}
\addtokomafont{subsection}{\color{crimson}}

% =============================================================================
% ABSTRACT ENVIRONMENT
% =============================================================================
\newenvironment{abstract}{
  \chapter*{\abstractname}
  \addcontentsline{toc}{chapter}{\abstractname}
  \small
}{
  \clearpage
}

% =============================================================================
% HYPERLINK CONFIGURATION
% =============================================================================
% Crimson-colored links throughout, two-page PDF layout
\hypersetup{
  linkcolor=crimson,
  citecolor=crimson,
  urlcolor=crimson,
  pdfpagelayout=TwoPageRight,   % Two-page spread view
  pdfstartview=Fit               % Initial zoom fits page
}

% =============================================================================
% PART SUMMARY SYSTEM
% =============================================================================
% Allows adding descriptive text below part titles
\newcommand{\partsummary}{}     % Empty by default
\newif\ifhaspartsummary%
\haspartsummaryfalse%

\newcommand{\setpartsummary}[1]{%
  \renewcommand{\partsummary}{#1}%
  \haspartsummarytrue%
}

% Additional colors for part page backgrounds
\definecolor{BrownLL}{RGB}{233,222,220}
\definecolor{BlueDD}{RGB}{62,100,125}
\colorlet{BlueDD}{magenta}

% ===============================================================================
% PART STYLING SYSTEM
% ===============================================================================
%
% This system provides three distinct visual styles for book organization:
%
% 1. NUMBERED PARTS (\part{title}) - For main book sections
%    - Roman numerals (I, II, III, etc.) in top right corner
%    - Crimson title with horizontal lines above/below
%    - "Part I" label in sidebar
%    - Used for: foundations, principles, optimization, deployment, etc.
%
% 2. UNNUMBERED PARTS (\part*{title}) - For special sections like "Labs"
%    - Division-style geometric background (left side)
%    - No Roman numerals
%    - Used for: labs section
%
% 3. DIVISIONS (\division{title}) - For major book divisions
%    - Clean geometric background with centered title
%    - Used for: frontmatter, main_content, backmatter
%
% The Lua filter (inject-parts.lua) automatically routes parts by {key:xxx} commands
% to the appropriate LaTeX command based on the key name.
% ===============================================================================

% NUMBERED PARTS: Roman numeral styling for main book sections
\titleformat{\part}[display]
{\thispagestyle{empty}}{}{20pt}{
\begin{tikzpicture}[remember picture,overlay]
%%%
%%
\node[crimson,align=flush right,
inner sep=0,outer sep=0mm,draw=none,%
anchor=east,minimum height=31mm, text width=1.2\textwidth,
yshift=-30mm,font={%
\fontsize{98pt}{104}\selectfont\bfseries}]  (BG) at (current page text area.north east){\thepart};
%
\node[black,inner sep=0mm,draw=none,
anchor=mid,text width=1.2\textwidth,
 minimum height=35mm, align=right,
node distance=7mm,below=of BG,
font={\fontsize{30pt}{34}\selectfont}]
(BGG)  {\hyphenchar\font=-1 \color{black}\MakeUppercase {#1}};
\draw [crimson,line width=3pt] ([yshift=0mm]BGG.north west) -- ([yshift=0mm]BGG.north east);
\draw [crimson,line width=2pt] ([yshift=0mm]BGG.south west) -- ([yshift=0mm]BGG.south east);
%
\node[fill=crimson,text=white,rotate=90,%
anchor=south west,minimum height=15mm,
minimum width=40mm,font={%
\fontsize{20pt}{20}\selectfont\bfseries}](BP)  at
(current page text area.south east)
{{\sffamily Part}~\thepart};
%
\path[red](BP.north west)-|coordinate(PS)(BGG.south west);
%
% Part summary box commented out for cleaner design
% \ifhaspartsummary
% \node[inner sep=4pt,text width=0.7\textwidth,draw=none,fill=BrownLL!40,
% align=justify,font={\fontsize{9pt}{12}\selectfont},anchor=south west]
% at (PS) {\partsummary};
% \fi
\end{tikzpicture}
}[]

\renewcommand{\thepart}{\Roman{part}}

% UNNUMBERED PARTS: Division-style background for special sections
\titleformat{name=\part,numberless}[display]
{\thispagestyle{empty}}{}{20pt}{
\begin{tikzpicture}[remember picture,overlay]
%%%
\coordinate(S1)at([yshift=-200mm]current page.north west);
\draw[draw=none,fill=BlueDD!7](S1)--++(45:16)coordinate(S2)-
|(S2|-current page.north west)--(current page.north west)coordinate(S3)--(S1);
%
\coordinate(E1)at([yshift=-98mm]current page.north west);
\draw[draw=none,fill=BlueDD!15](E1)--(current page.north west)coordinate(E2)
--++(0:98mm)coordinate(E3)--(E1);
%
\coordinate(D1)at([yshift=15mm]current page.south west);
\draw[draw=none,fill=BlueDD!40,opacity=0.5](D1)--++(45:5.5)coordinate(D2)
-|(D2|-current page.north west)--(current page.north west)coordinate(D3)--(D1);
%%%%
\path[red](S2)-|(S2-|current page.east)coordinate(SS2);
%PART
\node[crimson,align=flush right,inner sep=0,outer sep=0mm,draw=none,anchor=south,
font={\fontsize{48pt}{48}\selectfont\bfseries}]  (BG) at ($(S2)!0.5!(SS2)$){\hphantom{Part}};
%%%
\path[green]([yshift=15mm]D2)-|coordinate(TPD)(BG.south east);
\node[inner sep=0mm,draw=none,anchor=south east,%text width=0.9\textwidth,
align=right,font={\fontsize{40pt}{40}\selectfont}]
(BGG) at (TPD)  {\color{crimson}\MakeUppercase {#1}};%\MakeUppercase {}
\end{tikzpicture}
}

% Define \numberedpart command for numbered parts
\newcommand{\numberedpart}[1]{%
\FloatBarrier%  % Flush all pending floats before part break
\clearpage
\thispagestyle{empty}
\stepcounter{part}%
\begin{tikzpicture}[remember picture,overlay]
%%%
%%
\node[crimson,align=flush right,
inner sep=0,outer sep=0mm,draw=none,%
anchor=east,minimum height=31mm, text width=1.2\textwidth,
yshift=-30mm,font={%
\fontsize{98pt}{104}\selectfont\bfseries}]  (BG) at (current page text area.north east){\thepart};
%
\node[black,inner sep=0mm,draw=none,
anchor=mid,text width=1.2\textwidth,
 minimum height=35mm, align=right,
node distance=7mm,below=of BG,
font={\fontsize{30pt}{34}\selectfont}]
(BGG)  {\hyphenchar\font=-1 \color{black}\MakeUppercase {#1}};
\draw [crimson,line width=3pt] ([yshift=0mm]BGG.north west) -- ([yshift=0mm]BGG.north east);
\draw [crimson,line width=2pt] ([yshift=0mm]BGG.south west) -- ([yshift=0mm]BGG.south east);
%
\node[fill=crimson,text=white,rotate=90,%
anchor=south west,minimum height=15mm,
minimum width=40mm,font={%
\fontsize{20pt}{20}\selectfont\bfseries}](BP)  at
(current page text area.south east)
{{\sffamily Part}~\thepart};
%
\path[red](BP.north west)-|coordinate(PS)(BGG.south west);
%
% Part summary box commented out for cleaner design
% \ifhaspartsummary
% \node[inner sep=4pt,text width=0.7\textwidth,draw=none,fill=BrownLL!40,
% align=justify,font={\fontsize{9pt}{12}\selectfont},anchor=south west]
% at (PS) {\partsummary};
% \fi
\end{tikzpicture}
\clearpage
}



% DIVISIONS: Clean geometric styling with subtle tech elements
% Used for frontmatter, main_content, and backmatter divisions
\newcommand{\division}[1]{%
\FloatBarrier%  % Flush all pending floats before division break
\clearpage
\thispagestyle{empty}
\begin{tikzpicture}[remember picture,overlay]

% Clean geometric background (original design)
\coordinate(S1)at([yshift=-200mm]current page.north west);
\draw[draw=none,fill=BlueDD!7](S1)--++(45:16)coordinate(S2)-
|(S2|-current page.north west)--(current page.north west)coordinate(S3)--(S1);

\coordinate(E1)at([yshift=-98mm]current page.north west);
\draw[draw=none,fill=BlueDD!15](E1)--(current page.north west)coordinate(E2)
--++(0:98mm)coordinate(E3)--(E1);

\coordinate(D1)at([yshift=15mm]current page.south west);
\draw[draw=none,fill=BlueDD!40,opacity=0.5](D1)--++(45:5.5)coordinate(D2)
-|(D2|-current page.north west)--(current page.north west)coordinate(D3)--(D1);

% Subtle tech elements - positioned in white areas for better visibility
% Upper right white area - more visible
\draw[crimson!40, line width=0.8pt] ([xshift=140mm,yshift=-60mm]current page.north west) -- ++(40mm,0);
\draw[crimson!40, line width=0.8pt] ([xshift=150mm,yshift=-70mm]current page.north west) -- ++(30mm,0);
\draw[crimson!35, line width=0.7pt] ([xshift=160mm,yshift=-60mm]current page.north west) -- ++(0,-15mm);
\draw[crimson!35, line width=0.7pt] ([xshift=170mm,yshift=-70mm]current page.north west) -- ++(0,10mm);

% Circuit nodes - upper right
\fill[crimson!50] ([xshift=160mm,yshift=-60mm]current page.north west) circle (1.5mm);
\fill[white] ([xshift=160mm,yshift=-60mm]current page.north west) circle (0.8mm);
\fill[crimson!50] ([xshift=170mm,yshift=-70mm]current page.north west) circle (1.3mm);
\fill[white] ([xshift=170mm,yshift=-70mm]current page.north west) circle (0.6mm);

% Lower right white area - enhanced visibility
\draw[crimson!45, line width=0.9pt] ([xshift=140mm,yshift=-190mm]current page.north west) -- ++(45mm,0);
\draw[crimson!45, line width=0.9pt] ([xshift=150mm,yshift=-200mm]current page.north west) -- ++(35mm,0);
\draw[crimson!40, line width=0.8pt] ([xshift=160mm,yshift=-190mm]current page.north west) -- ++(0,-20mm);
\draw[crimson!40, line width=0.8pt] ([xshift=170mm,yshift=-200mm]current page.north west) -- ++(0,15mm);

% Additional connecting lines in lower right
\draw[crimson!35, line width=0.7pt] ([xshift=130mm,yshift=-180mm]current page.north west) -- ++(25mm,0);
\draw[crimson!35, line width=0.7pt] ([xshift=145mm,yshift=-180mm]current page.north west) -- ++(0,-25mm);

% Circuit nodes - lower right (more prominent)
\fill[crimson!55] ([xshift=160mm,yshift=-190mm]current page.north west) circle (1.6mm);
\fill[white] ([xshift=160mm,yshift=-190mm]current page.north west) circle (0.9mm);
\fill[crimson!55] ([xshift=170mm,yshift=-200mm]current page.north west) circle (1.4mm);
\fill[white] ([xshift=170mm,yshift=-200mm]current page.north west) circle (0.7mm);
\fill[crimson!50] ([xshift=145mm,yshift=-180mm]current page.north west) circle (1.2mm);
\fill[white] ([xshift=145mm,yshift=-180mm]current page.north west) circle (0.6mm);

% Title positioned in center - clean and readable
\node[inner sep=0mm,draw=none,anchor=center,text width=0.8\textwidth,
align=center,font={\fontsize{40pt}{40}\selectfont}]
(BGG) at (current page.center)  {\color{crimson}\MakeUppercase {#1}};

\end{tikzpicture}
\clearpage
}

% LAB DIVISIONS: Circuit-style neural network design for lab sections
% Used specifically for lab platform sections (arduino, xiao, grove, etc.)
\newcommand{\labdivision}[1]{%
\FloatBarrier%  % Flush all pending floats before lab division break
\clearpage
\thispagestyle{empty}
\begin{tikzpicture}[remember picture,overlay]
% Circuit background with subtle gradient
\coordinate(S1)at([yshift=-200mm]current page.north west);
\draw[draw=none,fill=BlueDD!5](S1)--++(45:16)coordinate(S2)-
|(S2|-current page.north west)--(current page.north west)coordinate(S3)--(S1);

% TOP AREA: Circuit lines in upper white space
\draw[crimson!50, line width=1.5pt] ([xshift=30mm,yshift=-40mm]current page.north west) -- ++(60mm,0);
\draw[crimson!40, line width=1pt] ([xshift=120mm,yshift=-50mm]current page.north west) -- ++(50mm,0);
\draw[crimson!50, line width=1.5pt] ([xshift=40mm,yshift=-70mm]current page.north west) -- ++(40mm,0);

% Connecting lines in top area
\draw[crimson!30, line width=1pt] ([xshift=60mm,yshift=-40mm]current page.north west) -- ++(0,-20mm);
\draw[crimson!30, line width=1pt] ([xshift=145mm,yshift=-50mm]current page.north west) -- ++(0,10mm);

% Neural nodes in top area
\fill[crimson!70] ([xshift=60mm,yshift=-40mm]current page.north west) circle (2.5mm);
\fill[white] ([xshift=60mm,yshift=-40mm]current page.north west) circle (1.5mm);
\fill[crimson!60] ([xshift=145mm,yshift=-50mm]current page.north west) circle (2mm);
\fill[white] ([xshift=145mm,yshift=-50mm]current page.north west) circle (1mm);
\fill[crimson!80] ([xshift=80mm,yshift=-70mm]current page.north west) circle (2mm);
\fill[white] ([xshift=80mm,yshift=-70mm]current page.north west) circle (1mm);

% BOTTOM AREA: Circuit lines in lower white space
\draw[crimson!50, line width=1.5pt] ([xshift=20mm,yshift=-200mm]current page.north west) -- ++(70mm,0);
\draw[crimson!40, line width=1pt] ([xshift=110mm,yshift=-210mm]current page.north west) -- ++(60mm,0);
\draw[crimson!50, line width=1.5pt] ([xshift=35mm,yshift=-230mm]current page.north west) -- ++(45mm,0);

% Connecting lines in bottom area
\draw[crimson!30, line width=1pt] ([xshift=55mm,yshift=-200mm]current page.north west) -- ++(0,-20mm);
\draw[crimson!30, line width=1pt] ([xshift=140mm,yshift=-210mm]current page.north west) -- ++(0,15mm);

% Neural nodes in bottom area
\fill[crimson!70] ([xshift=55mm,yshift=-200mm]current page.north west) circle (2.5mm);
\fill[white] ([xshift=55mm,yshift=-200mm]current page.north west) circle (1.5mm);
\fill[crimson!60] ([xshift=140mm,yshift=-210mm]current page.north west) circle (2mm);
\fill[white] ([xshift=140mm,yshift=-210mm]current page.north west) circle (1mm);
\fill[crimson!80] ([xshift=80mm,yshift=-230mm]current page.north west) circle (2mm);
\fill[white] ([xshift=80mm,yshift=-230mm]current page.north west) circle (1mm);

% SIDE AREAS: Subtle circuit elements on left and right edges
\draw[crimson!30, line width=1pt] ([xshift=15mm,yshift=-120mm]current page.north west) -- ++(20mm,0);
\draw[crimson!30, line width=1pt] ([xshift=175mm,yshift=-130mm]current page.north west) -- ++(15mm,0);
\fill[crimson!50] ([xshift=25mm,yshift=-120mm]current page.north west) circle (1.5mm);
\fill[white] ([xshift=25mm,yshift=-120mm]current page.north west) circle (0.8mm);
\fill[crimson!50] ([xshift=185mm,yshift=-130mm]current page.north west) circle (1.5mm);
\fill[white] ([xshift=185mm,yshift=-130mm]current page.north west) circle (0.8mm);

% Title positioned in center - CLEAN AREA
\node[inner sep=0mm,draw=none,anchor=center,text width=0.8\textwidth,
align=center,font={\fontsize{44pt}{44}\selectfont\bfseries}]
(BGG) at (current page.center)  {\color{crimson}\MakeUppercase {#1}};

\end{tikzpicture}
\clearpage
}

% Define \lab command for lab styling (different visual treatment)
\newcommand{\lab}[1]{%
\begin{tikzpicture}[remember picture,overlay]
%%%
% Different background pattern for labs
\coordinate(S1)at([yshift=-200mm]current page.north west);
\draw[draw=none,fill=BlueDD!15](S1)--++(45:16)coordinate(S2)-
|(S2|-current page.north west)--(current page.north west)coordinate(S3)--(S1);
%
\coordinate(E1)at([yshift=-98mm]current page.north west);
\draw[draw=none,fill=BlueDD!25](E1)--(current page.north west)coordinate(E2)
--++(0:98mm)coordinate(E3)--(E1);
%
\coordinate(D1)at([yshift=15mm]current page.south west);
\draw[draw=none,fill=BlueDD!60,opacity=0.7](D1)--++(45:5.5)coordinate(D2)
-|(D2|-current page.north west)--(current page.north west)coordinate(D3)--(D1);
%%%%
\path[red](S2)-|(S2-|current page.east)coordinate(SS2);
%LAB - Different styling
\node[crimson,align=flush right,inner sep=0,outer sep=0mm,draw=none,anchor=south,
font={\fontsize{48pt}{48}\selectfont\bfseries}]  (BG) at ($(S2)!0.5!(SS2)$){\hphantom{Workshop}};
%%%
\path[green]([yshift=15mm]D2)-|coordinate(TPD)(BG.south east);
\node[inner sep=0mm,draw=none,anchor=south east,%text width=0.9\textwidth,
align=right,font={\fontsize{40pt}{40}\selectfont}]
(BGG) at (TPD)  {\color{crimson}\MakeUppercase {#1}};%\MakeUppercase {}
\end{tikzpicture}
\thispagestyle{empty}
\clearpage
}

% =============================================================================
% SECTION FORMATTING
% =============================================================================
% All section levels use crimson color and are ragged right

% Section (Large, bold, crimson)
\titleformat{\section}
  {\normalfont\Large\bfseries\color{crimson}\raggedright}
  {\thesection}
  {0.5em}
  {#1}
\titlespacing*{\section}{0pc}{14pt plus 4pt minus 4pt}{6pt plus 2pt minus 2pt}[0pc]

% Subsection (large, bold, crimson)
\titleformat{\subsection}
  {\normalfont\large\bfseries\color{crimson}\raggedright}
  {\thesubsection}
  {0.5em}
  {#1}
\titlespacing*{\subsection}{0pc}{12pt plus 4pt minus 4pt}{5pt plus 1pt minus 2pt}[0pc]

% Subsubsection (normal size, bold, crimson)
\titleformat{\subsubsection}
  {\normalfont\normalsize\bfseries\color{crimson}\raggedright}
  {\thesubsubsection}
  {0.5em}
  {#1}
\titlespacing*{\subsubsection}{0pc}{12pt plus 4pt minus 4pt}{5pt plus 1pt minus 2pt}[0pc]

% Paragraph (run-in, bold, crimson, ends with period)
\titleformat{\paragraph}[runin]
  {\normalfont\normalsize\bfseries\color{crimson}}
  {\theparagraph}
  {0.5em}
  {#1}
  [\textbf{.}]
  \titlespacing*{\paragraph}{0pc}{6pt plus 2pt minus 2pt}{0.5em}[0pc]

% Subparagraph (run-in, italic, crimson, ends with period)
\titleformat{\subparagraph}[runin]
  {\normalfont\normalsize\itshape\color{crimson}}
  {\thesubparagraph}
  {0.5em}
  {#1}
  [\textbf{.}]
  \titlespacing*{\subparagraph}{0pc}{6pt plus 2pt minus 2pt}{0.5em}[0pc]

% =============================================================================
% CHAPTER FORMATTING
% =============================================================================
% Numbered chapters: "Chapter X" prefix, huge crimson title
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\color{crimson}}
  {\chaptername\ \thechapter}
  {20pt}
  {\Huge #1}
  []

% Unnumbered chapters: no prefix, huge crimson title
\titleformat{name=\chapter,numberless}
  {\normalfont\huge\bfseries\color{crimson}}
  {}
  {0pt}
  {\Huge #1}
  []

\renewcommand{\chaptername}{Chapter}
% =============================================================================
% TABLE OF CONTENTS FORMATTING
% =============================================================================
\setcounter{tocdepth}{2}                      % Show chapters, sections, subsections

% TOC spacing adjustments for number widths and indentation
\setlength{\cftchapnumwidth}{2em}             % Chapter number width
\setlength{\cftsecnumwidth}{2.75em}           % Section number width
\setlength{\cftsubsecnumwidth}{3.25em}        % Subsection number width
\setlength{\cftsubsubsecnumwidth}{4em}        % Subsubsection number width
\setlength{\cftsubsecindent}{4.25em}          % Subsection indent
\setlength{\cftsubsubsecindent}{7.5em}        % Subsubsection indent

% Chapter entries in TOC: bold crimson with "Chapter" prefix
\renewcommand{\cftchapfont}{\bfseries\color{crimson}}
\renewcommand{\cftchappresnum}{\color{crimson}Chapter~}

% Custom formatting for division entries (styled like parts)
\newcommand{\divisionchapter}[1]{%
  \addvspace{12pt}%
  \noindent\hfil\bfseries\color{crimson}#1\hfil\par%
  \addvspace{6pt}%
}

% Adjust TOC spacing for "Chapter" prefix
\newlength{\xtraspace}
\settowidth{\xtraspace}{\cftchappresnum\cftchapaftersnum}
\addtolength{\cftchapnumwidth}{\xtraspace}

% Unnumbered chapters with TOC entry
\newcommand{\likechapter}[1]{%
    \chapter*{#1}
    \addcontentsline{toc}{chapter}{\textcolor{crimson}{#1}}
}

% =============================================================================
% PAGE NUMBERING SYSTEM
% =============================================================================
% Implements traditional book numbering:
% - Roman numerals (i, ii, iii...) for frontmatter
% - Arabic numerals (1, 2, 3...) for mainmatter
% Automatically switches at first numbered chapter
\makeatletter
\newif\if@firstnumbered%
\@firstnumberedtrue%
\newif\if@firstunnumbered%
\@firstunnumberedtrue%

\newcounter{lastRomanPage}
\setcounter{lastRomanPage}{1}

% Start document with Roman numerals (frontmatter)
\AtBeginDocument{
  \pagenumbering{roman}
  \renewcommand{\thepage}{\roman{page}}
}

% Intercept chapter command
\let\old@chapter\chapter%
\renewcommand{\chapter}{%
  \@ifstar{\unnumbered@chapter}{\numbered@chapter}%
}

% Numbered chapters: switch to Arabic on first occurrence
\newcommand{\numbered@chapter}[1]{%
  \if@firstnumbered%
    \cleardoublepage%
    \setcounter{lastRomanPage}{\value{page}}%
    \pagenumbering{arabic}%
    \@firstnumberedfalse%
  \else
    \setcounter{page}{\value{page}}%
  \fi
  \setcounter{sidenote}{1}                    % Reset footnote counter per chapter
  \old@chapter{#1}%
}

% Unnumbered chapters: stay in Roman numerals
\newcommand{\unnumbered@chapter}[1]{%
  \if@firstunnumbered%
    \clearpage
    \setcounter{lastRomanPage}{\value{page}}%
    \pagenumbering{roman}%
    \@firstunnumberedfalse%
  \fi
  \setcounter{sidenote}{1}
  \old@chapter*{#1}%
}
\makeatother

% =============================================================================
% TABLE SIZING AND SPACING
% =============================================================================
% Make tables slightly smaller to fit more content
\AtBeginEnvironment{longtable}{\scriptsize}

% Increase vertical spacing in table cells (default is 1.0)
\renewcommand{\arraystretch}{1.3}

% Prefer placing tables at the top of pages
\makeatletter
\renewcommand{\fps@table}{t}  % Default placement: top of page
\makeatother

% =============================================================================
% LONGTABLE PAGE BREAKING FIXES (Windows compatibility)
% =============================================================================
% Prevent "Infinite glue shrinkage" errors on Windows LaTeX builds
% by giving longtable more flexibility in page breaking

% Allow more flexible page breaking (vs strict \flushbottom)
\raggedbottom

% Process more rows before attempting page break (default is 20)
\setcounter{LTchunksize}{50}

% Add extra stretch for longtable environments specifically
\AtBeginEnvironment{longtable}{%
  \setlength{\emergencystretch}{3em}%
  \setlength{\parskip}{0pt plus 1pt}%
}

% =============================================================================
% TABLE STYLING - Clean tables with crimson borders
% =============================================================================
% Professional table appearance with:
% - Clean white background (no colored rows)
% - Crimson-colored borders
% - Good spacing for readability
%
% Note: Headers are automatically bolded by Quarto when using **text** in source
\usepackage{booktabs}      % Professional table rules (\toprule, \midrule, \bottomrule)
\usepackage{colortbl}      % For colored borders (\arrayrulecolor)

% Global table styling - crimson borders
\setlength{\arrayrulewidth}{0.5pt}          % Thinner borders than default
%\arrayrulecolor{crimson}                    % Crimson borders matching brand

\setcounter{chapter}{0}
\usepackage{needspace}
\let\Needspace\needspace
\makeatletter
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{plain}
\@ifundefined{c@chapter}{\newfloat{vid}{h}{lovid}}{\newfloat{vid}{h}{lovid}[chapter]}
\floatname{vid}{Video}
\newcommand*\listofvids{\listof{vid}{List of Videos}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{sidenotes}{}{\usepackage{sidenotes}}
\@ifpackageloaded{marginnote}{}{\usepackage{marginnote}}
\makeatother
\newcommand{\fbxIconPath}{assets/images/icons/callouts}
\newcommand{\fbxIconFormat}{pdf}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
%%%% ---foldboxy preamble ----- %%%%%

% Load xstring for string manipulation
\RequirePackage{xstring}

% Icon path and format configuration - can be overridden in filter-metadata
\providecommand{\fbxIconPath}{assets/images/icons/callouts}
\providecommand{\fbxIconFormat}{pdf}

% Helper command to include icon with hyphen-to-underscore conversion
% This ensures consistency: callout-quiz-question -> callout_quiz_question
\newcommand{\fbxIncludeIcon}[2]{%
  \StrSubstitute{#1}{-}{_}[\fbxIconName]%
  \includegraphics[width=#2]{\fbxIconPath/icon_\fbxIconName.\fbxIconFormat}%
}

% Legacy fallback colors (keep for compatibility)
\definecolor{fbx-default-color1}{HTML}{c7c7d0}
\definecolor{fbx-default-color2}{HTML}{a3a3aa}
\definecolor{fbox-color1}{HTML}{c7c7d0}
\definecolor{fbox-color2}{HTML}{a3a3aa}

% arguments: #1 typelabelnummer: #2 titel: #3
\newenvironment{fbx}[3]{%
\begin{tcolorbox}[
  enhanced,
  breakable,
  %fontupper=\fontsize{8pt}{10pt}\selectfont,  % 95% of body text (10pt -> 9.5pt)
  before skip=8pt,  % space above box (increased)
  after skip=8pt,   % space below box (increased)
  attach boxed title to top*={xshift=0pt},
  boxed title style={
  %fuzzy shadow={1pt}{-1pt}{0mm}{0.1mm}{gray},
  arc=1.5pt,
  rounded corners=north,
  sharp corners=south,
  top=6pt,          % Adjusted for ~40px equivalent height
  bottom=5pt,       % Adjusted for ~40px equivalent height
  overlay={
      \node [left,outer sep=0em, black,draw=none,anchor=west,
        rectangle,fill=none,inner sep=0pt]
        at ([xshift=4mm]frame.west) {\fbxIncludeIcon{#1}{4.2mm}};
    },
  },
  colframe=#1-color2,             % Border color (auto-generated from YAML)
  colbacktitle=#1-color1,         % Background color (auto-generated from YAML)
  colback=white,
  coltitle=black,
  titlerule=0mm,
  toprule=0.5pt,
  bottomrule=0.5pt,
  leftrule=2.2pt,
  rightrule=0.5pt,
  outer arc=1.5pt,
  arc=1.5pt,
  left=0.5em,       % increased left padding
  bottomtitle=1.5mm, % increased title bottom margin
  toptitle=1.5mm,    % increased title top margin
  title=\hspace{2.5em}\protect#2\hspace{0.2em}\protect#3, % Protect parameters
  extras middle and last={top=4pt} % increased continuation spacing
]}
{\end{tcolorbox}}


% boxed environment with right border
\newenvironment{fbxSimple}[3]{\begin{tcolorbox}[
  enhanced,
  breakable,
  %fontupper=\fontsize{8pt}{10pt}\selectfont,  % 95% of body text (10pt -> 9.5pt)
  before skip=8pt,  % space above box (increased)
  after skip=8pt,   % space below box (increased)
  attach boxed title to top*={xshift=0pt},
  boxed title style={
  %fuzzy shadow={1pt}{-1pt}{0mm}{0.1mm}{gray},
  arc=1.5pt,
  rounded corners=north,
  sharp corners=south,
  top=6pt,          % Adjusted for ~40px equivalent height
  bottom=5pt,       % Adjusted for ~40px equivalent height
  overlay={
      \node [left,outer sep=0em, black,draw=none,anchor=west,
        rectangle,fill=none,inner sep=0pt]
        at ([xshift=3mm]frame.west) {\fbxIncludeIcon{#1}{4.2mm}};
    },
  },
  colframe=#1-color2,             % Border color (auto-generated from YAML)
  colbacktitle=#1-color1,         % Background color (auto-generated from YAML)
  colback=white,
  coltitle=black,
  titlerule=0mm,
  toprule=0.5pt,
  bottomrule=0.5pt,
  leftrule=2.2pt,
  rightrule=0.5pt,
  outer arc=1.5pt,
  arc=1.5pt,
  left=0.5em,       % increased left padding
  bottomtitle=1.5mm, % increased title bottom margin
  toptitle=1.5mm,    % increased title top margin
  title=\hspace{2.5em}\protect#2\hspace{0.2em}\protect#3, % Protect parameters
  boxsep=1pt,
  extras first={bottom=0pt},
  extras last={top=0pt,bottom=-4pt},
  overlay first={
    \draw[line width=1pt,white] ([xshift=2.2pt]frame.south west)-- ([xshift=-0.5pt]frame.south east);
  },
  overlay last={
    \draw[line width=1pt,white] ([xshift=2.2pt]frame.north west)-- ([xshift=-0.5pt]frame.north east);
   }
]}
{\end{tcolorbox}}

%%%% --- end foldboxy preamble ----- %%%%%
%%==== colors from yaml ===%
\definecolor{callout-example-color1}{HTML}{F0F8F6}
\definecolor{callout-example-color2}{HTML}{148F77}
\definecolor{callout-lighthouse-color1}{HTML}{FDF8E6}
\definecolor{callout-lighthouse-color2}{HTML}{B8860B}
\definecolor{callout-quiz-answer-color1}{HTML}{E8F2EA}
\definecolor{callout-quiz-answer-color2}{HTML}{4a7c59}
\definecolor{callout-notebook-color1}{HTML}{F2F7FF}
\definecolor{callout-notebook-color2}{HTML}{2C5282}
\definecolor{callout-chapter-connection-color1}{HTML}{FDF2F7}
\definecolor{callout-chapter-connection-color2}{HTML}{A51C30}
\definecolor{callout-resource-videos-color1}{HTML}{E0F2F1}
\definecolor{callout-resource-videos-color2}{HTML}{20B2AA}
\definecolor{callout-perspective-color1}{HTML}{F7F8FA}
\definecolor{callout-perspective-color2}{HTML}{4A5568}
\definecolor{callout-quiz-question-color1}{HTML}{F0F0F8}
\definecolor{callout-quiz-question-color2}{HTML}{5B4B8A}
\definecolor{callout-checkpoint-color1}{HTML}{E8F5E9}
\definecolor{callout-checkpoint-color2}{HTML}{2E7D32}
\definecolor{callout-colab-color1}{HTML}{FFF5E6}
\definecolor{callout-colab-color2}{HTML}{FF6B35}
\definecolor{callout-resource-slides-color1}{HTML}{E0F2F1}
\definecolor{callout-resource-slides-color2}{HTML}{20B2AA}
\definecolor{callout-definition-color1}{HTML}{F0F4F8}
\definecolor{callout-definition-color2}{HTML}{1B4F72}
\definecolor{callout-resource-exercises-color1}{HTML}{E0F2F1}
\definecolor{callout-resource-exercises-color2}{HTML}{20B2AA}
\definecolor{callout-code-color1}{HTML}{F2F4F8}
\definecolor{callout-code-color2}{HTML}{D1D7E0}
%=============%

\usepackage{hyphenat}
\usepackage{ifthen}
\usepackage{calc}
\usepackage{calculator}



\usepackage{graphicx}
\usepackage{geometry}
\usepackage{afterpage}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{fadings}
\usepackage[pagecolor=none]{pagecolor}


% Set the titlepage font families







% Set the coverpage font families

\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Machine Learning Systems},
  pdfauthor={Vijay Janapa Reddi},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Machine Learning Systems}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Volume I: Introduction}
\author{Vijay Janapa Reddi}
\date{January 28, 2026}
\begin{document}
%%%%% begin titlepage extension code

  \begin{frontmatter}

\begin{titlepage}
% This is a combination of Pandoc templating and LaTeX
% Pandoc templating https://pandoc.org/MANUAL.html#templates
% See the README for help

\thispagestyle{empty}

\newgeometry{top=-100in}

% Page color

\newcommand{\coverauthorstyle}[1]{{\fontsize{20}{24.0}\selectfont
{#1}}}

\begin{tikzpicture}[remember picture, overlay, inner sep=0pt, outer sep=0pt]

\tikzfading[name=fadeout, inner color=transparent!0,outer color=transparent!100]
\tikzfading[name=fadein, inner color=transparent!100,outer color=transparent!0]
\node[anchor=south west, rotate=0, opacity=1] at ($(current page.south west)+(0.225\paperwidth, 9)$) {
\includegraphics[width=\paperwidth, keepaspectratio]{assets/images/covers/cover-image-transparent-vol1.png}};

% Title
\newcommand{\titlelocationleft}{0.075\paperwidth}
\newcommand{\titlelocationbottom}{0.4\paperwidth}
\newcommand{\titlealign}{left}

\begin{scope}{%
\fontsize{52}{62.4}\selectfont
\node[anchor=north
west, align=left, rotate=0] (Title1) at ($(current page.south west)+(\titlelocationleft,\titlelocationbottom)$)  [text width = 0.9\paperwidth]  {{\nohyphens{Machine
Learning Systems}}};
}
\end{scope}

% Author
\newcommand{\authorlocationleft}{.925\paperwidth}
\newcommand{\authorlocationbottom}{0.150\paperwidth}
\newcommand{\authoralign}{right}

\begin{scope}
{%
\fontsize{20}{24.0}\selectfont
\node[anchor=north
east, align=right, rotate=0] (Author1) at ($(current page.south west)+(\authorlocationleft,\authorlocationbottom)$)  [text width = 6in]  {\coverauthorstyle{Vijay\\Janapa
Reddi\\}};
}
\end{scope}

% Footer
\newcommand{\footerlocationleft}{0.075\paperwidth}
\newcommand{\footerlocationbottom}{0.475\paperwidth}
\newcommand{\footerlocationalign}{left}

\begin{scope}
{%
\fontsize{25}{30.0}\selectfont
 \node[anchor=north west, align=left, rotate=0] (Footer1) at %
($(current page.south west)+(\footerlocationleft,\footerlocationbottom)$)  [text width = 0.9\paperwidth]  {{\nohyphens{Volume
I: Introduction}}};
}
\end{scope}

\end{tikzpicture}
\clearpage
\restoregeometry
%%% TITLE PAGE START

% Set up alignment commands
%Page
\newcommand{\titlepagepagealign}{
\ifthenelse{\equal{left}{right}}{\raggedleft}{}
\ifthenelse{\equal{left}{center}}{\centering}{}
\ifthenelse{\equal{left}{left}}{\raggedright}{}
}


\newcommand{\titleandsubtitle}{
% Title and subtitle
{{\huge{\bfseries{\nohyphens{Machine Learning Systems}}}}\par
}%

\vspace{\betweentitlesubtitle}
{
{\large{\textit{\nohyphens{Volume I: Introduction}}}}\par
}}
\newcommand{\titlepagetitleblock}{
\titleandsubtitle
}

\newcommand{\authorstyle}[1]{{\large{#1}}}

\newcommand{\affiliationstyle}[1]{{\large{#1}}}

\newcommand{\titlepageauthorblock}{
{\authorstyle{\nohyphens{Vijay Janapa
Reddi}{\textsuperscript{1}}\textsuperscript{,}{\textsuperscript{,*}}}}}

\newcommand{\titlepageaffiliationblock}{
\hangindent=1em
\hangafter=1
{\affiliationstyle{
{1}.~Harvard University


\vspace{1\baselineskip}
* \textit{Correspondence:}~Vijay Janapa Reddi~vj@eecs.harvard.edu
}}
}
\newcommand{\headerstyled}{%
{}
}
\newcommand{\footerstyled}{%
{\large{}}
}
\newcommand{\datestyled}{%
{January 28, 2026}
}


\newcommand{\titlepageheaderblock}{\headerstyled}

\newcommand{\titlepagefooterblock}{
\footerstyled
}

\newcommand{\titlepagedateblock}{
\datestyled
}

%set up blocks so user can specify order
\newcommand{\titleblock}{\newlength{\betweentitlesubtitle}
\setlength{\betweentitlesubtitle}{0.05\textheight}
{

{\titlepagetitleblock}
}

\vspace{4\baselineskip}
}

\newcommand{\authorblock}{{\titlepageauthorblock}

\vspace{2\baselineskip}
}

\newcommand{\affiliationblock}{{\titlepageaffiliationblock}

\vspace{0pt}
}

\newcommand{\logoblock}{}

\newcommand{\footerblock}{}

\newcommand{\dateblock}{{\titlepagedateblock}

\vspace{0pt}
}

\newcommand{\headerblock}{}

\thispagestyle{empty} % no page numbers on titlepages


\newcommand{\vrulecode}{\textcolor{black}{\rule{\vrulewidth}{\textheight}}}
\newlength{\vrulewidth}
\setlength{\vrulewidth}{2pt}
\newlength{\B}
\setlength{\B}{\ifdim\vrulewidth > 0pt 0.05\textwidth\else 0pt\fi}
\newlength{\minipagewidth}
\ifthenelse{\equal{left}{left} \OR \equal{left}{right} }
{% True case
\setlength{\minipagewidth}{\textwidth - \vrulewidth - \B - 0.1\textwidth}
}{
\setlength{\minipagewidth}{\textwidth - 2\vrulewidth - 2\B - 0.1\textwidth}
}
\ifthenelse{\equal{left}{left} \OR \equal{left}{leftright}}
{% True case
\raggedleft % needed for the minipage to work
\vrulecode
\hspace{\B}
}{%
\raggedright % else it is right only and width is not 0
}
% [position of box][box height][inner position]{width}
% [s] means stretch out vertically; assuming there is a vfill
\begin{minipage}[b][\textheight][s]{\minipagewidth}
\titlepagepagealign
\titleblock

Prof.~Vijay Janapa Reddi

School of Engineering and Applied Sciences

Harvard University

\vspace{80mm}

With heartfelt gratitude to the community for their invaluable
contributions and steadfast support.

\vfill

January 28, 2026

\vfill
\par

\end{minipage}\ifthenelse{\equal{left}{right} \OR \equal{left}{leftright} }{
\hspace{\B}
\vrulecode}{}
\clearpage
%%% TITLE PAGE END
\end{titlepage}
\setcounter{page}{1}
\end{frontmatter}

%%%%% end titlepage extension code

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\mainmatter
\bookmarksetup{startatroot}

\chapter*{Welcome to Volume I}\label{welcome-to-volume-i}
\addcontentsline{toc}{chapter}{Welcome to Volume I}

\markboth{Welcome to Volume I}{Welcome to Volume I}

\section*{What You Will Learn}\label{what-you-will-learn}
\addcontentsline{toc}{section}{What You Will Learn}

\markright{What You Will Learn}

Volume I progresses through four stages:

\begin{itemize}
\tightlist
\item
  \textbf{Part I: Foundations} --- Build your conceptual foundation with
  mental models that underpin all effective systems work.
\item
  \textbf{Part II: Build} --- Engineer complete workflows from data
  pipelines through training infrastructure.
\item
  \textbf{Part III: Optimize} --- Transform theoretical understanding
  into systems that run efficiently in resource-constrained
  environments.
\item
  \textbf{Part IV: Deploy} --- Navigate serving, operations, and
  responsible engineering practices.
\end{itemize}

\section*{Prerequisites}\label{prerequisites}
\addcontentsline{toc}{section}{Prerequisites}

\markright{Prerequisites}

This volume assumes:

\begin{itemize}
\tightlist
\item
  \textbf{Programming proficiency} in Python with familiarity in NumPy
\item
  \textbf{Mathematics foundations} in linear algebra, calculus, and
  probability at the undergraduate level
\item
  Prior ML experience is helpful but not required;
  \textbf{?@sec-deep-learning-systems-foundations} provides essential
  background
\end{itemize}

\section*{Support Our Mission}\label{support-our-mission}
\addcontentsline{toc}{section}{Support Our Mission}

\markright{Support Our Mission}

\section*{Continue Your Journey}\label{continue-your-journey}
\addcontentsline{toc}{section}{Continue Your Journey}

\markright{Continue Your Journey}

\section*{Listen to the AI Podcast}\label{listen-to-the-ai-podcast}
\addcontentsline{toc}{section}{Listen to the AI Podcast}

\markright{Listen to the AI Podcast}

\section*{Want to Help Out?}\label{want-to-help-out}
\addcontentsline{toc}{section}{Want to Help Out?}

\markright{Want to Help Out?}

This is a collaborative project, and your input matters. If you'd like
to contribute, check out our
\href{https://github.com/harvard-edge/cs249r_book/blob/dev/docs/contribute.md}{contribution
guidelines}. Feedback, corrections, and new ideas are welcome. Simply
file a GitHub
\href{https://github.com/harvard-edge/cs249r_book/issues}{issue}.

\bookmarksetup{startatroot}

\chapter{Conclusion}\label{sec-conclusion}

\marginnote{\begin{footnotesize}

\emph{DALL·E 3 Prompt: An image depicting a concluding chapter of an ML
systems book, open to a two-page spread. The pages summarize key
concepts such as neural networks, model architectures, hardware
acceleration, and MLOps. One page features a diagram of a neural network
and different model architectures, while the other page shows
illustrations of hardware components for acceleration and MLOps
workflows. The background includes subtle elements like circuit patterns
and data points to reinforce the technological theme. The colors are
professional and clean, with an emphasis on clarity and understanding.}

\end{footnotesize}}

\noindent
\pandocbounded{\includegraphics[keepaspectratio]{contents/vol1/conclusion/images/png/cover_conclusion.png}}

\section*{Purpose}\label{purpose}
\addcontentsline{toc}{section}{Purpose}

\markright{Purpose}

\emph{Why does building machine learning systems require synthesizing
principles from across the entire engineering stack rather than
mastering individual components in isolation?}

The systems that actually work in production are not collections of
independently optimized components but integrated wholes where decisions
in one domain propagate constraints to every other. A model architecture
choice determines memory requirements that constrain hardware selection,
which influences quantization strategy, which affects accuracy, which
feeds back to architecture design. An engineer who optimizes training
without considering serving builds models that cannot be deployed. An
engineer who selects hardware without understanding workload
characteristics wastes money on capabilities that will never be used. An
engineer who ignores operational requirements builds systems that work
in demos but fail in production. The discipline of ML systems
engineering is the discipline of seeing these connections---of
understanding that every choice opens some paths and closes others, that
optimization in isolation produces local maxima that are global
failures, and that the principles governing good decisions transcend the
specific technologies that implement them.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, colbacktitle=quarto-callout-tip-color!10!white, rightrule=.15mm, coltitle=black, colframe=quarto-callout-tip-color-frame, colback=white, left=2mm, bottomtitle=1mm, titlerule=0mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Learning Objectives}, toprule=.15mm, opacityback=0]

\begin{itemize}
\item
  Synthesize the six core systems engineering principles (measure
  everything, design for 10x scale, optimize the bottleneck, plan for
  failure, design cost-consciously, co-design for hardware) into a
  unified framework that transcends specific ML technologies
\item
  Analyze how systems engineering principles manifest differently across
  the three critical domains: building technical foundations,
  engineering for performance at scale, and navigating production
  reality
\item
  Evaluate trade-offs between deployment contexts (cloud, edge, mobile,
  embedded) by applying multiple principles simultaneously to assess
  scalability, efficiency, and reliability requirements
\item
  Assess the evolution from isolated components to integrated ML systems
  by tracing how data pipelines, training frameworks, model
  architectures, hardware acceleration, and operational infrastructure
  interconnect
\item
  Critique the societal implications of ML systems design decisions by
  examining how technical choices in efficiency, security, and
  sustainability affect democratization, accessibility, and
  environmental impact
\item
  Formulate professional strategies for applying systems thinking to
  emerging challenges in robust AI, compound systems, and the path
  toward artificial general intelligence
\end{itemize}

\end{tcolorbox}

\section{Synthesizing ML Systems Engineering: From Components to
Intelligence}\label{sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5}

This volume began with a simple mathematical formula: the \textbf{Iron
Law of ML Systems} (\textbf{?@sec-silicon-contract}). At the time, the
terms \textbf{Data Movement}, \textbf{Compute}, and \textbf{Overhead}
may have seemed abstract. Today, they are your primary engineering
levers. You have mastered the quantitative analysis of systems that
seemed opaque at the start. You now understand that building
intelligence is not just about writing algorithms; it is about honoring
the \textbf{Silicon Contract}---the physical and economic agreement
between the model and the machine. \textbf{?@sec-ai-acceleration}
equipped you to calculate arithmetic intensity and identify whether your
workloads are memory-bound or compute-bound, transforming vague
performance intuitions into quantitative engineering decisions.

This quantitative foundation reflects a broader truth: contemporary
artificial intelligence\sidenote{\textbf{Artificial Intelligence
(Systems Perspective)}: Intelligence emerging from integrated systems
rather than individual algorithms. Modern AI applications combine data
pipelines (often processing very large corpora), distributed training
(coordinating large accelerator fleets), efficient inference (serving
production traffic), security measures (preventing attacks), and
governance frameworks (ensuring safety). Success depends on systems
engineering excellence across all components. } achievements require
careful integration of interacting components that unifies computational
theory with engineering practice. This systems perspective positions
machine learning within the same engineering principles that built
reliable computers, where transformative capabilities arise from
coordinating many parts together. The Transformer architectures
(\citeproc{ref-vaswani2017attention}{Vaswani et al. 2017}) enabling
large language models exemplify this principle. Their practical utility
depends on integrating mathematical foundations with distributed
training infrastructure, algorithmic optimization techniques, and robust
operational frameworks.

Three fundamental questions define the boundaries of machine learning
systems engineering. First, what enduring principles transcend specific
technologies and guide engineering decisions across deployment contexts,
from contemporary production systems to anticipated artificial general
intelligence architectures? Second, how do these principles manifest
across resource-abundant cloud infrastructures, resource-constrained
edge devices, and emerging generative systems? Third, how can this
knowledge create systems that satisfy technical requirements while
addressing broader societal objectives and ethical considerations?

This systems thinking approach has structured our entire volume, drawing
from established computer systems research and engineering methodology.
From the technical concepts established throughout the text, we derive
six fundamental engineering principles: comprehensive measurement,
scale-oriented design, bottleneck optimization, systematic failure
planning, cost-conscious design, and hardware co-design. These
principles provide a framework for decision-making across machine
learning systems contexts, and we examine their application across three
domains: establishing technical foundations, engineering for performance
at scale, and navigating production deployment realities.

The analysis examines emerging frontiers where these principles face
their greatest challenges. From developing resilient AI systems that
manage failure modes gracefully to deploying artificial intelligence for
societal benefit across healthcare, education, and climate science,
these engineering principles will shape how artificial intelligence
affects society. As artificial intelligence systems approach general
intelligence capabilities\sidenote{\textbf{Artificial General
Intelligence (AGI)}: AI systems matching human-level performance across
all cognitive tasks. Any compute requirements for AGI remain highly
uncertain, but discussions often place them at the scale of
(10\^{}\{15\}) to (10\^{}\{17\}) FLOPS and beyond. Regardless of the
exact number, the systems challenge is that reaching such regimes would
demand novel distributed architectures, energy-efficient hardware, and
long-term infrastructure investment. }, the critical question becomes
whether they will be engineered according to established principles of
sound systems design and responsible computing.

The frameworks in this chapter establish approaches for navigating the
rapidly evolving artificial intelligence technology landscape while
maintaining focus on fundamental engineering objectives: creating
systems that scale effectively, perform reliably under diverse
conditions, and address significant societal challenges.

\subsection{The System is the
Model}\label{sec-conclusion-system-model-0103}

We often speak of the ``model'' as the weights file---the 500MB blob of
floating-point numbers. But in a production environment, the weights are
just one component of the true model.

The \textbf{True Model} is the sum of: * The \textbf{Data Pipeline} that
defines what the model sees. * The \textbf{Training Infrastructure} that
determines what it learns. * The \textbf{Serving System} that decides
how it interacts with the world. * The \textbf{Monitoring Loop} that
keeps it tethered to reality.

When you optimize the system, you improve the model. When you neglect
the system, you degrade the model. Systems Engineering is not a wrapper
around ML; it is the implementation of ML. The system \emph{is} the
model.

This insight that the system encompasses everything shaping model
behavior has significant implications for ML engineering. You now have
theoretical understanding and the conceptual foundation for professional
application. But understanding alone does not guide practice. We need
principles: distilled patterns that apply regardless of which framework
you use, which hardware you target, or which domain you serve. We begin
by articulating six core principles, then trace their application across
three critical domains.

\subsection{The Lighthouse
Journey}\label{sec-conclusion-lighthouse-journey}

Throughout this volume, five Lighthouse Archetypes have served as our
systems detectives, revealing how different workloads expose different
bottlenecks. \textbf{ResNet-50} taught us compute-bound optimization:
how batch size transforms memory-bound inference into compute-bound
throughput, and why pruning achieves different speedups on different
hardware. \textbf{GPT-2/Llama} exposed the memory bandwidth wall: why
attention is memory-bound, how KV-caches dominate serving costs, and why
model parallelism becomes necessary at scale. \textbf{MobileNetV2}
demonstrated efficiency under constraint: depthwise separable
convolutions trading parameters for latency, quantization enabling
deployment on mobile NPUs, and the Pareto frontier between accuracy and
power. \textbf{DLRM} revealed the embedding table challenge: memory
capacity as the binding constraint, the unique demands of recommendation
systems, and why sparse operations behave differently than dense matrix
multiplication. \textbf{Keyword Spotting (KWS)} brought us to the
extreme edge: sub-megabyte models running on microcontrollers, always-on
inference under microwatt power budgets, and the TinyML frontier where
every byte matters.

These five workloads span the full deployment spectrum from datacenter
to microcontroller, and together they have probed every principle we
will now synthesize. The systems thinking you have developed by
following these Lighthouses across chapters---from architecture design
through training, optimization, and deployment---is precisely the
integrated perspective that distinguishes ML systems engineering from
isolated algorithm development.

\phantomsection\label{quiz-question-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5}
\begin{fbx}{callout-quiz-question}{Self-Check: Question 1.1}{}
\phantomsection\label{quiz-question-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which principle is emphasized as crucial for the development of
  contemporary AI systems according to the overview?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Isolated algorithmic innovation
  \item
    Data collection
  \item
    Architectural innovation
  \item
    Systems integration
  \end{enumerate}
\item
  Explain how the systems thinking paradigm contributes to the
  development of AI systems.
\item
  What is a key challenge when scaling AI systems towards Artificial
  General Intelligence (AGI)?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Developing new algorithms
  \item
    Scaling current ML systems principles
  \item
    Increasing data collection
  \item
    Improving user interfaces
  \end{enumerate}
\item
  How might the principles of ML systems engineering be applied to
  address societal challenges?
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-answer-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5]{\textbf{See Answer~$\rightarrow$}}

\end{fbx}

\section{Systems Engineering Principles for
ML}\label{sec-conclusion-systems-engineering-principles-ml-2ca9}

Table~\ref{tbl-six-principles} presents these six core principles, which
outlast any particular tool or framework and provide enduring guidance
for building today's production systems and tomorrow's artificial
general intelligence.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2260}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2534}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2260}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2808}}@{}}
\caption{\textbf{Six Core Systems Engineering Principles}: These
principles provide enduring guidance regardless of how specific
technologies evolve. Each principle connects to a core question
engineers must answer, key metrics for measurement, and chapter examples
demonstrating application.}\label{tbl-six-principles}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Principle}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Core Question}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Key Metric}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Chapter Example}
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Principle}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Core Question}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Key Metric}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Chapter Example}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{1. Measure Everything} & Where are the bottlenecks? & Roofline
operational intensity & \textbf{?@sec-ai-acceleration} \\
\textbf{2. Design for 10x Scale} & Will it survive production? &
Headroom factor & \textbf{?@sec-machine-learning-operations-mlops} \\
\textbf{3. Optimize the Bottleneck} & What limits performance? & Memory
bandwidth utilization & \textbf{?@sec-ai-acceleration} \\
\textbf{4. Plan for Failure} & What happens when components fail? &
MTBF, recovery time &
\textbf{?@sec-machine-learning-operations-mlops} \\
\textbf{5. Design Cost-Consciously} & What is the TCO? & \$/FLOP,
\$/inference & \textbf{?@sec-introduction} \\
\textbf{6. Co-Design for Hardware} & Does algorithm match hardware? &
TOPS/W, arithmetic intensity & \textbf{?@sec-model-compression} \\
\end{longtable}

Understanding how these principles relate to the foundational frameworks
from earlier chapters reveals their interconnected nature. These
principles map directly onto the AI Triad that
\textbf{?@sec-introduction} established and operate within the
development lifecycle discipline that
\textbf{?@sec-ai-development-workflow} defined. The Data dimension
encompasses Principles 1 and 5, since data quality monitoring and
cost-effective data management determine learning outcomes. The
Algorithm dimension encompasses Principles 3 and 6, since algorithmic
efficiency and hardware alignment determine computational feasibility.
The Machine dimension encompasses Principles 2 and 4, since robust
machines that scale gracefully enable reliable deployment. This mapping
reveals why optimizing any single AI Triad component in isolation leads
to suboptimal outcomes, as the principles depend on each other across
all three dimensions. When performance stalls, check the DAM: where is
the flow blocked?

The following sections examine each principle in detail, tracing how it
emerged from concepts you have mastered and how it guides practice
across deployment contexts.

\textbf{Principle 1: Measure Everything}

\textbf{?@sec-benchmarking-ai} introduced measurement frameworks that,
together with the monitoring systems from
\textbf{?@sec-machine-learning-operations-mlops}, reinforce a
fundamental truth: you cannot optimize what you do not measure.
Successful ML systems instrument every component, and four analytical
frameworks provide measurement foundations that transcend specific
technologies.

Roofline analysis\sidenote{\textbf{Roofline Analysis}: Named for its
visual appearance, this performance model plots arithmetic intensity
against throughput, creating a shape resembling a house roofline.
Introduced by Williams, Waterman, and Patterson
(\citeproc{ref-williams2009roofline}{Williams, Waterman, and Patterson
2009}), the model uses two ``ceilings'': a horizontal compute roof (peak
FLOPS) and a sloped memory roof (peak bandwidth). Where your workload
falls relative to these ceilings reveals whether optimization should
target memory or compute. Transformer attention sits memory-bound (low
intensity); GEMM sits compute-bound (high intensity). } identifies
computational bottlenecks by plotting operational intensity against peak
performance. This technique reveals whether systems are memory bound or
compute bound, essential for optimizing everything from training
workloads to edge inference. Beyond performance, cost performance
evaluation compares total ownership costs against delivered
capabilities, incorporating training expenses, infrastructure
requirements, and operational overhead to guide deployment decisions.
Benchmarking then establishes reproducible measurement protocols that
enable fair comparisons across architectures, frameworks, and deployment
targets, ensuring optimization efforts target actual rather than
perceived bottlenecks.

\textbf{Principle 2: Design for 10x Scale}

Systems that work in research rarely survive production traffic.
Effective systems require design for an order of magnitude more data,
users, and computational demands than currently
needed\sidenote{\textbf{10x Scale Design}: Engineering rule of thumb
that systems should include substantial headroom relative to expected
load to survive real-world variability (traffic spikes, failures, and
changing usage patterns). The exact headroom factor depends on risk
tolerance and workload characteristics, but designing for significant
scale-up reduces the likelihood of brittle systems. }.
\textbf{?@sec-ml-system-architecture} demonstrated how this principle
manifests across deployment contexts: cloud systems must handle traffic
spikes from thousands to millions of users, edge systems need redundancy
for network partitions, and embedded systems require graceful
degradation under resource exhaustion.

Yet scale alone provides no value if systems waste resources on
non-critical paths. A recommendation system scaled to handle ten times
its current traffic still fails if that traffic spends ninety percent of
its time waiting for a single database query. This motivates our third
principle: identify and optimize the true
bottleneck\sidenote{\textbf{Bottleneck}: The literal term (the neck of a
bottle) dates to the early 18th century, but its metaphorical use
meaning ``a point where flow becomes congested'' first appeared in 1896.
By 1922, it had generalized to mean any obstruction to flow. The
metaphor works because it captures a systems insight: widening only the
bottleneck increases throughput, while widening anything else wastes
effort. In ML systems, bottlenecks shift between memory bandwidth,
compute, network, and I/O depending on workload characteristics. }
rather than distributing effort across all components equally.

\textbf{Principle 3: Optimize the Bottleneck}

The majority of performance gains come from addressing the primary
constraint rather than distributing effort across all components. Recall
the roofline analysis in \textbf{?@sec-ai-acceleration}: memory-bound
workloads can see multi-fold improvements (documented cases show up to
5x) from bandwidth optimization, while compute optimization yields
limited gains when memory is the true bottleneck. The primary constraint
may be memory bandwidth in training workloads, network latency in
distributed inference, or energy consumption in mobile deployment.

\textbf{Principle 4: Plan for Failure}

Robustness techniques and security frameworks assume systems will fail,
requiring redundancy, monitoring, and recovery mechanisms from the
start. Production systems experience component failures, network
partitions, and adversarial inputs daily. These realities demand circuit
breakers\sidenote{\textbf{Circuit Breakers}: Borrowed from electrical
engineering, where early circuit protection concepts emerged in the late
19th century (Edison developed related ideas in 1879, though modern
miniature circuit breakers were standardized by Brown, Boveri \& Cie in
1924). Michael Nygard adapted the metaphor for software in his 2007 book
``Release It!'', creating a pattern that prevents cascading failures by
temporarily blocking requests to failing services. When error rates
exceed thresholds, circuit breakers ``open'' to prevent additional load,
automatically ``closing'' after cooldown periods to detect service
recovery. }, graceful fallbacks, and automated recovery procedures.

\textbf{Principle 5: Design Cost-Consciously}

From sustainability concerns to operational expenses, every technical
decision has economic implications. Optimizing for total cost of
ownership\sidenote{\textbf{Total Cost of Ownership (TCO) for ML}:
Comprehensive cost including training, infrastructure, data preparation,
operations (monitoring, updates, compliance), and failure costs. For
large-scale systems, training and serving can both be significant
drivers, and downtime costs can dominate in high-revenue contexts. TCO
analysis drives architectural decisions from cloud vs.~edge deployment
to model compression priorities. } becomes critical when cloud
accelerator costs can reach tens of thousands of dollars per month for
large models (\citeproc{ref-strubell2019energy}{Strubell, Ganesh, and
McCallum 2019}), making efficiency optimizations potentially worth
millions in operational savings over deployment lifetimes.

\textbf{Principle 6: Co-Design for Hardware}

Efficient AI systems require algorithm-hardware co-optimization rather
than individual component excellence, as \textbf{?@sec-ai-acceleration}
made clear through acceleration techniques that depend on matching
algorithms to hardware capabilities. This approach spans three critical
dimensions. Algorithm hardware matching ensures computational patterns
align with target hardware capabilities: systolic arrays favor dense
matrix operations while sparse accelerators require structured pruning
patterns. Memory hierarchy optimization analyzes data movement costs and
optimizes for cache locality. Energy efficiency modeling incorporates
TOPS/W metrics to guide power-conscious design decisions essential for
mobile and edge deployment.

These six principles do not operate in isolation. Measuring everything
(Principle 1) identifies where optimization effort should focus
(Principle 3). Designing for scale (Principle 2) anticipates the
failures that must be planned for (Principle 4). Cost consciousness
(Principle 5) motivates the hardware co-design (Principle 6) that
maximizes value per dollar. Understanding these interconnections
prepares us to see how the principles manifest across different
engineering domains.

\phantomsection\label{quiz-question-sec-conclusion-systems-engineering-principles-ml-2ca9}
\begin{fbx}{callout-quiz-question}{Self-Check: Question 1.2}{}
\phantomsection\label{quiz-question-sec-conclusion-systems-engineering-principles-ml-2ca9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which of the following best describes the purpose of roofline analysis
  in ML systems?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    To determine the memory capacity of a system
  \item
    To evaluate the cost efficiency of cloud deployments
  \item
    To identify computational bottlenecks by plotting operational
    intensity against peak performance
  \item
    To measure the energy consumption of mobile devices
  \end{enumerate}
\item
  True or False: Designing for 10x scale means that systems should be
  optimized for current loads only.
\item
  Explain how the principle of `Optimize the Bottleneck' can be applied
  to enhance the performance of an ML system.
\item
  What is a critical insight gained from systematic benchmarking in ML
  systems?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Systems always fail at expected loads
  \item
    Systems rarely fail when demand exceeds design assumptions by orders
    of magnitude
  \item
    Benchmarking only measures computational throughput
  \item
    Benchmarking is unnecessary for cloud-based systems
  \end{enumerate}
\item
  In a production ML system, why is it important to plan for failure,
  and how can this be implemented?
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-answer-sec-conclusion-systems-engineering-principles-ml-2ca9]{\textbf{See Answer~$\rightarrow$}}

\end{fbx}

\section{Applying Principles Across Three Critical
Domains}\label{sec-conclusion-applying-principles-across-three-critical-domains-821a}

The six principles operate across three critical domains: building
robust technical foundations where measurement and co-design establish
the groundwork, engineering for performance at scale where optimization
and planning enable growth, and navigating production realities where
all principles converge under operational constraints.

\subsection{Building Technical
Foundations}\label{sec-conclusion-building-technical-foundations-d0ad}

Machine learning systems engineering rests on solid technical
foundations where measurement and co-design principles establish the
groundwork for everything that follows. Three foundational layers build
upon each other: data engineering provides quality inputs, mathematical
understanding enables effective algorithm design, and frameworks
translate that understanding into executable systems.

\textbf{?@sec-data-engineering-ml} established that data quality
determines system quality: production ML failures trace more frequently
to data issues than to algorithmic limitations. ``Data is the new code''
(\citeproc{ref-karpathy2017software}{Karpathy 2017}) for neural
networks, and like code, data requires version control, testing, and
continuous validation. That chapter's approaches to feature engineering,
data validation, and pipeline reliability enable production systems to
instrument schema evolution, lineage tracking, and quality degradation
detection. When data quality degrades, effects cascade through the
entire system, silently eroding accuracy without triggering conventional
error alerts, as \textbf{?@sec-introduction} examined when exploring how
ML systems fail differently from traditional software. This makes data
governance both a technical necessity and ethical imperative, with the
measurement principle applying through continuous monitoring of
distribution shifts, labeling consistency, and pipeline performance.

With quality data in place,
\textbf{?@sec-deep-learning-systems-foundations} provided the
mathematical foundations for understanding how neural networks learn,
from forward propagation through
backpropagation\sidenote{\textbf{Backpropagation}: Short for ``backward
propagation of errors.'' While the mathematical foundations trace to
Seppo Linnainmaa's 1970 work on automatic differentiation, Rumelhart,
Hinton, and Williams (\citeproc{ref-rumelhart1986learning}{Rumelhart,
Hinton, and Williams 1986}) popularized the technique in their landmark
1986 Nature paper. The name captures the algorithm's essence: computing
how errors at the output ``propagate backward'' through layers to
determine how each weight contributed to the mistake. }, establishing
the computational patterns that drive hardware and framework design
decisions.

Building on this understanding, frameworks and training systems embody
both scale and co-design principles. \textbf{?@sec-ai-frameworks}
introduced you to navigating trade-offs within the framework ecosystem:
TensorFlow's production maturity versus PyTorch's research flexibility,
TensorFlow Lite's mobile optimization versus JAX's research
expressiveness. These choices illustrate hardware co-design: the
framework you select constrains which hardware targets are practical and
which deployment paths remain open.

\textbf{?@sec-ai-training} then revealed how these frameworks scale
beyond single machines. Data parallelism strategies transform weeks of
training into hours. Model parallelism enables architectures too large
for any single device. Mixed precision techniques double effective
throughput. Gradient compression reduces communication overhead.
Together, these techniques demonstrate Principle 2: designing for ten
times scale beyond current needs while maintaining hardware alignment.

Model efficiency determines whether AI moves beyond laboratories to
resource-constrained deployment. Neural compression algorithms including
pruning, quantization, and knowledge distillation, detailed in
\textbf{?@sec-model-compression}, address bottlenecks in memory,
compute, and energy while maintaining performance. This multidimensional
optimization requires identifying the limiting factor and addressing it
directly rather than pursuing isolated improvements.

\subsection{Engineering for Performance at
Scale}\label{sec-conclusion-engineering-performance-scale-198d}

Technical foundations provide the substrate for ML systems, but a
recommendation system with clean data pipelines and efficient models
still fails if it cannot serve millions of users with sub-100ms latency.
The second pillar of ML systems engineering transforms these foundations
into systems that perform reliably at scale, shifting focus from ``does
it work?'' to ``does it work efficiently for millions of users?''

\subsubsection{Model Architecture and
Optimization}\label{sec-conclusion-model-architecture-optimization-ebaa}

\textbf{?@sec-dnn-architectures} covered the progression from simple
perceptrons\sidenote{\textbf{Perceptron}: Coined by psychologist Frank
Rosenblatt in 1957 (\citeproc{ref-rosenblatt1957perceptron}{Rosenblatt
1957}), combining ``percept'' (from perception) with ``-tron'' (the
era's suffix for electronic devices, as in electron or cyclotron).
Rosenblatt intended it as a generic name for neural networks that
perceive and recognize patterns. His work at the Cornell Aeronautical
Laboratory, simulated on an IBM 704, established the foundation for all
modern neural networks. }, where weighted inputs produce decisions,
through convolutional networks that exploit spatial structure for
parameter efficiency, to Transformer architectures whose attention
mechanisms\sidenote{\textbf{Attention Mechanism}: Named by analogy to
human cognitive attention, the ability to focus on relevant information
while filtering out distractions. First introduced by Bahdanau et al.
(\citeproc{ref-bahdanau2014neural}{Bahdanau, Cho, and Bengio 2014}) for
machine translation, then elevated to prominence by the 2017 ``Attention
Is All You Need'' paper (\citeproc{ref-vaswani2017attention}{Vaswani et
al. 2017}). The mechanism assigns learned weights to input elements
based on relevance, enabling models to ``attend'' selectively to
important parts of sequences. } enable the language understanding
powering today's AI assistants. Yet architectural innovation alone
proves insufficient for production deployment;
\textbf{?@sec-model-compression} bridges research architectures and
production constraints through optimization techniques that make
deployment feasible.

Following the hardware co-design principles outlined earlier, three
complementary compression approaches address bottleneck optimization.
Pruning removes redundant parameters while maintaining accuracy,
quantization reduces precision requirements for 4x memory reduction, and
knowledge distillation transfers capabilities to compact networks for
resource-constrained deployment.

The Deep Compression pipeline (\citeproc{ref-han2015deep}{Han, Mao, and
Dally 2015}) integrates these techniques:
pruning\sidenote{\textbf{Pruning}: Borrowed from horticulture, where it
means removing dead or overgrown branches to encourage healthy growth.
In neural networks, the metaphor gained additional resonance from
synaptic pruning in neuroscience, where the brain eliminates unused
neural connections between childhood and puberty. LeCun, Denker, and
Solla's ``Optimal Brain Damage'' (\citeproc{ref-lecun1990optimal}{LeCun,
Denker, and Solla 1989}) formalized the technique for artificial
networks, showing that removing low-magnitude weights improves both
efficiency and generalization. },
quantization\sidenote{\textbf{Quantization}: From Latin ``quantus''
meaning ``how much.'' Max Planck introduced the physics concept in 1900,
proposing that energy comes in discrete packets (quanta) rather than
continuous values. In ML, quantization similarly discretizes continuous
floating-point weights into a smaller set of values (e.g., INT8),
trading precision for 2-4x memory reduction and faster computation on
integer-optimized hardware. These optimizations validate Principle 3's
core insight: identify the bottleneck, whether memory, compute, or
energy, then optimize directly rather than pursuing isolated
improvements. }, and coding combine for 10-50x compression
ratios\sidenote{\textbf{Efficient Architecture Design}: MobileNets
(\citeproc{ref-howard2017mobilenets}{Howard et al. 2017}) decompose
standard convolutions into depthwise (spatial filtering) and pointwise
(channel mixing) operations, achieving 8-9x computation reduction. This
constraint-driven innovation, born from mobile deployment limits,
influenced all subsequent efficient architectures. EfficientNet,
MobileNetV3, and ShuffleNet build on these foundations. }. Operator
fusion, which combines conv-batchnorm-relu sequences, significantly
reduces memory bandwidth by eliminating intermediate memory round-trips,
demonstrating how algorithmic and systems optimizations compound when
guided by the co-design imperative.

\subsubsection{Hardware Acceleration and System
Performance}\label{sec-conclusion-hardware-acceleration-system-performance-59d7}

\textbf{?@sec-ai-acceleration} shows how specialized hardware transforms
computational bottlenecks into acceleration opportunities. GPUs excel at
parallel matrix operations, TPUs\sidenote{\textbf{Tensor Processing Unit
(TPU)}: Google's custom ML ASIC using systolic arrays (processing
elements arranged in a grid where data flows rhythmically from element
to element) for matrix operations. Initial benchmarks showed TPU v1
achieving 15-30x better performance/watt than contemporary 2016-era GPUs
(K80) and CPUs (Haswell) for inference workloads
(\citeproc{ref-jouppi2017datacenter}{Jouppi et al. 2017}); more recent
generations show smaller but still significant advantages as GPU
efficiency has improved. TPU v4 pods (4096 chips) deliver 1.1 exaFLOPs
with 3D torus interconnect. TPU design influenced industry adoption of
domain-specific accelerators, proving that ML workloads justify custom
silicon investment. } optimize for tensor workloads, and
FPGAs\sidenote{\textbf{Field-Programmable Gate Array (FPGA)}:
Reconfigurable hardware enabling post-manufacturing optimization for
specific neural network architectures. Microsoft's Brainwave achieves
\textless1 ms latency through custom datapaths; Xilinx Alveo
accelerators demonstrate FPGA deployment for ML inference. FPGAs bridge
the gap between GPU flexibility and ASIC efficiency, ideal for
low-latency applications and rapid architecture iteration. } provide
reconfigurable acceleration for specific operators. Software
optimizations must align with these hardware capabilities through kernel
fusion, operator scheduling, and precision selection that balances
accuracy with throughput.

Completing the performance engineering feedback loop,
\textbf{?@sec-benchmarking-ai} establishes benchmarking as the essential
measurement discipline. MLPerf\sidenote{\textbf{MLPerf}:
Industry-standard benchmark suite measuring AI system performance across
training and inference workloads. Since 2018, MLPerf
(\citeproc{ref-mattson2020mlperf}{Mattson et al. 2020}) has driven
hardware innovation, with participating systems demonstrating
substantial performance improvements across benchmark rounds (specific
gains vary by workload and hardware generation) while maintaining fair
comparisons across vendors. } provides standardized metrics across
hardware platforms, enabling data-driven decisions about deployment
trade-offs and extending performance engineering beyond centralized
systems to edge and mobile environments.

\subsection{Navigating Production
Reality}\label{sec-conclusion-navigating-production-reality-3024}

The third pillar addresses production deployment realities where all six
principles converge under the constraint that systems must serve users
reliably, securely, and responsibly. A fundamental shift marks this
convergence: the transition from training to inference inverts the
optimization objectives that governed model development. Where training
maximizes throughput over days of computation, inference optimizes
latency per request under strict time constraints measured in
milliseconds. \textbf{?@sec-benchmarking-ai} explored this inversion
through the MLPerf inference scenarios, revealing how different
deployment contexts (SingleStream for mobile, Server for cloud APIs,
Offline for batch processing) require fundamentally different
optimization strategies. The benchmarking techniques target percentile
latencies rather than aggregate throughput. The quantization methods
that \textbf{?@sec-model-compression} taught must be validated not just
for accuracy preservation but for calibration with production traffic.

Faster hardware does not automatically mean faster inference; as
Amdahl's Law (introduced in \textbf{?@sec-ml-system-architecture})
demonstrates, preprocessing and postprocessing often dominate latency.
In production systems with heavily optimized model inference,
preprocessing can consume the majority of total request time,
particularly for simpler models with complex data pipelines.

The measurement principle becomes critical for production systems.
Tracking p50, p95, and p99 latencies reveals how systems perform across
the full range of requests, since mean latency tells little about user
experience when one in a hundred users waits 40 times longer than
average. \textbf{?@sec-benchmarking-ai} established that systems
performing well under light load can suddenly violate service level
objectives when traffic increases, making tail latency monitoring
essential for production deployment.

Service level objectives connect directly to user experience and
business outcomes. Meeting a 100ms p99 latency target requires not just
fast models but careful capacity planning based on queuing analysis,
appropriate batching strategies matched to traffic patterns, and
preprocessing pipelines optimized for the serving context rather than
training convenience. These serving realities validate Principle 1 in
its most demanding form: production systems must instrument every
component of the request path to identify actual bottlenecks.

The operations and deployment landscape demonstrates how
MLOps\sidenote{\textbf{Machine Learning Operations (MLOps)}: Engineering
discipline applying DevOps principles to ML systems. In mature
organizations, automation and operational rigor can enable frequent
model updates and high service availability, but exact update rates and
uptime targets vary widely by product and risk tolerance. MLOps
encompasses continuous integration, deployment, monitoring, and
governance at production scale. } orchestrates the full system
lifecycle, from continuous integration pipelines with quality gates to
A/B testing frameworks for safe rollout, while edge deployment
exemplifies the convergence of multiple principles by balancing privacy
benefits against latency constraints and ensuring graceful degradation
under network failures.

Security and privacy considerations reveal ML's unique vulnerabilities,
including model extraction, data poisoning, and membership inference,
requiring layered defenses. Differential privacy provides formal privacy
guarantees, federated learning enables secure collaboration, and
adversarial training builds robustness against attacks that traditional
software rarely faces. Beyond these technical concerns,
\textbf{?@sec-responsible-engineering} broadened cost consciousness
beyond computation to include societal impact. Fairness metrics and
explainability requirements shape architectural choices from inception,
and environmental impact can become a design constraint motivating both
model efficiency and system-level efficiency. The scale of this impact
deserves concrete illustration.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, coltitle=black, colframe=quarto-callout-note-color-frame, colback=white, left=2mm, bottomtitle=1mm, titlerule=0mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Representative snapshot (energy scale intuition, as of 2021)}, toprule=.15mm, opacityback=0]

Published estimates for training large language models can be on the
order of (10\^{}3) MWh (\citeproc{ref-patterson2021carbon}{Patterson et
al. 2021}). Even small per-device savings can matter when deployed
across very large fleets of edge and mobile devices.

\end{tcolorbox}

These energy figures illustrate why environmental considerations connect
directly to broader responsible engineering principles. The measurement
imperative requires monitoring not just for performance but for fairness
violations: tracking prediction distributions across demographic groups,
detecting bias amplification over time, and alerting on unexplained
accuracy disparities. Failure planning must account for silent bias,
where systems continue operating while producing discriminatory outcomes
that evade conventional error detection. The cost-conscious design
principle expands to include societal costs; a highly efficient system
that produces biased outcomes imposes costs on affected populations that
no financial metric captures. These connections reveal that responsible
AI is an integral dimension of systems engineering.

Production reality shows that isolated technical excellence is
insufficient. Systems must integrate operational maturity, security
defenses, ethical frameworks, and environmental responsibility to
deliver sustained value.

\phantomsection\label{quiz-question-sec-conclusion-applying-principles-across-three-critical-domains-821a}
\begin{fbx}{callout-quiz-question}{Self-Check: Question 1.3}{}
\phantomsection\label{quiz-question-sec-conclusion-applying-principles-across-three-critical-domains-821a}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which principle is highlighted as essential for ensuring that AI
  systems can move beyond laboratory settings to resource-constrained
  deployments?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Data governance
  \item
    Optimization of bottlenecks
  \item
    Co-design
  \item
    Schema evolution
  \end{enumerate}
\item
  Explain how data governance acts as both a technical necessity and an
  ethical imperative in ML systems.
\item
  In ML systems, the principle of `Data is the new \_\_\_\_' emphasizes
  the critical role of data quality in determining system performance.
\item
  Order the following steps in building a robust ML system foundation:
  (1) Monitor distribution shifts, (2) Implement data governance, (3)
  Track schema evolution.
\item
  In a production ML system, what trade-offs might you consider when
  selecting a framework for deployment?
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-answer-sec-conclusion-applying-principles-across-three-critical-domains-821a]{\textbf{See Answer~$\rightarrow$}}

\end{fbx}

\section{Future Directions and Emerging
Opportunities}\label{sec-conclusion-future-directions-emerging-opportunities-337f}

The six principles you have learned will guide future development across
three emerging frontiers: near-term deployment across diverse contexts,
building resilient systems for societal benefit, and engineering the
path toward artificial general intelligence. Each frontier tests these
principles in new ways.

\subsection{Applying Principles to Emerging Deployment
Contexts}\label{sec-conclusion-applying-principles-emerging-deployment-contexts-f5eb}

As ML systems move beyond research labs, three deployment paradigms test
different combinations of our established principles: resource-abundant
cloud environments, resource-constrained edge devices, and emerging
generative systems.

Cloud deployment prioritizes throughput and scalability, achieving high
GPU utilization through kernel fusion, mixed precision training, and
gradient compression. \textbf{?@sec-model-compression} and
\textbf{?@sec-ai-training} explored these techniques, demonstrating how
they combine to balance performance optimization with cost efficiency at
scale.

In contrast, mobile and edge systems face stringent power, memory, and
latency constraints that demand sophisticated hardware-software
co-design. \textbf{?@sec-model-compression} introduced efficiency
techniques including depthwise separable convolutions, neural
architecture search, and quantization that enable deployment on devices
with 100--1000x less computational power than data centers. Systems that
cannot run on billions of edge devices cannot achieve global impact,
making edge deployment essential for AI
democratization\sidenote{\textbf{AI Democratization}: Making AI
accessible beyond a small number of well-resourced organizations through
efficient systems engineering. Mobile-optimized models and cloud APIs
can widen access, but doing so sustainably requires systematic
optimization across hardware, algorithms, and infrastructure to maintain
quality at scale. }.

Generative AI systems apply the principles at unprecedented scale,
requiring novel approaches to autoregressive computation, dynamic model
partitioning, and speculative decoding\sidenote{\textbf{Speculative
Decoding}: Inference optimization where a smaller draft model generates
candidate tokens that a larger target model verifies in parallel. Since
autoregressive generation is memory-bound (each token requires loading
the full model), speculative decoding trades compute for latency: the
draft model proposes 4-8 tokens; the target verifies them in a single
forward pass. Achieves 2-3x speedup when draft acceptance rates exceed
70\%, making it essential for interactive LLM applications. } that
demonstrate how measurement, optimization, and co-design principles
adapt to emerging technologies pushing infrastructure boundaries.

At the opposite extreme, TinyML and embedded systems face kilobyte
memory budgets, milliwatt power envelopes, and decade-long deployment
lifecycles. Success in these contexts validates the full systems
engineering approach: careful measurement reveals actual bottlenecks,
hardware co-design maximizes efficiency, and planning for failure
ensures reliability despite severe resource limitations. Indeed, mobile
deployment constraints have driven breakthrough techniques like
MobileNets and EfficientNets that benefit all AI deployment contexts,
demonstrating how systems constraints catalyze algorithmic innovation.

These deployment contexts confirm the core insight: success depends on
applying the six systems engineering principles together rather than
pursuing isolated optimizations.

\subsection{Building Robust AI
Systems}\label{sec-conclusion-building-robust-ai-systems-443a}

Each deployment context we examined assumes systems will function
correctly. But what happens when they do not? ML systems face unique
failure modes: distribution shifts degrade accuracy, adversarial inputs
exploit vulnerabilities, and edge cases reveal training data
limitations. Robustness requires designing for failure from the ground
up, combining redundant hardware for fault tolerance, ensemble methods
to reduce single-point failures, and uncertainty quantification to
enable graceful degradation. As AI systems assume increasingly
autonomous roles, planning for failure becomes the difference between
safe deployment and catastrophic failure. Advanced treatments of these
topics explore these robustness techniques in depth, showing how failure
planning scales to distributed production systems.

\subsection{AI for Societal
Benefit}\label{sec-conclusion-ai-societal-benefit-3796}

Building robust systems is the prerequisite for deploying AI where it
can benefit society. A medical AI that fails unpredictably cannot be
trusted with patient care; an educational system that degrades under
load cannot serve the students who need it most. AI's transformative
potential across healthcare, climate science, education, and
accessibility represents domains where all six principles converge, and
where robustness becomes not just an engineering virtue but an ethical
imperative. Climate modeling requires efficient inference; medical AI
demands explainable decisions and continuous monitoring; educational
technology needs privacy-preserving personalization at global scale.
These applications demonstrate that technical excellence alone is
insufficient; success requires interdisciplinary collaboration among
technologists, domain experts, policymakers, and affected communities.
Specialized studies examine these applications in detail, showing how
the principles you have learned apply to real-world societal challenges.

\subsection{The Path to AGI}\label{sec-conclusion-path-agi-3fc8}

The most ambitious application of these principles lies ahead:
engineering the path toward artificial general intelligence. Where
societal benefit applications require robustness within defined domains,
AGI demands systems that generalize across all cognitive tasks while
maintaining the reliability, efficiency, and safety that our principles
ensure.

\phantomsection\label{callout-definitionux2a-1.1}
\begin{fbx}{callout-definition}{Definition: }{Compound AI Systems}
\phantomsection\label{callout-definition*-1.1}
\textbf{Compound AI Systems} are architectures that combine multiple
specialized components (models, retrieval systems, tools) rather than
relying on a single monolithic model. Modular designs enable independent
scaling, debugging, and safety controls (e.g., routing, tool use,
validation), aligning with systems engineering principles of modularity
and fault isolation.

\end{fbx}

The compound AI systems framework provides the architectural blueprint
for advanced intelligence: modular components that can be updated
independently, specialized models optimized for specific tasks, and
decomposable architectures that enable interpretability and safety
through multiple validation layers. The engineering challenges ahead
require mastery across the full stack we have explored, from data
engineering and distributed training to model optimization and
operational infrastructure. These systems engineering principles, not
algorithmic breakthroughs alone, define the path toward artificial
general intelligence.

\phantomsection\label{callout-perspectiveux2a-1.2}
\begin{fbx}{callout-perspective}{Systems Perspective: }{A New Golden Age}
\phantomsection\label{callout-perspective*-1.2}
\textbf{Engineering the Future}: Hennessy and Patterson
(\citeproc{ref-hennessy_patterson_2019}{Hennessy and Patterson 2019})
declared a \textbf{``New Golden Age for Computer Architecture,''} driven
by the realization that general-purpose processors can no longer sustain
the exponential growth required by AI. Reaching AGI will not be a matter
of writing a better loss function; it will be an epic systems
engineering challenge. It will require a thousand-fold improvement in
energy efficiency, exascale interconnects that operate with the
reliability of a single chip, and software stacks that can manage
trillions of parameters as fluidly as we manage kilobytes today. The
principles you have learned in this volume---from the \textbf{DAM
Taxonomy} to \textbf{Hardware-Software Co-design}---are the blueprints
for this new era.

\end{fbx}

To put this in systems terms: achieving (10\^{}\{17\}) FLOPS requires
not just faster chips but fundamentally new approaches to power
delivery, cooling, interconnects, and software coordination. These
challenges await future engineers who can apply systems thinking to
problems beyond current imagination. You are now among those engineers.

\phantomsection\label{quiz-question-sec-conclusion-future-directions-emerging-opportunities-337f}
\begin{fbx}{callout-quiz-question}{Self-Check: Question 1.4}{}
\phantomsection\label{quiz-question-sec-conclusion-future-directions-emerging-opportunities-337f}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which deployment paradigm emphasizes the need for sophisticated
  hardware-software co-design due to stringent power, memory, and
  latency constraints?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Cloud environments
  \item
    Mobile and edge systems
  \item
    Generative AI systems
  \item
    TinyML and embedded systems
  \end{enumerate}
\item
  Explain how the principle of `designing for failure' is crucial in
  building robust AI systems.
\item
  In the context of AI for societal benefit, which principle is
  emphasized for medical AI systems?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Measure
  \item
    Optimize Bottleneck
  \item
    Design for Scale
  \item
    Plan for Failure
  \end{enumerate}
\item
  In a production system, what trade-offs might you consider when
  deploying AI systems across diverse contexts such as cloud, edge, and
  TinyML?
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-answer-sec-conclusion-future-directions-emerging-opportunities-337f]{\textbf{See Answer~$\rightarrow$}}

\end{fbx}

\section{Your Journey Forward: Engineering
Intelligence}\label{sec-conclusion-journey-forward-engineering-intelligence-fdd7}

This textbook began by presenting artificial intelligence as a
transformative force reshaping how we build software systems. You now
possess the systems engineering principles to contribute to that
transformation. Intelligence is a systems property that emerges from
integrating components rather than any single breakthrough. Consider
GPT-4's success (\citeproc{ref-openai2023gpt4}{OpenAI et al. 2023}): it
required robust data pipelines processing petabytes of text, distributed
training infrastructure\sidenote{\textbf{Distributed ML Systems}:
Traditional distributed systems principles (consensus, partitioning,
replication) extended for ML workloads. Training very large models can
require coordinating hundreds to thousands of accelerators, where
network topology and gradient synchronization become critical
bottlenecks. Unlike stateless web services, ML systems maintain massive
shared state, motivating techniques like gradient compression and
asynchronous updates. } coordinating thousands of GPUs, efficient
architectures leveraging attention mechanisms and mixture-of-experts,
secure deployment preventing prompt injection
attacks\sidenote{\textbf{Prompt Injection}: Security vulnerability where
malicious input manipulates LLM behavior by embedding instructions that
override system prompts. Unlike SQL injection (which exploits parsing
boundaries), prompt injection exploits the model's inability to
distinguish user data from control instructions. Defenses include input
sanitization, output filtering, and architectural separation between
system and user contexts, but no complete solution exists as of 2024. },
and responsible governance implementing safety filters and usage
policies.

\subsection{The Engineering
Responsibility}\label{the-engineering-responsibility}

Before we look to the horizon of scale, we must ground ourselves in
responsibility. The systems integration perspective explains why ethical
considerations cannot be separated from technical ones. The same
principles that enable efficient systems also determine who can access
them, what harms they might cause, and what benefits they can provide.
The question confronting our generation is not whether artificial
general intelligence will arrive but whether it will be built well:
efficiently enough to democratize access beyond wealthy institutions,
securely enough to resist exploitation, sustainably enough to preserve
our planet, and responsibly enough to serve all humanity equitably.

The intelligent systems that will define the coming decades require your
engineering expertise: climate models predicting extreme weather,
medical AI diagnosing rare diseases, educational systems personalizing
learning, and assistive technologies serving billions. You now possess
the knowledge to build them, the principles to guide design, the
techniques to ensure efficiency, the frameworks to support safe
deployment, and the wisdom to deploy responsibly.

\subsection{The Next Horizon: The Machine Learning
Fleet}\label{the-next-horizon-the-machine-learning-fleet}

This book has deliberately focused on \textbf{Mastering the ML Node}. We
established principles you can directly observe and experiment with on a
single system. Understanding bottlenecks on one machine---whether memory
bandwidth limitations, CPU-GPU data transfer overhead, or preprocessing
inefficiencies---enables recognition of when and why scaling becomes
necessary. You learned to calculate arithmetic intensity, optimize data
pipelines, and prune models to fit within strict constraints.

But as we saw in \textbf{?@sec-ai-training}, even a perfectly optimized
node has a physical ceiling. To train the next generation of foundation
models or serve billions of users, we must leave the single node behind.
We must transition from optimizing the individual unit to
\textbf{Orchestrating the ML Fleet}.

This is the frontier of the \textbf{Warehouse-Scale Computer}. In this
regime, the datacenter is no longer a building that houses computers;
the datacenter \emph{is} the computer.

\begin{itemize}
\tightlist
\item
  \textbf{From Bus to Network:} The memory bandwidth constraints we
  studied in \textbf{?@sec-ai-acceleration} expand to become network
  topology challenges. The interconnects between racks become the new
  system bus.
\item
  \textbf{From Failure to Resilience:} Failure planning shifts from
  ``if'' to ``when.'' In a cluster of thousands of GPUs, mean time
  between failures drops to hours. The system must be designed to heal
  itself while computation continues.
\item
  \textbf{From Synchronization to Consensus:} Training shifts from a
  local loop to a distributed consensus problem, where gradient updates
  must be synchronized across a fleet without stalling the math.
\end{itemize}

The transition from Node to Fleet is a fundamental shift in physics.
Yet, the foundation remains the same. The Iron Law still governs
performance, but the variables now span racks and zones. The DAM
taxonomy still applies, but the ``Machine'' is now a global
infrastructure.

You have mastered the unit. You are now ready to build the collective.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, colbacktitle=quarto-callout-important-color!10!white, rightrule=.15mm, coltitle=black, colframe=quarto-callout-important-color-frame, colback=white, left=2mm, bottomtitle=1mm, titlerule=0mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Key Takeaways}, toprule=.15mm, opacityback=0]

\begin{itemize}
\item
  \textbf{Six principles define ML systems engineering}: Measure
  everything, design for 10× scale, optimize the bottleneck, plan for
  failure, design cost-consciously, co-design for hardware.
\item
  \textbf{The AI Triad (DAM) governs all decisions}: Data, Algorithm,
  and Machine are interdependent. Optimizing one in isolation shifts
  bottlenecks rather than eliminating them. When performance stalls,
  check the DAM.
\item
  \textbf{The system is the model}: The true model is data pipeline +
  training infrastructure + serving system + monitoring loop. Optimize
  the system to improve the model.
\item
  \textbf{Production ML requires continuous operation}: Deployment is
  not an event but a process. Models degrade, data drifts, and the world
  changes. Monitor, measure, and adapt continuously.
\item
  \textbf{Technical excellence must combine with ethical commitment}:
  Build systems that are efficient, accessible, sustainable, and
  beneficial. Efficiency enables responsibility; responsibility demands
  efficiency.
\end{itemize}

\end{tcolorbox}

The future of intelligence is not something we will simply witness. It
is something we must build. Go build it well.

\emph{Prof.~Vijay Janapa Reddi, Harvard University}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacitybacktitle=0.6, breakable, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, coltitle=black, colframe=quarto-callout-note-color-frame, colback=white, left=2mm, bottomtitle=1mm, titlerule=0mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Next Steps: Orchestrating the Fleet}, toprule=.15mm, opacityback=0]

In future coverage of this discipline, we leave the single node behind.
We will explore how to orchestrate fleets of accelerators, manage
petabyte-scale data lakes, and deploy systems that serve millions of
users. The principles remain, but the physics change. Get ready to
scale.

\end{tcolorbox}

\phantomsection\label{quiz-question-sec-conclusion-journey-forward-engineering-intelligence-fdd7}
\begin{fbx}{callout-quiz-question}{Self-Check: Question 1.5}{}
\phantomsection\label{quiz-question-sec-conclusion-journey-forward-engineering-intelligence-fdd7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which of the following best describes the role of systems engineering
  in achieving artificial general intelligence (AGI)?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Focusing on a single breakthrough technology.
  \item
    Prioritizing hardware advancements over software improvements.
  \item
    Integrating diverse components into a cohesive system.
  \item
    Relying solely on data quality improvements.
  \end{enumerate}
\item
  True or False: The success of systems like GPT-4 is solely due to
  advancements in neural network architectures.
\item
  Explain how ethical considerations should influence the design and
  deployment of AI systems.
\item
  In the context of ML systems engineering, which principle is crucial
  for ensuring that AI systems are beneficial and trustworthy?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Maximizing computational power.
  \item
    Reducing model size.
  \item
    Increasing data collection.
  \item
    Serving users and society.
  \end{enumerate}
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-answer-sec-conclusion-journey-forward-engineering-intelligence-fdd7]{\textbf{See Answer~$\rightarrow$}}

\end{fbx}

\section{Self-Check Answers}\label{self-check-answers}

\phantomsection\label{quiz-answer-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5}
\begin{fbx}{callout-quiz-answer}{Self-Check: Answer 1.1}{}
\phantomsection\label{quiz-answer-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Which principle is emphasized as crucial for the development
  of contemporary AI systems according to the overview?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Isolated algorithmic innovation
  \item
    Data collection
  \item
    Architectural innovation
  \item
    Systems integration
  \end{enumerate}

  \emph{Answer}: The correct answer is D. Systems integration. This is
  emphasized as crucial because contemporary AI achievements emerge from
  the integration of computational theory with engineering practice,
  rather than isolated innovations.

  \emph{Learning Objective}: Understand the role of systems integration
  in the development of AI systems.
\item
  \textbf{Explain how the systems thinking paradigm contributes to the
  development of AI systems.}

  \emph{Answer}: Systems thinking contributes by integrating
  computational theory with engineering practice, enabling the
  orchestration of interdependent components. For example, transformer
  architectures rely on distributed training infrastructure and
  algorithmic optimization. This is important because it enables
  scalable and reliable AI systems that address complex challenges.

  \emph{Learning Objective}: Analyze the contribution of systems
  thinking to AI system development.
\item
  \textbf{What is a key challenge when scaling AI systems towards
  Artificial General Intelligence (AGI)?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Developing new algorithms
  \item
    Scaling current ML systems principles
  \item
    Increasing data collection
  \item
    Improving user interfaces
  \end{enumerate}

  \emph{Answer}: The correct answer is B. Scaling current ML systems
  principles. The challenge lies in scaling these principles to meet the
  computational requirements of AGI, which are significantly higher than
  current systems.

  \emph{Learning Objective}: Identify challenges in scaling AI systems
  towards AGI.
\item
  \textbf{How might the principles of ML systems engineering be applied
  to address societal challenges?}

  \emph{Answer}: ML systems engineering principles can be applied to
  design AI systems that perform reliably in healthcare, education, and
  climate science. For example, robust operational frameworks ensure
  AI's effective deployment in these fields. This is important because
  it aligns technical capabilities with societal needs.

  \emph{Learning Objective}: Apply ML systems engineering principles to
  societal challenges.
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-question-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-29b5]{\textbf{$\leftarrow$~Back to Question}}

\end{fbx}

\phantomsection\label{quiz-answer-sec-conclusion-systems-engineering-principles-ml-2ca9}
\begin{fbx}{callout-quiz-answer}{Self-Check: Answer 1.2}{}
\phantomsection\label{quiz-answer-sec-conclusion-systems-engineering-principles-ml-2ca9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Which of the following best describes the purpose of roofline
  analysis in ML systems?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    To determine the memory capacity of a system
  \item
    To evaluate the cost efficiency of cloud deployments
  \item
    To identify computational bottlenecks by plotting operational
    intensity against peak performance
  \item
    To measure the energy consumption of mobile devices
  \end{enumerate}

  \emph{Answer}: The correct answer is C. Roofline analysis identifies
  computational bottlenecks by plotting operational intensity against
  peak performance, revealing whether systems are memory bound or
  compute bound.

  \emph{Learning Objective}: Understand the role of roofline analysis in
  optimizing ML system performance.
\item
  \textbf{True or False: Designing for 10x scale means that systems
  should be optimized for current loads only.}

  \emph{Answer}: False. Designing for 10x scale means systems must
  handle an order of magnitude more data, users, and computational
  demands than currently needed, ensuring robustness under unexpected
  load increases.

  \emph{Learning Objective}: Recognize the importance of designing ML
  systems to handle significantly higher loads than anticipated.
\item
  \textbf{Explain how the principle of `Optimize the Bottleneck' can be
  applied to enhance the performance of an ML system.}

  \emph{Answer}: Optimizing the bottleneck involves identifying and
  addressing the primary constraint in a system, such as memory
  bandwidth in training workloads or network latency in distributed
  inference. By focusing on the main performance limiting factor,
  significant efficiency gains can be achieved. For example, optimizing
  memory usage in a training pipeline can reduce training time and
  resource consumption, leading to more efficient system operation.

  \emph{Learning Objective}: Apply the concept of bottleneck
  optimization to improve ML system performance.
\item
  \textbf{What is a critical insight gained from systematic benchmarking
  in ML systems?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Systems always fail at expected loads
  \item
    Systems rarely fail when demand exceeds design assumptions by orders
    of magnitude
  \item
    Benchmarking only measures computational throughput
  \item
    Benchmarking is unnecessary for cloud-based systems
  \end{enumerate}

  \emph{Answer}: The correct answer is B. Systematic benchmarking
  reveals that systems rarely fail at expected loads but often fail when
  demand exceeds design assumptions by orders of magnitude.

  \emph{Learning Objective}: Understand the role of benchmarking in
  identifying potential failure points in ML systems.
\item
  \textbf{In a production ML system, why is it important to plan for
  failure, and how can this be implemented?}

  \emph{Answer}: Planning for failure is crucial because production
  systems experience component failures, network partitions, and
  adversarial inputs. Implementing redundancy, monitoring, and recovery
  mechanisms, such as circuit breakers and automated recovery
  procedures, ensures system resilience. For example, a circuit breaker
  can prevent cascading failures by temporarily blocking requests to a
  failing service, allowing the system to recover gracefully.

  \emph{Learning Objective}: Explain the importance of failure planning
  in ML systems and how it can be practically implemented.
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-question-sec-conclusion-systems-engineering-principles-ml-2ca9]{\textbf{$\leftarrow$~Back to Question}}

\end{fbx}

\phantomsection\label{quiz-answer-sec-conclusion-applying-principles-across-three-critical-domains-821a}
\begin{fbx}{callout-quiz-answer}{Self-Check: Answer 1.3}{}
\phantomsection\label{quiz-answer-sec-conclusion-applying-principles-across-three-critical-domains-821a}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Which principle is highlighted as essential for ensuring that
  AI systems can move beyond laboratory settings to resource-constrained
  deployments?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Data governance
  \item
    Optimization of bottlenecks
  \item
    Co-design
  \item
    Schema evolution
  \end{enumerate}

  \emph{Answer}: The correct answer is B. Optimization of bottlenecks.
  This principle is crucial for addressing resource constraints in
  deployments by systematically identifying and addressing limiting
  factors like memory and compute.

  \emph{Learning Objective}: Understand the importance of optimizing
  bottlenecks for deploying AI systems in resource-constrained
  environments.
\item
  \textbf{Explain how data governance acts as both a technical necessity
  and an ethical imperative in ML systems.}

  \emph{Answer}: Data governance ensures data quality, which is crucial
  for system performance. It involves monitoring distribution shifts and
  labeling consistency. Ethically, it prevents biases and ensures
  fairness. For example, poor data quality can lead to biased models,
  making governance essential for ethical AI deployment.

  \emph{Learning Objective}: Analyze the dual role of data governance in
  technical and ethical contexts within ML systems.
\item
  \textbf{In ML systems, the principle of `Data is the new \_\_\_\_'
  emphasizes the critical role of data quality in determining system
  performance.}

  \emph{Answer}: code. This phrase highlights that data quality is as
  crucial as code quality in determining the effectiveness of machine
  learning models.

  \emph{Learning Objective}: Recall the importance of data quality in
  the context of ML system performance.
\item
  \textbf{Order the following steps in building a robust ML system
  foundation: (1) Monitor distribution shifts, (2) Implement data
  governance, (3) Track schema evolution.}

  \emph{Answer}: The correct order is: (2) Implement data governance,
  (3) Track schema evolution, (1) Monitor distribution shifts. Data
  governance sets the groundwork, schema evolution ensures data
  structure integrity, and monitoring distribution shifts maintains
  performance.

  \emph{Learning Objective}: Understand the sequence of actions required
  to establish a robust ML system foundation.
\item
  \textbf{In a production ML system, what trade-offs might you consider
  when selecting a framework for deployment?}

  \emph{Answer}: When selecting a framework, consider trade-offs between
  production maturity and research flexibility. For example, TensorFlow
  offers robust deployment tools, while PyTorch is favored for research.
  The choice affects development speed and deployment constraints,
  impacting overall system efficiency.

  \emph{Learning Objective}: Evaluate trade-offs in framework selection
  for ML system deployment.
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-question-sec-conclusion-applying-principles-across-three-critical-domains-821a]{\textbf{$\leftarrow$~Back to Question}}

\end{fbx}

\phantomsection\label{quiz-answer-sec-conclusion-future-directions-emerging-opportunities-337f}
\begin{fbx}{callout-quiz-answer}{Self-Check: Answer 1.4}{}
\phantomsection\label{quiz-answer-sec-conclusion-future-directions-emerging-opportunities-337f}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Which deployment paradigm emphasizes the need for
  sophisticated hardware-software co-design due to stringent power,
  memory, and latency constraints?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Cloud environments
  \item
    Mobile and edge systems
  \item
    Generative AI systems
  \item
    TinyML and embedded systems
  \end{enumerate}

  \emph{Answer}: The correct answer is B. Mobile and edge systems. These
  systems face stringent constraints, requiring advanced co-design to
  operate efficiently on limited resources. Cloud environments focus on
  scalability, while TinyML deals with even more extreme constraints.

  \emph{Learning Objective}: Understand the unique challenges and design
  considerations for mobile and edge system deployments.
\item
  \textbf{Explain how the principle of `designing for failure' is
  crucial in building robust AI systems.}

  \emph{Answer}: Designing for failure is crucial because ML systems
  face unique failure modes like distribution shifts and adversarial
  inputs. By planning for failure, systems can incorporate redundancy,
  ensemble methods, and uncertainty quantification to ensure safe
  deployment and avoid catastrophic failures. This approach is vital as
  AI systems become more autonomous.

  \emph{Learning Objective}: Analyze the importance of designing for
  failure in ensuring system robustness and reliability.
\item
  \textbf{In the context of AI for societal benefit, which principle is
  emphasized for medical AI systems?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Measure
  \item
    Optimize Bottleneck
  \item
    Design for Scale
  \item
    Plan for Failure
  \end{enumerate}

  \emph{Answer}: The correct answer is A. Measure. Medical AI systems
  require explainable decisions and continuous monitoring, emphasizing
  the need for precise measurement to ensure accuracy and reliability.

  \emph{Learning Objective}: Identify the key principles applied in AI
  systems designed for societal benefit, particularly in healthcare.
\item
  \textbf{In a production system, what trade-offs might you consider
  when deploying AI systems across diverse contexts such as cloud, edge,
  and TinyML?}

  \emph{Answer}: Trade-offs include balancing performance and cost in
  cloud environments, optimizing for power and latency in edge systems,
  and maximizing efficiency within extreme constraints for TinyML. Each
  context requires different optimizations, such as kernel fusion for
  clouds or quantization for edge devices, to ensure system
  effectiveness and scalability.

  \emph{Learning Objective}: Evaluate the trade-offs involved in
  deploying AI systems across various technological contexts.
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-question-sec-conclusion-future-directions-emerging-opportunities-337f]{\textbf{$\leftarrow$~Back to Question}}

\end{fbx}

\phantomsection\label{quiz-answer-sec-conclusion-journey-forward-engineering-intelligence-fdd7}
\begin{fbx}{callout-quiz-answer}{Self-Check: Answer 1.5}{}
\phantomsection\label{quiz-answer-sec-conclusion-journey-forward-engineering-intelligence-fdd7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Which of the following best describes the role of systems
  engineering in achieving artificial general intelligence (AGI)?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Focusing on a single breakthrough technology.
  \item
    Prioritizing hardware advancements over software improvements.
  \item
    Integrating diverse components into a cohesive system.
  \item
    Relying solely on data quality improvements.
  \end{enumerate}

  \emph{Answer}: The correct answer is C. Integrating diverse components
  into a cohesive system. This is correct because AGI requires a
  holistic approach that combines various technologies and principles,
  rather than focusing on a single breakthrough.

  \emph{Learning Objective}: Understand the role of systems engineering
  in achieving AGI.
\item
  \textbf{True or False: The success of systems like GPT-4 is solely due
  to advancements in neural network architectures.}

  \emph{Answer}: False. This is false because the success of systems
  like GPT-4 relies on a combination of robust data pipelines,
  distributed training infrastructure, efficient architectures, and
  responsible deployment and governance.

  \emph{Learning Objective}: Recognize the multifaceted nature of
  successful AI systems.
\item
  \textbf{Explain how ethical considerations should influence the design
  and deployment of AI systems.}

  \emph{Answer}: Ethical considerations should guide the design and
  deployment of AI systems to ensure they are secure, sustainable, and
  equitable. For example, implementing safety filters and usage policies
  can prevent misuse. This is important because AI systems should serve
  humanity and democratize access, not exacerbate inequalities.

  \emph{Learning Objective}: Understand the importance of ethical
  considerations in AI system design.
\item
  \textbf{In the context of ML systems engineering, which principle is
  crucial for ensuring that AI systems are beneficial and trustworthy?}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Maximizing computational power.
  \item
    Reducing model size.
  \item
    Increasing data collection.
  \item
    Serving users and society.
  \end{enumerate}

  \emph{Answer}: The correct answer is D. Serving users and society.
  This is crucial because AI systems should ultimately aim to improve
  real-world impact, such as improving lives and solving problems,
  rather than just technical metrics.

  \emph{Learning Objective}: Identify key principles that ensure AI
  systems are beneficial and trustworthy.
\end{enumerate}

\noindent\hspace*{1.25em}\hyperref[quiz-question-sec-conclusion-journey-forward-engineering-intelligence-fdd7]{\textbf{$\leftarrow$~Back to Question}}

\end{fbx}

\FloatBarrier\clearpage

\addtocontents{toc}{\par\addvspace{12pt}\noindent\hfil\bfseries\color{crimson}References\color{black}\hfil\par\addvspace{6pt}}

\addtocontents{toc}{\par\noindent\hfil{\color{crimson}\rule{0.6\textwidth}{0.5pt}}\hfil\par\addvspace{6pt}}

\division{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-bahdanau2014neural}
Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2014. {``Neural
Machine Translation by Jointly Learning to Align and Translate.''}
\emph{arXiv Preprint arXiv:1409.0473}, September.
\url{http://arxiv.org/abs/1409.0473v7}.

\bibitem[\citeproctext]{ref-han2015deep}
Han, Song, Huizi Mao, and William J. Dally. 2015. {``Deep Compression:
Compressing Deep Neural Networks with Pruning, Trained Quantization and
Huffman Coding.''} \emph{arXiv Preprint arXiv:1510.00149}, October.
\url{http://arxiv.org/abs/1510.00149v5}.

\bibitem[\citeproctext]{ref-hennessy_patterson_2019}
Hennessy, John L., and David A. Patterson. 2019. {``A New Golden Age for
Computer Architecture.''} \emph{Communications of the ACM} 62 (2):
48--60. \url{https://doi.org/10.1145/3282307}.

\bibitem[\citeproctext]{ref-howard2017mobilenets}
Howard, Andrew G., Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun
Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017.
{``MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
Applications.''} \emph{ArXiv Preprint} abs/1704.04861 (April).
\url{http://arxiv.org/abs/1704.04861v1}.

\bibitem[\citeproctext]{ref-jouppi2017datacenter}
Jouppi, Norman P., Cliff Young, Nishant Patil, David Patterson, Gaurav
Agrawal, Raminder Bajwa, Sarah Bates, et al. 2017. {``In-Datacenter
Performance Analysis of a Tensor Processing Unit.''} In
\emph{Proceedings of the 44th Annual International Symposium on Computer
Architecture}, 1--12. ISCA '17. New York, NY, USA: ACM.
\url{https://doi.org/10.1145/3079856.3080246}.

\bibitem[\citeproctext]{ref-karpathy2017software}
Karpathy, Andrej. 2017. {``Software 2.0.''} \emph{Medium}.
\url{https://karpathy.medium.com/software-2-0-a64152b37c35}.

\bibitem[\citeproctext]{ref-lecun1990optimal}
LeCun, Yann, John S. Denker, and Sara A. Solla. 1989. {``Optimal Brain
Damage.''} In \emph{Advances in Neural Information Processing Systems 2
(NIPS 1989)}, 598--605.
\url{http://papers.nips.cc/paper/250-optimal-brain-damage}.

\bibitem[\citeproctext]{ref-mattson2020mlperf}
Mattson, Peter, Vijay Janapa Reddi, Christine Cheng, Cody Coleman, Greg
Diamos, David Kanter, Paulius Micikevicius, et al. 2020. {``MLPerf: An
Industry Standard Benchmark Suite for Machine Learning Performance.''}
\emph{IEEE Micro} 40 (2): 8--16.
\url{https://doi.org/10.1109/mm.2020.2974843}.

\bibitem[\citeproctext]{ref-openai2023gpt4}
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge
Akkaya, Florencia Leoni Aleman, et al. 2023. {``GPT-4 Technical
Report,''} March. \url{http://arxiv.org/abs/2303.08774v6}.

\bibitem[\citeproctext]{ref-patterson2021carbon}
Patterson, David, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel
Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021.
{``Carbon Emissions and Large Neural Network Training.''} \emph{arXiv
Preprint arXiv:2104.10350}, April.
\url{http://arxiv.org/abs/2104.10350v3}.

\bibitem[\citeproctext]{ref-rosenblatt1957perceptron}
Rosenblatt, Frank. 1957. {``The Perceptron: A Perceiving and Recognizing
Automaton.''} 85-460-1. Cornell Aeronautical Laboratory.

\bibitem[\citeproctext]{ref-rumelhart1986learning}
Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1986.
{``Learning Representations by Back-Propagating Errors.''} \emph{Nature}
323 (6088): 533--36. \url{https://doi.org/10.1038/323533a0}.

\bibitem[\citeproctext]{ref-strubell2019energy}
Strubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. {``Energy and
Policy Considerations for Deep Learning in NLP.''} In \emph{Proceedings
of the 57th Annual Meeting of the Association for Computational
Linguistics}, 3645--50. Association for Computational Linguistics.
\url{https://doi.org/10.18653/v1/p19-1355}.

\bibitem[\citeproctext]{ref-vaswani2017attention}
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.
{``Attention Is All You Need.''} In \emph{Advances in Neural Information
Processing Systems}, 30:5998--6008. Curran Associates, Inc.
\url{https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}.

\bibitem[\citeproctext]{ref-williams2009roofline}
Williams, Samuel, Andrew Waterman, and David Patterson. 2009.
{``Roofline: An Insightful Visual Performance Model for Multicore
Architectures.''} \emph{Communications of the ACM} 52 (4): 65--76.
\url{https://doi.org/10.1145/1498765.1498785}.

\end{CSLReferences}


\backmatter


\end{document}
