---
title: "Hardware Kits"
sidebar: false
---

# Hardware Kits {.unnumbered}

This page provides a comprehensive overview of the hardware platforms we've carefully selected for our TinyML curriculum. Each kit represents a different approach to embedded machine learning, offering unique capabilities and learning opportunities.

## Curriculum Design Philosophy {#sec-kits-curriculum-philosophy}

Our hardware selection follows key pedagogical principles that ensure students gain both breadth and depth in embedded machine learning. We've chosen platforms that provide **progressive complexity**, moving from simple sensor integration to advanced neural processing units. This approach allows learners to build confidence with accessible tools before tackling more sophisticated systems.

The platforms represent **diverse architectures** spanning microcontrollers, application processors, and dedicated AI accelerators. This diversity is intentional—real-world ML deployment requires understanding how different hardware constraints and capabilities influence design decisions. Students experience everything from ultra-low-power microcontrollers running for months on a battery to powerful edge computers capable of running transformer models.

**Accessibility** remains paramount in our selection. Our kit recommendations range from $10 development boards to $200 comprehensive systems, ensuring that cost doesn't become a barrier to learning. We provide guidance for educational discounts and alternative sources to support students with varying budgets.

Each platform we've selected sees actual **real-world deployment** in commercial products, ensuring that skills learned in our labs transfer directly to professional practice. Finally, all platforms benefit from **strong development ecosystems** with comprehensive toolchains, extensive documentation, and active community support.

## Supported Hardware Platforms {#sec-kits-supported-platforms}

### Arduino Nicla Vision {#sec-kits-arduino-nicla}

![Arduino Nicla Vision with camera module](contents/labs/arduino/nicla_vision/images/nicla-setup.jpg){width=400}

The Arduino Nicla Vision exemplifies the art of doing more with less. Built around the STM32H7 microcontroller—the same chip found in many commercial IoT devices—this platform demonstrates how sophisticated machine learning can run on remarkably constrained hardware. Its **ultra-low power consumption** makes it ideal for battery-powered applications that need to operate for months or years without charging.

What makes the Nicla Vision particularly valuable for education is its **vision-optimized design**. Unlike general-purpose microcontrollers where camera interfacing requires complex setup, the Nicla Vision provides a seamless path from image capture to ML inference. Students can focus on learning ML concepts rather than debugging hardware interfaces.

The **Arduino ecosystem familiarity** cannot be overstated. Most students arrive with some Arduino experience, making the Nicla Vision an ideal bridge between maker projects and professional embedded systems. The development workflow feels familiar while introducing the constraints and considerations unique to ML deployment.

Through hands-on work with the Nicla Vision, students master microcontroller-based ML deployment, discover power optimization techniques that can extend battery life by orders of magnitude, understand real-time vision processing constraints, and become fluent in the Arduino development workflow that powers countless IoT products.

**Applications**: Image classification, object detection, keyword spotting, motion detection

---

### XIAO ESP32S3 (Seeed Studio) {#sec-kits-seeed-xiao}

![XIAO ESP32S3 development board](contents/labs/seeed/xiao_esp32s3/images/xiao-board.jpg){width=400}

Despite its thumb-sized form factor, the XIAO ESP32S3 packs remarkable capability into an incredibly compact package. This platform teaches students that **space constraints** drive many real-world design decisions, from IoT sensors that must fit inside existing infrastructure to wearable devices where every millimeter matters.

The board's **built-in wireless connectivity** through WiFi and Bluetooth opens up entirely new deployment paradigms. Students learn how edge ML devices can participate in larger systems, sending inference results to cloud services, receiving model updates over-the-air, or coordinating with other intelligent devices in mesh networks.

What makes the XIAO particularly powerful for education is its **versatile sensor ecosystem**. The same platform can handle computer vision, audio processing, environmental sensing, and motion detection. This versatility allows instructors to design labs that explore multi-modal sensor fusion—a critical skill in modern ML systems.

The platform's **cost-effectiveness** makes it accessible to individual students while its professional capabilities ensure the skills transfer to commercial development. Many students purchase their own XIAO boards to continue experimenting beyond the classroom.

Learning outcomes include mastering wireless ML model deployment, understanding multi-modal sensor fusion techniques, exploring edge-to-cloud connectivity patterns, and developing skills in resource-constrained optimization that apply broadly across embedded systems.

**Applications**: IoT sensor networks, remote monitoring, wireless ML inference

---

### Grove Vision AI V2 {#sec-kits-grove-vision}

![Grove Vision AI V2 with NPU](contents/labs/seeed/grove_vision_ai_v2/images/grove-ai-v2.jpg){width=400}

The Grove Vision AI V2 represents the cutting edge of embedded AI acceleration. Its **dedicated Neural Processing Unit (NPU)** provides students with hands-on experience of hardware-accelerated inference—the technology powering everything from smartphone cameras to autonomous vehicle perception systems.

Unlike software-only ML deployment, the Grove AI V2 demonstrates how **specialized hardware** can achieve dramatic improvements in both performance and power efficiency. Students witness firsthand how the same model that struggles to run in real-time on a general-purpose processor can achieve smooth video-rate inference on dedicated AI hardware.

The platform's **visual programming environment** through SenseCraft AI serves dual educational purposes. It provides rapid prototyping capabilities for students new to ML deployment while demonstrating how **professional-grade tools** can democratize AI development. Students learn to evaluate when visual tools accelerate development versus when code-based approaches provide necessary control.

Perhaps most importantly, the Grove AI V2 exposes students to **industrial-grade capabilities**. The same platform powering their class projects could be deployed in factory inspection systems, retail analytics, or smart city infrastructure. This connection between classroom learning and real-world impact motivates deeper engagement with the material.

Students develop skills in hardware-accelerated inference, professional ML deployment workflows, advanced computer vision applications, and the critical ability to analyze performance versus complexity trade-offs that determine project success.

**Applications**: Industrial inspection, advanced object detection, real-time video analytics

---

### Raspberry Pi (4/5 and Zero 2W) {#sec-kits-raspberry-pi}

![Raspberry Pi 5 and Pi Zero 2W comparison](contents/labs/raspi/images/jpeg/raspis.jpg){width=400}

The Raspberry Pi family bridges the gap between embedded systems and traditional computing, offering students experience with **full Linux environments** while maintaining the accessibility and affordability of educational hardware. This platform teaches students how to leverage the rich ecosystem of existing software tools and libraries in ML deployment.

The **scalable performance** from Pi Zero to Pi 5 provides a perfect laboratory for understanding how computational resources influence ML system design. Students can deploy the same model across the range, observing how increased computational power enables larger models, higher accuracy, or additional features.

The Pi's **extensive community and library support** demonstrates the value of choosing platforms with robust ecosystems. Students learn to leverage existing solutions rather than building everything from scratch—a crucial professional skill. The platform's compatibility with standard ML frameworks like TensorFlow and PyTorch provides a smooth transition from desktop development to edge deployment.

Most importantly, the Raspberry Pi's capability to run **more sophisticated models** opens up exploration of emerging areas like small language models and multimodal AI. Students can experiment with technologies that would be impossible on more constrained platforms, gaining insight into the future direction of edge AI.

Through Raspberry Pi projects, students master Linux-based ML deployment, develop model optimization skills for edge computing, learn performance scaling strategies, and explore integration patterns with cloud services that define modern AI architectures.

**Applications**: Edge AI gateways, computer vision systems, small language models, multi-modal AI

## Kit Comparison Matrix {#sec-kits-comparison}

| Feature | Arduino Nicla | XIAO ESP32S3 | Grove Vision AI V2 | Raspberry Pi |
|---------|:-------------:|:------------:|:------------------:|:------------:|
| **Power Consumption** | Ultra-low | Low | Medium | High |
| **Processing Power** | Low | Medium | High (NPU) | Very High |
| **Memory** | 2MB | 8MB | 16MB | 1-8GB |
| **ML Framework** | TensorFlow Lite | TensorFlow Lite | SenseCraft AI | TensorFlow, PyTorch |
| **Development** | Arduino IDE | Arduino/PlatformIO | Visual/Code | Python/Linux |
| **Cost Range** | $80-120 | $15-50 | $150-200 | $15-100 |
| **Best For** | Battery devices | IoT networks | Industrial AI | Edge computing |

## Lab Compatibility Matrix {#sec-kits-lab-compatibility}

Understanding which labs work with each platform helps you plan your learning journey and choose the right hardware for your projects.

| Lab Type | Arduino Nicla | XIAO ESP32S3 | Grove Vision AI V2 | Raspberry Pi |
|----------|:-------------:|:------------:|:------------------:|:------------:|
| **Setup & Getting Started** | ✓ | ✓ | ✓ | ✓ |
| **Image Classification** | ✓ | ✓ | ✓ | ✓ |
| **Object Detection** | ✓ | ✓ | ✓ | ✓ |
| **Keyword Spotting** | ✓ | ✓ | ✗ | ✗ |
| **Motion Classification** | ✓ | ✓ | ✗ | ✗ |
| **No-Code Applications** | ✗ | ✗ | ✓ | ✗ |
| **Large Language Models** | ✗ | ✗ | ✗ | ✓ |
| **Vision Language Models** | ✗ | ✗ | ✗ | ✓ |
| **DSP/Feature Engineering** | ✓ | ✓ | ✓ | ✓ |

### Lab Selection Guide {#sec-kits-lab-selection-guide}

**For Beginners**: Start with Image Classification on any platform to understand basic ML deployment concepts. The Arduino Nicla and XIAO ESP32S3 offer the most comprehensive lab coverage for foundational learning.

**For Audio/Sensor Applications**: Arduino Nicla and XIAO ESP32S3 provide complete keyword spotting and motion classification labs that demonstrate sensor fusion and audio processing.

**For Advanced Vision**: Grove Vision AI V2 and Raspberry Pi excel at sophisticated computer vision tasks, with the Grove offering no-code options and the Pi supporting complex multi-modal models.

**For Language Models**: Only Raspberry Pi supports LLM and VLM applications, making it essential for exploring the latest AI capabilities at the edge.

## Getting Started {#sec-kits-getting-started}

### Recommended Learning Path {#sec-kits-learning-path}

We recommend beginning with either the Arduino Nicla Vision or XIAO ESP32S3 to establish fundamental concepts. These platforms provide immediate feedback without overwhelming complexity, allowing students to build confidence with core ML deployment concepts.

As students become comfortable with basic inference and optimization, the Grove Vision AI V2 introduces hardware acceleration concepts that are increasingly important in commercial applications. The visual programming environment provides a bridge between educational exercises and professional development workflows.

The Raspberry Pi serves as the capstone platform, where students can integrate multiple concepts learned on simpler hardware while exploring advanced applications like language models and multimodal AI that require more computational resources.

### What's Included in Our Labs {#sec-kits-lab-coverage}

Each platform includes comprehensive tutorials covering setup and configuration, where students learn to establish development environments and understand toolchain workflows. Computer vision labs explore image classification, object detection, and real-time processing across different computational constraints. Audio processing tutorials cover keyword spotting, audio classification, and feature extraction techniques that apply broadly across signal processing applications.

Model deployment labs teach TensorFlow Lite optimization, performance tuning, and the systematic approaches to troubleshooting that separate successful projects from abandoned prototypes. Throughout all labs, we emphasize best practices for documentation, testing, and reproducible development that students will need in professional practice.

### Hardware Acquisition {#sec-kits-acquisition}

Many platforms offer educational discounts, and we provide guidance on accessing these programs. We recommend specific starter kits that include necessary sensors and accessories, eliminating the guesswork of component selection. For international students or those in regions with limited supplier networks, we maintain lists of compatible boards and alternative sources.

For educational institutions working with constrained budgets, we provide guidance on cost-effective deployment strategies, bulk purchasing options, and approaches to maximize learning impact per dollar invested.

## Integration with Curriculum {#sec-kits-curriculum-integration}

Our hardware selection directly supports the book's pedagogical progression. Foundational concepts in chapters 2-4 work effectively with any platform, allowing students to choose based on availability or interest. Platform-specific optimization techniques covered in chapters 5-8 become concrete through hands-on experimentation. Advanced deployment concepts in chapters 9-12 leverage the full capability of platforms like the Raspberry Pi and Grove AI V2.

Each platform teaches different aspects of the ML systems engineering discipline. Students progress from ultra-low-power constraints that define IoT applications to cloud-connected edge AI systems that power smart infrastructure. This progression mirrors the diversity of real-world ML deployment scenarios they'll encounter in their careers.

---

**Ready to start?** Visit our [Labs Overview](contents/labs/labs.qmd) to begin hands-on learning with your chosen platform. 