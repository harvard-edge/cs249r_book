# Hardware Kits {.unnumbered}

This page introduces the hardware platforms chosen for our TinyML curriculum. TinyML—machine learning on resource-constrained, embedded devices—serves as an effective context for teaching the full spectrum of machine learning systems engineering. By working with these platforms, students confront real-world challenges such as limited compute, memory, and power, as well as the integration of sensors and actuators, and the practicalities of deploying and maintaining models outside traditional data centers.

Cost and accessibility are central to our hardware choices. We have selected platforms across a range of price points, from affordable development boards to more advanced kits, and offer guidance on educational discounts and alternative sources to help make hands-on embedded ML experience widely attainable. Our aim is to lower barriers so that as many learners as possible can engage with embedded ML in a practical, meaningful way.

## Curriculum Design Philosophy {#sec-kits-curriculum-philosophy}

Our hardware selection is guided by pedagogical principles that promote both breadth and depth in embedded machine learning. Platforms are chosen to offer **progressive complexity**, enabling learners to start with accessible tools and advance to more sophisticated systems as their confidence grows.

We intentionally include **diverse architectures**—from microcontrollers to application processors and dedicated AI accelerators—so students can see how hardware constraints and capabilities shape design decisions. This exposure ranges from ultra-low-power devices to powerful edge computers.

**Accessibility** is prioritized, with kit recommendations spanning a wide price range to accommodate different budgets. We also provide information on discounts and alternative sources.

All selected platforms are used in commercial products, ensuring that the skills developed in our labs are directly relevant to professional practice. Each platform is supported by a robust development ecosystem, including comprehensive toolchains, documentation, and active community support.

## Supported Hardware Platforms {#sec-kits-supported-platforms}

### XIAOML Kit (Seeed Studio) {#sec-kits-seeed-xiao}

*Note: XIAO (小) means "tiny" in Chinese, reflecting this platform's ultra-compact design philosophy.*

![XIAO ESP32S3 development board](book/contents/labs/seeed/xiao_esp32s3/images/png/XIAOML_Kit_Complete.png){width=400}

Despite its thumb-sized form factor, the XIAO ESP32S3 packs remarkable capability into an incredibly compact package. This platform teaches students that space constraints drive many real-world design decisions in modern IoT deployments.

**Key Features:**
- **Ultra-compact design** demonstrating space-constrained engineering
- **Built-in wireless connectivity** (WiFi and Bluetooth) for IoT applications
- **Versatile sensor ecosystem** supporting multi-modal applications
- **Exceptional price-to-performance ratio** making it accessible to students

**Why This Platform Matters:**
The board's wireless connectivity opens up entirely new deployment paradigms where edge devices participate in larger systems. Students learn how ML devices can send inference results to cloud services, receive model updates over-the-air, or coordinate with other intelligent devices in mesh networks.

**Learning Outcomes:**
Students develop skills in wireless ML deployment, multi-modal sensor fusion, edge-to-cloud connectivity patterns, and resource-constrained optimization that apply broadly across embedded systems.

**Applications**: IoT sensor networks, remote monitoring, wireless ML inference

---

### Raspberry Pi (4/5 and Zero 2W) {#sec-kits-raspberry-pi}

![Raspberry Pi 5 and Pi Zero 2W comparison](contents/labs/raspi/images/jpeg/raspis.jpg){width=400}

The Raspberry Pi family bridges embedded systems and traditional computing, offering students experience with full Linux environments while maintaining educational hardware accessibility. This platform demonstrates how computational resources influence ML system design possibilities.

**Key Features:**
- **Full Linux environment** with complete development platform capabilities
- **Scalable performance** from ultra-low-power Pi Zero to high-performance Pi 5
- **Extensive ecosystem** with rich libraries and community support  
- **Advanced ML capabilities** supporting sophisticated models and frameworks

**Why This Platform Matters:**
The Pi's compatibility with standard ML frameworks like TensorFlow and PyTorch provides a smooth transition from desktop development to edge deployment. Students can leverage existing software tools while learning edge-specific optimization techniques.

**Learning Outcomes:**
Students master Linux-based ML deployment, develop model optimization skills for edge computing, learn performance scaling strategies, and explore integration patterns with cloud services that define modern AI architectures.

**Applications**: Edge AI gateways, computer vision systems, small language models, multi-modal AI

---

### Arduino Nicla Vision {#sec-kits-arduino-nicla}

![Arduino Nicla Vision with camera module](contents/labs/arduino/nicla_vision/images/jpg/nicla_vision_quarter.jpeg){width=400}

The Arduino Nicla Vision exemplifies the art of doing more with less. Built around the STM32H7 microcontroller—the same chip found in many commercial IoT devices—this platform demonstrates how sophisticated machine learning can run on remarkably constrained hardware.

**Key Features:**
- **Ultra-low power consumption** for battery-powered applications lasting months
- **Vision-optimized design** with seamless camera-to-ML inference pipeline  
- **Arduino ecosystem compatibility** providing familiar development workflows
- **Professional-grade hardware** using industry-standard STM32H7 processor

**Why This Platform Matters:**
Unlike general-purpose microcontrollers where camera interfacing requires complex setup, the Nicla Vision provides an immediate path from image capture to ML inference. Students can focus on learning ML concepts rather than debugging hardware interfaces, while still working within the constraints that define real-world embedded systems.

**Learning Outcomes:**
Students master microcontroller-based ML deployment, discover power optimization techniques, understand real-time vision processing constraints, and gain fluency in Arduino development workflows that power countless commercial IoT products.

**Applications**: Image classification, object detection, keyword spotting, motion detection

---

### Grove Vision AI V2 {#sec-kits-grove-vision}

![Grove Vision AI V2 with NPU](book/contents/labs/seeed/grove_vision_ai_v2/images/jpeg/grove_vision_ai_v2.jpeg){width=400}

The Grove Vision AI V2 represents the cutting edge of embedded AI acceleration. Its dedicated Neural Processing Unit (NPU) provides students with hands-on experience of hardware-accelerated inference—the technology powering everything from smartphone cameras to autonomous vehicle perception systems.

**Key Features:**
- **Dedicated NPU** delivering dramatic performance improvements over software-only solutions
- **Visual programming environment** through SenseCraft AI for rapid prototyping
- **Industrial-grade capabilities** suitable for commercial deployment scenarios
- **Hardware-accelerated inference** demonstrating specialized AI processor benefits

**Why This Platform Matters:**
Unlike software-only ML deployment, the Grove AI V2 shows how specialized hardware can achieve orders-of-magnitude improvements in both performance and power efficiency. Students witness the same model that struggles on general-purpose processors achieving smooth video-rate inference on dedicated AI hardware.

**Learning Outcomes:**
Students develop expertise in hardware-accelerated inference, professional ML deployment workflows, advanced computer vision applications, and critical analysis of performance versus complexity trade-offs.

**Applications**: Industrial inspection, advanced object detection, real-time video analytics

## Kit Comparison Matrix {#sec-kits-comparison}

+-----------------------+---------------+---------------+----------------+---------------------+
| Feature               | XIAOML Kit    | Raspberry Pi  | Arduino Nicla  | Grove Vision AI V2  |
+=======================+===============+===============+================+=====================+
| **Power Consumption** | Low           | High          | Ultra-low      | Medium              |
+-----------------------+---------------+---------------+----------------+---------------------+
| **Processing Power**  | Medium        | Very High     | Low            | High (NPU)          |
+-----------------------+---------------+---------------+----------------+---------------------+
| **Memory**            | 8MB           | 1-8GB         | 2MB            | 16MB                |
+-----------------------+---------------+---------------+----------------+---------------------+
| **ML Framework**      | TF Lite       | TensorFlow,   | TensorFlow Lite| SenseCraft AI       |
|                       |               | PyTorch       |                |                     |
+-----------------------+---------------+---------------+----------------+---------------------+
| **Development**       | Arduino/      | Python/Linux  | Arduino IDE    | Visual/Code         |
|                       | PlatformIO    |               |                |                     |
+-----------------------+---------------+---------------+----------------+---------------------+
| **Cost Range**        | $15-50        | $15-100       | >$100          | ~$30                |
+-----------------------+---------------+---------------+----------------+---------------------+
| **Best For**          | IoT networks  | Edge computing| Battery devices| Industrial AI       |
+-----------------------+---------------+---------------+----------------+---------------------+

## Lab Compatibility Matrix {#sec-kits-lab-compatibility}

Understanding which labs work with each platform helps you plan your learning journey and choose the right hardware for your projects.

+---------------------------+---------------+--------------+--------------------+--------------+
| Lab Type                  | Arduino Nicla | XIAOML Kit   | Grove Vision AI V2 | Raspberry Pi |
+===========================+===============+==============+====================+==============+
| **Getting Started**       | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Image Classification**  | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Object Detection**      | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Keyword Spotting**      | ✓             | ✓            |                    |              |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Motion Classification** | ✓             | ✓            |                    |              |
+---------------------------+---------------+--------------+--------------------+--------------+
| **No-Code Applications**  |               |              | ✓                  |              |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Large Language Models** |               |              |                    | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **Vision Language Models**|               |              |                    | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+
| **DSP/Feature Engr.**     | ✓             | ✓            | ✓                  | ✓            |
+---------------------------+---------------+--------------+--------------------+--------------+

### Lab Selection Guide {#sec-kits-lab-selection-guide}

**For Beginners**: Start with Image Classification on any platform to understand basic ML deployment concepts. The Arduino Nicla and XIAOML Kit offer the most comprehensive lab coverage for foundational learning.

**For Audio/Sensor Applications**: Arduino Nicla and XIAOML Kit provide complete keyword spotting and motion classification labs that demonstrate sensor fusion and audio processing.

**For Advanced Vision**: Grove Vision AI V2 and Raspberry Pi excel at sophisticated computer vision tasks, with the Grove offering no-code options and the Pi supporting complex multi-modal models.

**For Language Models**: Only Raspberry Pi supports LLM and VLM applications, making it essential for exploring the latest AI capabilities at the edge.

## Getting Started {#sec-kits-getting-started}

### Recommended Learning Path {#sec-kits-learning-path}

We recommend beginning with either the Arduino Nicla Vision or XIAOML Kit to establish fundamental concepts. These platforms provide immediate feedback without overwhelming complexity, allowing students to build confidence with core ML deployment concepts.

As students become comfortable with basic inference and optimization, the Grove Vision AI V2 introduces hardware acceleration concepts that are increasingly important in commercial applications. The visual programming environment provides a bridge between educational exercises and professional development workflows.

The Raspberry Pi serves as the capstone platform, where students can integrate multiple concepts learned on simpler hardware while exploring advanced applications like language models and multimodal AI that require more computational resources.

### What's Included in Our Labs {#sec-kits-lab-coverage}

Each platform includes comprehensive tutorials covering setup and configuration, where students learn to establish development environments and understand toolchain workflows. Computer vision labs explore image classification, object detection, and real-time processing across different computational constraints. Audio processing tutorials cover keyword spotting, audio classification, and feature extraction techniques that apply broadly across signal processing applications.

Model deployment labs teach TensorFlow Lite optimization, performance tuning, and the systematic approaches to troubleshooting that separate successful projects from abandoned prototypes. Throughout all labs, we emphasize best practices for documentation, testing, and reproducible development that students will need in professional practice.

### Hardware Acquisition {#sec-kits-acquisition}

Many platforms offer educational discounts, and we provide guidance on accessing these programs. We recommend specific starter kits that include necessary sensors and accessories, eliminating the guesswork of component selection. For international students or those in regions with limited supplier networks, we maintain lists of compatible boards and alternative sources.

For educational institutions working with constrained budgets, we provide guidance on cost-effective deployment strategies, bulk purchasing options, and approaches to maximize learning impact per dollar invested.

## Integration with Curriculum {#sec-kits-curriculum-integration}

Our hardware selection directly supports the book's pedagogical progression. Foundational concepts in chapters 2-4 work effectively with any platform, allowing students to choose based on availability or interest. Platform-specific optimization techniques covered in chapters 5-8 become concrete through hands-on experimentation. Advanced deployment concepts in chapters 9-12 leverage the full capability of platforms like the Raspberry Pi and Grove AI V2.

Each platform teaches different aspects of the ML systems engineering discipline. Students progress from ultra-low-power constraints that define IoT applications to cloud-connected edge AI systems that power smart infrastructure. This progression mirrors the diversity of real-world ML deployment scenarios they'll encounter in their careers.

---

**Ready to start?** Visit our [Labs Overview](contents/labs/labs.qmd) to begin hands-on learning with your chosen platform. 