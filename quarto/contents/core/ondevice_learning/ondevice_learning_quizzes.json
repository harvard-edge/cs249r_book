{
  "metadata": {
    "source_file": "/Users/VJ/GitHub/MLSysBook/quarto/contents/core/ondevice_learning/ondevice_learning.qmd",
    "total_sections": 9,
    "sections_with_quizzes": 7,
    "sections_without_quizzes": 2
  },
  "sections": [
    {
      "section_id": "#sec-ondevice-learning-overview-c195",
      "section_title": "Overview",
      "quiz_data": {
        "quiz_needed": false,
        "rationale": "This section primarily provides an overview of on-device learning, its historical context, and technological advancements. It does not delve into technical tradeoffs, system components, or operational implications that require active understanding or application by students. The section sets the stage for more detailed discussions in subsequent sections, making a self-check quiz unnecessary at this point."
      }
    },
    {
      "section_id": "#sec-ondevice-learning-deployment-drivers-e37e",
      "section_title": "Deployment Drivers",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "On-device learning benefits",
            "Decentralized vs. centralized learning paradigms",
            "Application domains for on-device learning"
          ],
          "question_strategy": "Focus on system-level implications and practical applications of on-device learning, emphasizing benefits and trade-offs compared to centralized approaches.",
          "difficulty_progression": "Start with understanding basic concepts of on-device learning, then progress to analyzing its benefits and application domains.",
          "integration": "Connect on-device learning concepts with real-world applications and system-level implications, ensuring students can relate theory to practice.",
          "ranking_explanation": "The section introduces significant shifts in ML deployment strategies and their implications, warranting a self-check to reinforce understanding and application."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following is NOT a benefit of on-device learning?",
            "choices": [
              "Improved personalization",
              "Increased reliance on centralized infrastructure",
              "Enhanced privacy by keeping data local",
              "Reduced latency and increased availability"
            ],
            "answer": "The correct answer is B. On-device learning reduces reliance on centralized infrastructure by enabling models to adapt locally using device-specific data, thus enhancing personalization, reducing latency, and preserving privacy.",
            "learning_objective": "Identify the benefits of on-device learning and understand how it contrasts with centralized learning."
          },
          {
            "question_type": "SHORT",
            "question": "Explain how on-device learning can improve privacy for users.",
            "answer": "On-device learning improves privacy by keeping sensitive data on the device, reducing the need to transmit personal information to centralized servers. This approach aligns with privacy regulations like GDPR, as it minimizes data exposure and potential compliance issues.",
            "learning_objective": "Understand the privacy implications of on-device learning and its alignment with data protection regulations."
          },
          {
            "question_type": "CALC",
            "question": "A centralized ML system processes 100MB of user data daily from 1,000 devices. If on-device learning reduces data transmission by 80%, calculate the new daily data transmission volume.",
            "answer": "Original data transmission: 100MB × 1,000 = 100,000MB. Reduction: 100,000MB × 0.80 = 80,000MB. New transmission volume: 100,000MB - 80,000MB = 20,000MB. On-device learning significantly reduces data transmission, enhancing privacy and reducing bandwidth usage.",
            "learning_objective": "Calculate the impact of on-device learning on data transmission volumes and understand its benefits in terms of privacy and efficiency."
          },
          {
            "question_type": "MCQ",
            "question": "In which application domain is on-device learning especially beneficial due to high inter-user variability?",
            "choices": [
              "Cloud-based training",
              "Centralized data aggregation",
              "Static model deployment",
              "Mobile input prediction"
            ],
            "answer": "The correct answer is D. Mobile input prediction benefits from on-device learning due to the high variability in user typing patterns, which require personalized adaptations that static models cannot provide.",
            "learning_objective": "Recognize application domains where on-device learning offers significant advantages due to user-specific data and variability."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-design-constraints-c776",
      "section_title": "Design Constraints",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Model constraints and architecture design",
            "Data characteristics and their impact on learning",
            "Computational constraints in on-device learning"
          ],
          "question_strategy": "Use a mix of question types to cover different aspects of design constraints, focusing on model, data, and computational limitations.",
          "difficulty_progression": "Begin with foundational understanding and progress to application and analysis of constraints in real-world scenarios.",
          "integration": "Questions will reinforce understanding of how constraints affect system design and operation, building on concepts introduced earlier in the chapter.",
          "ranking_explanation": "This section introduces critical system-level considerations for on-device learning, making self-check questions essential for reinforcing and applying these concepts."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following is a primary challenge when designing models for on-device learning?",
            "choices": [
              "Access to large, curated datasets",
              "Unlimited computational resources",
              "Memory and storage constraints",
              "High-speed network connectivity"
            ],
            "answer": "The correct answer is C. Memory and storage constraints are a primary challenge in on-device learning, as models must fit within limited resources while maintaining performance.",
            "learning_objective": "Understand the key challenges in designing models for on-device learning."
          },
          {
            "question_type": "FILL",
            "question": "On-device learning systems often deal with data that is ______, which can complicate model convergence and update mechanisms.",
            "answer": "non-IID. Non-independent and identically distributed data can vary significantly across devices, complicating model convergence and update mechanisms.",
            "learning_objective": "Recognize the impact of non-IID data on on-device learning systems."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why quantization is important for on-device learning.",
            "answer": "Quantization reduces the memory and computational requirements of models by representing weights and activations with lower precision, such as 8-bit integers. This is crucial for fitting models within the limited resources of edge devices while maintaining acceptable performance levels.",
            "learning_objective": "Understand the role of quantization in optimizing models for resource-constrained environments."
          },
          {
            "question_type": "ORDER",
            "question": "Order the following steps in the on-device adaptation pipeline: (1) Train selected layers and channels, (2) Meta-training with generic data, (3) Rank channels and layers based on multi-objective metrics.",
            "answer": "The correct order is: (2) Meta-training with generic data, (3) Rank channels and layers based on multi-objective metrics, (1) Train selected layers and channels. This sequence allows for initial model preparation, evaluation of constraints, and targeted adaptation.",
            "learning_objective": "Reinforce understanding of the on-device adaptation pipeline process."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-model-adaptation-6a82",
      "section_title": "Model Adaptation",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Model adaptation strategies",
            "Tradeoffs in resource-constrained environments",
            "Implementation of bias-only and residual updates"
          ],
          "question_strategy": "The questions will focus on understanding the practical implementation of model adaptation strategies, the tradeoffs involved, and the application of these strategies in real-world scenarios.",
          "difficulty_progression": "The quiz will start with basic understanding questions and progress to more complex application and analysis questions.",
          "integration": "Questions will build on the foundational concepts of model adaptation, emphasizing their application in constrained environments and the tradeoffs involved.",
          "ranking_explanation": "The section introduces critical concepts necessary for understanding on-device learning and model adaptation, making a quiz essential to reinforce these ideas."
        },
        "questions": [
          {
            "question_type": "TF",
            "question": "Bias-only adaptation in on-device learning significantly reduces memory usage by updating only the bias terms while keeping all other parameters frozen.",
            "answer": "True. Bias-only adaptation reduces memory usage by updating only the bias terms, which are scalar offsets, thus minimizing the number of trainable parameters and stored gradients.",
            "learning_objective": "Understand the efficiency of bias-only adaptation in reducing memory usage."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why residual adapters are beneficial in on-device learning compared to bias-only updates.",
            "answer": "Residual adapters provide greater flexibility and expressivity by introducing small trainable layers that allow the model to adapt to new data. They enable more substantial deviations from the pretrained task, which is beneficial when the frozen model does not align well with the target distribution.",
            "learning_objective": "Analyze the benefits of using residual adapters over bias-only updates in terms of model expressivity."
          },
          {
            "question_type": "CALC",
            "question": "A MobileNetV2 model originally has 3 million parameters. Using TinyTL, the model is reduced to 50,000 parameters. Calculate the percentage reduction in the number of parameters.",
            "answer": "Original parameters: 3,000,000. Reduced parameters: 50,000. Reduction = 3,000,000 - 50,000 = 2,950,000. Percentage reduction = (2,950,000 / 3,000,000) × 100 = 98.33%. This significant reduction allows the model to fit within the memory constraints of edge devices.",
            "learning_objective": "Apply parameter reduction concepts to quantify memory savings in model adaptation."
          },
          {
            "question_type": "ORDER",
            "question": "Order the following steps involved in task-adaptive sparse updates: (1) Evaluate improvement in validation accuracy, (2) Freeze the entire model, (3) Rank layers by performance gain per unit cost, (4) Unfreeze one candidate layer.",
            "answer": "The correct order is: (2) Freeze the entire model, (4) Unfreeze one candidate layer, (1) Evaluate improvement in validation accuracy, (3) Rank layers by performance gain per unit cost. This sequence ensures a systematic approach to identifying the most impactful layers for sparse updates.",
            "learning_objective": "Understand the process of implementing task-adaptive sparse updates in model adaptation."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-data-efficiency-c701",
      "section_title": "Data Efficiency",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Data-efficient learning strategies",
            "Few-shot and streaming adaptation",
            "Experience replay and data compression"
          ],
          "question_strategy": "Use a variety of question types to explore different aspects of data efficiency, including practical applications and theoretical understanding.",
          "difficulty_progression": "Start with basic understanding of concepts, then move to application and analysis of strategies in real-world scenarios.",
          "integration": "Questions build on foundational concepts of data efficiency, emphasizing the constraints and methods used in on-device learning systems.",
          "ranking_explanation": "This section introduces critical strategies for handling data scarcity in on-device learning, making it essential for students to understand and apply these concepts."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following best describes the main challenge addressed by few-shot adaptation in on-device learning?",
            "choices": [
              "Handling large volumes of labeled data",
              "Generalizing from a small number of examples",
              "Reducing computational complexity of models",
              "Ensuring data privacy in centralized systems"
            ],
            "answer": "The correct answer is B. Few-shot adaptation focuses on generalizing from a small number of examples, which is crucial in on-device learning where data is scarce and often unlabeled.",
            "learning_objective": "Understand the purpose and challenges of few-shot adaptation in data-scarce environments."
          },
          {
            "question_type": "TF",
            "question": "True or False: Experience replay in on-device learning systems primarily aims to increase the model's training speed.",
            "answer": "False. Experience replay aims to prevent catastrophic forgetting and improve stability in non-stationary environments by allowing models to retrain on past examples.",
            "learning_objective": "Recognize the purpose of experience replay in maintaining model performance over time."
          },
          {
            "question_type": "SHORT",
            "question": "Explain how compressed data representations benefit on-device learning systems.",
            "answer": "Compressed data representations reduce memory and compute costs by transforming raw inputs into lower-dimensional embeddings, allowing devices to maintain longer histories and simplify learning tasks under tight resource constraints.",
            "learning_objective": "Analyze the benefits of using compressed data representations in resource-constrained environments."
          },
          {
            "question_type": "CALC",
            "question": "A keyword spotting system uses a replay buffer with a capacity of 100 samples, each compressed to 128 bytes. Calculate the total memory required for the buffer and discuss its feasibility on a device with 256KB of available memory.",
            "answer": "The total memory required is 100 samples × 128 bytes = 12,800 bytes (12.8KB). This is feasible on a device with 256KB of available memory, as it leaves ample space for other operations, demonstrating efficient use of limited memory resources.",
            "learning_objective": "Apply memory calculations to evaluate the feasibility of replay buffers in on-device learning systems."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-federated-learning-6e7e",
      "section_title": "Federated Learning",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "Federated Learning Principles",
            "System Implications and Tradeoffs",
            "Communication and Personalization Strategies"
          ],
          "question_strategy": "Focus on understanding and applying federated learning principles, exploring system-level implications, and analyzing tradeoffs in communication and personalization strategies.",
          "difficulty_progression": "Begin with foundational understanding of federated learning principles and system implications, then progress to analyzing tradeoffs and strategies for communication and personalization.",
          "integration": "Build on earlier sections by contrasting federated learning with on-device and centralized learning paradigms, emphasizing system-level reasoning and practical implications.",
          "ranking_explanation": "Federated learning is a foundational concept in ML systems, requiring understanding of its principles, system implications, and tradeoffs. Questions should reinforce these key areas and connect to practical applications."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following best describes a key advantage of federated learning over traditional centralized learning?",
            "choices": [
              "It requires less computational power on edge devices.",
              "It preserves data privacy by keeping data local.",
              "It eliminates the need for a central server.",
              "It allows for real-time data processing on devices."
            ],
            "answer": "The correct answer is B. Federated learning preserves data privacy by keeping data local and only sharing model updates, unlike centralized learning which requires raw data transmission to a central server.",
            "learning_objective": "Understand the privacy-preserving advantage of federated learning compared to centralized learning."
          },
          {
            "question_type": "SHORT",
            "question": "Explain how federated learning balances data privacy with collective model improvement.",
            "answer": "Federated learning balances data privacy with collective model improvement by allowing devices to train locally on private data and only share model updates with a central server. This approach enables global model improvement without transmitting raw data, thus preserving user privacy while benefiting from distributed intelligence.",
            "learning_objective": "Explain the balance between privacy and model improvement in federated learning."
          },
          {
            "question_type": "CALC",
            "question": "A federated learning system uses FedAvg with 10 clients, each holding 1,000 data samples. If each client performs 5 local epochs with a batch size of 100, calculate the total number of local updates performed across all clients in one round.",
            "answer": "Each client performs 5 epochs × (1,000/100) batches = 50 updates. With 10 clients, the total is 10 × 50 = 500 local updates per round. This calculation shows the scale of local computation before aggregation in federated learning.",
            "learning_objective": "Apply federated learning concepts to calculate local update scales in distributed systems."
          },
          {
            "question_type": "TF",
            "question": "True or False: In federated learning, all participating devices must have identical hardware capabilities to ensure effective model training.",
            "answer": "False. Federated learning accommodates heterogeneous devices with varying capabilities. The system is designed to handle differences in hardware, data availability, and connectivity, using strategies like weighted aggregation and adaptive client selection.",
            "learning_objective": "Understand the role of device heterogeneity in federated learning systems."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-practical-system-design-7619",
      "section_title": "Practical System Design",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "System design principles for on-device learning",
            "Adaptation strategies and resource constraints",
            "Security and privacy considerations in adaptation"
          ],
          "question_strategy": "Use a mix of question types to test understanding of system design, adaptation strategies, and security considerations. Include a CALC question to apply quantitative reasoning to adaptation footprint.",
          "difficulty_progression": "Begin with understanding system design principles, then move to application of adaptation strategies, and conclude with security and privacy implications.",
          "integration": "These questions build on the section's emphasis on system design principles and adaptation strategies, without overlapping with previous sections' focus on on-device learning benefits and challenges.",
          "ranking_explanation": "The focus on system design and adaptation strategies is central to understanding practical ML systems, making this section highly suitable for self-check questions."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which adaptation strategy is recommended for minimizing the adaptation footprint in on-device learning systems?",
            "choices": [
              "Full-model fine-tuning",
              "Bias-only optimization",
              "Centralized feature extraction",
              "Heavy adaptation with residual adapters"
            ],
            "answer": "The correct answer is B. Bias-only optimization minimizes the adaptation footprint by updating only the bias terms, which is feasible for resource-constrained edge platforms.",
            "learning_objective": "Understand the importance of minimizing adaptation footprint in on-device learning systems."
          },
          {
            "question_type": "CALC",
            "question": "A model with 20 million FP32 parameters is adapted using bias-only optimization, reducing the parameter count to 200,000. Calculate the percentage reduction in the number of parameters.",
            "answer": "Original parameters: 20M. Bias-only parameters: 200K. Reduction: 20M - 200K = 19.8M. Percentage reduction: (19.8M / 20M) × 100 = 99%. This significant reduction demonstrates the efficiency of bias-only optimization in reducing the adaptation footprint.",
            "learning_objective": "Apply quantitative reasoning to understand the impact of adaptation strategies on parameter reduction."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why opportunistic scheduling is important in on-device learning.",
            "answer": "Opportunistic scheduling defers local updates to periods of device idleness, external power connection, and reliable network operation, minimizing the impact on latency, battery consumption, and thermal performance, thus preserving user experience.",
            "learning_objective": "Analyze the role of scheduling in optimizing resource usage and user experience in on-device learning."
          },
          {
            "question_type": "TF",
            "question": "True or False: Security measures alone are sufficient to ensure model robustness during local adaptation.",
            "answer": "False. While security measures protect data and model update integrity, monitoring adaptation dynamics with techniques like confidence scoring and drift detection is crucial to identify divergence and maintain robustness.",
            "learning_objective": "Evaluate the role of security and monitoring in maintaining model robustness during adaptation."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-challenges-b30f",
      "section_title": "Challenges",
      "quiz_data": {
        "quiz_needed": true,
        "rationale": {
          "focus_areas": [
            "System heterogeneity and its impact on deployment",
            "Data fragmentation and non-IID data challenges",
            "Resource management and scheduling"
          ],
          "question_strategy": "Use a mix of question types to cover trade-offs, operational concerns, and practical implications of on-device learning challenges.",
          "difficulty_progression": "Start with basic understanding of heterogeneity, then move to data fragmentation, and finally address resource management complexities.",
          "integration": "Questions are designed to build on the foundational understanding of on-device learning challenges and explore their practical implications.",
          "ranking_explanation": "The section introduces critical system-level challenges, making a quiz essential to reinforce understanding and application of these concepts."
        },
        "questions": [
          {
            "question_type": "MCQ",
            "question": "Which of the following best describes a challenge introduced by system heterogeneity in on-device learning?",
            "choices": [
              "Diverse hardware and software configurations",
              "Consistent software environments",
              "Uniform hardware capabilities across devices",
              "Centralized data validation"
            ],
            "answer": "The correct answer is A. Diverse hardware and software configurations. System heterogeneity in on-device learning involves a wide range of device capabilities and software environments, complicating deployment and optimization.",
            "learning_objective": "Understand the impact of system heterogeneity on deploying machine learning models at the edge."
          },
          {
            "question_type": "SHORT",
            "question": "Explain why non-IID data poses a challenge for on-device learning systems.",
            "answer": "Non-IID data means that data distributions are specific to individual devices, leading to challenges in optimization and generalization. This can result in models that overfit to local data and perform poorly when aggregated globally.",
            "learning_objective": "Analyze the challenges posed by non-IID data in decentralized learning environments."
          },
          {
            "question_type": "TF",
            "question": "True or False: On-device learning systems can easily validate updates using centralized datasets.",
            "answer": "False. On-device learning systems lack centralized datasets for validation, making it difficult to assess the quality and direction of updates without interfering with user experience or violating privacy.",
            "learning_objective": "Evaluate the limitations of validation and monitoring in on-device learning systems."
          },
          {
            "question_type": "CALC",
            "question": "A microcontroller consumes 100mW during training. If it operates on a 1000mAh battery, calculate how long it can continuously train before exhausting the battery.",
            "answer": "The microcontroller consumes 100mW. A 1000mAh battery at 3.6V provides 3.6Wh, equivalent to 3600mW. Continuous training would exhaust the battery in 3600mWh / 100mW = 36 hours. This illustrates the need for efficient energy management in on-device learning.",
            "learning_objective": "Apply energy consumption calculations to understand resource constraints in on-device learning."
          }
        ]
      }
    },
    {
      "section_id": "#sec-ondevice-learning-summary-0af9",
      "section_title": "Summary",
      "quiz_data": {
        "quiz_needed": false,
        "rationale": "This section serves as a summary and high-level overview of the concepts discussed throughout the chapter on on-device learning. It provides context and motivation but does not introduce new technical concepts, system components, or operational implications that require active understanding or application. The section primarily synthesizes information already covered in depth in previous sections, which have been addressed with self-check questions. Therefore, a quiz is not pedagogically necessary for reinforcing this summary content."
      }
    }
  ]
}