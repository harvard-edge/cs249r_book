
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The Learning Journey: From Atoms to Intelligence &#8212; Tinyüî•Torch</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=009d37f4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs";

const defaultStyle = document.createElement('style');
defaultStyle.textContent = `pre.mermaid {
    /* Same as .mermaid-container > pre */
    display: block;
    width: 100%;
}

pre.mermaid > svg {
    /* Same as .mermaid-container > pre > svg */
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}
`;
document.head.appendChild(defaultStyle);

const fullscreenStyle = document.createElement('style');
fullscreenStyle.textContent = `.mermaid-container {
    display: flex;
    flex-direction: row;
    width: 100%;
}

.mermaid-container > pre {
    display: block;
    width: 100%;
}

.mermaid-container > pre > svg {
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}

.mermaid-fullscreen-btn {
    width: 28px;
    height: 28px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.3);
    border-radius: 4px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.2);
    font-size: 14px;
    line-height: 1;
    padding: 0;
    color: #333;
}

.mermaid-fullscreen-btn:hover {
    opacity: 100% !important;
    background: rgba(255, 255, 255, 1);
    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.3);
    transform: scale(1.1);
}

.mermaid-fullscreen-btn.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.3);
    color: #e0e0e0;
}

.mermaid-fullscreen-btn.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 3px 10px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal {
    display: none;
    position: fixed !important;
    top: 0 !important;
    left: 0 !important;
    width: 95vw;
    height: 100vh;
    background: rgba(255, 255, 255, 0.98);
    z-index: 9999;
    padding: 20px;
    overflow: auto;
}

.mermaid-fullscreen-modal.dark-theme {
    background: rgba(0, 0, 0, 0.98);
}

.mermaid-fullscreen-modal.active {
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen {
    position: relative;
    width: 95vw;
    height: 90vh;
    max-width: 95vw;
    max-height: 90vh;
    background: white;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
    overflow: auto;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen.dark-theme {
    background: #1a1a1a;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.8);
}

.mermaid-container-fullscreen pre.mermaid {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen .mermaid svg {
    height: 100% !important;
    width: 100% !important;
    cursor: grab;
}

.mermaid-fullscreen-close {
    position: fixed !important;
    top: 20px !important;
    right: 20px !important;
    width: 40px;
    height: 40px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.2);
    border-radius: 50%;
    cursor: pointer;
    z-index: 10000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: all 0.2s;
    font-size: 24px;
    line-height: 1;
    color: #333;
}

.mermaid-fullscreen-close:hover {
    background: white;
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
    transform: scale(1.1);
}

.mermaid-fullscreen-close.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.2);
    color: #e0e0e0;
}

.mermaid-fullscreen-close.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 6px 16px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal .mermaid-fullscreen-btn {
    display: none !important;
}`;
document.head.appendChild(fullscreenStyle);

// Detect if page has dark background
const isDarkTheme = () => {
    const bgColor = window.getComputedStyle(document.body).backgroundColor;
    const match = bgColor.match(/rgb\((\d+),\s*(\d+),\s*(\d+)/);
    if (match) {
        const r = parseInt(match[1]);
        const g = parseInt(match[2]);
        const b = parseInt(match[3]);
        const brightness = (r * 299 + g * 587 + b * 114) / 1000;
        return brightness < 128;
    }
    return false;
};

const load = async () => {
    await mermaid.run();

    const all_mermaids = document.querySelectorAll(".mermaid");
    const mermaids_processed = document.querySelectorAll(".mermaid[data-processed='true']");

    if ("False" === "True") {
        const mermaids_to_add_zoom = -1 === -1 ? all_mermaids.length : -1;
        if(mermaids_to_add_zoom > 0) {
            var svgs = d3.selectAll("");
            if(all_mermaids.length !== mermaids_processed.length) {
                setTimeout(load, 200);
                return;
            } else if(svgs.size() !== mermaids_to_add_zoom) {
                setTimeout(load, 200);
                return;
            } else {
                svgs.each(function() {
                    var svg = d3.select(this);
                    svg.html("<g class='wrapper'>" + svg.html() + "</g>");
                    var inner = svg.select("g");
                    var zoom = d3.zoom().on("zoom", function(event) {
                        inner.attr("transform", event.transform);
                    });
                    svg.call(zoom);
                });
            }
        }
    } else if(all_mermaids.length !== mermaids_processed.length) {
        // Wait for mermaid to process all diagrams
        setTimeout(load, 200);
        return;
    }

    const darkTheme = isDarkTheme();

    // Stop here if not adding fullscreen capability
    if ("True" !== "True") return;

    const modal = document.createElement('div');
    modal.className = 'mermaid-fullscreen-modal' + (darkTheme ? ' dark-theme' : '');
    modal.setAttribute('role', 'dialog');
    modal.setAttribute('aria-modal', 'true');
    modal.setAttribute('aria-label', 'Fullscreen diagram viewer');
    modal.innerHTML = `
        <button class="mermaid-fullscreen-close${darkTheme ? ' dark-theme' : ''}" aria-label="Close fullscreen">‚úï</button>
        <div class="mermaid-container-fullscreen${darkTheme ? ' dark-theme' : ''}"></div>
    `;
    document.body.appendChild(modal);

    const modalContent = modal.querySelector('.mermaid-container-fullscreen');
    const closeBtn = modal.querySelector('.mermaid-fullscreen-close');

    let previousScrollOffset = [window.scrollX, window.scrollY];

    const closeModal = () => {
        modal.classList.remove('active');
        modalContent.innerHTML = '';
        document.body.style.overflow = ''
        window.scrollTo({left: previousScrollOffset[0], top: previousScrollOffset[1], behavior: 'instant'});
    };

    closeBtn.addEventListener('click', closeModal);
    modal.addEventListener('click', (e) => {
        if (e.target === modal) closeModal();
    });
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeModal();
        }
    });

    const allButtons = [];

    document.querySelectorAll('.mermaid').forEach((mermaidDiv) => {
        if (mermaidDiv.parentNode.classList.contains('mermaid-container') ||
            mermaidDiv.closest('.mermaid-fullscreen-modal')) {
            return;
        }

        const container = document.createElement('div');
        container.className = 'mermaid-container';
        mermaidDiv.parentNode.insertBefore(container, mermaidDiv);
        container.appendChild(mermaidDiv);

        const fullscreenBtn = document.createElement('button');
        fullscreenBtn.className = 'mermaid-fullscreen-btn' + (darkTheme ? ' dark-theme' : '');
        fullscreenBtn.setAttribute('aria-label', 'View diagram in fullscreen');
        fullscreenBtn.textContent = '‚õ∂';
        fullscreenBtn.style.opacity = '50%';

        // Calculate dynamic position based on diagram's margin and padding
        const diagramStyle = window.getComputedStyle(mermaidDiv);
        const marginTop = parseFloat(diagramStyle.marginTop) || 0;
        const marginRight = parseFloat(diagramStyle.marginRight) || 0;
        const paddingTop = parseFloat(diagramStyle.paddingTop) || 0;
        const paddingRight = parseFloat(diagramStyle.paddingRight) || 0;
        fullscreenBtn.style.top = `${marginTop + paddingTop + 4}px`;
        fullscreenBtn.style.right = `${marginRight + paddingRight + 4}px`;

        fullscreenBtn.addEventListener('click', () => {
            previousScrollOffset = [window.scroll, window.scrollY];
            const clone = mermaidDiv.cloneNode(true);
            modalContent.innerHTML = '';
            modalContent.appendChild(clone);

            const svg = clone.querySelector('svg');
            if (svg) {
                svg.removeAttribute('width');
                svg.removeAttribute('height');
                svg.style.width = '100%';
                svg.style.height = 'auto';
                svg.style.maxWidth = '100%';
                svg.style.sdisplay = 'block';

                if ("False" === "True") {
                    setTimeout(() => {
                        const g = svg.querySelector('g');
                        if (g) {
                            var svgD3 = d3.select(svg);
                            svgD3.html("<g class='wrapper'>" + svgD3.html() + "</g>");
                            var inner = svgD3.select("g");
                            var zoom = d3.zoom().on("zoom", function(event) {
                                inner.attr("transform", event.transform);
                            });
                            svgD3.call(zoom);
                        }
                    }, 100);
                }
            }

            modal.classList.add('active');
            document.body.style.overflow = 'hidden';
        });

        container.appendChild(fullscreenBtn);
        allButtons.push(fullscreenBtn);
    });

    // Update theme classes when theme changes
    const updateTheme = () => {
        const dark = isDarkTheme();
        allButtons.forEach(btn => {
            if (dark) {
                btn.classList.add('dark-theme');
            } else {
                btn.classList.remove('dark-theme');
            }
        });
        if (dark) {
            modal.classList.add('dark-theme');
            modalContent.classList.add('dark-theme');
            closeBtn.classList.add('dark-theme');
        } else {
            modal.classList.remove('dark-theme');
            modalContent.classList.remove('dark-theme');
            closeBtn.classList.remove('dark-theme');
        }
    };

    // Watch for theme changes
    const observer = new MutationObserver(updateTheme);
    observer.observe(document.documentElement, {
        attributes: true,
        attributeFilter: ['class', 'style', 'data-theme']
    });
    observer.observe(document.body, {
        attributes: true,
        attributeFilter: ['class', 'style']
    });
};

window.addEventListener("load", load);
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/learning-journey';</script>
    <script src="../_static/ml-timeline.js?v=76e9b3e3"></script>
    <script src="../_static/wip-banner.js?v=04a7e74d"></script>
    <script src="../_static/marimo-badges.js?v=e6289128"></script>
    <script src="../_static/sidebar-link.js?v=404b701b"></script>
    <script src="../_static/hero-carousel.js?v=10341d2a"></script>
    <script src="../_static/subscribe-modal.js?v=42919b64"></script>
    <link rel="icon" href="../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Journey Through ML History" href="milestones.html" />
    <link rel="prev" title="Prerequisites &amp; Self-Assessment" href="../prerequisites.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo-tinytorch.png" class="logo__image only-light" alt="Tinyüî•Torch - Home"/>
    <script>document.write(`<img src="../_static/logo-tinytorch.png" class="logo__image only-dark" alt="Tinyüî•Torch - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">üöÄ Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Complete Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üèó Foundation Tier (01-07)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/foundation.html">üìñ Tier Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/01_tensor_ABOUT.html">01. Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/02_activations_ABOUT.html">02. Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/03_layers_ABOUT.html">03. Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/04_losses_ABOUT.html">04. Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/05_autograd_ABOUT.html">05. Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/06_optimizers_ABOUT.html">06. Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/07_training_ABOUT.html">07. Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üèõÔ∏è Architecture Tier (08-13)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/architecture.html">üìñ Tier Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/08_dataloader_ABOUT.html">08. DataLoader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/09_spatial_ABOUT.html">09. Convolutions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/10_tokenization_ABOUT.html">10. Tokenization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/11_embeddings_ABOUT.html">11. Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/12_attention_ABOUT.html">12. Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/13_transformers_ABOUT.html">13. Transformers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">‚è±Ô∏è Optimization Tier (14-19)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/optimization.html">üìñ Tier Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/14_profiling_ABOUT.html">14. Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/15_quantization_ABOUT.html">15. Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/16_compression_ABOUT.html">16. Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/17_memoization_ABOUT.html">17. Memoization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/18_acceleration_ABOUT.html">18. Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/19_benchmarking_ABOUT.html">19. Benchmarking</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üèÖ Capstone Competition</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/olympics.html">üìñ Competition Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/20_capstone_ABOUT.html">20. Torch Olympics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üß≠ Course Orientation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00-introduction.html">Course Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prerequisites.html">Prerequisites &amp; Resources</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Learning Journey</a></li>
<li class="toctree-l1"><a class="reference internal" href="milestones.html">Historical Milestones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üõ†Ô∏è TITO CLI Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tito/overview.html">Command Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/modules.html">Module Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/milestones.html">Milestone System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/data.html">Progress &amp; Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Datasets Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ü§ù Community</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../community.html">Ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Learning Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../credits.html">Credits &amp; Acknowledgments</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/learning-journey.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Learning Journey: From Atoms to Intelligence</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-this-page-is-about">What This Page Is About</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use-this-narrative">How to Use This Narrative</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-six-act-learning-story">The Six-Act Learning Story</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-i-foundation-modules-01-04-building-the-atomic-components">Act I: Foundation (Modules 01-04) - Building the Atomic Components</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-01-tensor-the-universal-data-structure">Module 01: Tensor - The Universal Data Structure</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-02-activations-adding-intelligence">Module 02: Activations - Adding Intelligence</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-03-layers-composable-building-blocks">Module 03: Layers - Composable Building Blocks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-04-losses-measuring-success">Module 04: Losses - Measuring Success</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-ii-learning-modules-05-07-the-gradient-revolution">Act II: Learning (Modules 05-07) - The Gradient Revolution</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-05-autograd-the-gradient-engine">Module 05: Autograd - The Gradient Engine</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-06-optimizers-following-the-gradient-downhill">Module 06: Optimizers - Following the Gradient Downhill</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-07-training-the-learning-loop">Module 07: Training - The Learning Loop</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-iii-data-scale-modules-08-09-handling-real-world-complexity">Act III: Data &amp; Scale (Modules 08-09) - Handling Real-World Complexity</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-08-dataloader-feeding-the-training-loop">Module 08: DataLoader - Feeding the Training Loop</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-09-spatial-seeing-the-world-in-images">Module 09: Spatial - Seeing the World in Images</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-iv-language-modules-10-13-understanding-sequential-data">Act IV: Language (Modules 10-13) - Understanding Sequential Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-10-tokenization-text-to-numbers">Module 10: Tokenization - Text to Numbers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-11-embeddings-learning-semantic-representations">Module 11: Embeddings - Learning Semantic Representations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-12-attention-dynamic-context-weighting">Module 12: Attention - Dynamic Context Weighting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-13-transformers-the-complete-architecture">Module 13: Transformers - The Complete Architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-v-production-modules-14-19-optimization-deployment">Act V: Production (Modules 14-19) - Optimization &amp; Deployment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-14-profiling-measuring-before-optimizing">Module 14: Profiling - Measuring Before Optimizing</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-15-quantization-reduced-precision-for-efficiency">Module 15: Quantization - Reduced Precision for Efficiency</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-16-compression-removing-redundancy">Module 16: Compression - Removing Redundancy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-17-memoization-avoiding-redundant-computation">Module 17: Memoization - Avoiding Redundant Computation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-18-acceleration-vectorization-parallel-execution">Module 18: Acceleration - Vectorization &amp; Parallel Execution</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-19-benchmarking-rigorous-performance-measurement">Module 19: Benchmarking - Rigorous Performance Measurement</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-vi-integration-module-20-building-real-ai-systems">Act VI: Integration (Module 20) - Building Real AI Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-20-capstone-tinygpt-end-to-end">Module 20: Capstone - TinyGPT End-to-End</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-this-journey-connects-to-everything-else">How This Journey Connects to Everything Else</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#journey-6-acts-vs-tiers-3-levels">Journey (6 Acts) vs. Tiers (3 Levels)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#journey-vs-milestones-two-dimensions-of-progress">Journey vs. Milestones: Two Dimensions of Progress</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#journey-vs-capabilities-tracking-your-skills">Journey vs. Capabilities: Tracking Your Skills</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-your-complete-journey">Visualizing Your Complete Journey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-this-journey-student-guidance">Using This Journey: Student Guidance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-starting-tinytorch">When Starting TinyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#during-your-learning-journey">During Your Learning Journey</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#module-by-module-orientation">Module-by-Module Orientation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-teaching-tinytorch">When Teaching TinyTorch</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-pedagogical-arc-why-this-progression-works">The Pedagogical Arc: Why This Progression Works</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bottom-up-learning-from-atoms-to-systems">Bottom-Up Learning: From Atoms to Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#progressive-complexity-scaffolded-learning">Progressive Complexity: Scaffolded Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#systems-thinking-see-the-whole-not-just-parts">Systems Thinking: See the Whole, Not Just Parts</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#faq-understanding-the-journey">FAQ: Understanding the Journey</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-six-acts-instead-of-just-three-tiers">Why six acts instead of just three tiers?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#can-i-skip-acts-or-jump-around">Can I skip acts or jump around?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#which-act-is-the-hardest">Which act is the hardest?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-long-does-each-act-take">How long does each act take?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-do-i-unlock-milestones">When do I unlock milestones?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What‚Äôs Next?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="the-learning-journey-from-atoms-to-intelligence">
<h1>The Learning Journey: From Atoms to Intelligence<a class="headerlink" href="#the-learning-journey-from-atoms-to-intelligence" title="Link to this heading">#</a></h1>
<p><strong>Understand the pedagogical narrative connecting modules 01-20 into a complete learning story from atomic components to production AI systems.</strong></p>
<hr class="docutils" />
<section id="what-this-page-is-about">
<h2>What This Page Is About<a class="headerlink" href="#what-this-page-is-about" title="Link to this heading">#</a></h2>
<p>This page tells the <strong>pedagogical story</strong> behind TinyTorch‚Äôs module progression. While other pages explain:</p>
<ul class="simple">
<li><p><strong>WHAT you‚Äôll build</strong> (<a class="reference internal" href="00-introduction.html"><span class="std std-doc">Three-Tier Structure</span></a>) - organized module breakdown</p></li>
<li><p><strong>WHEN in history</strong> (<a class="reference internal" href="milestones.html"><span class="std std-doc">Milestones</span></a>) - recreating ML breakthroughs</p></li>
<li><p><strong>WHERE you are</strong> (<span class="xref myst">Student Workflow</span>) - development workflow and progress</p></li>
</ul>
<p>This page explains <strong>WHY modules flow this way</strong> - the learning narrative that transforms 20 individual modules into a coherent journey from mathematical foundations to production AI systems.</p>
<section id="how-to-use-this-narrative">
<h3>How to Use This Narrative<a class="headerlink" href="#how-to-use-this-narrative" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Starting TinyTorch?</strong> Read this to understand the complete arc before diving into modules</p></li>
<li><p><strong>Mid-journey?</strong> Return here when wondering ‚ÄúWhy am I building DataLoader now?‚Äù</p></li>
<li><p><strong>Planning your path?</strong> Use this to understand how modules build on each other pedagogically</p></li>
<li><p><strong>Teaching TinyTorch?</strong> Share this narrative to help students see the big picture</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="the-six-act-learning-story">
<h2>The Six-Act Learning Story<a class="headerlink" href="#the-six-act-learning-story" title="Link to this heading">#</a></h2>
<p>TinyTorch‚Äôs 20 modules follow a carefully crafted six-act narrative arc. Each act represents a fundamental shift in what you‚Äôre learning and what you can build.</p>
<pre  class="mermaid">
        graph LR
    Act1[&quot;Act I: Foundation&lt;br/&gt;01-04&lt;br/&gt;Atomic Components&quot;] --&gt; Act2[&quot;Act II: Learning&lt;br/&gt;05-07&lt;br/&gt;Gradient Revolution&quot;]
    Act2 --&gt; Act3[&quot;Act III: Data &amp; Scale&lt;br/&gt;08-09&lt;br/&gt;Real Complexity&quot;]
    Act3 --&gt; Act4[&quot;Act IV: Language&lt;br/&gt;10-13&lt;br/&gt;Sequential Data&quot;]
    Act4 --&gt; Act5[&quot;Act V: Production&lt;br/&gt;14-19&lt;br/&gt;Optimization&quot;]
    Act5 --&gt; Act6[&quot;Act VI: Integration&lt;br/&gt;20&lt;br/&gt;Complete Systems&quot;]

    style Act1 fill:#e3f2fd
    style Act2 fill:#fff8e1
    style Act3 fill:#e8f5e9
    style Act4 fill:#f3e5f5
    style Act5 fill:#fce4ec
    style Act6 fill:#fff3e0
    </pre><hr class="docutils" />
<section id="act-i-foundation-modules-01-04-building-the-atomic-components">
<h3>Act I: Foundation (Modules 01-04) - Building the Atomic Components<a class="headerlink" href="#act-i-foundation-modules-01-04-building-the-atomic-components" title="Link to this heading">#</a></h3>
<p><strong>The Beginning</strong>: You start with nothing but Python and NumPy. Before you can build intelligence, you need the atoms.</p>
<div style="background: #f8f9fa; border-left: 4px solid #007bff; padding: 1.5rem; margin: 2rem 0;">
<p><strong>What You Learn</strong>: Mathematical infrastructure that powers all neural networks - data structures, nonlinearity, composable transformations, and error measurement.</p>
<p><strong>What You Build</strong>: The fundamental building blocks that everything else depends on.</p>
</div>
<section id="module-01-tensor-the-universal-data-structure">
<h4>Module 01: Tensor - The Universal Data Structure<a class="headerlink" href="#module-01-tensor-the-universal-data-structure" title="Link to this heading">#</a></h4>
<p>You begin by building the Tensor class - the fundamental container for all ML data. Tensors are to ML what integers are to programming: the foundation everything else is built on. You implement arithmetic, matrix operations, reshaping, slicing, and broadcasting. Every component you build afterward will use Tensors.</p>
<p><strong>Systems Insight</strong>: Understanding tensor memory layout, contiguous storage, and view semantics prepares you for optimization in Act V.</p>
</section>
<section id="module-02-activations-adding-intelligence">
<h4>Module 02: Activations - Adding Intelligence<a class="headerlink" href="#module-02-activations-adding-intelligence" title="Link to this heading">#</a></h4>
<p>With Tensors ready, you add nonlinearity. You implement ReLU, Sigmoid, Tanh, and Softmax - the functions that give neural networks their power to approximate any function. Without activations, networks are just linear algebra. With them, they can learn complex patterns.</p>
<p><strong>Systems Insight</strong>: Each activation has different computational and numerical stability properties - knowledge critical for debugging training later.</p>
</section>
<section id="module-03-layers-composable-building-blocks">
<h4>Module 03: Layers - Composable Building Blocks<a class="headerlink" href="#module-03-layers-composable-building-blocks" title="Link to this heading">#</a></h4>
<p>Now you construct layers - reusable components that transform inputs to outputs. Linear layers perform matrix multiplication, LayerNorm stabilizes training, Dropout prevents overfitting. Each layer encapsulates transformation logic with a clean forward() interface.</p>
<p><strong>Systems Insight</strong>: The layer abstraction teaches composability and modularity - how complex systems emerge from simple, well-designed components.</p>
</section>
<section id="module-04-losses-measuring-success">
<h4>Module 04: Losses - Measuring Success<a class="headerlink" href="#module-04-losses-measuring-success" title="Link to this heading">#</a></h4>
<p>How do you know if your model is learning? Loss functions measure the gap between predictions and truth. MSELoss for regression, CrossEntropyLoss for classification, ContrastiveLoss for embeddings. Losses convert abstract predictions into concrete numbers you can minimize.</p>
<p><strong>Systems Insight</strong>: Loss functions shape the optimization landscape - understanding their properties explains why some problems train easily while others struggle.</p>
<p><strong>üéØ Act I Achievement</strong>: You‚Äôve built the atomic components. But they‚Äôre static - they can compute forward passes but cannot learn. You‚Äôre ready for the revolution‚Ä¶</p>
<p><strong>Connection to Act II</strong>: Static components are useful, but the real power comes when they can LEARN from data. That requires gradients.</p>
</section>
</section>
<hr class="docutils" />
<section id="act-ii-learning-modules-05-07-the-gradient-revolution">
<h3>Act II: Learning (Modules 05-07) - The Gradient Revolution<a class="headerlink" href="#act-ii-learning-modules-05-07-the-gradient-revolution" title="Link to this heading">#</a></h3>
<p><strong>The Breakthrough</strong>: Your static components awaken. Automatic differentiation transforms computation into learning.</p>
<div style="background: #fff8e1; border-left: 4px solid #ffa726; padding: 1.5rem; margin: 2rem 0;">
<p><strong>What You Learn</strong>: The mathematics and systems engineering that enable learning - computational graphs, reverse-mode differentiation, gradient-based optimization, and training loops.</p>
<p><strong>What You Build</strong>: A complete training system that can optimize any neural network architecture.</p>
</div>
<section id="module-05-autograd-the-gradient-engine">
<h4>Module 05: Autograd - The Gradient Engine<a class="headerlink" href="#module-05-autograd-the-gradient-engine" title="Link to this heading">#</a></h4>
<p>This is the magic. You enhance Tensors with automatic differentiation - the ability to compute gradients automatically by building a computation graph. You implement backward() and the Function class. Now your Tensors remember their history and can propagate gradients through any computation.</p>
<p><strong>Systems Insight</strong>: Understanding computational graphs explains memory growth during training and why checkpointing saves memory - critical for scaling to large models.</p>
<p><strong>Pedagogical Note</strong>: This is the moment everything clicks. Students realize that <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> isn‚Äôt magic - it‚Äôs a carefully designed system they can understand and modify.</p>
</section>
<section id="module-06-optimizers-following-the-gradient-downhill">
<h4>Module 06: Optimizers - Following the Gradient Downhill<a class="headerlink" href="#module-06-optimizers-following-the-gradient-downhill" title="Link to this heading">#</a></h4>
<p>Gradients tell you which direction to move, but how far? You implement optimization algorithms: SGD takes simple steps, SGDMomentum adds velocity, RMSprop adapts step sizes, Adam combines both. Each optimizer is a strategy for navigating the loss landscape.</p>
<p><strong>Systems Insight</strong>: Optimizers have different memory footprints (Adam needs 3√ó parameter memory) and convergence properties - trade-offs that matter in production.</p>
</section>
<section id="module-07-training-the-learning-loop">
<h4>Module 07: Training - The Learning Loop<a class="headerlink" href="#module-07-training-the-learning-loop" title="Link to this heading">#</a></h4>
<p>You assemble everything into the training loop - the heartbeat of machine learning. Trainer orchestrates forward passes, loss computation, backward passes, and optimizer steps. You add learning rate schedules, checkpointing, and validation. This is where learning actually happens.</p>
<p><strong>Systems Insight</strong>: The training loop reveals how all components interact - a systems view that‚Äôs invisible when just calling model.fit().</p>
<p><strong>üéØ Act II Achievement</strong>: You can now train neural networks to learn from data! MLPs achieve 95%+ accuracy on MNIST using 100% your own implementations.</p>
<p><strong>Connection to Act III</strong>: Your learning system works beautifully on clean datasets that fit in memory. But real ML means messy data at scale.</p>
</section>
</section>
<hr class="docutils" />
<section id="act-iii-data-scale-modules-08-09-handling-real-world-complexity">
<h3>Act III: Data &amp; Scale (Modules 08-09) - Handling Real-World Complexity<a class="headerlink" href="#act-iii-data-scale-modules-08-09-handling-real-world-complexity" title="Link to this heading">#</a></h3>
<p><strong>The Challenge</strong>: Laboratory ML meets production reality. Real data is large, messy, and requires specialized processing.</p>
<div style="background: #e8f5e9; border-left: 4px solid #66bb6a; padding: 1.5rem; margin: 2rem 0;">
<p><strong>What You Learn</strong>: How to handle real-world data and spatial structure - the bridge from toy problems to production systems.</p>
<p><strong>What You Build</strong>: Data pipelines and computer vision capabilities that work on real image datasets.</p>
</div>
<section id="module-08-dataloader-feeding-the-training-loop">
<h4>Module 08: DataLoader - Feeding the Training Loop<a class="headerlink" href="#module-08-dataloader-feeding-the-training-loop" title="Link to this heading">#</a></h4>
<p>Real datasets don‚Äôt fit in memory. DataLoader provides batching, shuffling, and efficient iteration over large datasets. It separates data handling from model logic, enabling training on datasets larger than RAM through streaming and mini-batch processing.</p>
<p><strong>Systems Insight</strong>: Understanding batch processing, memory hierarchies, and I/O bottlenecks - the data pipeline is often the real bottleneck in production systems.</p>
</section>
<section id="module-09-spatial-seeing-the-world-in-images">
<h4>Module 09: Spatial - Seeing the World in Images<a class="headerlink" href="#module-09-spatial-seeing-the-world-in-images" title="Link to this heading">#</a></h4>
<p>Neural networks need specialized operations for spatial data. Conv2D applies learnable filters, MaxPool2D reduces dimensions while preserving features, Flatten converts spatial features to vectors. These are the building blocks of computer vision.</p>
<p><strong>Systems Insight</strong>: Convolutions exploit weight sharing and local connectivity - architectural choices that reduce parameters 100√ó compared to fully connected layers while improving performance.</p>
<p><strong>üéØ Act III Achievement</strong>: CNNs achieve 75%+ accuracy on CIFAR-10 natural images - real computer vision with YOUR spatial operations!</p>
<p><strong>Connection to Act IV</strong>: You‚Äôve mastered vision. But the most exciting ML breakthroughs are happening in language. Time to understand sequential data.</p>
</section>
</section>
<hr class="docutils" />
<section id="act-iv-language-modules-10-13-understanding-sequential-data">
<h3>Act IV: Language (Modules 10-13) - Understanding Sequential Data<a class="headerlink" href="#act-iv-language-modules-10-13-understanding-sequential-data" title="Link to this heading">#</a></h3>
<p><strong>The Modern Era</strong>: From pixels to words. You implement the architectures powering the LLM revolution.</p>
<div style="background: #f3e5f5; border-left: 4px solid #ab47bc; padding: 1.5rem; margin: 2rem 0;">
<p><strong>What You Learn</strong>: How to process language and implement the attention mechanisms that revolutionized AI - the path to GPT, BERT, and modern LLMs.</p>
<p><strong>What You Build</strong>: Complete transformer architecture capable of understanding and generating language.</p>
</div>
<section id="module-10-tokenization-text-to-numbers">
<h4>Module 10: Tokenization - Text to Numbers<a class="headerlink" href="#module-10-tokenization-text-to-numbers" title="Link to this heading">#</a></h4>
<p>Language models need numbers, not words. You implement character-level and BPE tokenization - converting text into sequences of integers. This is the bridge from human language to neural network inputs.</p>
<p><strong>Systems Insight</strong>: Tokenization choices (vocabulary size, subword splitting) directly impact model size and training efficiency - crucial decisions for production systems.</p>
</section>
<section id="module-11-embeddings-learning-semantic-representations">
<h4>Module 11: Embeddings - Learning Semantic Representations<a class="headerlink" href="#module-11-embeddings-learning-semantic-representations" title="Link to this heading">#</a></h4>
<p>Token IDs are just indices - they carry no meaning. Embeddings transform discrete tokens into continuous vectors where similar words cluster together. You add positional embeddings so models know word order.</p>
<p><strong>Systems Insight</strong>: Embeddings are often the largest single component in language models - understanding their memory footprint matters for deployment.</p>
</section>
<section id="module-12-attention-dynamic-context-weighting">
<h4>Module 12: Attention - Dynamic Context Weighting<a class="headerlink" href="#module-12-attention-dynamic-context-weighting" title="Link to this heading">#</a></h4>
<p>Not all words matter equally. Attention mechanisms let models focus on relevant parts of the input. You implement scaled dot-product attention and multi-head attention - the core innovation that powers modern language models.</p>
<p><strong>Systems Insight</strong>: Attention scales O(n¬≤) with sequence length - understanding this limitation explains why context windows are limited and why KV-caching matters (Act V).</p>
<p><strong>Pedagogical Note</strong>: This is often the ‚Äúaha!‚Äù moment for students - seeing attention as a differentiable dictionary lookup demystifies transformers.</p>
</section>
<section id="module-13-transformers-the-complete-architecture">
<h4>Module 13: Transformers - The Complete Architecture<a class="headerlink" href="#module-13-transformers-the-complete-architecture" title="Link to this heading">#</a></h4>
<p>You assemble attention, embeddings, and feed-forward layers into the Transformer architecture. TransformerBlock stacks self-attention with normalization and residual connections. This is the architecture that revolutionized NLP and enabled GPT, BERT, and modern AI.</p>
<p><strong>Systems Insight</strong>: Transformers are highly parallelizable (unlike RNNs) but memory-intensive - architectural trade-offs that shaped the modern ML landscape.</p>
<p><strong>üéØ Act IV Achievement</strong>: Your transformer generates coherent text! You‚Äôve implemented the architecture powering ChatGPT, GPT-4, and the modern AI revolution.</p>
<p><strong>Connection to Act V</strong>: Your transformer works, but it‚Äôs slow and memory-hungry. Time to optimize for production.</p>
</section>
</section>
<hr class="docutils" />
<section id="act-v-production-modules-14-19-optimization-deployment">
<h3>Act V: Production (Modules 14-19) - Optimization &amp; Deployment<a class="headerlink" href="#act-v-production-modules-14-19-optimization-deployment" title="Link to this heading">#</a></h3>
<p><strong>The Engineering Challenge</strong>: Research models meet production constraints. You transform working prototypes into deployable systems.</p>
<div style="background: #e0f7fa; border-left: 4px solid #26c6da; padding: 1.5rem; margin: 2rem 0;">
<p><strong>What You Learn</strong>: The systems engineering that makes ML production-ready - profiling, quantization, compression, caching, acceleration, and benchmarking.</p>
<p><strong>What You Build</strong>: Optimized systems competitive with industry implementations, ready for real-world deployment.</p>
</div>
<section id="module-14-profiling-measuring-before-optimizing">
<h4>Module 14: Profiling - Measuring Before Optimizing<a class="headerlink" href="#module-14-profiling-measuring-before-optimizing" title="Link to this heading">#</a></h4>
<p>You can‚Äôt optimize what you don‚Äôt measure. Profiler tracks memory usage, execution time, parameter counts, and FLOPs. You identify bottlenecks and validate that optimizations actually work.</p>
<p><strong>Systems Insight</strong>: Premature optimization is the root of all evil. Profiling reveals that the bottleneck is rarely where you think it is.</p>
</section>
<section id="module-15-quantization-reduced-precision-for-efficiency">
<h4>Module 15: Quantization - Reduced Precision for Efficiency<a class="headerlink" href="#module-15-quantization-reduced-precision-for-efficiency" title="Link to this heading">#</a></h4>
<p>Models use 32-bit floats by default, but 8-bit integers work almost as well. You implement INT8 quantization with calibration, reducing memory 4√ó and enabling 2-4√ó speedup on appropriate hardware.</p>
<p><strong>Systems Insight</strong>: Quantization trades precision for efficiency - understanding this trade-off is essential for edge deployment (mobile, IoT) where memory and power are constrained.</p>
</section>
<section id="module-16-compression-removing-redundancy">
<h4>Module 16: Compression - Removing Redundancy<a class="headerlink" href="#module-16-compression-removing-redundancy" title="Link to this heading">#</a></h4>
<p>Neural networks are over-parameterized. You implement magnitude pruning (removing small weights), structured pruning (removing neurons), low-rank decomposition (matrix factorization), and knowledge distillation (teacher-student training).</p>
<p><strong>Systems Insight</strong>: Different compression techniques offer different trade-offs. Structured pruning enables real speedup (unstructured doesn‚Äôt without sparse kernels).</p>
</section>
<section id="module-17-memoization-avoiding-redundant-computation">
<h4>Module 17: Memoization - Avoiding Redundant Computation<a class="headerlink" href="#module-17-memoization-avoiding-redundant-computation" title="Link to this heading">#</a></h4>
<p>Why recompute what you‚Äôve already calculated? You implement memoization with cache invalidation - dramatically speeding up recurrent patterns like autoregressive text generation.</p>
<p><strong>Systems Insight</strong>: KV-caching in transformers reduces generation from O(n¬≤) to O(n) - the optimization that makes real-time LLM interaction possible.</p>
</section>
<section id="module-18-acceleration-vectorization-parallel-execution">
<h4>Module 18: Acceleration - Vectorization &amp; Parallel Execution<a class="headerlink" href="#module-18-acceleration-vectorization-parallel-execution" title="Link to this heading">#</a></h4>
<p>Modern CPUs have SIMD instructions operating on multiple values simultaneously. You implement vectorized operations using NumPy‚Äôs optimized routines and explore parallel execution patterns.</p>
<p><strong>Systems Insight</strong>: Understanding hardware capabilities (SIMD width, cache hierarchy, instruction pipelining) enables 10-100√ó speedups through better code.</p>
</section>
<section id="module-19-benchmarking-rigorous-performance-measurement">
<h4>Module 19: Benchmarking - Rigorous Performance Measurement<a class="headerlink" href="#module-19-benchmarking-rigorous-performance-measurement" title="Link to this heading">#</a></h4>
<p>You build comprehensive benchmarking tools with precise timing, statistical analysis, and comparison frameworks. Benchmarks let you compare implementations objectively and measure real-world impact.</p>
<p><strong>Systems Insight</strong>: Benchmarking is a science - proper methodology (warmup, statistical significance, controlling variables) matters as much as the measurements themselves.</p>
<p><strong>üéØ Act V Achievement</strong>: Production-ready systems competitive in Torch Olympics benchmarks! Models achieve &lt;100ms inference latency with 4√ó memory reduction.</p>
<p><strong>Connection to Act VI</strong>: You have all the pieces - foundation, learning, data, language, optimization. Time to assemble them into a complete AI system.</p>
</section>
</section>
<hr class="docutils" />
<section id="act-vi-integration-module-20-building-real-ai-systems">
<h3>Act VI: Integration (Module 20) - Building Real AI Systems<a class="headerlink" href="#act-vi-integration-module-20-building-real-ai-systems" title="Link to this heading">#</a></h3>
<p><strong>The Culmination</strong>: Everything comes together. You build TinyGPT - a complete language model from scratch.</p>
<div style="background: #fce4ec; border-left: 4px solid #ec407a; padding: 1.5rem; margin: 2rem 0;">
<p><strong>What You Learn</strong>: Systems integration and end-to-end thinking - how all components work together to create functional AI.</p>
<p><strong>What You Build</strong>: A complete transformer-based language model with training, optimization, and text generation.</p>
</div>
<section id="module-20-capstone-tinygpt-end-to-end">
<h4>Module 20: Capstone - TinyGPT End-to-End<a class="headerlink" href="#module-20-capstone-tinygpt-end-to-end" title="Link to this heading">#</a></h4>
<p>Using all 19 previous modules, you build TinyGPT - a complete language model with:</p>
<ul class="simple">
<li><p>Text tokenization and embedding (Act IV)</p></li>
<li><p>Multi-layer transformer architecture (Act IV)</p></li>
<li><p>Training loop with optimization (Act II)</p></li>
<li><p>Quantization and pruning for efficiency (Act V)</p></li>
<li><p>Comprehensive benchmarking (Act V)</p></li>
<li><p>Text generation with sampling (Act IV + V)</p></li>
</ul>
<p><strong>Systems Insight</strong>: Integration reveals emergent complexity. Individual components are simple, but their interactions create surprising behaviors - the essence of systems engineering.</p>
<p><strong>Pedagogical Note</strong>: The capstone isn‚Äôt about learning new techniques - it‚Äôs about synthesis. Students discover that they‚Äôve built something real, not just completed exercises.</p>
<p><strong>üéØ Act VI Achievement</strong>: You‚Äôve built a complete AI framework and deployed a real language model - entirely from scratch, from tensors to text generation!</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="how-this-journey-connects-to-everything-else">
<h2>How This Journey Connects to Everything Else<a class="headerlink" href="#how-this-journey-connects-to-everything-else" title="Link to this heading">#</a></h2>
<section id="journey-6-acts-vs-tiers-3-levels">
<h3>Journey (6 Acts) vs. Tiers (3 Levels)<a class="headerlink" href="#journey-6-acts-vs-tiers-3-levels" title="Link to this heading">#</a></h3>
<p><strong>Acts</strong> and <strong>Tiers</strong> are complementary views of the same curriculum:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Perspective</p></th>
<th class="head"><p>Purpose</p></th>
<th class="head"><p>Granularity</p></th>
<th class="head"><p>Used For</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Tiers</strong> (3)</p></td>
<td><p>Structural organization</p></td>
<td><p>Coarse-grained</p></td>
<td><p>Navigation, TOCs, planning</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Acts</strong> (6)</p></td>
<td><p>Pedagogical narrative</p></td>
<td><p>Fine-grained</p></td>
<td><p>Understanding progression, storytelling</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Mapping Acts to Tiers</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>üèóÔ∏è FOUNDATION TIER (Modules 01-07)
  ‚îú‚îÄ Act I: Foundation (01-04) - Atomic components
  ‚îî‚îÄ Act II: Learning (05-07) - Gradient revolution

üèõÔ∏è ARCHITECTURE TIER (Modules 08-13)
  ‚îú‚îÄ Act III: Data &amp; Scale (08-09) - Real-world complexity
  ‚îî‚îÄ Act IV: Language (10-13) - Sequential understanding

‚ö° OPTIMIZATION TIER (Modules 14-20)
  ‚îú‚îÄ Act V: Production (14-19) - Deployment optimization
  ‚îî‚îÄ Act VI: Integration (20) - Complete systems
</pre></div>
</div>
<p><strong>When to use Tiers</strong>: Navigating the website, planning your study schedule, understanding time commitment.</p>
<p><strong>When to use Acts</strong>: Understanding why you‚Äôre learning something now, seeing how modules connect, maintaining motivation through the narrative arc.</p>
</section>
<hr class="docutils" />
<section id="journey-vs-milestones-two-dimensions-of-progress">
<h3>Journey vs. Milestones: Two Dimensions of Progress<a class="headerlink" href="#journey-vs-milestones-two-dimensions-of-progress" title="Link to this heading">#</a></h3>
<p>As you progress through TinyTorch, you advance along <strong>two dimensions simultaneously</strong>:</p>
<p><strong>Pedagogical Dimension (Acts)</strong>: What you‚Äôre LEARNING</p>
<ul class="simple">
<li><p><strong>Act I (01-04)</strong>: Building atomic components - mathematical foundations</p></li>
<li><p><strong>Act II (05-07)</strong>: The gradient revolution - systems that learn</p></li>
<li><p><strong>Act III (08-09)</strong>: Real-world complexity - data and scale</p></li>
<li><p><strong>Act IV (10-13)</strong>: Sequential intelligence - language understanding</p></li>
<li><p><strong>Act V (14-19)</strong>: Production systems - optimization and deployment</p></li>
<li><p><strong>Act VI (20)</strong>: Complete integration - unified AI systems</p></li>
</ul>
<p><strong>Historical Dimension (Milestones)</strong>: What you CAN BUILD</p>
<ul class="simple">
<li><p><strong>1957: Perceptron</strong> - Binary classification (after Act I)</p></li>
<li><p><strong>1969: XOR</strong> - Non-linear learning (after Act II)</p></li>
<li><p><strong>1986: MLP</strong> - Multi-class vision achieving 95%+ on MNIST (after Act II)</p></li>
<li><p><strong>1998: CNN</strong> - Spatial intelligence achieving 75%+ on CIFAR-10 (after Act III)</p></li>
<li><p><strong>2017: Transformers</strong> - Language generation (after Act IV)</p></li>
<li><p><strong>2024: Systems</strong> - Production optimization (after Act V)</p></li>
</ul>
<p><strong>How They Connect</strong>:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Learning Act</p></th>
<th class="head"><p>Unlocked Milestone</p></th>
<th class="head"><p>Proof of Mastery</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Act I: Foundation</strong></p></td>
<td><p>üß† 1957 Perceptron</p></td>
<td><p>Your Linear layer recreates history</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Act II: Learning</strong></p></td>
<td><p>‚ö° 1969 XOR + üî¢ 1986 MLP</p></td>
<td><p>Your autograd enables training (95%+ MNIST)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Act III: Data &amp; Scale</strong></p></td>
<td><p>üñºÔ∏è 1998 CNN</p></td>
<td><p>Your Conv2d achieves 75%+ on CIFAR-10</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Act IV: Language</strong></p></td>
<td><p>ü§ñ 2017 Transformers</p></td>
<td><p>Your attention generates coherent text</p></td>
</tr>
<tr class="row-even"><td><p><strong>Act V: Production</strong></p></td>
<td><p>‚ö° 2024 Systems Age</p></td>
<td><p>Your optimizations compete in benchmarks</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Act VI: Integration</strong></p></td>
<td><p>üèÜ TinyGPT Capstone</p></td>
<td><p>Your complete framework works end-to-end</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Understanding Both Dimensions</strong>: The <strong>Acts</strong> explain WHY you‚Äôre building each component (pedagogical progression). The <strong>Milestones</strong> prove WHAT you‚Äôve built actually works (historical validation).</p>
<p><strong>üìñ See <a class="reference internal" href="milestones.html"><span class="std std-doc">Journey Through ML History</span></a></strong> for complete milestone details and how to run them.</p>
</section>
<hr class="docutils" />
<section id="journey-vs-capabilities-tracking-your-skills">
<h3>Journey vs. Capabilities: Tracking Your Skills<a class="headerlink" href="#journey-vs-capabilities-tracking-your-skills" title="Link to this heading">#</a></h3>
<p>The learning journey also maps to <strong>21 capability checkpoints</strong> you can track:</p>
<p><strong>Foundation Capabilities (Act I-II)</strong>:</p>
<ul class="simple">
<li><p>Checkpoint 01: Tensor manipulation ‚úì</p></li>
<li><p>Checkpoint 02: Nonlinearity ‚úì</p></li>
<li><p>Checkpoint 03: Network layers ‚úì</p></li>
<li><p>Checkpoint 04: Loss measurement ‚úì</p></li>
<li><p>Checkpoint 05: Gradient computation ‚úì</p></li>
<li><p>Checkpoint 06: Parameter optimization ‚úì</p></li>
<li><p>Checkpoint 07: Model training ‚úì</p></li>
</ul>
<p><strong>Architecture Capabilities (Act III-IV)</strong>:</p>
<ul class="simple">
<li><p>Checkpoint 08: Image processing ‚úì</p></li>
<li><p>Checkpoint 09: Data loading ‚úì</p></li>
<li><p>Checkpoint 10: Text processing ‚úì</p></li>
<li><p>Checkpoint 11: Embeddings ‚úì</p></li>
<li><p>Checkpoint 12: Attention mechanisms ‚úì</p></li>
<li><p>Checkpoint 13: Transformers ‚úì</p></li>
</ul>
<p><strong>Production Capabilities (Act V-VI)</strong>:</p>
<ul class="simple">
<li><p>Checkpoint 14: Performance profiling ‚úì</p></li>
<li><p>Checkpoint 15: Model quantization ‚úì</p></li>
<li><p>Checkpoint 16: Network compression ‚úì</p></li>
<li><p>Checkpoint 17: Computation caching ‚úì</p></li>
<li><p>Checkpoint 18: Algorithm acceleration ‚úì</p></li>
<li><p>Checkpoint 19: Competitive benchmarking ‚úì</p></li>
<li><p>Checkpoint 20: Complete systems ‚úì</p></li>
</ul>
<p>See <span class="xref myst">Student Workflow</span> for the development workflow and progress tracking.</p>
</section>
</section>
<hr class="docutils" />
<section id="visualizing-your-complete-journey">
<h2>Visualizing Your Complete Journey<a class="headerlink" href="#visualizing-your-complete-journey" title="Link to this heading">#</a></h2>
<p>Here‚Äôs how the three views work together:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    PEDAGOGICAL NARRATIVE (6 Acts)
    ‚Üì
Act I ‚Üí Act II ‚Üí Act III ‚Üí Act IV ‚Üí Act V ‚Üí Act VI
01-04   05-07    08-09     10-13    14-19    20
  ‚îÇ       ‚îÇ        ‚îÇ         ‚îÇ        ‚îÇ       ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                ‚îÇ
    STRUCTURE (3 Tiers)      ‚îÇ                ‚îÇ
    Foundation Tier ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
    Architecture Tier ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    Optimization Tier ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
    VALIDATION (Historical Milestones)
    ‚îÇ
    ‚îú‚îÄ 1957 Perceptron (after Act I)
    ‚îú‚îÄ 1969 XOR + 1986 MLP (after Act II)
    ‚îú‚îÄ 1998 CNN 75%+ CIFAR-10 (after Act III)
    ‚îú‚îÄ 2017 Transformers (after Act IV)
    ‚îú‚îÄ 2024 Systems Age (after Act V)
    ‚îî‚îÄ TinyGPT Capstone (after Act VI)
</pre></div>
</div>
<p><strong>Use all three views</strong>:</p>
<ul class="simple">
<li><p><strong>Tiers</strong> help you navigate and plan</p></li>
<li><p><strong>Acts</strong> help you understand and stay motivated</p></li>
<li><p><strong>Milestones</strong> help you validate and celebrate</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="using-this-journey-student-guidance">
<h2>Using This Journey: Student Guidance<a class="headerlink" href="#using-this-journey-student-guidance" title="Link to this heading">#</a></h2>
<section id="when-starting-tinytorch">
<h3>When Starting TinyTorch<a class="headerlink" href="#when-starting-tinytorch" title="Link to this heading">#</a></h3>
<p><strong>Read this page FIRST</strong> (you‚Äôre doing it right!) to understand:</p>
<ul class="simple">
<li><p>Where you‚Äôre going (Act VI: complete AI systems)</p></li>
<li><p>Why modules are ordered this way (pedagogical progression)</p></li>
<li><p>How modules build on each other (each act enables the next)</p></li>
</ul>
</section>
<section id="during-your-learning-journey">
<h3>During Your Learning Journey<a class="headerlink" href="#during-your-learning-journey" title="Link to this heading">#</a></h3>
<p><strong>Return to this page when</strong>:</p>
<ul class="simple">
<li><p>Wondering ‚ÄúWhy am I building DataLoader now?‚Äù (Act III: Real data at scale)</p></li>
<li><p>Feeling lost in the details (zoom out to see which act you‚Äôre in)</p></li>
<li><p>Planning your next study session (understand what‚Äôs coming next)</p></li>
<li><p>Celebrating a milestone (see how it connects to the learning arc)</p></li>
</ul>
</section>
<section id="module-by-module-orientation">
<h3>Module-by-Module Orientation<a class="headerlink" href="#module-by-module-orientation" title="Link to this heading">#</a></h3>
<p>As you work through modules, ask yourself:</p>
<ul class="simple">
<li><p><strong>Which act am I in?</strong> (Foundation, Learning, Data &amp; Scale, Language, Production, or Integration)</p></li>
<li><p><strong>What did I learn in the previous act?</strong> (Act I: atomic components)</p></li>
<li><p><strong>What am I learning in this act?</strong> (Act II: how they learn)</p></li>
<li><p><strong>What will I unlock next act?</strong> (Act III: real-world data)</p></li>
</ul>
<p><strong>This narrative provides the context that makes individual modules meaningful.</strong></p>
</section>
<section id="when-teaching-tinytorch">
<h3>When Teaching TinyTorch<a class="headerlink" href="#when-teaching-tinytorch" title="Link to this heading">#</a></h3>
<p><strong>Share this narrative</strong> to help students:</p>
<ul class="simple">
<li><p>See the big picture before diving into details</p></li>
<li><p>Understand why prerequisites matter (each act builds on previous)</p></li>
<li><p>Stay motivated through challenging modules (see where it‚Äôs going)</p></li>
<li><p>Appreciate the pedagogical design (not arbitrary order)</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="the-pedagogical-arc-why-this-progression-works">
<h2>The Pedagogical Arc: Why This Progression Works<a class="headerlink" href="#the-pedagogical-arc-why-this-progression-works" title="Link to this heading">#</a></h2>
<section id="bottom-up-learning-from-atoms-to-systems">
<h3>Bottom-Up Learning: From Atoms to Systems<a class="headerlink" href="#bottom-up-learning-from-atoms-to-systems" title="Link to this heading">#</a></h3>
<p>TinyTorch follows a <strong>bottom-up progression</strong> - you build foundational components before assembling them into systems:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Act I: Atoms (Tensor, Activations, Layers, Losses)
  ‚Üì
Act II: Learning (Autograd, Optimizers, Training)
  ‚Üì
Act III: Scale (DataLoader, Spatial)
  ‚Üì
Act IV: Intelligence (Tokenization, Embeddings, Attention, Transformers)
  ‚Üì
Act V: Production (Profiling, Quantization, Compression, Acceleration)
  ‚Üì
Act VI: Systems (Complete integration)
</pre></div>
</div>
<p><strong>Why bottom-up?</strong></p>
<ul class="simple">
<li><p>You can‚Äôt understand training loops without understanding gradients</p></li>
<li><p>You can‚Äôt understand gradients without understanding computational graphs</p></li>
<li><p>You can‚Äôt understand computational graphs without understanding tensor operations</p></li>
</ul>
<p><strong>Each act requires mastery of previous acts</strong> - no forward references, no circular dependencies.</p>
</section>
<section id="progressive-complexity-scaffolded-learning">
<h3>Progressive Complexity: Scaffolded Learning<a class="headerlink" href="#progressive-complexity-scaffolded-learning" title="Link to this heading">#</a></h3>
<p>The acts increase in complexity while maintaining momentum:</p>
<p><strong>Act I (4 modules)</strong>: Simple mathematical operations - build confidence
<strong>Act II (3 modules)</strong>: Core learning algorithms - consolidate understanding
<strong>Act III (2 modules)</strong>: Real-world data handling - practical skills
<strong>Act IV (4 modules)</strong>: Modern architectures - exciting applications
<strong>Act V (6 modules)</strong>: Production optimization - diverse techniques
<strong>Act VI (1 module)</strong>: Integration - synthesis and mastery</p>
<p><strong>The pacing is intentional</strong>: shorter acts when introducing hard concepts (autograd), longer acts when students are ready for complexity (production optimization).</p>
</section>
<section id="systems-thinking-see-the-whole-not-just-parts">
<h3>Systems Thinking: See the Whole, Not Just Parts<a class="headerlink" href="#systems-thinking-see-the-whole-not-just-parts" title="Link to this heading">#</a></h3>
<p>Each act teaches <strong>systems thinking</strong> - how components interact to create emergent behavior:</p>
<ul class="simple">
<li><p><strong>Act I</strong>: Components in isolation</p></li>
<li><p><strong>Act II</strong>: Components communicating (gradients flow backward)</p></li>
<li><p><strong>Act III</strong>: Components scaling (data pipelines)</p></li>
<li><p><strong>Act IV</strong>: Components specializing (attention routing)</p></li>
<li><p><strong>Act V</strong>: Components optimizing (trade-offs everywhere)</p></li>
<li><p><strong>Act VI</strong>: Complete system integration</p></li>
</ul>
<p><strong>By Act VI, you think like a systems engineer</strong> - not just ‚ÄúHow do I implement this?‚Äù but ‚ÄúHow does this affect memory? Compute? Training time? Accuracy?‚Äù</p>
</section>
</section>
<hr class="docutils" />
<section id="faq-understanding-the-journey">
<h2>FAQ: Understanding the Journey<a class="headerlink" href="#faq-understanding-the-journey" title="Link to this heading">#</a></h2>
<section id="why-six-acts-instead-of-just-three-tiers">
<h3>Why six acts instead of just three tiers?<a class="headerlink" href="#why-six-acts-instead-of-just-three-tiers" title="Link to this heading">#</a></h3>
<p><strong>Tiers</strong> are for organization. <strong>Acts</strong> are for learning.</p>
<p>Tiers group modules by theme (foundation, architecture, optimization). Acts explain pedagogical progression (why Module 08 comes after Module 07, not just that they‚Äôre in the same tier).</p>
<p>Think of tiers as book chapters, acts as narrative arcs.</p>
</section>
<section id="can-i-skip-acts-or-jump-around">
<h3>Can I skip acts or jump around?<a class="headerlink" href="#can-i-skip-acts-or-jump-around" title="Link to this heading">#</a></h3>
<p><strong>No</strong> - each act builds on previous acts with hard dependencies:</p>
<ul class="simple">
<li><p>Can‚Äôt do Act II (Autograd) without Act I (Tensors)</p></li>
<li><p>Can‚Äôt do Act IV (Transformers) without Act II (Training) and Act III (DataLoader)</p></li>
<li><p>Can‚Äôt do Act V (Quantization) without Act IV (models to optimize)</p></li>
</ul>
<p><strong>The progression is carefully designed</strong> to avoid forward references and circular dependencies.</p>
</section>
<section id="which-act-is-the-hardest">
<h3>Which act is the hardest?<a class="headerlink" href="#which-act-is-the-hardest" title="Link to this heading">#</a></h3>
<p><strong>Act II (Autograd)</strong> is conceptually hardest - automatic differentiation requires understanding computational graphs and reverse-mode differentiation.</p>
<p><strong>Act V (Production)</strong> is breadth-wise hardest - six diverse optimization techniques, each with different trade-offs.</p>
<p><strong>Act IV (Transformers)</strong> is most exciting - seeing attention generate text is the ‚Äúwow‚Äù moment for many students.</p>
</section>
<section id="how-long-does-each-act-take">
<h3>How long does each act take?<a class="headerlink" href="#how-long-does-each-act-take" title="Link to this heading">#</a></h3>
<p>Typical time estimates (varies by background):</p>
<ul class="simple">
<li><p><strong>Act I</strong>: 8-12 hours (2 weeks &#64; 4-6 hrs/week)</p></li>
<li><p><strong>Act II</strong>: 6-9 hours (1.5 weeks &#64; 4-6 hrs/week)</p></li>
<li><p><strong>Act III</strong>: 6-8 hours (1 week &#64; 6-8 hrs/week)</p></li>
<li><p><strong>Act IV</strong>: 12-15 hours (2-3 weeks &#64; 4-6 hrs/week)</p></li>
<li><p><strong>Act V</strong>: 18-24 hours (3-4 weeks &#64; 6-8 hrs/week)</p></li>
<li><p><strong>Act VI</strong>: 8-10 hours (1.5 weeks &#64; 5-7 hrs/week)</p></li>
</ul>
<p><strong>Total</strong>: ~60-80 hours over 14-18 weeks</p>
</section>
<section id="when-do-i-unlock-milestones">
<h3>When do I unlock milestones?<a class="headerlink" href="#when-do-i-unlock-milestones" title="Link to this heading">#</a></h3>
<p><strong>After completing acts</strong>:</p>
<ul class="simple">
<li><p>Act I ‚Üí Perceptron (1957)</p></li>
<li><p>Act II ‚Üí XOR (1969) + MLP (1986)</p></li>
<li><p>Act III ‚Üí CNN (1998)</p></li>
<li><p>Act IV ‚Üí Transformers (2017)</p></li>
<li><p>Act V ‚Üí Systems (2024)</p></li>
<li><p>Act VI ‚Üí TinyGPT (complete)</p></li>
</ul>
<p><strong>üìñ See <a class="reference internal" href="milestones.html"><span class="std std-doc">Milestones</span></a></strong> for details.</p>
</section>
</section>
<hr class="docutils" />
<section id="whats-next">
<h2>What‚Äôs Next?<a class="headerlink" href="#whats-next" title="Link to this heading">#</a></h2>
<p><strong>Ready to begin your journey?</strong></p>
<div style="background: #f8f9fa; padding: 2rem; border-radius: 0.5rem; margin: 2rem 0; text-align: center;">
<h3 style="margin: 0 0 1rem 0; color: #495057;">Start Your Learning Journey</h3>
<p style="margin: 0 0 1.5rem 0; color: #6c757d;">Begin with Act I: Foundation - build the atomic components</p>
<a href="../quickstart-guide.html" style="display: inline-block; background: #007bff; color: white; padding: 0.75rem 1.5rem; border-radius: 0.25rem; text-decoration: none; font-weight: 500; margin-right: 1rem;">15-Minute Quick Start ‚Üí</a>
<a href="00-introduction.html" style="display: inline-block; background: #28a745; color: white; padding: 0.75rem 1.5rem; border-radius: 0.25rem; text-decoration: none; font-weight: 500;">View Course Structure ‚Üí</a>
</div>
<p><strong>Related Resources</strong>:</p>
<ul class="simple">
<li><p><strong><a class="reference internal" href="00-introduction.html"><span class="std std-doc">Three-Tier Structure</span></a></strong> - Organized module breakdown with time estimates</p></li>
<li><p><strong><a class="reference internal" href="milestones.html"><span class="std std-doc">Journey Through ML History</span></a></strong> - Historical milestones you‚Äôll recreate</p></li>
<li><p><strong><span class="xref myst">Student Workflow</span></strong> - Development workflow and progress tracking</p></li>
<li><p><strong><span class="xref myst">Quick Start Guide</span></strong> - Hands-on setup and first module</p></li>
</ul>
<hr class="docutils" />
<p><strong>Remember</strong>: You‚Äôre not just learning ML algorithms. You‚Äôre building ML systems - from mathematical foundations to production deployment. This journey transforms you from a framework user into a systems engineer who truly understands how modern AI works.</p>
<p><strong>Welcome to the learning journey. Let‚Äôs build something amazing together.</strong> üöÄ</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../prerequisites.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Prerequisites &amp; Self-Assessment</p>
      </div>
    </a>
    <a class="right-next"
       href="milestones.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Journey Through ML History</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-this-page-is-about">What This Page Is About</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use-this-narrative">How to Use This Narrative</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-six-act-learning-story">The Six-Act Learning Story</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-i-foundation-modules-01-04-building-the-atomic-components">Act I: Foundation (Modules 01-04) - Building the Atomic Components</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-01-tensor-the-universal-data-structure">Module 01: Tensor - The Universal Data Structure</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-02-activations-adding-intelligence">Module 02: Activations - Adding Intelligence</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-03-layers-composable-building-blocks">Module 03: Layers - Composable Building Blocks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-04-losses-measuring-success">Module 04: Losses - Measuring Success</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-ii-learning-modules-05-07-the-gradient-revolution">Act II: Learning (Modules 05-07) - The Gradient Revolution</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-05-autograd-the-gradient-engine">Module 05: Autograd - The Gradient Engine</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-06-optimizers-following-the-gradient-downhill">Module 06: Optimizers - Following the Gradient Downhill</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-07-training-the-learning-loop">Module 07: Training - The Learning Loop</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-iii-data-scale-modules-08-09-handling-real-world-complexity">Act III: Data &amp; Scale (Modules 08-09) - Handling Real-World Complexity</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-08-dataloader-feeding-the-training-loop">Module 08: DataLoader - Feeding the Training Loop</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-09-spatial-seeing-the-world-in-images">Module 09: Spatial - Seeing the World in Images</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-iv-language-modules-10-13-understanding-sequential-data">Act IV: Language (Modules 10-13) - Understanding Sequential Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-10-tokenization-text-to-numbers">Module 10: Tokenization - Text to Numbers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-11-embeddings-learning-semantic-representations">Module 11: Embeddings - Learning Semantic Representations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-12-attention-dynamic-context-weighting">Module 12: Attention - Dynamic Context Weighting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-13-transformers-the-complete-architecture">Module 13: Transformers - The Complete Architecture</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-v-production-modules-14-19-optimization-deployment">Act V: Production (Modules 14-19) - Optimization &amp; Deployment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-14-profiling-measuring-before-optimizing">Module 14: Profiling - Measuring Before Optimizing</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-15-quantization-reduced-precision-for-efficiency">Module 15: Quantization - Reduced Precision for Efficiency</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-16-compression-removing-redundancy">Module 16: Compression - Removing Redundancy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-17-memoization-avoiding-redundant-computation">Module 17: Memoization - Avoiding Redundant Computation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-18-acceleration-vectorization-parallel-execution">Module 18: Acceleration - Vectorization &amp; Parallel Execution</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-19-benchmarking-rigorous-performance-measurement">Module 19: Benchmarking - Rigorous Performance Measurement</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#act-vi-integration-module-20-building-real-ai-systems">Act VI: Integration (Module 20) - Building Real AI Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#module-20-capstone-tinygpt-end-to-end">Module 20: Capstone - TinyGPT End-to-End</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-this-journey-connects-to-everything-else">How This Journey Connects to Everything Else</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#journey-6-acts-vs-tiers-3-levels">Journey (6 Acts) vs. Tiers (3 Levels)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#journey-vs-milestones-two-dimensions-of-progress">Journey vs. Milestones: Two Dimensions of Progress</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#journey-vs-capabilities-tracking-your-skills">Journey vs. Capabilities: Tracking Your Skills</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-your-complete-journey">Visualizing Your Complete Journey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-this-journey-student-guidance">Using This Journey: Student Guidance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-starting-tinytorch">When Starting TinyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#during-your-learning-journey">During Your Learning Journey</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#module-by-module-orientation">Module-by-Module Orientation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-teaching-tinytorch">When Teaching TinyTorch</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-pedagogical-arc-why-this-progression-works">The Pedagogical Arc: Why This Progression Works</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bottom-up-learning-from-atoms-to-systems">Bottom-Up Learning: From Atoms to Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#progressive-complexity-scaffolded-learning">Progressive Complexity: Scaffolded Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#systems-thinking-see-the-whole-not-just-parts">Systems Thinking: See the Whole, Not Just Parts</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#faq-understanding-the-journey">FAQ: Understanding the Journey</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-six-acts-instead-of-just-three-tiers">Why six acts instead of just three tiers?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#can-i-skip-acts-or-jump-around">Can I skip acts or jump around?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#which-act-is-the-hardest">Which act is the hardest?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-long-does-each-act-take">How long does each act take?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#when-do-i-unlock-milestones">When do I unlock milestones?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What‚Äôs Next?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Prof. Vijay Janapa Reddi (Harvard University)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>