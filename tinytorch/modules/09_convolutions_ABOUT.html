
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Module 09: Spatial" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://mlsysbook.ai/tinytorch/modules/09_convolutions_ABOUT.html" />
<meta property="og:site_name" content="Tinyüî•Torch" />
<meta property="og:description" content="Overview: Spatial operations transform machine learning from working with flattened vectors to understanding images and spatial patterns. When you look at a photo, your brain naturally processes sp..." />
<meta property="og:image" content="https://mlsysbook.ai/tinytorch/_static/logos/logo-tinytorch.png" />
<meta property="og:image:alt" content="Tinyüî•Torch" />
<meta name="description" content="Overview: Spatial operations transform machine learning from working with flattened vectors to understanding images and spatial patterns. When you look at a photo, your brain naturally processes sp..." />

    <title>Module 09: Spatial &#8212; Tinyüî•Torch</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=6f4f0411" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.2.0/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs";

const defaultStyle = document.createElement('style');
defaultStyle.textContent = `pre.mermaid {
    /* Same as .mermaid-container > pre */
    display: block;
    width: 100%;
}

pre.mermaid > svg {
    /* Same as .mermaid-container > pre > svg */
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}
`;
document.head.appendChild(defaultStyle);

const fullscreenStyle = document.createElement('style');
fullscreenStyle.textContent = `.mermaid-container {
    display: flex;
    flex-direction: row;
    width: 100%;
}

.mermaid-container > pre {
    display: block;
    width: 100%;
}

.mermaid-container > pre > svg {
    height: 500px;
    width: 100%;
    max-width: 100% !important;
}

.mermaid-fullscreen-btn {
    width: 28px;
    height: 28px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.3);
    border-radius: 4px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.2);
    font-size: 14px;
    line-height: 1;
    padding: 0;
    color: #333;
}

.mermaid-fullscreen-btn:hover {
    opacity: 100% !important;
    background: rgba(255, 255, 255, 1);
    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.3);
    transform: scale(1.1);
}

.mermaid-fullscreen-btn.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.3);
    color: #e0e0e0;
}

.mermaid-fullscreen-btn.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 3px 10px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal {
    display: none;
    position: fixed !important;
    top: 0 !important;
    left: 0 !important;
    width: 95vw;
    height: 100vh;
    background: rgba(255, 255, 255, 0.98);
    z-index: 9999;
    padding: 20px;
    overflow: auto;
}

.mermaid-fullscreen-modal.dark-theme {
    background: rgba(0, 0, 0, 0.98);
}

.mermaid-fullscreen-modal.active {
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen {
    position: relative;
    width: 95vw;
    height: 90vh;
    max-width: 95vw;
    max-height: 90vh;
    background: white;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
    overflow: auto;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen.dark-theme {
    background: #1a1a1a;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.8);
}

.mermaid-container-fullscreen pre.mermaid {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-container-fullscreen .mermaid svg {
    height: 100% !important;
    width: 100% !important;
    cursor: grab;
}

.mermaid-fullscreen-close {
    position: fixed !important;
    top: 20px !important;
    right: 20px !important;
    width: 40px;
    height: 40px;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(0, 0, 0, 0.2);
    border-radius: 50%;
    cursor: pointer;
    z-index: 10000;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: all 0.2s;
    font-size: 24px;
    line-height: 1;
    color: #333;
}

.mermaid-fullscreen-close:hover {
    background: white;
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
    transform: scale(1.1);
}

.mermaid-fullscreen-close.dark-theme {
    background: rgba(50, 50, 50, 0.95);
    border: 1px solid rgba(255, 255, 255, 0.2);
    color: #e0e0e0;
}

.mermaid-fullscreen-close.dark-theme:hover {
    background: rgba(60, 60, 60, 1);
    box-shadow: 0 6px 16px rgba(255, 255, 255, 0.2);
}

.mermaid-fullscreen-modal .mermaid-fullscreen-btn {
    display: none !important;
}`;
document.head.appendChild(fullscreenStyle);

// Detect if page has dark background
const isDarkTheme = () => {
    const bgColor = window.getComputedStyle(document.body).backgroundColor;
    const match = bgColor.match(/rgb\((\d+),\s*(\d+),\s*(\d+)/);
    if (match) {
        const r = parseInt(match[1]);
        const g = parseInt(match[2]);
        const b = parseInt(match[3]);
        const brightness = (r * 299 + g * 587 + b * 114) / 1000;
        return brightness < 128;
    }
    return false;
};

const load = async () => {
    await mermaid.run();

    const all_mermaids = document.querySelectorAll(".mermaid");
    const mermaids_processed = document.querySelectorAll(".mermaid[data-processed='true']");

    if ("False" === "True") {
        const mermaids_to_add_zoom = -1 === -1 ? all_mermaids.length : -1;
        if(mermaids_to_add_zoom > 0) {
            var svgs = d3.selectAll("");
            if(all_mermaids.length !== mermaids_processed.length) {
                setTimeout(load, 200);
                return;
            } else if(svgs.size() !== mermaids_to_add_zoom) {
                setTimeout(load, 200);
                return;
            } else {
                svgs.each(function() {
                    var svg = d3.select(this);
                    svg.html("<g class='wrapper'>" + svg.html() + "</g>");
                    var inner = svg.select("g");
                    var zoom = d3.zoom().on("zoom", function(event) {
                        inner.attr("transform", event.transform);
                    });
                    svg.call(zoom);
                });
            }
        }
    } else if(all_mermaids.length !== mermaids_processed.length) {
        // Wait for mermaid to process all diagrams
        setTimeout(load, 200);
        return;
    }

    const darkTheme = isDarkTheme();

    // Stop here if not adding fullscreen capability
    if ("True" !== "True") return;

    const modal = document.createElement('div');
    modal.className = 'mermaid-fullscreen-modal' + (darkTheme ? ' dark-theme' : '');
    modal.setAttribute('role', 'dialog');
    modal.setAttribute('aria-modal', 'true');
    modal.setAttribute('aria-label', 'Fullscreen diagram viewer');
    modal.innerHTML = `
        <button class="mermaid-fullscreen-close${darkTheme ? ' dark-theme' : ''}" aria-label="Close fullscreen">‚úï</button>
        <div class="mermaid-container-fullscreen${darkTheme ? ' dark-theme' : ''}"></div>
    `;
    document.body.appendChild(modal);

    const modalContent = modal.querySelector('.mermaid-container-fullscreen');
    const closeBtn = modal.querySelector('.mermaid-fullscreen-close');

    let previousScrollOffset = [window.scrollX, window.scrollY];

    const closeModal = () => {
        modal.classList.remove('active');
        modalContent.innerHTML = '';
        document.body.style.overflow = ''
        window.scrollTo({left: previousScrollOffset[0], top: previousScrollOffset[1], behavior: 'instant'});
    };

    closeBtn.addEventListener('click', closeModal);
    modal.addEventListener('click', (e) => {
        if (e.target === modal) closeModal();
    });
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeModal();
        }
    });

    const allButtons = [];

    document.querySelectorAll('.mermaid').forEach((mermaidDiv) => {
        if (mermaidDiv.parentNode.classList.contains('mermaid-container') ||
            mermaidDiv.closest('.mermaid-fullscreen-modal')) {
            return;
        }

        const container = document.createElement('div');
        container.className = 'mermaid-container';
        mermaidDiv.parentNode.insertBefore(container, mermaidDiv);
        container.appendChild(mermaidDiv);

        const fullscreenBtn = document.createElement('button');
        fullscreenBtn.className = 'mermaid-fullscreen-btn' + (darkTheme ? ' dark-theme' : '');
        fullscreenBtn.setAttribute('aria-label', 'View diagram in fullscreen');
        fullscreenBtn.textContent = '‚õ∂';
        fullscreenBtn.style.opacity = '50%';

        // Calculate dynamic position based on diagram's margin and padding
        const diagramStyle = window.getComputedStyle(mermaidDiv);
        const marginTop = parseFloat(diagramStyle.marginTop) || 0;
        const marginRight = parseFloat(diagramStyle.marginRight) || 0;
        const paddingTop = parseFloat(diagramStyle.paddingTop) || 0;
        const paddingRight = parseFloat(diagramStyle.paddingRight) || 0;
        fullscreenBtn.style.top = `${marginTop + paddingTop + 4}px`;
        fullscreenBtn.style.right = `${marginRight + paddingRight + 4}px`;

        fullscreenBtn.addEventListener('click', () => {
            previousScrollOffset = [window.scroll, window.scrollY];
            const clone = mermaidDiv.cloneNode(true);
            modalContent.innerHTML = '';
            modalContent.appendChild(clone);

            const svg = clone.querySelector('svg');
            if (svg) {
                svg.removeAttribute('width');
                svg.removeAttribute('height');
                svg.style.width = '100%';
                svg.style.height = 'auto';
                svg.style.maxWidth = '100%';
                svg.style.sdisplay = 'block';

                if ("False" === "True") {
                    setTimeout(() => {
                        const g = svg.querySelector('g');
                        if (g) {
                            var svgD3 = d3.select(svg);
                            svgD3.html("<g class='wrapper'>" + svgD3.html() + "</g>");
                            var inner = svgD3.select("g");
                            var zoom = d3.zoom().on("zoom", function(event) {
                                inner.attr("transform", event.transform);
                            });
                            svgD3.call(zoom);
                        }
                    }, 100);
                }
            }

            modal.classList.add('active');
            document.body.style.overflow = 'hidden';
        });

        container.appendChild(fullscreenBtn);
        allButtons.push(fullscreenBtn);
    });

    // Update theme classes when theme changes
    const updateTheme = () => {
        const dark = isDarkTheme();
        allButtons.forEach(btn => {
            if (dark) {
                btn.classList.add('dark-theme');
            } else {
                btn.classList.remove('dark-theme');
            }
        });
        if (dark) {
            modal.classList.add('dark-theme');
            modalContent.classList.add('dark-theme');
            closeBtn.classList.add('dark-theme');
        } else {
            modal.classList.remove('dark-theme');
            modalContent.classList.remove('dark-theme');
            closeBtn.classList.remove('dark-theme');
        }
    };

    // Watch for theme changes
    const observer = new MutationObserver(updateTheme);
    observer.observe(document.documentElement, {
        attributes: true,
        attributeFilter: ['class', 'style', 'data-theme']
    });
    observer.observe(document.body, {
        attributes: true,
        attributeFilter: ['class', 'style']
    });
};

window.addEventListener("load", load);
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/09_convolutions_ABOUT';</script>
    <script src="../_static/ml-timeline.js?v=50797cee"></script>
    <script src="../_static/wip-banner.js?v=90b45b94"></script>
    <script src="../_static/marimo-badges.js?v=dca17944"></script>
    <script src="../_static/sidebar-link.js?v=404b701b"></script>
    <script src="../_static/hero-carousel.js?v=fa18433d"></script>
    <script src="../_static/subscribe-modal.js?v=173232fd"></script>
    <link rel="icon" href="../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Module 10: Tokenization" href="10_tokenization_ABOUT.html" />
    <link rel="prev" title="Module 08: DataLoader" href="08_dataloader_ABOUT.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo-tinytorch.png" class="logo__image only-light" alt="Tinyüî•Torch - Home"/>
    <script>document.write(`<img src="../_static/logo-tinytorch.png" class="logo__image only-dark" alt="Tinyüî•Torch - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="_static/downloads/TinyTorch-Guide.pdf" title="PDF Guide" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-file-pdf fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PDF Guide</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="_static/downloads/TinyTorch-Paper.pdf" title="Paper" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-scroll fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Paper</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mlsysbook.ai" title="MLSysBook" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-book fa-lg" aria-hidden="true"></i>
            <span class="sr-only">MLSysBook</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/harvard-edge/cs249r_book" title="Star" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Star</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/EZyaFgpB4F" title="Community" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Community</span></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">üöÄ Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../preface.html">Welcome</a></li>
<li class="toctree-l1"><a class="reference internal" href="../big-picture.html">Big Picture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Quick Start</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üèó Foundation Tier (01-07)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/foundation.html">üìñ Tier Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_tensor_ABOUT.html">01. Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_activations_ABOUT.html">02. Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_layers_ABOUT.html">03. Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_losses_ABOUT.html">04. Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_autograd_ABOUT.html">05. Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_optimizers_ABOUT.html">06. Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_training_ABOUT.html">07. Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üèõÔ∏è Architecture Tier (08-13)</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/architecture.html">üìñ Tier Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_dataloader_ABOUT.html">08. DataLoader</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">09. Convolutions</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_tokenization_ABOUT.html">10. Tokenization</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_embeddings_ABOUT.html">11. Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_attention_ABOUT.html">12. Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_transformers_ABOUT.html">13. Transformers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">‚è±Ô∏è Optimization Tier (14-19)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/optimization.html">üìñ Tier Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_profiling_ABOUT.html">14. Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_quantization_ABOUT.html">15. Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_compression_ABOUT.html">16. Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_memoization_ABOUT.html">17. Memoization</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_acceleration_ABOUT.html">18. Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="19_benchmarking_ABOUT.html">19. Benchmarking</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üèÖ Capstone Competition</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tiers/olympics.html">üìñ Competition Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="20_capstone_ABOUT.html">20. Torch Olympics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üõ†Ô∏è TITO CLI Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tito/overview.html">Command Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/modules.html">Module Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/milestones.html">Milestone System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/data.html">Progress &amp; Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tito/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Datasets Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ü§ù Community</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../community.html">Ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Learning Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../credits.html">Credits &amp; Acknowledgments</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/modules/09_convolutions_ABOUT.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Module 09: Spatial</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youll-build">What You‚Äôll Build</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youre-not-building-yet">What You‚Äôre NOT Building (Yet)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#api-reference">API Reference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conv2d-constructor">Conv2d Constructor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maxpool2d-constructor">MaxPool2d Constructor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#avgpool2d-constructor">AvgPool2d Constructor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-methods">Core Methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output-shape-calculation">Output Shape Calculation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-concepts">Core Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution-operation">Convolution Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stride-and-padding">Stride and Padding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#receptive-fields">Receptive Fields</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling-operations">Pooling Operations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Output Shape Calculation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-complexity">Computational Complexity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-errors">Common Errors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-mismatch-in-conv2d">Shape Mismatch in Conv2d</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dimension-calculation-errors">Dimension Calculation Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-value-confusion">Padding Value Confusion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stride-kernel-mismatch-in-pooling">Stride/Kernel Mismatch in Pooling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-overflow">Memory Overflow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#production-context">Production Context</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#your-implementation-vs-pytorch">Your Implementation vs. PyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-comparison">Code Comparison</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-spatial-operations-matter-at-scale">Why Spatial Operations Matter at Scale</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-your-understanding">Check Your Understanding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">Further Reading</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-papers">Seminal Papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What‚Äôs Next</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-started">Get Started</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-09-spatial">
<h1>Module 09: Spatial<a class="headerlink" href="#module-09-spatial" title="Link to this heading">#</a></h1>
<div class="note admonition">
<p class="admonition-title">Module Info</p>
<p><strong>ARCHITECTURE TIER</strong> | Difficulty: ‚óè‚óè‚óè‚óã | Time: 6-8 hours | Prerequisites: 01-08</p>
<p><strong>Prerequisites: Modules 01-08</strong> assumes you have:</p>
<ul class="simple">
<li><p>Built the complete training pipeline (Modules 01-07)</p></li>
<li><p>Implemented DataLoader for batch processing (Module 08)</p></li>
<li><p>Understanding of parameter initialization, forward/backward passes, and optimization</p></li>
</ul>
<p>If you can train an MLP on MNIST using your training loop and DataLoader, you‚Äôre ready.</p>
</div>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>Spatial operations transform machine learning from working with flattened vectors to understanding images and spatial patterns. When you look at a photo, your brain naturally processes spatial relationships: edges connect to form textures, textures form objects. Convolution gives neural networks this same capability by detecting local patterns through sliding filters across images.</p>
<p>This module implements Conv2d, MaxPool2d, and AvgPool2d with explicit loops to reveal the true computational cost of spatial processing. You‚Äôll see why a single forward pass through a convolutional layer can require billions of operations, and why efficient implementations are critical for computer vision.</p>
<p>By the end, your spatial operations will enable convolutional neural networks (CNNs) that can classify images, detect objects, and extract hierarchical visual features.</p>
</section>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>By completing this module, you will:</p>
<ul class="simple">
<li><p><strong>Implement</strong> Conv2d with explicit 7-nested loops revealing O(B√óC√óH√óW√óK¬≤√óC_in) computational complexity</p></li>
<li><p><strong>Master</strong> spatial dimension calculations with stride, padding, and kernel size interactions</p></li>
<li><p><strong>Understand</strong> receptive fields, parameter sharing, and translation equivariance in CNNs</p></li>
<li><p><strong>Analyze</strong> memory vs computation trade-offs: pooling reduces spatial dimensions 4x while preserving features</p></li>
<li><p><strong>Connect</strong> your implementations to production CNN architectures like ResNet and VGG</p></li>
</ul>
</div>
</section>
<section id="what-youll-build">
<h2>What You‚Äôll Build<a class="headerlink" href="#what-youll-build" title="Link to this heading">#</a></h2>
<figure class="align-center" id="id2">
<pre  class="mermaid">
        flowchart LR
    subgraph &quot;Your Spatial Operations&quot;
        A[&quot;Conv2d&lt;br/&gt;Spatial feature extraction&quot;]
        B[&quot;MaxPool2d&lt;br/&gt;Strong feature selection&quot;]
        C[&quot;AvgPool2d&lt;br/&gt;Smooth feature averaging&quot;]
    end

    D[&quot;Input Image&lt;br/&gt;(B, C_in, H, W)&quot;]
    E[&quot;Feature Maps&lt;br/&gt;(B, C_out, H', W')&quot;]
    F[&quot;Pooled Features&lt;br/&gt;(B, C, H/2, W/2)&quot;]

    D --&gt; A --&gt; E
    E --&gt; B --&gt; F
    E --&gt; C --&gt; F

    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#f8d7da
    </pre><figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Your Spatial Operations</span><a class="headerlink" href="#id2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Implementation roadmap:</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Part</p></th>
<th class="head"><p>What You‚Äôll Implement</p></th>
<th class="head"><p>Key Concept</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Conv2d.__init__()</span></code></p></td>
<td><p>He initialization for ReLU networks</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Conv2d.forward()</span></code></p></td>
<td><p>7-nested loops for spatial convolution</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MaxPool2d.forward()</span></code></p></td>
<td><p>Maximum selection in sliding windows</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">AvgPool2d.forward()</span></code></p></td>
<td><p>Average pooling for smooth features</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>The pattern you‚Äôll enable:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Building a CNN block</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pool</span> <span class="o">=</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">image_batch</span><span class="p">)</span>  <span class="c1"># (32, 3, 224, 224)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># (32, 64, 112, 112)</span>
</pre></div>
</div>
<section id="what-youre-not-building-yet">
<h3>What You‚Äôre NOT Building (Yet)<a class="headerlink" href="#what-youre-not-building-yet" title="Link to this heading">#</a></h3>
<p>To keep this module focused, you will <strong>not</strong> implement:</p>
<ul class="simple">
<li><p>Dilated convolutions (PyTorch supports this with <code class="docutils literal notranslate"><span class="pre">dilation</span></code> parameter)</p></li>
<li><p>Grouped convolutions (that‚Äôs for efficient architectures like MobileNet)</p></li>
<li><p>Depthwise separable convolutions (advanced optimization technique)</p></li>
<li><p>Transposed convolutions for upsampling (used in GANs and segmentation)</p></li>
<li><p>Optimized implementations (cuDNN uses Winograd algorithm and FFT convolution)</p></li>
</ul>
<p><strong>You are building the foundational spatial operations.</strong> Advanced convolution variants and GPU optimizations come later.</p>
</section>
</section>
<section id="api-reference">
<h2>API Reference<a class="headerlink" href="#api-reference" title="Link to this heading">#</a></h2>
<p>This section provides a quick reference for the spatial operations you‚Äôll build. Use it as your guide while implementing and debugging convolution and pooling layers.</p>
<section id="conv2d-constructor">
<h3>Conv2d Constructor<a class="headerlink" href="#conv2d-constructor" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Creates a 2D convolutional layer with learnable filters.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">in_channels</span></code>: Number of input channels (e.g., 3 for RGB)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">out_channels</span></code>: Number of output feature maps</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>: Size of convolution kernel (int or tuple)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stride</span></code>: Stride of convolution (default: 1)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code>: Zero-padding added to input (default: 0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>: Whether to add learnable bias (default: True)</p></li>
</ul>
<p><strong>Weight shape:</strong> <code class="docutils literal notranslate"><span class="pre">(out_channels,</span> <span class="pre">in_channels,</span> <span class="pre">kernel_h,</span> <span class="pre">kernel_w)</span></code></p>
</section>
<section id="maxpool2d-constructor">
<h3>MaxPool2d Constructor<a class="headerlink" href="#maxpool2d-constructor" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Creates a max pooling layer for spatial dimension reduction.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>: Size of pooling window (int or tuple)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stride</span></code>: Stride of pooling (default: same as kernel_size)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code>: Zero-padding added to input (default: 0)</p></li>
</ul>
</section>
<section id="avgpool2d-constructor">
<h3>AvgPool2d Constructor<a class="headerlink" href="#avgpool2d-constructor" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Creates an average pooling layer for smooth spatial reduction.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>: Size of pooling window (int or tuple)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stride</span></code>: Stride of pooling (default: same as kernel_size)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code>: Zero-padding added to input (default: 0)</p></li>
</ul>
</section>
<section id="core-methods">
<h3>Core Methods<a class="headerlink" href="#core-methods" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Signature</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">forward</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">forward(x:</span> <span class="pre">Tensor)</span> <span class="pre">-&gt;</span> <span class="pre">Tensor</span></code></p></td>
<td><p>Apply spatial operation to input</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">parameters</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">parameters()</span> <span class="pre">-&gt;</span> <span class="pre">list</span></code></p></td>
<td><p>Return trainable parameters (Conv2d only)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">__call__</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">__call__(x:</span> <span class="pre">Tensor)</span> <span class="pre">-&gt;</span> <span class="pre">Tensor</span></code></p></td>
<td><p>Enable <code class="docutils literal notranslate"><span class="pre">layer(x)</span></code> syntax</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="output-shape-calculation">
<h3>Output Shape Calculation<a class="headerlink" href="#output-shape-calculation" title="Link to this heading">#</a></h3>
<p>For both convolution and pooling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>output_height = (input_height + 2√ópadding - kernel_height) √∑ stride + 1
output_width = (input_width + 2√ópadding - kernel_width) √∑ stride + 1
</pre></div>
</div>
</section>
</section>
<section id="core-concepts">
<h2>Core Concepts<a class="headerlink" href="#core-concepts" title="Link to this heading">#</a></h2>
<p>This section covers the fundamental ideas you need to understand spatial operations deeply. These concepts apply to every computer vision system, from simple image classifiers to advanced object detectors.</p>
<section id="convolution-operation">
<h3>Convolution Operation<a class="headerlink" href="#convolution-operation" title="Link to this heading">#</a></h3>
<p>Convolution detects local patterns by sliding a small filter (kernel) across the entire input, computing weighted sums at each position. Think of it as using a template to find matching patterns everywhere in an image.</p>
<p>Here‚Äôs how your implementation performs this operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># Calculate output dimensions</span>
    <span class="n">out_height</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_height</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">-</span> <span class="n">kernel_h</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">out_width</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_width</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">-</span> <span class="n">kernel_w</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># Initialize output</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">out_height</span><span class="p">,</span> <span class="n">out_width</span><span class="p">))</span>

    <span class="c1"># Explicit 7-nested loop convolution</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">out_ch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_channels</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">out_h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_height</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">out_w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_width</span><span class="p">):</span>
                    <span class="n">in_h_start</span> <span class="o">=</span> <span class="n">out_h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>
                    <span class="n">in_w_start</span> <span class="o">=</span> <span class="n">out_w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>

                    <span class="n">conv_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">k_h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">kernel_h</span><span class="p">):</span>
                        <span class="k">for</span> <span class="n">k_w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">kernel_w</span><span class="p">):</span>
                            <span class="k">for</span> <span class="n">in_ch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">in_channels</span><span class="p">):</span>
                                <span class="n">input_val</span> <span class="o">=</span> <span class="n">padded_input</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">,</span>
                                                       <span class="n">in_h_start</span> <span class="o">+</span> <span class="n">k_h</span><span class="p">,</span>
                                                       <span class="n">in_w_start</span> <span class="o">+</span> <span class="n">k_w</span><span class="p">]</span>
                                <span class="n">weight_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">k_h</span><span class="p">,</span> <span class="n">k_w</span><span class="p">]</span>
                                <span class="n">conv_sum</span> <span class="o">+=</span> <span class="n">input_val</span> <span class="o">*</span> <span class="n">weight_val</span>

                    <span class="n">output</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_sum</span>
</pre></div>
</div>
<p>The seven nested loops reveal where the computational cost comes from. For a typical CNN layer processing a batch of 32 RGB images (224√ó224) with 64 output channels and 3√ó3 kernels, this structure executes <strong>2.8 billion multiply-accumulate operations</strong> per forward pass. This is why optimized implementations matter.</p>
<p>Each output pixel summarizes information from a local neighborhood in the input. A 3√ó3 convolution looks at 9 pixels to produce each output value, enabling the network to detect local patterns like edges, corners, and textures.</p>
</section>
<section id="stride-and-padding">
<h3>Stride and Padding<a class="headerlink" href="#stride-and-padding" title="Link to this heading">#</a></h3>
<p>Stride controls how far the kernel moves between positions, and padding adds zeros around the input border. Together, they determine the output spatial dimensions and receptive field coverage.</p>
<p><strong>Stride = 1</strong> means the kernel moves one pixel at a time, producing an output nearly as large as the input. <strong>Stride = 2</strong> means the kernel jumps two pixels, halving the spatial dimensions and dramatically reducing computation. A stride-2 convolution processes 4√ó fewer positions than stride-1.</p>
<p><strong>Padding</strong> solves the border problem. Without padding, a 3√ó3 convolution on a 224√ó224 image produces a 222√ó222 output, shrinking the representation. With <code class="docutils literal notranslate"><span class="pre">padding=1</span></code>, you add a 1-pixel border of zeros, keeping the output at 224√ó224. This preserves spatial dimensions and ensures edge pixels get processed as many times as center pixels.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>No Padding (shrinks):           Padding=1 (preserves):
Input: 5√ó5                      Input: 5√ó5 ‚Üí Padded: 7√ó7
Kernel: 3√ó3                     Kernel: 3√ó3
Output: 3√ó3                     Output: 5√ó5

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 2 3 4 5‚îÇ                   ‚îÇ0 0 0 0 0 0 0‚îÇ
‚îÇ 6 7 8 9 0‚îÇ    3√ó3 kernel     ‚îÇ0 1 2 3 4 5 0‚îÇ
‚îÇ 1 2 3 4 5‚îÇ    ‚Üí              ‚îÇ0 6 7 8 9 0 0‚îÇ
‚îÇ 6 7 8 9 0‚îÇ    3√ó3 output     ‚îÇ0 1 2 3 4 5 0‚îÇ
‚îÇ 1 2 3 4 5‚îÇ                   ‚îÇ0 6 7 8 9 0 0‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ0 1 2 3 4 5 0‚îÇ
                                ‚îÇ0 0 0 0 0 0 0‚îÇ
                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                5√ó5 output preserved
</pre></div>
</div>
<p>The formula connecting these parameters is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>output_size = (input_size + 2√ópadding - kernel_size) / stride + 1
</pre></div>
</div>
<p>For a 224√ó224 input with kernel=3, padding=1, stride=1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>output_size = (224 + 2√ó1 - 3) / 1 + 1 = 224
</pre></div>
</div>
<p>For the same input with stride=2:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>output_size = (224 + 2√ó1 - 3) / 2 + 1 = 112
</pre></div>
</div>
</section>
<section id="receptive-fields">
<h3>Receptive Fields<a class="headerlink" href="#receptive-fields" title="Link to this heading">#</a></h3>
<p>The receptive field is the region in the original input that influences a particular output neuron. In a single 3√ó3 convolution, each output pixel has a 3√ó3 receptive field. But in deep networks, receptive fields grow with each layer.</p>
<p>Consider two stacked 3√ó3 convolutions. The first layer produces features with 3√ó3 receptive fields. The second layer takes those features as input, so each output now depends on a 5√ó5 region of the original input. Stack five 3√ó3 convolutions and you get an 11√ó11 receptive field.</p>
<p>This hierarchical growth is why CNNs work. Early layers detect edges and textures (small receptive fields), middle layers detect parts like eyes and wheels (medium receptive fields), and deep layers detect whole objects like faces and cars (large receptive fields).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Receptive Field Growth:

Layer 1 (3√ó3 conv):    Layer 2 (3√ó3 conv):    Layer 3 (3√ó3 conv):
‚îå‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ‚ñì‚ñì‚ñì‚îÇ ‚Üí 3√ó3 RF        ‚îÇ‚ñì‚ñì‚ñì‚ñì‚ñì‚îÇ ‚Üí 5√ó5 RF       ‚îÇ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚îÇ ‚Üí 7√ó7 RF
‚îî‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Stacking N 3√ó3 convolutions:
Receptive Field = 1 + 2√óN

VGG-16 uses this principle: stack many small kernels instead of few large ones.
</pre></div>
</div>
<p>Parameter sharing means the same 3√ó3 kernel processes every position in the image. This drastically reduces parameters compared to fully connected layers while maintaining translation equivariance: if you shift the input, the output shifts identically.</p>
</section>
<section id="pooling-operations">
<h3>Pooling Operations<a class="headerlink" href="#pooling-operations" title="Link to this heading">#</a></h3>
<p>Pooling reduces spatial dimensions while preserving important features. Max pooling selects the strongest activation in each window, preserving sharp features like edges. Average pooling computes the mean, creating smoother, more general features.</p>
<p>Here‚Äôs how max pooling works in your implementation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># Calculate output dimensions</span>
    <span class="n">out_height</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_height</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">-</span> <span class="n">kernel_h</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">out_width</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_width</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">-</span> <span class="n">kernel_w</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">out_height</span><span class="p">,</span> <span class="n">out_width</span><span class="p">))</span>

    <span class="c1"># Explicit nested loop max pooling</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">channels</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">out_h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_height</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">out_w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_width</span><span class="p">):</span>
                    <span class="n">in_h_start</span> <span class="o">=</span> <span class="n">out_h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>
                    <span class="n">in_w_start</span> <span class="o">=</span> <span class="n">out_w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>

                    <span class="c1"># Find maximum in window</span>
                    <span class="n">max_val</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
                    <span class="k">for</span> <span class="n">k_h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">kernel_h</span><span class="p">):</span>
                        <span class="k">for</span> <span class="n">k_w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">kernel_w</span><span class="p">):</span>
                            <span class="n">input_val</span> <span class="o">=</span> <span class="n">padded_input</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span>
                                                   <span class="n">in_h_start</span> <span class="o">+</span> <span class="n">k_h</span><span class="p">,</span>
                                                   <span class="n">in_w_start</span> <span class="o">+</span> <span class="n">k_w</span><span class="p">]</span>
                            <span class="n">max_val</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_val</span><span class="p">,</span> <span class="n">input_val</span><span class="p">)</span>

                    <span class="n">output</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_val</span>
</pre></div>
</div>
<p>A 2√ó2 max pooling with stride=2 divides spatial dimensions by 2, reducing memory and computation by 4√ó. For a 224√ó224√ó64 feature map (12.8 MB), pooling produces 112√ó112√ó64 (3.2 MB), saving 9.6 MB.</p>
<p>Max pooling provides translation invariance: if a cat‚Äôs ear moves one pixel, the max in that region remains roughly the same, making the network robust to small shifts. This is crucial for object recognition where precise pixel alignment doesn‚Äôt matter.</p>
<p>Average pooling smooths features by averaging windows, useful for global feature summarization. Modern architectures often use global average pooling (averaging entire feature maps to single values) instead of fully connected layers, dramatically reducing parameters.</p>
</section>
<section id="id1">
<h3>Output Shape Calculation<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Understanding output shapes is critical for building CNNs. A shape mismatch crashes your network, while correct dimensions ensure features flow properly through layers.</p>
<p>The output shape formula applies to both convolution and pooling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>H_out = ‚åä(H_in + 2√ópadding - kernel_h) / stride‚åã + 1
W_out = ‚åä(W_in + 2√ópadding - kernel_w) / stride‚åã + 1
</pre></div>
</div>
<p>The floor operation (‚åä‚åã) ensures integer dimensions. If the calculation doesn‚Äôt divide evenly, the rightmost and bottommost regions get ignored.</p>
<p><strong>Example calculations:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input: (32, 3, 224, 224)  [batch=32, RGB channels, 224√ó224 image]

Conv2d(3, 64, kernel_size=3, padding=1, stride=1):
H_out = (224 + 2√ó1 - 3) / 1 + 1 = 224
W_out = (224 + 2√ó1 - 3) / 1 + 1 = 224
Output: (32, 64, 224, 224)

MaxPool2d(kernel_size=2, stride=2):
H_out = (224 + 0 - 2) / 2 + 1 = 112
W_out = (224 + 0 - 2) / 2 + 1 = 112
Output: (32, 64, 112, 112)

Conv2d(64, 128, kernel_size=3, padding=0, stride=2):
H_out = (112 + 0 - 3) / 2 + 1 = 55
W_out = (112 + 0 - 3) / 2 + 1 = 55
Output: (32, 128, 55, 55)
</pre></div>
</div>
<p><strong>Common patterns:</strong></p>
<ul class="simple">
<li><p><strong>Same convolution</strong> (padding=1, stride=1, kernel=3): Preserves spatial dimensions</p></li>
<li><p><strong>Stride-2 convolution</strong>: Halves dimensions, replaces pooling in some architectures (ResNet)</p></li>
<li><p><strong>2√ó2 pooling, stride=2</strong>: Classic dimension reduction, halves H and W</p></li>
</ul>
</section>
<section id="computational-complexity">
<h3>Computational Complexity<a class="headerlink" href="#computational-complexity" title="Link to this heading">#</a></h3>
<p>Convolution is expensive. The explicit loops reveal exactly why: you‚Äôre visiting every position in the output, and for each position, sliding over the entire kernel across all input channels.</p>
<p>For a single Conv2d forward pass:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Operations = B √ó C_out √ó H_out √ó W_out √ó C_in √ó K_h √ó K_w
</pre></div>
</div>
<p><strong>Example:</strong> Batch=32, Input=(3, 224, 224), Conv2d(3‚Üí64, kernel=3, padding=1, stride=1)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Operations = 32 √ó 64 √ó 224 √ó 224 √ó 3 √ó 3 √ó 3
          = 32 √ó 64 √ó 50,176 √ó 27
          = 2,764,800,000 multiply-accumulate operations
          ‚âà 2.8 billion operations per forward pass!
</pre></div>
</div>
<p>This is why kernel size matters enormously. A 7√ó7 kernel requires (7√ó7)/(3√ó3) = 5.4√ó more computation than 3√ó3. Modern architectures favor stacking multiple 3√ó3 convolutions instead of using large kernels.</p>
<p>Pooling operations are cheap by comparison: no learnable parameters, just comparison or addition operations. A 2√ó2 max pooling visits each output position once and compares 4 values, requiring only 4√ó comparisons per output.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Operation</p></th>
<th class="head"><p>Complexity</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Conv2d (K√óK)</p></td>
<td><p>O(B√óC_out√óH√óW√óC_in√óK¬≤)</p></td>
<td><p>Cubic in spatial dims, quadratic in kernel</p></td>
</tr>
<tr class="row-odd"><td><p>MaxPool2d (K√óK)</p></td>
<td><p>O(B√óC√óH√óW√óK¬≤)</p></td>
<td><p>No channel mixing, just spatial reduction</p></td>
</tr>
<tr class="row-even"><td><p>AvgPool2d (K√óK)</p></td>
<td><p>O(B√óC√óH√óW√óK¬≤)</p></td>
<td><p>Same as MaxPool but with addition</p></td>
</tr>
</tbody>
</table>
</div>
<p>Memory consumption follows the output shape. A (32, 64, 224, 224) float32 tensor requires:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>32 √ó 64 √ó 224 √ó 224 √ó 4 bytes = 411 MB
</pre></div>
</div>
<p>This is why batch size matters: doubling batch size doubles memory usage. GPUs have limited memory (typically 8-24 GB), constraining how large your batches and feature maps can be.</p>
</section>
</section>
<section id="common-errors">
<h2>Common Errors<a class="headerlink" href="#common-errors" title="Link to this heading">#</a></h2>
<p>These are the errors you‚Äôll encounter most often when working with spatial operations. Understanding why they happen will save you hours of debugging CNNs.</p>
<section id="shape-mismatch-in-conv2d">
<h3>Shape Mismatch in Conv2d<a class="headerlink" href="#shape-mismatch-in-conv2d" title="Link to this heading">#</a></h3>
<p><strong>Error</strong>: <code class="docutils literal notranslate"><span class="pre">ValueError:</span> <span class="pre">Expected</span> <span class="pre">4D</span> <span class="pre">input</span> <span class="pre">(batch,</span> <span class="pre">channels,</span> <span class="pre">height,</span> <span class="pre">width),</span> <span class="pre">got</span> <span class="pre">(3,</span> <span class="pre">224,</span> <span class="pre">224)</span></code></p>
<p>Conv2d requires 4D input: (batch, channels, height, width). If you forget the batch dimension, the layer interprets channels as batch, height as channels, causing chaos.</p>
<p><strong>Fix</strong>: Add batch dimension: <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">x.reshape(1,</span> <span class="pre">3,</span> <span class="pre">224,</span> <span class="pre">224)</span></code> or ensure your data pipeline always includes batch dimension.</p>
</section>
<section id="dimension-calculation-errors">
<h3>Dimension Calculation Errors<a class="headerlink" href="#dimension-calculation-errors" title="Link to this heading">#</a></h3>
<p><strong>Error</strong>: Output shape is 55 when you expected 56</p>
<p>The floor operation in output dimension calculation can surprise you. If <code class="docutils literal notranslate"><span class="pre">(input</span> <span class="pre">+</span> <span class="pre">2√ópadding</span> <span class="pre">-</span> <span class="pre">kernel)</span> <span class="pre">/</span> <span class="pre">stride</span></code> doesn‚Äôt divide evenly, the result gets floored.</p>
<p><strong>Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Input: 224√ó224, kernel=3, padding=0, stride=2</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span> <span class="o">+</span> <span class="mi">0</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">221</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">110</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">111</span>
</pre></div>
</div>
<p><strong>Fix</strong>: Use calculators or test with dummy data to verify dimensions before building full architecture.</p>
</section>
<section id="padding-value-confusion">
<h3>Padding Value Confusion<a class="headerlink" href="#padding-value-confusion" title="Link to this heading">#</a></h3>
<p><strong>Error</strong>: Max pooling produces zeros at borders when using <code class="docutils literal notranslate"><span class="pre">padding</span> <span class="pre">&gt;</span> <span class="pre">0</span></code></p>
<p>If you pad max pooling input with zeros (constant_values=0), and your feature map has negative values, the padded zeros will be selected as maximums at borders, creating artifacts.</p>
<p><strong>Fix</strong>: Pad max pooling with <code class="docutils literal notranslate"><span class="pre">-np.inf</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">padded_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="stride-kernel-mismatch-in-pooling">
<h3>Stride/Kernel Mismatch in Pooling<a class="headerlink" href="#stride-kernel-mismatch-in-pooling" title="Link to this heading">#</a></h3>
<p><strong>Error</strong>: Overlapping pooling windows when stride ‚â† kernel_size</p>
<p>By convention, pooling uses non-overlapping windows: <code class="docutils literal notranslate"><span class="pre">stride</span> <span class="pre">=</span> <span class="pre">kernel_size</span></code>. If you accidentally set stride=1 with kernel=2, windows overlap, creating redundant computation and unexpected behavior.</p>
<p><strong>Fix</strong>: Ensure <code class="docutils literal notranslate"><span class="pre">stride</span> <span class="pre">=</span> <span class="pre">kernel_size</span></code> for pooling, or set <code class="docutils literal notranslate"><span class="pre">stride=None</span></code> to use default (equals kernel_size).</p>
</section>
<section id="memory-overflow">
<h3>Memory Overflow<a class="headerlink" href="#memory-overflow" title="Link to this heading">#</a></h3>
<p><strong>Error</strong>: <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">CUDA</span> <span class="pre">out</span> <span class="pre">of</span> <span class="pre">memory</span></code> or system hangs</p>
<p>Large feature maps consume enormous memory. A batch of 64 images at 224√ó224√ó64 channels = 1.3 GB for a single layer‚Äôs output. Deep networks with many layers can exceed GPU memory.</p>
<p><strong>Fix</strong>: Reduce batch size, use smaller images, or add more pooling layers to reduce spatial dimensions faster.</p>
</section>
</section>
<section id="production-context">
<h2>Production Context<a class="headerlink" href="#production-context" title="Link to this heading">#</a></h2>
<section id="your-implementation-vs-pytorch">
<h3>Your Implementation vs. PyTorch<a class="headerlink" href="#your-implementation-vs-pytorch" title="Link to this heading">#</a></h3>
<p>Your TinyTorch spatial operations and PyTorch‚Äôs <code class="docutils literal notranslate"><span class="pre">torch.nn.Conv2d</span></code> share the same conceptual foundation: sliding kernels, stride, padding, output shape formulas. The differences lie in optimization and hardware support.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>Your Implementation</p></th>
<th class="head"><p>PyTorch</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Backend</strong></p></td>
<td><p>NumPy loops (Python)</p></td>
<td><p>cuDNN (CUDA C++)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Speed</strong></p></td>
<td><p>1x (baseline)</p></td>
<td><p>100-1000x faster on GPU</p></td>
</tr>
<tr class="row-even"><td><p><strong>Optimization</strong></p></td>
<td><p>Explicit loops</p></td>
<td><p>im2col + GEMM, Winograd, FFT</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Memory</strong></p></td>
<td><p>Straightforward allocation</p></td>
<td><p>Memory pooling, gradient checkpointing</p></td>
</tr>
<tr class="row-even"><td><p><strong>Features</strong></p></td>
<td><p>Basic conv + pool</p></td>
<td><p>Dilated, grouped, transposed, 3D convolutions</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="code-comparison">
<h3>Code Comparison<a class="headerlink" href="#code-comparison" title="Link to this heading">#</a></h3>
<p>The following comparison shows equivalent operations in TinyTorch and PyTorch. Notice how the API mirrors perfectly, making your knowledge transfer directly to production frameworks.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Your TinyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tinytorch.core.spatial</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2d</span><span class="p">,</span> <span class="n">MaxPool2d</span><span class="p">,</span> <span class="n">AvgPool2d</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tinytorch.core.activations</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReLU</span>

<span class="c1"># Build a CNN block</span>
<span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv2</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pool</span> <span class="o">=</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Or use AvgPool2d for smooth features</span>
<span class="n">relu</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()</span>

<span class="c1"># Forward pass</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">image_batch</span><span class="p">)</span>  <span class="c1"># (32, 3, 224, 224)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>       <span class="c1"># (32, 64, 224, 224)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>              <span class="c1"># (32, 64, 112, 112)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>       <span class="c1"># (32, 128, 112, 112)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>              <span class="c1"># (32, 128, 56, 56)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
‚ö° PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># Build a CNN block</span>
<span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

<span class="c1"># Forward pass (identical structure!)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image_batch</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs walk through each line to understand the comparison:</p>
<ul class="simple">
<li><p><strong>Lines 1-2 (Imports)</strong>: TinyTorch separates spatial operations and activations into different modules; PyTorch consolidates into <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>. Same concepts, different organization.</p></li>
<li><p><strong>Lines 4-7 (Layer creation)</strong>: Identical API. Both use <code class="docutils literal notranslate"><span class="pre">Conv2d(in,</span> <span class="pre">out,</span> <span class="pre">kernel_size,</span> <span class="pre">padding)</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPool2d(kernel_size,</span> <span class="pre">stride)</span></code>. The parameter names and semantics are identical.</p></li>
<li><p><strong>Line 10 (Input)</strong>: TinyTorch wraps in <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>; PyTorch uses <code class="docutils literal notranslate"><span class="pre">torch.tensor()</span></code> with explicit dtype. Same abstraction.</p></li>
<li><p><strong>Lines 11-14 (Forward pass)</strong>: Identical call patterns. ReLU activations, pooling for dimension reduction, growing channels (3‚Üí64‚Üí128). This is the standard CNN building block.</p></li>
<li><p><strong>Shapes</strong>: Every intermediate shape matches between frameworks because the formulas are identical.</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>What‚Äôs Identical</p>
<p>Convolution mathematics, stride and padding formulas, receptive field growth, and parameter sharing. The APIs are intentionally identical so your understanding transfers directly to production systems.</p>
</div>
</section>
<section id="why-spatial-operations-matter-at-scale">
<h3>Why Spatial Operations Matter at Scale<a class="headerlink" href="#why-spatial-operations-matter-at-scale" title="Link to this heading">#</a></h3>
<p>To appreciate why convolution optimization matters, consider the scale of production vision systems:</p>
<ul class="simple">
<li><p><strong>ResNet-50</strong>: 25 million parameters, <strong>4 billion operations</strong> per image, processes thousands of images per second in production</p></li>
<li><p><strong>YOLO object detection</strong>: Processes 30 FPS video at 1080p, requiring <strong>60 billion convolution operations per second</strong></p></li>
<li><p><strong>Self-driving cars</strong>: Run 10+ CNN models simultaneously on 6 cameras at 30 FPS, consuming <strong>300 billion operations per second</strong> with 50ms latency budget</p></li>
</ul>
<p>A single forward pass of your educational Conv2d might take 800ms on CPU. The equivalent PyTorch operation runs in 8ms on GPU using cuDNN optimizations like im2col matrix multiplication and Winograd transforms. This 100√ó speedup is the difference between research prototypes and production systems.</p>
<p>Modern frameworks achieve this through:</p>
<ul class="simple">
<li><p><strong>im2col + GEMM</strong>: Transforms convolution into matrix multiplication, leveraging highly optimized BLAS libraries</p></li>
<li><p><strong>Winograd algorithm</strong>: Reduces multiplication count for small kernels (3√ó3, 5√ó5) by 2.25√ó</p></li>
<li><p><strong>FFT convolution</strong>: For large kernels, Fourier transforms reduce complexity from O(n¬≤) to O(n log n)</p></li>
</ul>
</section>
</section>
<section id="check-your-understanding">
<h2>Check Your Understanding<a class="headerlink" href="#check-your-understanding" title="Link to this heading">#</a></h2>
<p>Test yourself with these systems thinking questions. They‚Äôre designed to build intuition for the spatial operations and performance characteristics you‚Äôll encounter in real CNN architectures.</p>
<p><strong>Q1: Output Shape Calculation</strong></p>
<p>Given input (32, 3, 128, 128), what‚Äôs the output shape after Conv2d(3, 64, kernel_size=5, padding=2, stride=2)?</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Calculate height and width:</p>
</div>
<p>H_out = (128 + 2√ó2 - 5) / 2 + 1 = (128 + 4 - 5) / 2 + 1 = 127 / 2 + 1 = 63 + 1 = 64
W_out = (128 + 2√ó2 - 5) / 2 + 1 = 64</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
Output shape: **(32, 64, 64, 64)**

Batch and channels change (3‚Üí64), spatial dimensions halve due to stride=2.
</pre></div>
</div>
<p><strong>Q2: Parameter Counting</strong></p>
<p>How many parameters in Conv2d(3, 64, kernel_size=3, bias=True)?</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Weight parameters: out_channels √ó in_channels √ó kernel_h √ó kernel_w</p>
</div>
<p>Weight: 64 √ó 3 √ó 3 √ó 3 = 1,728 parameters
Bias: 64 parameters
Total: 1,792 parameters</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
Compare this to a fully connected layer for 224√ó224 RGB images:
</pre></div>
</div>
<p>Dense(224√ó224√ó3, 64) = 150,528 √ó 64 = 9,633,792 parameters!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
Convolution achieves **5,373√ó fewer parameters** through parameter sharing!
</pre></div>
</div>
<p><strong>Q3: Computational Complexity</strong></p>
<p>For input (16, 64, 56, 56) and Conv2d(64, 128, kernel_size=3, padding=1, stride=1), how many multiply-accumulate operations?</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Operations = B √ó C_out √ó H_out √ó W_out √ó C_in √ó K_h √ó K_w</p>
<p>First calculate output dimensions:</p>
</div>
<p>H_out = (56 + 2√ó1 - 3) / 1 + 1 = 56
W_out = (56 + 2√ó1 - 3) / 1 + 1 = 56</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">Then</span> <span class="n">total</span> <span class="n">operations</span><span class="p">:</span>
</pre></div>
</div>
<p>16 √ó 128 √ó 56 √ó 56 √ó 64 √ó 3 √ó 3
= 16 √ó 128 √ó 3,136 √ó 576
= 3,707,764,736 operations
‚âà 3.7 billion operations per forward pass!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">This</span> <span class="ow">is</span> <span class="n">why</span> <span class="n">batch</span> <span class="n">size</span> <span class="n">directly</span> <span class="n">impacts</span> <span class="n">training</span> <span class="n">time</span><span class="p">:</span> <span class="n">doubling</span> <span class="n">batch</span> <span class="n">doubles</span> <span class="n">operations</span><span class="o">.</span>
</pre></div>
</div>
<p><strong>Q4: Memory Calculation</strong></p>
<p>What‚Äôs the memory requirement for storing the output of Conv2d(3, 256, kernel_size=7, stride=2, padding=3) on input (64, 3, 224, 224)?</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>First calculate output dimensions:</p>
</div>
<p>H_out = (224 + 2√ó3 - 7) / 2 + 1 = (224 + 6 - 7) / 2 + 1 = 223 / 2 + 1 = 111 + 1 = 112
W_out = 112</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">Output</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">)</span>

<span class="n">Memory</span> <span class="p">(</span><span class="n">float32</span> <span class="o">=</span> <span class="mi">4</span> <span class="nb">bytes</span><span class="p">):</span>
</pre></div>
</div>
<p>64 √ó 256 √ó 112 √ó 112 √ó 4 = 825,753,600 bytes
‚âà 826 MB for a single layer‚Äôs output!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">This</span> <span class="ow">is</span> <span class="n">why</span> <span class="n">deep</span> <span class="n">CNNs</span> <span class="n">require</span> <span class="n">GPUs</span> <span class="k">with</span> <span class="n">large</span> <span class="n">memory</span> <span class="p">(</span><span class="mi">16</span><span class="o">+</span> <span class="n">GB</span><span class="p">)</span><span class="o">.</span> <span class="n">Storing</span> <span class="n">activations</span> <span class="k">for</span> <span class="n">backpropagation</span> <span class="n">across</span> <span class="mi">50</span><span class="o">+</span> <span class="n">layers</span> <span class="n">quickly</span> <span class="n">exceeds</span> <span class="n">memory</span> <span class="n">limits</span><span class="o">.</span>
</pre></div>
</div>
<p><strong>Q5: Receptive Field Growth</strong></p>
<p>Starting with 224√ó224 input, you stack: Conv(3√ó3, stride=1) ‚Üí MaxPool(2√ó2, stride=2) ‚Üí Conv(3√ó3, stride=1) ‚Üí Conv(3√ó3, stride=1). What‚Äôs the receptive field of the final layer?</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Track receptive field growth through each layer:</p>
<p>Layer 1 - Conv(3√ó3, stride=1): RF = 3
Layer 2 - MaxPool(2√ó2, stride=2): RF = 3 + (2-1)√ó1 = 4
Layer 3 - Conv(3√ó3, stride=1): RF = 4 + (3-1)√ó2 = 8  (stride accumulates)
Layer 4 - Conv(3√ó3, stride=1): RF = 8 + (3-1)√ó2 = 12</p>
<p><strong>Receptive field = 12√ó12</strong></p>
<p>Each neuron in the final layer sees a 12√ó12 region of the original input. This is why stacking layers with stride/pooling is crucial: it grows the receptive field so deeper layers can detect larger patterns.</p>
<p>Formula: RF_new = RF_old + (kernel_size - 1) √ó stride_product</p>
<p>where stride_product is the accumulated stride from all previous layers.</p>
</div>
</section>
<section id="further-reading">
<h2>Further Reading<a class="headerlink" href="#further-reading" title="Link to this heading">#</a></h2>
<p>For students who want to understand the academic foundations and explore spatial operations further:</p>
<section id="seminal-papers">
<h3>Seminal Papers<a class="headerlink" href="#seminal-papers" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Gradient-Based Learning Applied to Document Recognition</strong> - LeCun et al. (1998). The paper that launched convolutional neural networks, introducing LeNet-5 for handwritten digit recognition. Essential reading for understanding why convolution works for vision. <a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">IEEE</a></p></li>
<li><p><strong>ImageNet Classification with Deep Convolutional Neural Networks</strong> - Krizhevsky et al. (2012). AlexNet, the breakthrough that demonstrated CNNs could win ImageNet. Introduced ReLU, dropout, and data augmentation patterns still used today. <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">NeurIPS</a></p></li>
<li><p><strong>Very Deep Convolutional Networks for Large-Scale Image Recognition</strong> - Simonyan &amp; Zisserman (2014). VGG networks showed that stacking many 3√ó3 convolutions works better than few large kernels. This principle guides modern architecture design. <a class="reference external" href="https://arxiv.org/abs/1409.1556">arXiv:1409.1556</a></p></li>
<li><p><strong>Deep Residual Learning for Image Recognition</strong> - He et al. (2015). ResNet introduced skip connections that enable training 100+ layer networks. Revolutionized computer vision and won ImageNet 2015. <a class="reference external" href="https://arxiv.org/abs/1512.03385">arXiv:1512.03385</a></p></li>
</ul>
</section>
<section id="additional-resources">
<h3>Additional Resources<a class="headerlink" href="#additional-resources" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>CS231n: Convolutional Neural Networks for Visual Recognition</strong> - Stanford course notes with excellent visualizations of convolution, receptive fields, and feature maps: <a class="reference external" href="https://cs231n.github.io/convolutional-networks/">https://cs231n.github.io/convolutional-networks/</a></p></li>
<li><p><strong>Textbook</strong>: ‚ÄúDeep Learning‚Äù by Goodfellow, Bengio, and Courville - Chapter 9 covers convolutional networks with mathematical depth</p></li>
<li><p><strong>Distill.pub</strong>: ‚ÄúFeature Visualization‚Äù - Interactive article showing what CNN filters learn at different depths: <a class="reference external" href="https://distill.pub/2017/feature-visualization/">https://distill.pub/2017/feature-visualization/</a></p></li>
</ul>
</section>
</section>
<section id="whats-next">
<h2>What‚Äôs Next<a class="headerlink" href="#whats-next" title="Link to this heading">#</a></h2>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Coming Up: Module 10 - Tokenization</p>
<p>Shift from spatial processing (images) to sequential processing (text). You‚Äôll implement tokenizers that convert text into numeric representations, unlocking natural language processing and transformers.</p>
</div>
<p><strong>Preview - How Your Spatial Operations Enable Future Work:</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Module</p></th>
<th class="head"><p>What It Does</p></th>
<th class="head"><p>Your Spatial Ops In Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Milestone 3: CNN</strong></p></td>
<td><p>Complete CNN for CIFAR-10</p></td>
<td><p>Stack your Conv2d and MaxPool2d for image classification</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Module 18: Acceleration</strong></p></td>
<td><p>Optimize convolution</p></td>
<td><p>Replace loops with im2col and vectorized operations</p></td>
</tr>
<tr class="row-even"><td><p><strong>Vision Projects</strong></p></td>
<td><p>Object detection, segmentation</p></td>
<td><p>Your spatial foundations scale to advanced architectures</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="get-started">
<h2>Get Started<a class="headerlink" href="#get-started" title="Link to this heading">#</a></h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Interactive Options</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://mybinder.org/v2/gh/harvard-edge/cs249r_book/main?filepath=tinytorch/src/09_convolutions/09_convolutions.py">Launch Binder</a></strong> - Run interactively in browser, no setup required</p></li>
<li><p><strong><a class="reference external" href="https://colab.research.google.com/github/harvard-edge/cs249r_book/blob/main/tinytorch/src/09_convolutions/09_convolutions.py">Open in Colab</a></strong> - Use Google Colab for cloud compute</p></li>
<li><p><strong><a class="reference external" href="https://github.com/harvard-edge/cs249r_book/blob/main/src/09_convolutions/09_convolutions.py">View Source</a></strong> - Browse the implementation code</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Save Your Progress</p>
<p>Binder and Colab sessions are temporary. Download your completed notebook when done, or clone the repository for persistent local work.</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./modules"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="08_dataloader_ABOUT.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Module 08: DataLoader</p>
      </div>
    </a>
    <a class="right-next"
       href="10_tokenization_ABOUT.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Module 10: Tokenization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youll-build">What You‚Äôll Build</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-youre-not-building-yet">What You‚Äôre NOT Building (Yet)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#api-reference">API Reference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conv2d-constructor">Conv2d Constructor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maxpool2d-constructor">MaxPool2d Constructor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#avgpool2d-constructor">AvgPool2d Constructor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-methods">Core Methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output-shape-calculation">Output Shape Calculation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-concepts">Core Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution-operation">Convolution Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stride-and-padding">Stride and Padding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#receptive-fields">Receptive Fields</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling-operations">Pooling Operations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Output Shape Calculation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-complexity">Computational Complexity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-errors">Common Errors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-mismatch-in-conv2d">Shape Mismatch in Conv2d</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dimension-calculation-errors">Dimension Calculation Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-value-confusion">Padding Value Confusion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stride-kernel-mismatch-in-pooling">Stride/Kernel Mismatch in Pooling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-overflow">Memory Overflow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#production-context">Production Context</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#your-implementation-vs-pytorch">Your Implementation vs. PyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-comparison">Code Comparison</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-spatial-operations-matter-at-scale">Why Spatial Operations Matter at Scale</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-your-understanding">Check Your Understanding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">Further Reading</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seminal-papers">Seminal Papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What‚Äôs Next</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-started">Get Started</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Prof. Vijay Janapa Reddi (Harvard University)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025 Harvard University.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>